{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db252ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 16:57:30.656471: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-24 16:57:30.773666: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from random import shuffle, choice\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import regularizers\n",
    "from random import shuffle, choice\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "batch_size = 250\n",
    "epochs = 100\n",
    "epochs_traits = 500\n",
    "num_classes = 3\n",
    "\n",
    "#From: https://towardsdatascience.com/neural-networks-ensemble-33f33bea7df3\n",
    "class LinearW(Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearW, self).__init__()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.W = self.add_weight(name='name',\n",
    "                    shape=(1,1,len(input_shape)),\n",
    "                    initializer='uniform',\n",
    "                    dtype=tf.float32,\n",
    "                    trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "\n",
    "        # inputs is a list of tensor of shape [(n_batch, n_feat), ..., (n_batch, n_feat)]\n",
    "        # expand last dim of each input passed [(n_batch, n_feat, 1), ..., (n_batch, n_feat, 1)]\n",
    "        inputs = [tf.expand_dims(i, -1) for i in inputs]\n",
    "        inputs = Concatenate(axis=-1)(inputs) # (n_batch, n_feat, n_inputs)\n",
    "        weights = tf.nn.softmax(self.W, axis=-1) # (1,1,n_inputs)\n",
    "        # weights sum up to one on last dim\n",
    "\n",
    "        return tf.reduce_sum(weights*inputs, axis=-1) # (n_batch, n_feat)\n",
    "\n",
    "def create_mlp(traitstrain, regularizer=None):\n",
    "  \"\"\"Creates a three-layer MLP with inputs of the given dimension\"\"\"\n",
    "  model = Sequential()\n",
    "  model.add(Dense(150, use_bias=False, input_dim=traitstrain.shape[1], activation=\"relu\", kernel_regularizer=regularizers.l1(0.001)))\n",
    "  model.add(BatchNormalization())\n",
    "  #model.add(Dropout(0.5))\n",
    "  model.add(Dense(150, use_bias=False, activation=\"relu\"))\n",
    "  model.add(BatchNormalization())\n",
    "  #model.add(Dropout(0.5))\n",
    "  model.add(Dense(50, activation=\"relu\"))\n",
    "  return model\n",
    "  \n",
    "def create_cnn(xtest, regularizer=None):\n",
    "  inputShape = (xtest.shape[1], xtest.shape[2])\n",
    "  inputs = Input(shape=inputShape)\n",
    "  x = inputs\n",
    "  x = Conv1D(250, kernel_size=3, activation='relu', use_bias=False, input_shape=(xtest.shape[1], xtest.shape[2]))(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Conv1D(250, kernel_size=3, use_bias=False, activation='relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Conv1D(250, kernel_size=3, use_bias=False, activation='relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = MaxPooling1D(pool_size=3)(x)\n",
    "  x = Flatten()(x)\n",
    "  x = Dense(125, activation='relu')(x)\n",
    "  x = Dropout(0.5)(x)\n",
    "  x = Dense(125, activation='relu')(x)\n",
    "  x = Dropout(0.5)(x)\n",
    "  # Apply another fully-connected layer, this one to match the number of nodes coming out of the MLP\n",
    "  x = Dense(50, kernel_regularizer=regularizer)(x)\n",
    "  x = Activation(\"relu\")(x)\n",
    "  # Construct the CNN\n",
    "  model = Model(inputs, x)\n",
    "  # Return the CNN\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af7e7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 20:12:09.374056: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-24 20:12:09.992051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22129 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:73:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#Load data\n",
    "################################################################################################################################################\n",
    "\n",
    "traits_BM = []\n",
    "traits_BM = np.loadtxt(\"./traits/traits_BM.txt\").reshape(30000,-1,28)\n",
    "\n",
    "scalers_BM = {}\n",
    "for i in range(traits_BM.shape[2]):\n",
    "    scalers_BM[i] = StandardScaler(copy=False)\n",
    "    traits_BM[:, :, i] = scalers_BM[i].fit_transform(traits_BM[:, :, i]) \n",
    "\n",
    "traits_BM = np.array(traits_BM)\n",
    "\n",
    "#Add missing individuals\n",
    "for i in range(traits_BM.shape[0]):\n",
    "  for j in range(0,4):\n",
    "    traits_BM[i,j,:] = 0\n",
    "  for j in range(77,81):\n",
    "    traits_BM[i,j,:] = 0\n",
    "  for j in range(134,136):\n",
    "    traits_BM[i,j,:] = 0\n",
    "\n",
    "d_traits = []\n",
    "d_traits = np.loadtxt(\"./traits/traits_disc.txt\").reshape(30000,-1,3)\n",
    "traits = np.concatenate((traits_BM,d_traits),axis=2)\n",
    "\n",
    "u1 = np.load(\"./trainingSims/Model_2sp.npz\")\n",
    "u2 = np.load(\"./trainingSims/Model_6sp.npz\")\n",
    "u3 = np.load(\"./trainingSims/Model_6spMig.npz\")\n",
    "\n",
    "x=np.concatenate((u1['Model_2sp'],u2['Model_6sp'],u3['Model_6spMig']),axis=0)\n",
    "\n",
    "#transform major alleles in -1 and minor 1\n",
    "for arr,array in enumerate(x):\n",
    "  for idx,row in enumerate(array):\n",
    "    if np.count_nonzero(row) > len(row)/2:\n",
    "      x[arr][idx][x[arr][idx] == 1] = -1\n",
    "      x[arr][idx][x[arr][idx] == 0] = 1\n",
    "    else:\n",
    "      x[arr][idx][x[arr][idx] == 0] = -1\n",
    "\n",
    "y=[0 for i in range(len(u1['Model_2sp']))]\n",
    "y.extend([1 for i in range(len(u2['Model_6sp']))])\n",
    "y.extend([2 for i in range(len(u3['Model_6spMig']))])\n",
    "y = np.array(y)\n",
    "\n",
    "print (len(x), len(y), len(traits))\n",
    "shf = list(range(len(x)))\n",
    "shuffle(shf)\n",
    "\n",
    "y = y[shf]\n",
    "x = x[shf]\n",
    "traits = traits[shf]\n",
    "\n",
    "\n",
    "#Add missing data as 0s, according to a specifies missing data percentage\n",
    "#54,477,268 SNP datapoints and 24,326,002 missing genotypes = 44.6%\n",
    "missD_perc = 44.6\n",
    "missD = int(x.shape[1]*x.shape[2]*(missD_perc/100))\n",
    "for i in range(x.shape[0]):\n",
    "  for m in range(missD):\n",
    "    j = random.randint(0, x.shape[1] - 1)\n",
    "    k = random.randint(0, x.shape[2] - 1)\n",
    "    x[i][j][k] = 0\n",
    "\n",
    "del(missD)\n",
    "\n",
    "xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n",
    "ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n",
    "traits_train, traits_test = traits[int(len(y)*.25):], traits[:int(len(y)*.25)]\n",
    "\n",
    "\n",
    "ytest = np_utils.to_categorical(ytest, num_classes)\n",
    "ytrain = np_utils.to_categorical(ytrain, num_classes)\n",
    "traits_train=traits_train.reshape((traits_train.shape[0], (traits_train.shape[1]*traits_train.shape[2])))\n",
    "traits_test=traits_test.reshape((traits_test.shape[0], (traits_test.shape[1]*traits_test.shape[2])))\n",
    "\n",
    "# Create the MLP and CNN models\n",
    "mlp = create_mlp(traits_train)\n",
    "cnn = create_cnn(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a417d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1000, 458)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 998, 250)     343500      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 998, 250)    1000        ['conv1d[0][0]']                 \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 996, 250)     187500      ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 996, 250)    1000        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 994, 250)     187500      ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 994, 250)    1000        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 331, 250)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 82750)        0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " dense_input (InputLayer)       [(None, 7099)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 125)          10343875    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 150)          1064850     ['dense_input[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 125)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 150)         600         ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 125)          15750       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 150)          22500       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 125)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 150)         600         ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 50)           6300        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 50)           7550        ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 50)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " linear_w (LinearW)             (None, 50)           2           ['dense_2[0][0]',                \n",
      "                                                                  'activation[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 50)           2550        ['linear_w[0][0]']               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 3)            153         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,186,230\n",
      "Trainable params: 12,184,130\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 14:07:12.149169: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-03-24 14:07:12.388667: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2023-03-24 14:07:14.112088: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-24 14:07:14.113883: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-24 14:07:14.113901: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-03-24 14:07:14.115818: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-24 14:07:14.123042: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 31s 261ms/step - loss: 16.4565 - accuracy: 0.3603 - val_loss: 16.3121 - val_accuracy: 0.3931\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 16s 174ms/step - loss: 16.2275 - accuracy: 0.4519 - val_loss: 16.1194 - val_accuracy: 0.5404\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 17s 190ms/step - loss: 15.9983 - accuracy: 0.5470 - val_loss: 15.8367 - val_accuracy: 0.6585\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 15.7828 - accuracy: 0.6038 - val_loss: 15.5951 - val_accuracy: 0.6929\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 16s 175ms/step - loss: 15.6031 - accuracy: 0.6386 - val_loss: 15.4226 - val_accuracy: 0.6956\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 18s 196ms/step - loss: 15.4579 - accuracy: 0.6545 - val_loss: 15.2857 - val_accuracy: 0.7085\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 15.3244 - accuracy: 0.6712 - val_loss: 15.1646 - val_accuracy: 0.7163\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 17s 187ms/step - loss: 15.2040 - accuracy: 0.6757 - val_loss: 15.0545 - val_accuracy: 0.7245\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 17s 185ms/step - loss: 15.0785 - accuracy: 0.6936 - val_loss: 14.9475 - val_accuracy: 0.7303\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 16s 175ms/step - loss: 14.9733 - accuracy: 0.6931 - val_loss: 14.8534 - val_accuracy: 0.7235\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 16s 177ms/step - loss: 14.8604 - accuracy: 0.7041 - val_loss: 14.7453 - val_accuracy: 0.7331\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 17s 191ms/step - loss: 14.7595 - accuracy: 0.7091 - val_loss: 14.6483 - val_accuracy: 0.7377\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 16s 178ms/step - loss: 14.6552 - accuracy: 0.7144 - val_loss: 14.5519 - val_accuracy: 0.7424\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 14.5508 - accuracy: 0.7224 - val_loss: 14.4535 - val_accuracy: 0.7492\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 14.4524 - accuracy: 0.7252 - val_loss: 14.3583 - val_accuracy: 0.7533\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 17s 194ms/step - loss: 14.3577 - accuracy: 0.7275 - val_loss: 14.2651 - val_accuracy: 0.7536\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 14.2555 - accuracy: 0.7349 - val_loss: 14.1660 - val_accuracy: 0.7621\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 14.1558 - accuracy: 0.7408 - val_loss: 14.0755 - val_accuracy: 0.7620\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 14.0638 - accuracy: 0.7413 - val_loss: 13.9825 - val_accuracy: 0.7677\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 17s 184ms/step - loss: 13.9645 - accuracy: 0.7511 - val_loss: 13.8873 - val_accuracy: 0.7735\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 17s 184ms/step - loss: 13.8696 - accuracy: 0.7508 - val_loss: 13.7918 - val_accuracy: 0.7772\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 13.7767 - accuracy: 0.7554 - val_loss: 13.7011 - val_accuracy: 0.7809\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 13.6808 - accuracy: 0.7632 - val_loss: 13.6063 - val_accuracy: 0.7859\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 13.5888 - accuracy: 0.7629 - val_loss: 13.5161 - val_accuracy: 0.7880\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 17s 190ms/step - loss: 13.4900 - accuracy: 0.7710 - val_loss: 13.4200 - val_accuracy: 0.7939\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 16s 176ms/step - loss: 13.4016 - accuracy: 0.7703 - val_loss: 13.3283 - val_accuracy: 0.7983\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 16s 174ms/step - loss: 13.3054 - accuracy: 0.7787 - val_loss: 13.2360 - val_accuracy: 0.8021\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 16s 174ms/step - loss: 13.2150 - accuracy: 0.7823 - val_loss: 13.1436 - val_accuracy: 0.8076\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 16s 173ms/step - loss: 13.1201 - accuracy: 0.7895 - val_loss: 13.0507 - val_accuracy: 0.8105\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 18s 196ms/step - loss: 13.0298 - accuracy: 0.7921 - val_loss: 12.9606 - val_accuracy: 0.8185\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 16s 174ms/step - loss: 12.9317 - accuracy: 0.7998 - val_loss: 12.8669 - val_accuracy: 0.8240\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 12.8436 - accuracy: 0.7993 - val_loss: 12.7775 - val_accuracy: 0.8272\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 12.7498 - accuracy: 0.8114 - val_loss: 12.6818 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 18s 198ms/step - loss: 12.6533 - accuracy: 0.8167 - val_loss: 12.5907 - val_accuracy: 0.8400\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 16s 183ms/step - loss: 12.5622 - accuracy: 0.8197 - val_loss: 12.4975 - val_accuracy: 0.8488\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 16s 179ms/step - loss: 12.4664 - accuracy: 0.8291 - val_loss: 12.4028 - val_accuracy: 0.8576\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 16s 173ms/step - loss: 12.3741 - accuracy: 0.8348 - val_loss: 12.3115 - val_accuracy: 0.8645\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 16s 174ms/step - loss: 12.2756 - accuracy: 0.8437 - val_loss: 12.2169 - val_accuracy: 0.8723\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 16s 173ms/step - loss: 12.1817 - accuracy: 0.8513 - val_loss: 12.1160 - val_accuracy: 0.8843\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 17s 189ms/step - loss: 12.0836 - accuracy: 0.8611 - val_loss: 12.0179 - val_accuracy: 0.8908\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 16s 182ms/step - loss: 11.9922 - accuracy: 0.8670 - val_loss: 11.9314 - val_accuracy: 0.8900\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 11.8933 - accuracy: 0.8728 - val_loss: 11.8354 - val_accuracy: 0.8931\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 11.7986 - accuracy: 0.8786 - val_loss: 11.7411 - val_accuracy: 0.8987\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 11.7061 - accuracy: 0.8849 - val_loss: 11.6579 - val_accuracy: 0.8928\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 11.6096 - accuracy: 0.8926 - val_loss: 11.5433 - val_accuracy: 0.9132\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 16s 178ms/step - loss: 11.5152 - accuracy: 0.9012 - val_loss: 11.4659 - val_accuracy: 0.9052\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 17s 186ms/step - loss: 11.4244 - accuracy: 0.9028 - val_loss: 11.3703 - val_accuracy: 0.9115\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 16s 174ms/step - loss: 11.3348 - accuracy: 0.9066 - val_loss: 11.2909 - val_accuracy: 0.9067\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 16s 173ms/step - loss: 11.2413 - accuracy: 0.9144 - val_loss: 11.1946 - val_accuracy: 0.9131\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 11.1468 - accuracy: 0.9208 - val_loss: 11.0944 - val_accuracy: 0.9260\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 16s 174ms/step - loss: 11.0622 - accuracy: 0.9217 - val_loss: 11.0213 - val_accuracy: 0.9169\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 17s 187ms/step - loss: 10.9720 - accuracy: 0.9256 - val_loss: 10.9387 - val_accuracy: 0.9177\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 10.8828 - accuracy: 0.9290 - val_loss: 10.8329 - val_accuracy: 0.9333\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 16s 173ms/step - loss: 10.8004 - accuracy: 0.9317 - val_loss: 10.7465 - val_accuracy: 0.9372\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 10.7101 - accuracy: 0.9358 - val_loss: 10.6510 - val_accuracy: 0.9449\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 10.6234 - accuracy: 0.9398 - val_loss: 10.5900 - val_accuracy: 0.9336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "90/90 [==============================] - 17s 184ms/step - loss: 10.5375 - accuracy: 0.9439 - val_loss: 10.5199 - val_accuracy: 0.9277\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 16s 179ms/step - loss: 10.4559 - accuracy: 0.9440 - val_loss: 10.4237 - val_accuracy: 0.9379\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 10.3755 - accuracy: 0.9454 - val_loss: 10.3256 - val_accuracy: 0.9488\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 10.2906 - accuracy: 0.9468 - val_loss: 10.2428 - val_accuracy: 0.9504\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 17s 189ms/step - loss: 10.2080 - accuracy: 0.9502 - val_loss: 10.1622 - val_accuracy: 0.9535\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 16s 178ms/step - loss: 10.1222 - accuracy: 0.9532 - val_loss: 10.0811 - val_accuracy: 0.9527\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 16s 182ms/step - loss: 10.0449 - accuracy: 0.9535 - val_loss: 10.0052 - val_accuracy: 0.9529\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 9.9628 - accuracy: 0.9555 - val_loss: 9.9287 - val_accuracy: 0.9520\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 9.8810 - accuracy: 0.9572 - val_loss: 9.8506 - val_accuracy: 0.9528\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 9.8034 - accuracy: 0.9561 - val_loss: 9.7693 - val_accuracy: 0.9555\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 17s 189ms/step - loss: 9.7234 - accuracy: 0.9597 - val_loss: 9.6959 - val_accuracy: 0.9536\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 9.6433 - accuracy: 0.9604 - val_loss: 9.6204 - val_accuracy: 0.9544\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 9.5658 - accuracy: 0.9626 - val_loss: 9.5505 - val_accuracy: 0.9523\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 9.4890 - accuracy: 0.9620 - val_loss: 9.4664 - val_accuracy: 0.9545\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 9.4081 - accuracy: 0.9639 - val_loss: 9.3880 - val_accuracy: 0.9585\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 16s 174ms/step - loss: 9.3310 - accuracy: 0.9653 - val_loss: 9.3129 - val_accuracy: 0.9563\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 17s 188ms/step - loss: 9.2545 - accuracy: 0.9657 - val_loss: 9.2384 - val_accuracy: 0.9572\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 9.1803 - accuracy: 0.9667 - val_loss: 9.1685 - val_accuracy: 0.9576\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 9.1012 - accuracy: 0.9674 - val_loss: 9.0915 - val_accuracy: 0.9581\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 9.0268 - accuracy: 0.9688 - val_loss: 9.0220 - val_accuracy: 0.9567\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 8.9528 - accuracy: 0.9690 - val_loss: 8.9425 - val_accuracy: 0.9583\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 17s 185ms/step - loss: 8.8754 - accuracy: 0.9706 - val_loss: 8.8727 - val_accuracy: 0.9585\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 8.8004 - accuracy: 0.9728 - val_loss: 8.7980 - val_accuracy: 0.9595\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 8.7307 - accuracy: 0.9711 - val_loss: 8.7304 - val_accuracy: 0.9585\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 8.6528 - accuracy: 0.9737 - val_loss: 8.6564 - val_accuracy: 0.9597\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 8.5757 - accuracy: 0.9752 - val_loss: 8.5843 - val_accuracy: 0.9584\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 17s 185ms/step - loss: 8.5060 - accuracy: 0.9743 - val_loss: 8.5147 - val_accuracy: 0.9569\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 16s 178ms/step - loss: 8.4336 - accuracy: 0.9760 - val_loss: 8.4449 - val_accuracy: 0.9584\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 8.3622 - accuracy: 0.9754 - val_loss: 8.3733 - val_accuracy: 0.9579\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 8.2853 - accuracy: 0.9787 - val_loss: 8.3031 - val_accuracy: 0.9573\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 8.2146 - accuracy: 0.9777 - val_loss: 8.2474 - val_accuracy: 0.9548\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 8.1430 - accuracy: 0.9791 - val_loss: 8.1583 - val_accuracy: 0.9599\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 17s 188ms/step - loss: 8.0707 - accuracy: 0.9801 - val_loss: 8.1079 - val_accuracy: 0.9540\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 8.0040 - accuracy: 0.9782 - val_loss: 8.0248 - val_accuracy: 0.9609\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 16s 174ms/step - loss: 7.9343 - accuracy: 0.9790 - val_loss: 7.9623 - val_accuracy: 0.9591\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 7.8621 - accuracy: 0.9807 - val_loss: 7.8993 - val_accuracy: 0.9557\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 7.7924 - accuracy: 0.9814 - val_loss: 7.8315 - val_accuracy: 0.9545\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 7.7215 - accuracy: 0.9820 - val_loss: 7.7816 - val_accuracy: 0.9479\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 18s 197ms/step - loss: 7.6525 - accuracy: 0.9824 - val_loss: 7.6834 - val_accuracy: 0.9615\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 16s 178ms/step - loss: 7.5862 - accuracy: 0.9832 - val_loss: 7.6479 - val_accuracy: 0.9509\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 16s 177ms/step - loss: 7.5173 - accuracy: 0.9826 - val_loss: 7.5516 - val_accuracy: 0.9604\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 16s 173ms/step - loss: 7.4458 - accuracy: 0.9855 - val_loss: 7.5041 - val_accuracy: 0.9537\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 7.3803 - accuracy: 0.9837 - val_loss: 7.4226 - val_accuracy: 0.9611\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 16s 184ms/step - loss: 7.3160 - accuracy: 0.9839 - val_loss: 7.3624 - val_accuracy: 0.9587\n",
      "Time: 1613.4436717033386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./TrainedModels/Trained_Comb_Model_1KSNPs_BM.acc.mod/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./TrainedModels/Trained_Comb_Model_1KSNPs_BM.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#Train the combined SNPs + traits (BM) network\n",
    "################################################################################################################################################\n",
    "\n",
    "# Create the input to the final set of layers as the output of both the MLP and CNN\n",
    "combinedInput = LinearW()([mlp.output, cnn.output])\n",
    "\n",
    "# The final fully-connected layer head will have two dense layers (one relu and one sigmoid)\n",
    "x = Dense(50, activation=\"relu\")(combinedInput)\n",
    "x = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "\n",
    "# The final model accepts numerical data on the MLP input and images on the CNN input, outputting a single value\n",
    "model1 = Model(inputs=[mlp.input, cnn.input], outputs=x)\n",
    "\n",
    "opt = SGD(learning_rate=0.001)\n",
    "\n",
    "model1.compile(loss=keras.losses.categorical_crossentropy,\n",
    "\t              optimizer=opt,\n",
    "\t              metrics=['accuracy'])\n",
    "\n",
    "print(model1.summary())\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_accuracy', patience=100, verbose=0, mode='max', restore_best_weights=True)\n",
    "start = time.time()\n",
    "model1.fit([traits_train, xtrain], ytrain, batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=([traits_test, xtest], ytest),callbacks=[earlyStopping])\n",
    "print (f'Time: {time.time() - start}')\n",
    "\n",
    "model1.save(filepath='./TrainedModels/Trained_Comb_Model_1KSNPs_BM.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8395b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1000, 458)]       0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 998, 250)          343500    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 998, 250)         1000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 996, 250)          187500    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 996, 250)         1000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 994, 250)          187500    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 994, 250)         1000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 331, 250)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 82750)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 125)               10343875  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 125)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 125)               15750     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 125)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 50)                6300      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 50)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,087,578\n",
      "Trainable params: 11,086,078\n",
      "Non-trainable params: 1,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 12:19:48.619536: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2023-03-27 12:19:50.120208: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-27 12:19:50.121849: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-27 12:19:50.121864: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-03-27 12:19:50.123632: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-27 12:19:50.123701: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-03-27 12:19:51.159244: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 27s 226ms/step - loss: 1.1498 - accuracy: 0.3916 - val_loss: 1.0245 - val_accuracy: 0.5915\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 17s 185ms/step - loss: 0.9620 - accuracy: 0.4923 - val_loss: 0.8730 - val_accuracy: 0.5973\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 15s 166ms/step - loss: 0.8557 - accuracy: 0.5618 - val_loss: 0.7225 - val_accuracy: 0.6416\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 16s 174ms/step - loss: 0.7763 - accuracy: 0.6035 - val_loss: 0.6010 - val_accuracy: 0.6971\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 16s 182ms/step - loss: 0.7222 - accuracy: 0.6250 - val_loss: 0.5476 - val_accuracy: 0.7041\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 0.6761 - accuracy: 0.6516 - val_loss: 0.5179 - val_accuracy: 0.7083\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 17s 186ms/step - loss: 0.6490 - accuracy: 0.6620 - val_loss: 0.4974 - val_accuracy: 0.7313\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 0.6204 - accuracy: 0.6722 - val_loss: 0.4819 - val_accuracy: 0.7300\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 17s 185ms/step - loss: 0.5957 - accuracy: 0.6899 - val_loss: 0.4662 - val_accuracy: 0.7485\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 16s 181ms/step - loss: 0.5817 - accuracy: 0.6903 - val_loss: 0.4618 - val_accuracy: 0.7428\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 0.5646 - accuracy: 0.7039 - val_loss: 0.4563 - val_accuracy: 0.7515\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 18s 199ms/step - loss: 0.5526 - accuracy: 0.7070 - val_loss: 0.4484 - val_accuracy: 0.7649\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 0.5414 - accuracy: 0.7115 - val_loss: 0.4347 - val_accuracy: 0.7664\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 19s 213ms/step - loss: 0.5221 - accuracy: 0.7239 - val_loss: 0.4408 - val_accuracy: 0.7700\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 15s 164ms/step - loss: 0.5134 - accuracy: 0.7292 - val_loss: 0.4277 - val_accuracy: 0.7816\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 18s 201ms/step - loss: 0.5007 - accuracy: 0.7371 - val_loss: 0.4197 - val_accuracy: 0.7876\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 15s 164ms/step - loss: 0.4882 - accuracy: 0.7475 - val_loss: 0.4214 - val_accuracy: 0.7837\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 0.4751 - accuracy: 0.7562 - val_loss: 0.4114 - val_accuracy: 0.7941\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 18s 202ms/step - loss: 0.4668 - accuracy: 0.7620 - val_loss: 0.3974 - val_accuracy: 0.8044\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 0.4556 - accuracy: 0.7681 - val_loss: 0.4053 - val_accuracy: 0.8068\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 0.4433 - accuracy: 0.7757 - val_loss: 0.3780 - val_accuracy: 0.8215\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 0.4292 - accuracy: 0.7861 - val_loss: 0.3771 - val_accuracy: 0.8269\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 0.4191 - accuracy: 0.7935 - val_loss: 0.3627 - val_accuracy: 0.8372\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 0.3992 - accuracy: 0.8086 - val_loss: 0.3635 - val_accuracy: 0.8421\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 0.3881 - accuracy: 0.8183 - val_loss: 0.3463 - val_accuracy: 0.8540\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 17s 192ms/step - loss: 0.3657 - accuracy: 0.8312 - val_loss: 0.3311 - val_accuracy: 0.8652\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 16s 178ms/step - loss: 0.3523 - accuracy: 0.8383 - val_loss: 0.3273 - val_accuracy: 0.8635\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 16s 174ms/step - loss: 0.3374 - accuracy: 0.8486 - val_loss: 0.3190 - val_accuracy: 0.8688\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 16s 177ms/step - loss: 0.3153 - accuracy: 0.8588 - val_loss: 0.2803 - val_accuracy: 0.8876\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 15s 166ms/step - loss: 0.2972 - accuracy: 0.8716 - val_loss: 0.2916 - val_accuracy: 0.8793\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 0.2794 - accuracy: 0.8837 - val_loss: 0.2871 - val_accuracy: 0.8812\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 0.2689 - accuracy: 0.8886 - val_loss: 0.2406 - val_accuracy: 0.9051\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 0.2573 - accuracy: 0.8932 - val_loss: 0.2557 - val_accuracy: 0.8969\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 0.2399 - accuracy: 0.9038 - val_loss: 0.2097 - val_accuracy: 0.9196\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 18s 202ms/step - loss: 0.2302 - accuracy: 0.9098 - val_loss: 0.2213 - val_accuracy: 0.9136\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 0.2132 - accuracy: 0.9170 - val_loss: 0.2132 - val_accuracy: 0.9191\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 0.2050 - accuracy: 0.9198 - val_loss: 0.2278 - val_accuracy: 0.9072\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 15s 163ms/step - loss: 0.1949 - accuracy: 0.9232 - val_loss: 0.2102 - val_accuracy: 0.9197\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 0.1843 - accuracy: 0.9289 - val_loss: 0.1998 - val_accuracy: 0.9243\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 15s 164ms/step - loss: 0.1795 - accuracy: 0.9339 - val_loss: 0.1833 - val_accuracy: 0.9305\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 0.1713 - accuracy: 0.9376 - val_loss: 0.1865 - val_accuracy: 0.9289\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 0.1608 - accuracy: 0.9409 - val_loss: 0.1596 - val_accuracy: 0.9392\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 15s 164ms/step - loss: 0.1549 - accuracy: 0.9420 - val_loss: 0.1555 - val_accuracy: 0.9419\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 0.1480 - accuracy: 0.9463 - val_loss: 0.1618 - val_accuracy: 0.9392\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 0.1437 - accuracy: 0.9486 - val_loss: 0.1551 - val_accuracy: 0.9408\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 0.1413 - accuracy: 0.9487 - val_loss: 0.1437 - val_accuracy: 0.9433\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 16s 178ms/step - loss: 0.1316 - accuracy: 0.9544 - val_loss: 0.1646 - val_accuracy: 0.9407\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 16s 177ms/step - loss: 0.1288 - accuracy: 0.9544 - val_loss: 0.1427 - val_accuracy: 0.9456\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 15s 164ms/step - loss: 0.1244 - accuracy: 0.9568 - val_loss: 0.1461 - val_accuracy: 0.9448\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 0.1204 - accuracy: 0.9582 - val_loss: 0.1500 - val_accuracy: 0.9443\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 0.1149 - accuracy: 0.9603 - val_loss: 0.1434 - val_accuracy: 0.9453\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 0.1108 - accuracy: 0.9610 - val_loss: 0.1393 - val_accuracy: 0.9472\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 0.1040 - accuracy: 0.9638 - val_loss: 0.1485 - val_accuracy: 0.9465\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 0.1041 - accuracy: 0.9641 - val_loss: 0.1400 - val_accuracy: 0.9483\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 0.0986 - accuracy: 0.9662 - val_loss: 0.1324 - val_accuracy: 0.9496\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 0.0970 - accuracy: 0.9669 - val_loss: 0.1410 - val_accuracy: 0.9503\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 15s 165ms/step - loss: 0.0948 - accuracy: 0.9673 - val_loss: 0.1381 - val_accuracy: 0.9481\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 16s 173ms/step - loss: 0.0923 - accuracy: 0.9674 - val_loss: 0.1400 - val_accuracy: 0.9483\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 16s 180ms/step - loss: 0.0863 - accuracy: 0.9713 - val_loss: 0.1391 - val_accuracy: 0.9499\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 16s 180ms/step - loss: 0.0853 - accuracy: 0.9706 - val_loss: 0.1425 - val_accuracy: 0.9501\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 0.0794 - accuracy: 0.9727 - val_loss: 0.1407 - val_accuracy: 0.9513\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 0.0808 - accuracy: 0.9724 - val_loss: 0.1363 - val_accuracy: 0.9497\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 0.0773 - accuracy: 0.9735 - val_loss: 0.1351 - val_accuracy: 0.9515\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 0.0735 - accuracy: 0.9740 - val_loss: 0.1757 - val_accuracy: 0.9459\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 16s 173ms/step - loss: 0.0741 - accuracy: 0.9756 - val_loss: 0.1420 - val_accuracy: 0.9509\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 0.0706 - accuracy: 0.9774 - val_loss: 0.1377 - val_accuracy: 0.9516\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 0.0645 - accuracy: 0.9797 - val_loss: 0.1507 - val_accuracy: 0.9513\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 17s 184ms/step - loss: 0.0657 - accuracy: 0.9783 - val_loss: 0.1429 - val_accuracy: 0.9521\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 17s 190ms/step - loss: 0.0652 - accuracy: 0.9793 - val_loss: 0.1344 - val_accuracy: 0.9525\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 0.0652 - accuracy: 0.9791 - val_loss: 0.1518 - val_accuracy: 0.9511\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 0.0623 - accuracy: 0.9802 - val_loss: 0.1401 - val_accuracy: 0.9531\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 15s 163ms/step - loss: 0.0602 - accuracy: 0.9801 - val_loss: 0.1420 - val_accuracy: 0.9523\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 0.0590 - accuracy: 0.9803 - val_loss: 0.1434 - val_accuracy: 0.9504\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 0.0557 - accuracy: 0.9829 - val_loss: 0.1467 - val_accuracy: 0.9524\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 0.0565 - accuracy: 0.9820 - val_loss: 0.1401 - val_accuracy: 0.9540\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 0.0541 - accuracy: 0.9820 - val_loss: 0.1478 - val_accuracy: 0.9527\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 0.0537 - accuracy: 0.9836 - val_loss: 0.1404 - val_accuracy: 0.9524\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 15s 166ms/step - loss: 0.0473 - accuracy: 0.9858 - val_loss: 0.1978 - val_accuracy: 0.9465\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 16s 180ms/step - loss: 0.0478 - accuracy: 0.9855 - val_loss: 0.1784 - val_accuracy: 0.9509\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 17s 188ms/step - loss: 0.0487 - accuracy: 0.9851 - val_loss: 0.1485 - val_accuracy: 0.9547\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 15s 163ms/step - loss: 0.0475 - accuracy: 0.9854 - val_loss: 0.1462 - val_accuracy: 0.9539\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 15s 163ms/step - loss: 0.0453 - accuracy: 0.9858 - val_loss: 0.1432 - val_accuracy: 0.9529\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 15s 163ms/step - loss: 0.0445 - accuracy: 0.9856 - val_loss: 0.1734 - val_accuracy: 0.9513\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 0.0442 - accuracy: 0.9859 - val_loss: 0.1580 - val_accuracy: 0.9541\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 0.0438 - accuracy: 0.9872 - val_loss: 0.1547 - val_accuracy: 0.9553\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 0.0436 - accuracy: 0.9864 - val_loss: 0.1603 - val_accuracy: 0.9528\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 15s 164ms/step - loss: 0.0415 - accuracy: 0.9866 - val_loss: 0.1554 - val_accuracy: 0.9543\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 15s 162ms/step - loss: 0.0417 - accuracy: 0.9867 - val_loss: 0.1644 - val_accuracy: 0.9545\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 16s 178ms/step - loss: 0.0398 - accuracy: 0.9880 - val_loss: 0.1498 - val_accuracy: 0.9537\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 16s 182ms/step - loss: 0.0419 - accuracy: 0.9870 - val_loss: 0.1605 - val_accuracy: 0.9539\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 15s 164ms/step - loss: 0.0399 - accuracy: 0.9879 - val_loss: 0.1579 - val_accuracy: 0.9559\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 0.0397 - accuracy: 0.9883 - val_loss: 0.1587 - val_accuracy: 0.9540\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 15s 163ms/step - loss: 0.0375 - accuracy: 0.9886 - val_loss: 0.1713 - val_accuracy: 0.9552\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 0.0351 - accuracy: 0.9897 - val_loss: 0.1679 - val_accuracy: 0.9527\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 15s 162ms/step - loss: 0.0329 - accuracy: 0.9896 - val_loss: 0.1818 - val_accuracy: 0.9551\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 15s 164ms/step - loss: 0.0345 - accuracy: 0.9896 - val_loss: 0.1699 - val_accuracy: 0.9515\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 15s 164ms/step - loss: 0.0324 - accuracy: 0.9906 - val_loss: 0.1899 - val_accuracy: 0.9533\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 14s 160ms/step - loss: 0.0348 - accuracy: 0.9896 - val_loss: 0.1705 - val_accuracy: 0.9549\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 14s 161ms/step - loss: 0.0345 - accuracy: 0.9890 - val_loss: 0.1687 - val_accuracy: 0.9555\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 17s 189ms/step - loss: 0.0321 - accuracy: 0.9904 - val_loss: 0.1715 - val_accuracy: 0.9547\n",
      "Time: 1570.0571336746216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Trained_CNN_Model_1KSNPs.acc.mod/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Trained_CNN_Model_1KSNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#Train the SNPs only network\n",
    "################################################################################################################################################\n",
    "\n",
    "xCNN = Dense(num_classes, activation=\"softmax\")(cnn.output)\n",
    "\n",
    "model2 = Model(inputs=cnn.input, outputs=xCNN)\n",
    "\n",
    "opt = SGD(learning_rate=0.001)\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_accuracy', patience=100, verbose=0, mode='max', restore_best_weights=True)\n",
    "\n",
    "model2.compile(loss=keras.losses.categorical_crossentropy,\n",
    "\t              optimizer=opt,\n",
    "\t              metrics=['accuracy'])\n",
    "\n",
    "print(model2.summary())\n",
    "\n",
    "start = time.time()\n",
    "model2.fit(xtrain, ytrain, batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(xtest, ytest),callbacks=[earlyStopping])\n",
    "print (f'Time: {time.time() - start}')\n",
    "\n",
    "model2.save(filepath='./TrainedModels/Trained_CNN_Model_1KSNPs.acc.mod')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ddf1c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_input (InputLayer)    [(None, 7099)]            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 150)               1064850   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 150)              600       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 150)               22500     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 150)              600       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                7550      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,096,253\n",
      "Trainable params: 1,095,653\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 2s 16ms/step - loss: 16.6381 - accuracy: 0.3317 - val_loss: 16.4287 - val_accuracy: 0.3471\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 16.4125 - accuracy: 0.3705 - val_loss: 16.3004 - val_accuracy: 0.3759\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 16.2310 - accuracy: 0.4083 - val_loss: 16.1741 - val_accuracy: 0.4027\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 16.0752 - accuracy: 0.4454 - val_loss: 16.0484 - val_accuracy: 0.4237\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 15.9304 - accuracy: 0.4768 - val_loss: 15.9239 - val_accuracy: 0.4436\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 15.7947 - accuracy: 0.5071 - val_loss: 15.8027 - val_accuracy: 0.4652\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 15.6623 - accuracy: 0.5369 - val_loss: 15.6839 - val_accuracy: 0.4824\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 15.5355 - accuracy: 0.5642 - val_loss: 15.5675 - val_accuracy: 0.5020\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 15.4128 - accuracy: 0.5852 - val_loss: 15.4515 - val_accuracy: 0.5167\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 15.2904 - accuracy: 0.6043 - val_loss: 15.3375 - val_accuracy: 0.5345\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 15.1695 - accuracy: 0.6260 - val_loss: 15.2266 - val_accuracy: 0.5443\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 15.0531 - accuracy: 0.6448 - val_loss: 15.1164 - val_accuracy: 0.5556\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 14.9381 - accuracy: 0.6577 - val_loss: 15.0061 - val_accuracy: 0.5647\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 14.8251 - accuracy: 0.6753 - val_loss: 14.8977 - val_accuracy: 0.5749\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 14.7119 - accuracy: 0.6890 - val_loss: 14.7906 - val_accuracy: 0.5824\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 14.6000 - accuracy: 0.7000 - val_loss: 14.6840 - val_accuracy: 0.5871\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 14.4903 - accuracy: 0.7120 - val_loss: 14.5791 - val_accuracy: 0.5985\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 14.3791 - accuracy: 0.7231 - val_loss: 14.4760 - val_accuracy: 0.6076\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 14.2733 - accuracy: 0.7330 - val_loss: 14.3733 - val_accuracy: 0.6119\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 14.1668 - accuracy: 0.7402 - val_loss: 14.2707 - val_accuracy: 0.6183\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 14.0583 - accuracy: 0.7534 - val_loss: 14.1704 - val_accuracy: 0.6231\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 13.9547 - accuracy: 0.7603 - val_loss: 14.0706 - val_accuracy: 0.6279\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 13.8515 - accuracy: 0.7672 - val_loss: 13.9716 - val_accuracy: 0.6316\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 13.7462 - accuracy: 0.7760 - val_loss: 13.8734 - val_accuracy: 0.6389\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 13.6443 - accuracy: 0.7843 - val_loss: 13.7760 - val_accuracy: 0.6399\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 13.5432 - accuracy: 0.7893 - val_loss: 13.6789 - val_accuracy: 0.6444\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 13.4408 - accuracy: 0.7979 - val_loss: 13.5836 - val_accuracy: 0.6497\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 13.3411 - accuracy: 0.8043 - val_loss: 13.4882 - val_accuracy: 0.6497\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 13.2401 - accuracy: 0.8108 - val_loss: 13.3934 - val_accuracy: 0.6537\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 13.1416 - accuracy: 0.8173 - val_loss: 13.3002 - val_accuracy: 0.6585\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 13.0437 - accuracy: 0.8230 - val_loss: 13.2067 - val_accuracy: 0.6588\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 12.9450 - accuracy: 0.8285 - val_loss: 13.1140 - val_accuracy: 0.6597\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 12.8477 - accuracy: 0.8342 - val_loss: 13.0219 - val_accuracy: 0.6636\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 12.7521 - accuracy: 0.8396 - val_loss: 12.9305 - val_accuracy: 0.6660\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 12.6560 - accuracy: 0.8449 - val_loss: 12.8392 - val_accuracy: 0.6681\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 12.5592 - accuracy: 0.8514 - val_loss: 12.7487 - val_accuracy: 0.6709\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 12.4648 - accuracy: 0.8559 - val_loss: 12.6594 - val_accuracy: 0.6737\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 12.3715 - accuracy: 0.8598 - val_loss: 12.5703 - val_accuracy: 0.6775\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 12.2759 - accuracy: 0.8636 - val_loss: 12.4816 - val_accuracy: 0.6791\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 12.1823 - accuracy: 0.8715 - val_loss: 12.3940 - val_accuracy: 0.6791\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 12.0894 - accuracy: 0.8751 - val_loss: 12.3062 - val_accuracy: 0.6819\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 11.9967 - accuracy: 0.8784 - val_loss: 12.2189 - val_accuracy: 0.6828\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 11.9045 - accuracy: 0.8829 - val_loss: 12.1320 - val_accuracy: 0.6857\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.8131 - accuracy: 0.8870 - val_loss: 12.0464 - val_accuracy: 0.6836\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 11.7220 - accuracy: 0.8915 - val_loss: 11.9606 - val_accuracy: 0.6845\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 11.6321 - accuracy: 0.8953 - val_loss: 11.8748 - val_accuracy: 0.6856\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 1s 10ms/step - loss: 11.5416 - accuracy: 0.8984 - val_loss: 11.7912 - val_accuracy: 0.6879\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 11.4524 - accuracy: 0.9048 - val_loss: 11.7060 - val_accuracy: 0.6891\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 11.3629 - accuracy: 0.9075 - val_loss: 11.6226 - val_accuracy: 0.6911\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 11.2758 - accuracy: 0.9102 - val_loss: 11.5396 - val_accuracy: 0.6915\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 11.1854 - accuracy: 0.9146 - val_loss: 11.4573 - val_accuracy: 0.6924\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 11.0966 - accuracy: 0.9187 - val_loss: 11.3740 - val_accuracy: 0.6940\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 11.0104 - accuracy: 0.9195 - val_loss: 11.2922 - val_accuracy: 0.6953\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 10.9232 - accuracy: 0.9229 - val_loss: 11.2107 - val_accuracy: 0.6961\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.8364 - accuracy: 0.9260 - val_loss: 11.1309 - val_accuracy: 0.6965\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.7504 - accuracy: 0.9275 - val_loss: 11.0497 - val_accuracy: 0.6993\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.6653 - accuracy: 0.9317 - val_loss: 10.9696 - val_accuracy: 0.6985\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.5788 - accuracy: 0.9362 - val_loss: 10.8890 - val_accuracy: 0.7004\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.4946 - accuracy: 0.9364 - val_loss: 10.8101 - val_accuracy: 0.7029\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.4096 - accuracy: 0.9400 - val_loss: 10.7304 - val_accuracy: 0.7040\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 10.3247 - accuracy: 0.9436 - val_loss: 10.6520 - val_accuracy: 0.7035\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.2416 - accuracy: 0.9460 - val_loss: 10.5743 - val_accuracy: 0.7029\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.1587 - accuracy: 0.9476 - val_loss: 10.4970 - val_accuracy: 0.7040\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.0744 - accuracy: 0.9514 - val_loss: 10.4195 - val_accuracy: 0.7035\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.9926 - accuracy: 0.9541 - val_loss: 10.3438 - val_accuracy: 0.7057\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.9108 - accuracy: 0.9554 - val_loss: 10.2660 - val_accuracy: 0.7100\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.8278 - accuracy: 0.9566 - val_loss: 10.1904 - val_accuracy: 0.7083\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.7473 - accuracy: 0.9583 - val_loss: 10.1139 - val_accuracy: 0.7079\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.6661 - accuracy: 0.9622 - val_loss: 10.0370 - val_accuracy: 0.7093\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.5842 - accuracy: 0.9644 - val_loss: 9.9627 - val_accuracy: 0.7112\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.5050 - accuracy: 0.9654 - val_loss: 9.8890 - val_accuracy: 0.7103\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.4258 - accuracy: 0.9663 - val_loss: 9.8137 - val_accuracy: 0.7108\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.3459 - accuracy: 0.9692 - val_loss: 9.7391 - val_accuracy: 0.7115\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2676 - accuracy: 0.9693 - val_loss: 9.6665 - val_accuracy: 0.7139\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.1887 - accuracy: 0.9722 - val_loss: 9.5932 - val_accuracy: 0.7113\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.1093 - accuracy: 0.9747 - val_loss: 9.5198 - val_accuracy: 0.7127\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0325 - accuracy: 0.9758 - val_loss: 9.4479 - val_accuracy: 0.7119\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.9539 - accuracy: 0.9769 - val_loss: 9.3758 - val_accuracy: 0.7108\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.8775 - accuracy: 0.9783 - val_loss: 9.3046 - val_accuracy: 0.7127\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.8009 - accuracy: 0.9794 - val_loss: 9.2327 - val_accuracy: 0.7136\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7241 - accuracy: 0.9808 - val_loss: 9.1617 - val_accuracy: 0.7145\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.6477 - accuracy: 0.9820 - val_loss: 9.0899 - val_accuracy: 0.7139\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.5731 - accuracy: 0.9822 - val_loss: 9.0211 - val_accuracy: 0.7139\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4989 - accuracy: 0.9832 - val_loss: 8.9514 - val_accuracy: 0.7177\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4227 - accuracy: 0.9864 - val_loss: 8.8828 - val_accuracy: 0.7164\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3500 - accuracy: 0.9860 - val_loss: 8.8131 - val_accuracy: 0.7179\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.2762 - accuracy: 0.9870 - val_loss: 8.7445 - val_accuracy: 0.7160\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.2020 - accuracy: 0.9886 - val_loss: 8.6752 - val_accuracy: 0.7165\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 15ms/step - loss: 8.1290 - accuracy: 0.9890 - val_loss: 8.6075 - val_accuracy: 0.7168\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.0557 - accuracy: 0.9900 - val_loss: 8.5385 - val_accuracy: 0.7196\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 7.9835 - accuracy: 0.9909 - val_loss: 8.4710 - val_accuracy: 0.7187\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 7.9116 - accuracy: 0.9915 - val_loss: 8.4052 - val_accuracy: 0.7173\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.8401 - accuracy: 0.9922 - val_loss: 8.3378 - val_accuracy: 0.7191\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 7.7685 - accuracy: 0.9930 - val_loss: 8.2722 - val_accuracy: 0.7168\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 7.6972 - accuracy: 0.9936 - val_loss: 8.2069 - val_accuracy: 0.7221\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 7.6270 - accuracy: 0.9941 - val_loss: 8.1402 - val_accuracy: 0.7196\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 7.5578 - accuracy: 0.9951 - val_loss: 8.0746 - val_accuracy: 0.7183\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 7.4870 - accuracy: 0.9947 - val_loss: 8.0097 - val_accuracy: 0.7217\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 7.4185 - accuracy: 0.9952 - val_loss: 7.9455 - val_accuracy: 0.7195\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.3488 - accuracy: 0.9953 - val_loss: 7.8802 - val_accuracy: 0.7208\n",
      "Time: 97.66459512710571\n",
      "INFO:tensorflow:Assets written to: ./TrainedModels/Trained_Traits_Model_BM.acc.mod/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./TrainedModels/Trained_Traits_Model_BM.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#Train the traits only (BM) network\n",
    "################################################################################################################################################\n",
    "\n",
    "xMLP = Dense(num_classes, activation=\"softmax\")(mlp.output)\n",
    "\n",
    "model3 = Model(inputs=mlp.input, outputs=xMLP)\n",
    "\n",
    "model3.compile(loss=keras.losses.categorical_crossentropy,\n",
    "\t              optimizer=opt,\n",
    "\t              metrics=['accuracy'])\n",
    "\n",
    "print(model3.summary())\n",
    "\n",
    "start = time.time()\n",
    "model3.fit(traits_train, ytrain, batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(traits_test, ytest),callbacks=[earlyStopping])\n",
    "print (f'Time: {time.time() - start}')\n",
    "          \n",
    "model3.save(filepath='./TrainedModels/Trained_Traits_Model_BM.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff3dd0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000 30000\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#Load OU traits\n",
    "################################################################################################################################################\n",
    "\n",
    "traits_OU = []\n",
    "traits_OU = np.loadtxt(\"./traits/trait x  s_OU.txt\").reshape(30000,-1,28)\n",
    "\n",
    "scalers_OU = {}\n",
    "for i in range(traits_OU.shape[2]):\n",
    "    scalers_OU[i] = StandardScaler(copy=False)\n",
    "    traits_OU[:, :, i] = scalers_OU[i].fit_transform(traits_OU[:, :, i]) \n",
    "\n",
    "traits_OU = np.array(traits_OU)\n",
    "\n",
    "#Add missing individuals\n",
    "for i in range(traits_OU.shape[0]):\n",
    "  for j in range(0,4):\n",
    "    traits_OU[i,j,:] = 0\n",
    "  for j in range(77,81):\n",
    "    traits_OU[i,j,:] = 0\n",
    "  for j in range(134,136):\n",
    "    traits_OU[i,j,:] = 0\n",
    "\n",
    "d_traits = []\n",
    "d_traits = np.loadtxt(\"./traits/traits_disc.txt\").reshape(30000,-1,3)\n",
    "traits = np.concatenate((traits_OU,d_traits),axis=2)\n",
    "\n",
    "u1 = np.load(\"./trainingSims/Model_2sp.npz\")\n",
    "u2 = np.load(\"./trainingSims/Model_6sp.npz\")\n",
    "u3 = np.load(\"./trainingSims/Model_6spMig.npz\")\n",
    "\n",
    "x=np.concatenate((u1['Model_2sp'],u2['Model_6sp'],u3['Model_6spMig']),axis=0)\n",
    "\n",
    "#transform major alleles in -1 and minor 1\n",
    "for arr,array in enumerate(x):\n",
    "  for idx,row in enumerate(array):\n",
    "    if np.count_nonzero(row) > len(row)/2:\n",
    "      x[arr][idx][x[arr][idx] == 1] = -1\n",
    "      x[arr][idx][x[arr][idx] == 0] = 1\n",
    "    else:\n",
    "      x[arr][idx][x[arr][idx] == 0] = -1\n",
    "\n",
    "y=[0 for i in range(len(u1['Model_2sp']))]\n",
    "y.extend([1 for i in range(len(u2['Model_6sp']))])\n",
    "y.extend([2 for i in range(len(u3['Model_6spMig']))])\n",
    "y = np.array(y)\n",
    "\n",
    "print (len(x), len(y), len(traits))\n",
    "shf = list(range(len(x)))\n",
    "shuffle(shf)\n",
    "\n",
    "y = y[shf]\n",
    "x = x[shf]\n",
    "traits = traits[shf]\n",
    "\n",
    "\n",
    "#Add missing data as 0s, according to a specifies missing data percentage\n",
    "#54,477,268 SNP datapoints and 24,326,002 missing genotypes = 44.6%\n",
    "missD_perc = 44.6\n",
    "missD = int(x.shape[1]*x.shape[2]*(missD_perc/100))\n",
    "for i in range(x.shape[0]):\n",
    "  for m in range(missD):\n",
    "    j = random.randint(0, x.shape[1] - 1)\n",
    "    k = random.randint(0, x.shape[2] - 1)\n",
    "    x[i][j][k] = 0\n",
    "\n",
    "del(missD)\n",
    "\n",
    "xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n",
    "ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n",
    "traits_train, traits_test = traits[int(len(y)*.25):], traits[:int(len(y)*.25)]\n",
    "\n",
    "\n",
    "ytest = np_utils.to_categorical(ytest, num_classes)\n",
    "ytrain = np_utils.to_categorical(ytrain, num_classes)\n",
    "traits_train=traits_train.reshape((traits_train.shape[0], (traits_train.shape[1]*traits_train.shape[2])))\n",
    "traits_test=traits_test.reshape((traits_test.shape[0], (traits_test.shape[1]*traits_test.shape[2])))\n",
    "\n",
    "# Create the MLP and CNN models\n",
    "mlp = create_mlp(traits_train)\n",
    "cnn = create_cnn(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7f4a22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 1000, 458)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 998, 250)     343500      ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 998, 250)    1000        ['conv1d_6[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 996, 250)     187500      ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 996, 250)    1000        ['conv1d_7[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 994, 250)     187500      ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 994, 250)    1000        ['conv1d_8[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 331, 250)    0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 82750)        0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dense_22_input (InputLayer)    [(None, 7099)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 125)          10343875    ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 150)          1064850     ['dense_22_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 125)          0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 150)         600         ['dense_22[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 125)          15750       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 150)          22500       ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 125)          0           ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 150)         600         ['dense_23[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 50)           6300        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 50)           7550        ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 50)           0           ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_1 (LinearW)           (None, 50)           2           ['dense_24[0][0]',               \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 50)           2550        ['linear_w_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 3)            153         ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,186,230\n",
      "Trainable params: 12,184,130\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 22s 232ms/step - loss: 16.4591 - accuracy: 0.3429 - val_loss: 16.3297 - val_accuracy: 0.3600\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 15s 164ms/step - loss: 16.2944 - accuracy: 0.3748 - val_loss: 16.2086 - val_accuracy: 0.4092\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 15s 163ms/step - loss: 16.1371 - accuracy: 0.4363 - val_loss: 16.0284 - val_accuracy: 0.5304\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 15s 164ms/step - loss: 15.9471 - accuracy: 0.5141 - val_loss: 15.7749 - val_accuracy: 0.6356\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 15.7457 - accuracy: 0.5772 - val_loss: 15.5375 - val_accuracy: 0.6655\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 18s 201ms/step - loss: 15.5672 - accuracy: 0.6144 - val_loss: 15.3591 - val_accuracy: 0.6783\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 15s 166ms/step - loss: 15.4096 - accuracy: 0.6315 - val_loss: 15.2129 - val_accuracy: 0.6867\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 15s 162ms/step - loss: 15.2705 - accuracy: 0.6479 - val_loss: 15.0896 - val_accuracy: 0.6929\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 15s 164ms/step - loss: 15.1405 - accuracy: 0.6617 - val_loss: 14.9776 - val_accuracy: 0.6989\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 17s 192ms/step - loss: 15.0209 - accuracy: 0.6694 - val_loss: 14.8710 - val_accuracy: 0.7023\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 15s 164ms/step - loss: 14.9051 - accuracy: 0.6767 - val_loss: 14.7667 - val_accuracy: 0.7061\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 15s 164ms/step - loss: 14.7945 - accuracy: 0.6852 - val_loss: 14.6668 - val_accuracy: 0.7119\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 14.6892 - accuracy: 0.6920 - val_loss: 14.5689 - val_accuracy: 0.7127\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 15s 164ms/step - loss: 14.5837 - accuracy: 0.6973 - val_loss: 14.4716 - val_accuracy: 0.7145\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 16s 179ms/step - loss: 14.4871 - accuracy: 0.6992 - val_loss: 14.3759 - val_accuracy: 0.7196\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 16s 175ms/step - loss: 14.3863 - accuracy: 0.7036 - val_loss: 14.2810 - val_accuracy: 0.7267\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 14.2891 - accuracy: 0.7050 - val_loss: 14.1873 - val_accuracy: 0.7327\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 15s 166ms/step - loss: 14.1901 - accuracy: 0.7152 - val_loss: 14.0915 - val_accuracy: 0.7437\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 14.0922 - accuracy: 0.7180 - val_loss: 13.9979 - val_accuracy: 0.7436\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 15s 162ms/step - loss: 13.9961 - accuracy: 0.7217 - val_loss: 13.9059 - val_accuracy: 0.7425\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 15s 163ms/step - loss: 13.9065 - accuracy: 0.7231 - val_loss: 13.8142 - val_accuracy: 0.7473\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 15s 163ms/step - loss: 13.8068 - accuracy: 0.7290 - val_loss: 13.7219 - val_accuracy: 0.7505\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 15s 164ms/step - loss: 13.7145 - accuracy: 0.7327 - val_loss: 13.6302 - val_accuracy: 0.7564\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 13.6209 - accuracy: 0.7373 - val_loss: 13.5393 - val_accuracy: 0.7555\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 17s 185ms/step - loss: 13.5254 - accuracy: 0.7415 - val_loss: 13.4480 - val_accuracy: 0.7605\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 13.4321 - accuracy: 0.7443 - val_loss: 13.3558 - val_accuracy: 0.7716\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 13.3412 - accuracy: 0.7477 - val_loss: 13.2666 - val_accuracy: 0.7703\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 13.2495 - accuracy: 0.7529 - val_loss: 13.1764 - val_accuracy: 0.7767\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 13.1597 - accuracy: 0.7566 - val_loss: 13.0852 - val_accuracy: 0.7784\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 13.0657 - accuracy: 0.7616 - val_loss: 12.9965 - val_accuracy: 0.7803\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 15s 166ms/step - loss: 12.9784 - accuracy: 0.7644 - val_loss: 12.9063 - val_accuracy: 0.7861\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 15s 163ms/step - loss: 12.8878 - accuracy: 0.7691 - val_loss: 12.8175 - val_accuracy: 0.7897\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 15s 164ms/step - loss: 12.7933 - accuracy: 0.7761 - val_loss: 12.7284 - val_accuracy: 0.7916\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 12.7094 - accuracy: 0.7748 - val_loss: 12.6426 - val_accuracy: 0.7928\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 12.6167 - accuracy: 0.7828 - val_loss: 12.5522 - val_accuracy: 0.7980\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 16s 183ms/step - loss: 12.5270 - accuracy: 0.7862 - val_loss: 12.4628 - val_accuracy: 0.8021\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 16s 174ms/step - loss: 12.4399 - accuracy: 0.7884 - val_loss: 12.3740 - val_accuracy: 0.8051\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 12.3497 - accuracy: 0.7903 - val_loss: 12.2901 - val_accuracy: 0.8093\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 15s 166ms/step - loss: 12.2639 - accuracy: 0.7944 - val_loss: 12.2032 - val_accuracy: 0.8101\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 15s 166ms/step - loss: 12.1727 - accuracy: 0.8012 - val_loss: 12.1120 - val_accuracy: 0.8175\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 12.0797 - accuracy: 0.8069 - val_loss: 12.0250 - val_accuracy: 0.8177\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 15s 166ms/step - loss: 11.9939 - accuracy: 0.8088 - val_loss: 11.9402 - val_accuracy: 0.8203\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 11.9067 - accuracy: 0.8151 - val_loss: 11.8530 - val_accuracy: 0.8247\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 11.8130 - accuracy: 0.8214 - val_loss: 11.7688 - val_accuracy: 0.8248\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 11.7235 - accuracy: 0.8269 - val_loss: 11.6726 - val_accuracy: 0.8397\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 15s 166ms/step - loss: 11.6337 - accuracy: 0.8309 - val_loss: 11.5802 - val_accuracy: 0.8475\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 11.5460 - accuracy: 0.8376 - val_loss: 11.4955 - val_accuracy: 0.8517\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 11.4528 - accuracy: 0.8474 - val_loss: 11.4160 - val_accuracy: 0.8505\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 15s 166ms/step - loss: 11.3598 - accuracy: 0.8540 - val_loss: 11.3260 - val_accuracy: 0.8555\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 11.2698 - accuracy: 0.8604 - val_loss: 11.2304 - val_accuracy: 0.8641\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 16s 184ms/step - loss: 11.1834 - accuracy: 0.8622 - val_loss: 11.1347 - val_accuracy: 0.8775\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 16s 176ms/step - loss: 11.0868 - accuracy: 0.8728 - val_loss: 11.0682 - val_accuracy: 0.8476\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 16s 175ms/step - loss: 10.9945 - accuracy: 0.8796 - val_loss: 10.9430 - val_accuracy: 0.8936\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 10.9025 - accuracy: 0.8862 - val_loss: 10.8647 - val_accuracy: 0.8827\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 10.8114 - accuracy: 0.8924 - val_loss: 10.7649 - val_accuracy: 0.8976\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 10.7150 - accuracy: 0.9004 - val_loss: 10.6823 - val_accuracy: 0.8907\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 15s 166ms/step - loss: 10.6265 - accuracy: 0.9095 - val_loss: 10.5977 - val_accuracy: 0.8920\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 10.5313 - accuracy: 0.9141 - val_loss: 10.4926 - val_accuracy: 0.9104\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 10.4497 - accuracy: 0.9159 - val_loss: 10.4124 - val_accuracy: 0.9100\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 10.3615 - accuracy: 0.9227 - val_loss: 10.3161 - val_accuracy: 0.9208\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 10.2729 - accuracy: 0.9267 - val_loss: 10.2362 - val_accuracy: 0.9195\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 10.1866 - accuracy: 0.9312 - val_loss: 10.1514 - val_accuracy: 0.9236\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 10.1024 - accuracy: 0.9342 - val_loss: 10.0585 - val_accuracy: 0.9328\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 10.0185 - accuracy: 0.9368 - val_loss: 9.9869 - val_accuracy: 0.9291\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 9.9364 - accuracy: 0.9384 - val_loss: 9.8918 - val_accuracy: 0.9379\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 9.8535 - accuracy: 0.9413 - val_loss: 9.8250 - val_accuracy: 0.9333\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 9.7716 - accuracy: 0.9418 - val_loss: 9.7498 - val_accuracy: 0.9332\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 9.6883 - accuracy: 0.9465 - val_loss: 9.6530 - val_accuracy: 0.9420\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 9.6066 - accuracy: 0.9483 - val_loss: 9.5701 - val_accuracy: 0.9453\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 16s 179ms/step - loss: 9.5285 - accuracy: 0.9495 - val_loss: 9.5241 - val_accuracy: 0.9321\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 16s 173ms/step - loss: 9.4469 - accuracy: 0.9536 - val_loss: 9.4140 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "90/90 [==============================] - 16s 176ms/step - loss: 9.3678 - accuracy: 0.9531 - val_loss: 9.3439 - val_accuracy: 0.9452\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 16s 180ms/step - loss: 9.2930 - accuracy: 0.9544 - val_loss: 9.2630 - val_accuracy: 0.9488\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 9.2143 - accuracy: 0.9555 - val_loss: 9.2015 - val_accuracy: 0.9436\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 9.1367 - accuracy: 0.9580 - val_loss: 9.1064 - val_accuracy: 0.9535\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 9.0542 - accuracy: 0.9606 - val_loss: 9.0365 - val_accuracy: 0.9513\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 8.9793 - accuracy: 0.9609 - val_loss: 8.9648 - val_accuracy: 0.9509\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 8.9057 - accuracy: 0.9619 - val_loss: 8.8879 - val_accuracy: 0.9540\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 8.8286 - accuracy: 0.9644 - val_loss: 8.8087 - val_accuracy: 0.9555\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 8.7546 - accuracy: 0.9639 - val_loss: 8.7401 - val_accuracy: 0.9543\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 8.6788 - accuracy: 0.9663 - val_loss: 8.6782 - val_accuracy: 0.9521\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 8.6038 - accuracy: 0.9674 - val_loss: 8.5909 - val_accuracy: 0.9563\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 8.5327 - accuracy: 0.9678 - val_loss: 8.5175 - val_accuracy: 0.9561\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 8.4624 - accuracy: 0.9679 - val_loss: 8.4457 - val_accuracy: 0.9576\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 15s 167ms/step - loss: 8.3847 - accuracy: 0.9692 - val_loss: 8.3753 - val_accuracy: 0.9575\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 8.3139 - accuracy: 0.9697 - val_loss: 8.3009 - val_accuracy: 0.9589\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 15s 168ms/step - loss: 8.2400 - accuracy: 0.9712 - val_loss: 8.2506 - val_accuracy: 0.9536\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 16s 180ms/step - loss: 8.1677 - accuracy: 0.9718 - val_loss: 8.1571 - val_accuracy: 0.9595\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 16s 175ms/step - loss: 8.0961 - accuracy: 0.9732 - val_loss: 8.0924 - val_accuracy: 0.9592\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 16s 174ms/step - loss: 8.0228 - accuracy: 0.9753 - val_loss: 8.0259 - val_accuracy: 0.9569\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 15s 172ms/step - loss: 7.9518 - accuracy: 0.9745 - val_loss: 7.9661 - val_accuracy: 0.9571\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 7.8865 - accuracy: 0.9741 - val_loss: 7.8834 - val_accuracy: 0.9596\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 7.8132 - accuracy: 0.9752 - val_loss: 7.8166 - val_accuracy: 0.9597\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 15s 171ms/step - loss: 7.7402 - accuracy: 0.9773 - val_loss: 7.7513 - val_accuracy: 0.9600\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 7.6754 - accuracy: 0.9771 - val_loss: 7.6904 - val_accuracy: 0.9587\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 7.6047 - accuracy: 0.9768 - val_loss: 7.6141 - val_accuracy: 0.9604\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 15s 170ms/step - loss: 7.5354 - accuracy: 0.9785 - val_loss: 7.5509 - val_accuracy: 0.9597\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 7.4700 - accuracy: 0.9776 - val_loss: 7.4831 - val_accuracy: 0.9600\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 15s 169ms/step - loss: 7.3981 - accuracy: 0.9797 - val_loss: 7.4299 - val_accuracy: 0.9584\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 15s 162ms/step - loss: 7.3301 - accuracy: 0.9811 - val_loss: 7.3591 - val_accuracy: 0.9604\n",
      "Time: 1541.705693244934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./TrainedModels/Trained_Comb_Model_1KSNPs_OU.acc.mod/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./TrainedModels/Trained_Comb_Model_1KSNPs_OU.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#Train the combined SNPs + traits (OU) network\n",
    "################################################################################################################################################\n",
    "\n",
    "# Create the input to the final set of layers as the output of both the MLP and CNN\n",
    "combinedInput = LinearW()([mlp.output, cnn.output])\n",
    "\n",
    "# The final fully-connected layer head will have two dense layers (one relu and one sigmoid)\n",
    "x = Dense(50, activation=\"relu\")(combinedInput)\n",
    "x = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "\n",
    "# The final model accepts numerical data on the MLP input and images on the CNN input, outputting a single value\n",
    "model1 = Model(inputs=[mlp.input, cnn.input], outputs=x)\n",
    "\n",
    "opt = SGD(learning_rate=0.001)\n",
    "\n",
    "model1.compile(loss=keras.losses.categorical_crossentropy,\n",
    "\t              optimizer=opt,\n",
    "\t              metrics=['accuracy'])\n",
    "\n",
    "print(model1.summary())\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_accuracy', patience=100, verbose=0, mode='max', restore_best_weights=True)\n",
    "start = time.time()\n",
    "model1.fit([traits_train, xtrain], ytrain, batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=([traits_test, xtest], ytest),callbacks=[earlyStopping])\n",
    "print (f'Time: {time.time() - start}')\n",
    "\n",
    "model1.save(filepath='./TrainedModels/Trained_Comb_Model_1KSNPs_OU.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "baefa01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22_input (InputLayer)  [(None, 7099)]           0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 150)               1064850   \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 150)               22500     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 50)                7550      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,096,253\n",
      "Trainable params: 1,095,653\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 2s 14ms/step - loss: 8.4644 - accuracy: 0.3815 - val_loss: 8.3912 - val_accuracy: 0.4211\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.2225 - accuracy: 0.4808 - val_loss: 8.2274 - val_accuracy: 0.4723\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.0494 - accuracy: 0.5512 - val_loss: 8.1037 - val_accuracy: 0.5099\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.9078 - accuracy: 0.6049 - val_loss: 7.9971 - val_accuracy: 0.5364\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.7800 - accuracy: 0.6513 - val_loss: 7.8977 - val_accuracy: 0.5507\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.6652 - accuracy: 0.6861 - val_loss: 7.8034 - val_accuracy: 0.5667\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.5565 - accuracy: 0.7173 - val_loss: 7.7139 - val_accuracy: 0.5777\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.4540 - accuracy: 0.7430 - val_loss: 7.6310 - val_accuracy: 0.5900\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 7.3553 - accuracy: 0.7662 - val_loss: 7.5502 - val_accuracy: 0.5968\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 7.2595 - accuracy: 0.7864 - val_loss: 7.4666 - val_accuracy: 0.6091\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 7.1669 - accuracy: 0.8056 - val_loss: 7.3920 - val_accuracy: 0.6156\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 7.0749 - accuracy: 0.8229 - val_loss: 7.3167 - val_accuracy: 0.6213\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 6.9885 - accuracy: 0.8368 - val_loss: 7.2419 - val_accuracy: 0.6240\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 6.9023 - accuracy: 0.8488 - val_loss: 7.1669 - val_accuracy: 0.6319\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 6.8165 - accuracy: 0.8611 - val_loss: 7.0942 - val_accuracy: 0.6385\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7337 - accuracy: 0.8723 - val_loss: 7.0237 - val_accuracy: 0.6428\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 6.6505 - accuracy: 0.8837 - val_loss: 6.9528 - val_accuracy: 0.6471\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 6.5703 - accuracy: 0.8931 - val_loss: 6.8841 - val_accuracy: 0.6527\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 6.4903 - accuracy: 0.9018 - val_loss: 6.8164 - val_accuracy: 0.6527\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4127 - accuracy: 0.9080 - val_loss: 6.7478 - val_accuracy: 0.6592\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 6.3354 - accuracy: 0.9158 - val_loss: 6.6812 - val_accuracy: 0.6623\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 6.2588 - accuracy: 0.9243 - val_loss: 6.6199 - val_accuracy: 0.6612\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 6.1837 - accuracy: 0.9317 - val_loss: 6.5546 - val_accuracy: 0.6636\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 6.1090 - accuracy: 0.9386 - val_loss: 6.4891 - val_accuracy: 0.6663\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 6.0364 - accuracy: 0.9421 - val_loss: 6.4220 - val_accuracy: 0.6715\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 5.9628 - accuracy: 0.9477 - val_loss: 6.3620 - val_accuracy: 0.6703\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 5.8916 - accuracy: 0.9528 - val_loss: 6.2986 - val_accuracy: 0.6731\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 5.8212 - accuracy: 0.9570 - val_loss: 6.2377 - val_accuracy: 0.6743\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 5.7513 - accuracy: 0.9605 - val_loss: 6.1768 - val_accuracy: 0.6777\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 5.6819 - accuracy: 0.9648 - val_loss: 6.1180 - val_accuracy: 0.6797\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 5.6127 - accuracy: 0.9688 - val_loss: 6.0612 - val_accuracy: 0.6807\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 5.5462 - accuracy: 0.9712 - val_loss: 5.9978 - val_accuracy: 0.6817\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 5.4785 - accuracy: 0.9752 - val_loss: 5.9416 - val_accuracy: 0.6825\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 5.4118 - accuracy: 0.9776 - val_loss: 5.8844 - val_accuracy: 0.6813\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 5.3464 - accuracy: 0.9793 - val_loss: 5.8244 - val_accuracy: 0.6868\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 5.2825 - accuracy: 0.9813 - val_loss: 5.7708 - val_accuracy: 0.6868\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 5.2173 - accuracy: 0.9836 - val_loss: 5.7133 - val_accuracy: 0.6841\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 5.1549 - accuracy: 0.9853 - val_loss: 5.6572 - val_accuracy: 0.6900\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 5.0919 - accuracy: 0.9871 - val_loss: 5.6002 - val_accuracy: 0.6896\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 5.0286 - accuracy: 0.9888 - val_loss: 5.5465 - val_accuracy: 0.6893\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 4.9676 - accuracy: 0.9900 - val_loss: 5.4938 - val_accuracy: 0.6909\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 4.9076 - accuracy: 0.9913 - val_loss: 5.4380 - val_accuracy: 0.6903\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 4.8464 - accuracy: 0.9916 - val_loss: 5.3848 - val_accuracy: 0.6912\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 4.7866 - accuracy: 0.9932 - val_loss: 5.3346 - val_accuracy: 0.6937\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 4.7286 - accuracy: 0.9937 - val_loss: 5.2796 - val_accuracy: 0.6917\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 4.6702 - accuracy: 0.9952 - val_loss: 5.2263 - val_accuracy: 0.6939\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 4.6119 - accuracy: 0.9953 - val_loss: 5.1773 - val_accuracy: 0.6957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 4.5547 - accuracy: 0.9956 - val_loss: 5.1244 - val_accuracy: 0.7000\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 4.4974 - accuracy: 0.9963 - val_loss: 5.0700 - val_accuracy: 0.6988\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 4.4410 - accuracy: 0.9971 - val_loss: 5.0231 - val_accuracy: 0.7001\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 4.3852 - accuracy: 0.9975 - val_loss: 4.9723 - val_accuracy: 0.7001\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 4.3314 - accuracy: 0.9977 - val_loss: 4.9195 - val_accuracy: 0.6988\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 4.2758 - accuracy: 0.9983 - val_loss: 4.8726 - val_accuracy: 0.7003\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 13ms/step - loss: 4.2214 - accuracy: 0.9984 - val_loss: 4.8206 - val_accuracy: 0.7007\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 4.1680 - accuracy: 0.9985 - val_loss: 4.7757 - val_accuracy: 0.6991\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 4.1149 - accuracy: 0.9988 - val_loss: 4.7287 - val_accuracy: 0.7019\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 4.0616 - accuracy: 0.9991 - val_loss: 4.6771 - val_accuracy: 0.7021\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 4.0097 - accuracy: 0.9992 - val_loss: 4.6314 - val_accuracy: 0.7023\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 3.9578 - accuracy: 0.9993 - val_loss: 4.5810 - val_accuracy: 0.7020\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 3.9067 - accuracy: 0.9993 - val_loss: 4.5366 - val_accuracy: 0.7025\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 3.8558 - accuracy: 0.9995 - val_loss: 4.4850 - val_accuracy: 0.7017\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 3.8049 - accuracy: 0.9995 - val_loss: 4.4374 - val_accuracy: 0.7037\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 3.7552 - accuracy: 0.9996 - val_loss: 4.3941 - val_accuracy: 0.7028\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 3.7057 - accuracy: 0.9996 - val_loss: 4.3443 - val_accuracy: 0.7045\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 3.6566 - accuracy: 0.9997 - val_loss: 4.3000 - val_accuracy: 0.7057\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 3.6075 - accuracy: 0.9999 - val_loss: 4.2514 - val_accuracy: 0.7073\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 3.5589 - accuracy: 0.9999 - val_loss: 4.2073 - val_accuracy: 0.7067\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 3.5120 - accuracy: 0.9999 - val_loss: 4.1633 - val_accuracy: 0.7060\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 3.4644 - accuracy: 0.9999 - val_loss: 4.1206 - val_accuracy: 0.7076\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 3.4168 - accuracy: 0.9999 - val_loss: 4.0767 - val_accuracy: 0.7067\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 3.3700 - accuracy: 0.9999 - val_loss: 4.0298 - val_accuracy: 0.7087\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 3.3236 - accuracy: 1.0000 - val_loss: 3.9889 - val_accuracy: 0.7089\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 3.2778 - accuracy: 1.0000 - val_loss: 3.9460 - val_accuracy: 0.7081\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 3.2322 - accuracy: 1.0000 - val_loss: 3.9039 - val_accuracy: 0.7087\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 3.1873 - accuracy: 1.0000 - val_loss: 3.8572 - val_accuracy: 0.7113\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 3.1426 - accuracy: 1.0000 - val_loss: 3.8160 - val_accuracy: 0.7093\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 3.0978 - accuracy: 1.0000 - val_loss: 3.7756 - val_accuracy: 0.7107\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 3.0538 - accuracy: 1.0000 - val_loss: 3.7303 - val_accuracy: 0.7108\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 3.0103 - accuracy: 1.0000 - val_loss: 3.6906 - val_accuracy: 0.7097\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 2.9667 - accuracy: 1.0000 - val_loss: 3.6496 - val_accuracy: 0.7127\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 2.9240 - accuracy: 1.0000 - val_loss: 3.6059 - val_accuracy: 0.7125\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 2.8809 - accuracy: 1.0000 - val_loss: 3.5711 - val_accuracy: 0.7136\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 2.8385 - accuracy: 1.0000 - val_loss: 3.5302 - val_accuracy: 0.7135\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.7966 - accuracy: 1.0000 - val_loss: 3.4883 - val_accuracy: 0.7133\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 2.7548 - accuracy: 1.0000 - val_loss: 3.4533 - val_accuracy: 0.7145\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.7138 - accuracy: 1.0000 - val_loss: 3.4086 - val_accuracy: 0.7141\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.6727 - accuracy: 1.0000 - val_loss: 3.3686 - val_accuracy: 0.7136\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.6322 - accuracy: 1.0000 - val_loss: 3.3346 - val_accuracy: 0.7155\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.5920 - accuracy: 1.0000 - val_loss: 3.2924 - val_accuracy: 0.7135\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.5524 - accuracy: 1.0000 - val_loss: 3.2556 - val_accuracy: 0.7148\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.5122 - accuracy: 1.0000 - val_loss: 3.2146 - val_accuracy: 0.7152\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.4732 - accuracy: 1.0000 - val_loss: 3.1795 - val_accuracy: 0.7179\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.4346 - accuracy: 1.0000 - val_loss: 3.1432 - val_accuracy: 0.7175\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.3960 - accuracy: 1.0000 - val_loss: 3.1038 - val_accuracy: 0.7185\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.3574 - accuracy: 1.0000 - val_loss: 3.0689 - val_accuracy: 0.7168\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.3197 - accuracy: 1.0000 - val_loss: 3.0322 - val_accuracy: 0.7169\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.2823 - accuracy: 1.0000 - val_loss: 2.9993 - val_accuracy: 0.7168\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.2452 - accuracy: 1.0000 - val_loss: 2.9577 - val_accuracy: 0.7200\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.2082 - accuracy: 1.0000 - val_loss: 2.9253 - val_accuracy: 0.7179\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.1714 - accuracy: 1.0000 - val_loss: 2.8884 - val_accuracy: 0.7208\n",
      "Time: 96.34918737411499\n",
      "INFO:tensorflow:Assets written to: ./TrainedModels/Trained_Traits_Model_OU.acc.mod/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./TrainedModels/Trained_Traits_Model_OU.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#Train the traits only (OU) network\n",
    "################################################################################################################################################\n",
    "\n",
    "xMLP = Dense(num_classes, activation=\"softmax\")(mlp.output)\n",
    "\n",
    "model3 = Model(inputs=mlp.input, outputs=xMLP)\n",
    "\n",
    "model3.compile(loss=keras.losses.categorical_crossentropy,\n",
    "\t              optimizer=opt,\n",
    "\t              metrics=['accuracy'])\n",
    "\n",
    "print(model3.summary())\n",
    "\n",
    "start = time.time()\n",
    "model3.fit(traits_train, ytrain, batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(traits_test, ytest),callbacks=[earlyStopping])\n",
    "print (f'Time: {time.time() - start}')\n",
    "          \n",
    "model3.save(filepath='./TrainedModels/Trained_Traits_Model_OU.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ebec1d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 1s 11ms/step\n",
      "[[999   0   1]\n",
      " [  0 958  42]\n",
      " [  0  79 921]]\n",
      "94/94 [==============================] - 1s 10ms/step\n",
      "[[998   0   2]\n",
      " [  0 941  59]\n",
      " [  0  66 934]]\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "[[940  14  46]\n",
      " [ 35 686 279]\n",
      " [ 80 361 559]]\n",
      "94/94 [==============================] - 1s 11ms/step\n",
      "[[999   0   1]\n",
      " [  0 986  14]\n",
      " [  0 110 890]]\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "[[944  18  38]\n",
      " [ 52 653 295]\n",
      " [107 389 504]]\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#Perform cross-validation\n",
    "################################################################################################################################################\n",
    "\n",
    "\n",
    "model1 = load_model('./TrainedModels/Trained_Comb_Model_1KSNPs_BM.acc.mod')\n",
    "model2 = load_model('./TrainedModels/Trained_CNN_Model_1KSNPs.acc.mod')\n",
    "model3 = load_model('./TrainedModels/Trained_Traits_Model_BM.acc.mod')\n",
    "model4 = load_model('./TrainedModels/Trained_Comb_Model_1KSNPs_OU.acc.mod')\n",
    "model5 = load_model('./TrainedModels/Trained_Traits_Model_OU.acc.mod')\n",
    "\n",
    "traits_BM = []\n",
    "traits_BM = np.loadtxt(\"./testSims/traits/traits_BM.txt\").reshape(3000,-1,28)\n",
    "\n",
    "for i in range(traits_BM.shape[2]):\n",
    "    traits_BM[:, :, i] = scalers_BM[i].transform(traits_BM[:, :, i]) \n",
    "\n",
    "traits_BM = np.array(traits_BM)\n",
    "\n",
    "#Add missing individuals\n",
    "for i in range(traits_BM.shape[0]):\n",
    "  for j in range(0,4):\n",
    "    traits_BM[i,j,:] = 0\n",
    "  for j in range(77,81):\n",
    "    traits_BM[i,j,:] = 0\n",
    "  for j in range(134,136):\n",
    "    traits_BM[i,j,:] = 0\n",
    "\n",
    "d_traits = []\n",
    "d_traits = np.loadtxt(\"./testSims/traits/traits_disc.txt\").reshape(3000,-1,3)\n",
    "traits = np.concatenate((traits_BM,d_traits),axis=2)\n",
    "\n",
    "u1 = np.load(\"./testSims/Model_2sp.npz\")\n",
    "u2 = np.load(\"./testSims/Model_6sp.npz\")\n",
    "u3 = np.load(\"./testSims/Model_6spMig.npz\")\n",
    "\n",
    "xtest=np.concatenate((u1['Model_2sp'],u2['Model_6sp'],u3['Model_6spMig']),axis=0)\n",
    "\n",
    "#transform major alleles in -1 and minor 1\n",
    "for arr,array in enumerate(xtest):\n",
    "  for idx,row in enumerate(array):\n",
    "    if np.count_nonzero(row) > len(row)/2:\n",
    "      xtest[arr][idx][xtest[arr][idx] == 1] = -1\n",
    "      xtest[arr][idx][xtest[arr][idx] == 0] = 1\n",
    "    else:\n",
    "      xtest[arr][idx][xtest[arr][idx] == 0] = -1\n",
    "\n",
    "#Add missing data as 0s, according to a specifies missing data percentage\n",
    "#54,477,268 SNP datapoints and 24,326,002 missing genotypes = 44.6%\n",
    "missD_perc = 44.6\n",
    "missD = int(xtest.shape[1]*xtest.shape[2]*(missD_perc/100))\n",
    "for i in range(xtest.shape[0]):\n",
    "  for m in range(missD):\n",
    "    j = random.randint(0, xtest.shape[1] - 1)\n",
    "    k = random.randint(0, xtest.shape[2] - 1)\n",
    "    xtest[i][j][k] = 0\n",
    "\n",
    "\n",
    "ytest=[0 for i in range(len(u1['Model_2sp']))]\n",
    "ytest.extend([1 for i in range(len(u2['Model_6sp']))])\n",
    "ytest.extend([2 for i in range(len(u3['Model_6spMig']))])\n",
    "ytest = np.array(ytest)\n",
    "\n",
    "#first get the predictions\n",
    "pred = model1.predict([traits.reshape(3000,-1), xtest])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "print (confusion_matrix(ytest, pred_cat))\n",
    "\n",
    "\n",
    "#first get the predictions\n",
    "pred = model2.predict(xtest)\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "print (confusion_matrix(ytest, pred_cat))\n",
    "\n",
    "#first get the predictions\n",
    "pred = model3.predict(traits.reshape(3000,-1))\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "print (confusion_matrix(ytest, pred_cat))\n",
    "\n",
    "traits_OU = []\n",
    "traits_OU = np.loadtxt(\"./testSims/traits/traits_OU.txt\").reshape(3000,-1,28)\n",
    "\n",
    "for i in range(traits_OU.shape[2]):\n",
    "    traits_OU[:, :, i] = scalers_OU[i].transform(traits_OU[:, :, i]) \n",
    "\n",
    "traits_OU = np.array(traits_OU)\n",
    "\n",
    "#Add missing individuals\n",
    "for i in range(traits_OU.shape[0]):\n",
    "  for j in range(0,4):\n",
    "    traits_OU[i,j,:] = 0\n",
    "  for j in range(77,81):\n",
    "    traits_OU[i,j,:] = 0\n",
    "  for j in range(134,136):\n",
    "    traits_OU[i,j,:] = 0\n",
    "\n",
    "d_traits = []\n",
    "d_traits = np.loadtxt(\"./testSims/traits/traits_disc.txt\").reshape(3000,-1,3)\n",
    "traits = np.concatenate((traits_OU,d_traits),axis=2)\n",
    "\n",
    "#first get the predictions\n",
    "pred = model4.predict([traits.reshape(3000,-1), xtest])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "print (confusion_matrix(ytest, pred_cat))\n",
    "\n",
    "\n",
    "#first get the predictions\n",
    "pred = model5.predict(traits.reshape(3000,-1))\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "print (confusion_matrix(ytest, pred_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92d35c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################################\n",
    "#Predict empirical data\n",
    "################################################################################################################################################\n",
    "\n",
    "\n",
    "inSNPs=np.loadtxt(\"./input_T.txt\")\n",
    "inp=np.array(inSNPs)\n",
    "num_samples=100\n",
    "res = []\n",
    "for i in range(0,num_samples):\n",
    "\tidx = np.random.choice(inp.shape[0], 1000, replace=False)\n",
    "\tn = inp[idx,:]\n",
    "\tres.append(np.array(n))\n",
    "\n",
    "EmpSNPs = np.array(res)\n",
    "\n",
    "#transform major alleles in -1 and minor 1\n",
    "for arr,array in enumerate(EmpSNPs):\n",
    "  for idx,row in enumerate(array):\n",
    "    if np.count_nonzero(row==1) > np.count_nonzero(row==-1):\n",
    "      EmpSNPs[arr][idx][EmpSNPs[arr][idx] == 1] = 9\n",
    "      EmpSNPs[arr][idx][EmpSNPs[arr][idx] == -1] = 1\n",
    "      EmpSNPs[arr][idx][EmpSNPs[arr][idx] == 9] = -1\n",
    "\n",
    "Laqu_Lpel=np.genfromtxt(\"./input_traits_Laqu_Lpel.txt\", delimiter=\"\\t\", filling_values=0)\n",
    "Laqu=np.genfromtxt(\"./input_traits_Laqu.txt\", delimiter=\"\\t\", filling_values=0)\n",
    "Lmeg=np.genfromtxt(\"./input_traits_Lmeg.txt\", delimiter=\"\\t\", filling_values=0)\n",
    "Loua=np.genfromtxt(\"./input_traits_Loua.txt\", delimiter=\"\\t\", filling_values=0)\n",
    "Lozk_Lmeg=np.genfromtxt(\"./input_traits_Lozk_Lmeg.txt\", delimiter=\"\\t\", filling_values=0)\n",
    "Lozk=np.genfromtxt(\"./input_traits_Lozk.txt\", delimiter=\"\\t\", filling_values=0)\n",
    "Lpel_Lmeg=np.genfromtxt(\"./input_traits_Lpel_Lmeg.txt\", delimiter=\"\\t\", filling_values=0)\n",
    "Lpel=np.genfromtxt(\"./input_traits_Lpel.txt\", delimiter=\"\\t\", filling_values=0)\n",
    "Lsol_Lmeg=np.genfromtxt(\"./input_traits_Lsol_Lmeg.txt\", delimiter=\"\\t\", filling_values=0)\n",
    "Lsol=np.genfromtxt(\"./input_traits_Lsol.txt\", delimiter=\"\\t\", filling_values=0)\n",
    "\n",
    "Laqu_Lpel=np.array(Laqu_Lpel)\n",
    "Laqu=np.array(Laqu)\n",
    "Lmeg=np.array(Lmeg)\n",
    "Loua=np.array(Loua)\n",
    "Lozk_Lmeg=np.array(Lozk_Lmeg)\n",
    "Lozk=np.array(Lozk)\n",
    "Lpel_Lmeg=np.array(Lpel_Lmeg)\n",
    "Lpel=np.array(Lpel)\n",
    "Lsol_Lmeg=np.array(Lsol_Lmeg)\n",
    "Lsol=np.array(Lsol)\n",
    "\n",
    "\n",
    "res = []\n",
    "for i in range(0,num_samples):\n",
    "  n = np.zeros((4,31))\n",
    "  idx_aqu_pel = np.random.choice(Laqu_Lpel.shape[0], 6, replace=False)\n",
    "  n = np.concatenate((n,Laqu_Lpel[idx_aqu_pel,:]), axis=0)\n",
    "  idx_aqu = np.random.choice(Laqu.shape[0], 68, replace=False)\n",
    "  n = np.concatenate((n,Laqu[idx_aqu,:]), axis=0)\n",
    "  n = np.concatenate((n,np.zeros((3,31))), axis=0)\n",
    "  idx_meg = np.random.choice(Lmeg.shape[0], 44, replace=False)\n",
    "  n = np.concatenate((n,Lmeg[idx_meg,:]), axis=0)\n",
    "  idx_oua = np.random.choice(Loua.shape[0], 10, replace=False)\n",
    "  n = np.concatenate((n,Loua[idx_oua,:]), axis=0)\n",
    "  n = np.concatenate((n,np.zeros((1,31))), axis=0)\n",
    "  idx_ozk_meg = np.random.choice(Lozk_Lmeg.shape[0], 8, replace=False)\n",
    "  n = np.concatenate((n,Lozk_Lmeg[idx_ozk_meg,:]), axis=0)\n",
    "  idx_ozk = np.random.choice(Lozk.shape[0], 15, replace=False)\n",
    "  n = np.concatenate((n,Lozk[idx_ozk,:]), axis=0)\n",
    "  idx_pel_meg = np.random.choice(Lpel_Lmeg.shape[0], 10, replace=False)\n",
    "  n = np.concatenate((n,Lpel_Lmeg[idx_pel_meg,:]), axis=0)\n",
    "  idx_pel = np.random.choice(Lpel.shape[0], 19, replace=False)\n",
    "  n = np.concatenate((n,Lpel[idx_pel,:]), axis=0)\n",
    "  idx_sol_meg = np.random.choice(Lsol_Lmeg.shape[0], 5, replace=False)\n",
    "  n = np.concatenate((n,Lsol_Lmeg[idx_sol_meg,:]), axis=0)\n",
    "  idx_sol = np.random.choice(Lsol.shape[0], 36, replace=False)\n",
    "  n = np.concatenate((n,Lsol[idx_sol,:]), axis=0)\n",
    "  res.append(np.array(n))\n",
    "\n",
    "traits = np.array(res)\n",
    "\n",
    "c_traits = traits[:,:,0:28]\n",
    "d_traits = traits[:,:,28:32]\n",
    "\n",
    "for i in range(c_traits.shape[2]):\n",
    "    c_traits[:, :, i] = scalers_BM[i].transform(c_traits[:, :, i]) \n",
    "\n",
    "emp_traits_BM = np.concatenate((c_traits, d_traits), axis=2)\n",
    "\n",
    "c_traits = traits[:,:,0:28]\n",
    "\n",
    "for i in range(c_traits.shape[2]):\n",
    "    c_traits[:, :, i] = scalers_OU[i].transform(c_traits[:, :, i]) \n",
    "\n",
    "emp_traits_OU = np.concatenate((c_traits, d_traits), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b9299de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step\n",
      "4/4 [==============================] - 0s 16ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 16ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "Emp_Comb_BM_pred = model1.predict([emp_traits_BM.reshape(100,-1),EmpSNPs])\n",
    "\n",
    "np.savetxt(\"Pred_Emp_Comb_BM_Predictions.txt\", Emp_Comb_BM_pred)\n",
    "\n",
    "Emp_SNP_pred = model2.predict(EmpSNPs)\n",
    "\n",
    "np.savetxt(\"Pred_Emp_SNP_Predictions.txt\", Emp_SNP_pred)\n",
    "\n",
    "Emp_traits_BM_pred = model3.predict(emp_traits_BM.reshape(100,-1))\n",
    "\n",
    "np.savetxt(\"Pred_Emp_traits_BM_Predictions.txt\", Emp_traits_BM_pred)\n",
    "\n",
    "Emp_Comb_OU_pred = model4.predict([emp_traits_OU.reshape(100,-1),EmpSNPs])\n",
    "\n",
    "np.savetxt(\"Pred_Emp_Comb_OU_Predictions.txt\", Emp_Comb_OU_pred)\n",
    "\n",
    "Emp_traits_OU_pred = model5.predict(emp_traits_OU.reshape(100,-1))\n",
    "\n",
    "np.savetxt(\"Pred_Emp_traits_OU_Predictions.txt\", Emp_traits_OU_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582fed5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
