{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Zgc_VfbydhlW",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import all required libraries\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from random import shuffle, choice\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import regularizers\n",
    "from random import shuffle, choice\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "# define a function to build MLP for the trait data.    \n",
    "def create_mlp(traitstrain, regularizer=None):\n",
    "  model = Sequential()\n",
    "  # first layer, remember to remove bias if you are intercalating with batch normalization. ReLu is the activation (nonlinear) function.\n",
    "  model.add(Dense(150, use_bias=False, input_dim=traitstrain.shape[1], activation=\"relu\", kernel_regularizer=regularizers.l1(0.001)))\n",
    "  # batch normalization.\n",
    "  model.add(BatchNormalization())\n",
    "  # second layer.\n",
    "  model.add(Dense(150, use_bias=False, activation=\"relu\", kernel_regularizer=regularizers.l1(0.001)))\n",
    "  model.add(BatchNormalization())\n",
    "  # third layer.\n",
    "  model.add(Dense(50, activation=\"relu\", kernel_regularizer=regularizers.l1(0.001)))\n",
    "  return model\n",
    "\n",
    "# define a function to build a CNN for the SNP data. \n",
    "def create_cnn(xtest, regularizer=None):\n",
    "  # obtain the input dimensions.\n",
    "  inputShape = (xtest.shape[1], xtest.shape[2])\n",
    "  inputs = Input(shape=inputShape)\n",
    "  x = inputs\n",
    "  # first convolutional layer, remember to remove bias if you are intercalating with batch normalization.\n",
    "  x = Conv1D(250, kernel_size=3, activation='relu', use_bias=False, input_shape=(xtest.shape[1], xtest.shape[2]))(x)\n",
    "  # batch normalization.\n",
    "  x = BatchNormalization()(x)\n",
    "  # second layer.\n",
    "  x = Conv1D(250, kernel_size=3, use_bias=False, activation='relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  # third layer.\n",
    "  x = Conv1D(250, kernel_size=3, use_bias=False, activation='relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  # pool the CNN outputs.\n",
    "  x = MaxPooling1D(pool_size=3)(x)\n",
    "  # flatten in a single vector.\n",
    "  x = Flatten()(x)\n",
    "  # this part is similar to the MLP, a fully connected neural network. We intercalated with dropout to reduce overfitting.\n",
    "  x = Dense(125, activation='relu')(x)\n",
    "  # dropout.\n",
    "  x = Dropout(0.5)(x)\n",
    "  # second layer of the fully connected neural network.\n",
    "  x = Dense(125, activation='relu')(x)\n",
    "  x = Dropout(0.5)(x)\n",
    "  # third layer of the fully connected neural network. This one matches the number of nodes coming out of the MLP.\n",
    "  x = Dense(50, kernel_regularizer=regularizer)(x)\n",
    "  x = Activation(\"relu\")(x)\n",
    "  # Construct the CNN\n",
    "  model = Model(inputs, x)\n",
    "  # Return the CNN\n",
    "  return model\n",
    "\n",
    "# define a function to combine the outputs of the MLP and the CNN.\n",
    "# this was obtained from: https://towardsdatascience.com/neural-networks-ensemble-33f33bea7df3\n",
    "class LinearW(Layer):\n",
    "    def __init__(self):\n",
    "        super(LinearW, self).__init__()    \n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='name',\n",
    "                    shape=(1,1,len(input_shape)),\n",
    "                    initializer='uniform',\n",
    "                    dtype=tf.float32,\n",
    "                    trainable=True)\n",
    "    def call(self, inputs):\n",
    "        # inputs is a list of tensor of shape [(n_batch, n_feat), ..., (n_batch, n_feat)]\n",
    "        # expand last dim of each input passed [(n_batch, n_feat, 1), ..., (n_batch, n_feat, 1)]\n",
    "        inputs = [tf.expand_dims(i, -1) for i in inputs]\n",
    "        inputs = Concatenate(axis=-1)(inputs) # (n_batch, n_feat, n_inputs)\n",
    "        weights = tf.nn.softmax(self.W, axis=-1) # (1,1,n_inputs)\n",
    "        # weights sum up to one on last dim\n",
    "        return tf.reduce_sum(weights*inputs, axis=-1) # (n_batch, n_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "N9nDx2HPbIjP",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000 30000\n"
     ]
    }
   ],
   "source": [
    "## define variables that will be used to train all networks.\n",
    "# size of the minibatches containing simulations are passed through the network in each epoch.\n",
    "batch_size = 250\n",
    "# number of training iterations (epochs) for the SNP only and the combined networks.\n",
    "epochs = 100\n",
    "# number of training iterations (epochs) for the traits only networks.\n",
    "epochs_traits = 500\n",
    "# number of scenarios being classified.\n",
    "num_classes = 3\n",
    "\n",
    "# load the traits simulated under the BM model for the 3 scenarios. \n",
    "traits_BM = []\n",
    "traits_BM = np.loadtxt(\"./traits/traits_BM.txt\").reshape(30000,-1,100)\n",
    "# transform into a NumPy array. \n",
    "traits_BM = np.array(traits_BM)\n",
    "\n",
    "# standard scale the continuous (BM) traits\n",
    "scalers_BM = {}\n",
    "for i in range(traits_BM.shape[2]):\n",
    "    scalers_BM[i] = StandardScaler(copy=False)\n",
    "    traits_BM[:, :, i] = scalers_BM[i].fit_transform(traits_BM[:, :, i]) \n",
    "\n",
    "# load the SNPs simulated for the 3 scenarios. \n",
    "u1 = np.load(\"./trainingSims/Model_1sp.npz\",mmap_mode='r')\n",
    "u2 = np.load(\"./trainingSims/Model_2sp.npz\",mmap_mode='r')\n",
    "u3 = np.load(\"./trainingSims/Model_3sp.npz\",mmap_mode='r')\n",
    "\n",
    "# combine the loaded SNPs in a single NumPy array.\n",
    "X=np.concatenate((u1['Model_1sp'],u2['Model_2sp'],u3['Model_3sp']),axis=0)\n",
    "\n",
    "# transform SNP major alleles in -1 and minor in 1.\n",
    "for arr,array in enumerate(X):\n",
    "    for idx,row in enumerate(array):\n",
    "        if np.count_nonzero(row) > len(row)/2:\n",
    "            X[arr][idx][X[arr][idx] == 1] = -1\n",
    "            X[arr][idx][X[arr][idx] == 0] = 1\n",
    "        else:\n",
    "            X[arr][idx][X[arr][idx] == 0] = -1\n",
    "\n",
    "# create a label vector in the same order as the simulations.\n",
    "y=[0 for i in range(len(u1['Model_1sp']))]\n",
    "y.extend([1 for i in range(len(u2['Model_2sp']))])\n",
    "y.extend([2 for i in range(len(u3['Model_3sp']))])\n",
    "y = np.array(y)\n",
    "\n",
    "# make sure labels, SNP and traits matrices all have the same length.\n",
    "print (len(y), len(X), len(traits_BM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################################################################################################################################\n",
    "# We will start with traits simulated under the BM model.\n",
    "################################################################################################################################################\n",
    "\n",
    "# Since we will run the analysis on several subsets, define a function for training on each data subsets (Combined datasets, SNP only and BM traits only).\n",
    "\n",
    "# function to train on the combined datasets\n",
    "def combined_BM_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test):\n",
    "    # convert labels to a categorical matrix of binary values (0 or 1). The number of rows is the length of the input vector (number of simulations) and the number of columns is the number of classes (3 scenarios).\n",
    "    ytest = np_utils.to_categorical(ytest, num_classes)\n",
    "    ytrain = np_utils.to_categorical(ytrain, num_classes)\n",
    "    # reshape the traits matrices to input them into the MLP\n",
    "    traits_BM_train=traits_BM_train.reshape((traits_BM_train.shape[0], (traits_BM_train.shape[1]*traits_BM_train.shape[2])))\n",
    "    traits_BM_test=traits_BM_test.reshape((traits_BM_test.shape[0], (traits_BM_test.shape[1]*traits_BM_test.shape[2])))\n",
    "    # Create the MLP, the CNN and the combined models\n",
    "    mlp = create_mlp(traits_BM_train)\n",
    "    cnn = create_cnn(xtest)\n",
    "    combinedInput = LinearW()([mlp.output, cnn.output])\n",
    "\n",
    "    # The final fully-connected layer head will have two dense layers (one relu and one softmax)\n",
    "    x = Dense(50, activation=\"relu\")(combinedInput)\n",
    "    x = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    # The final model accepts numerical data on the MLP input and images on the CNN input, outputting a single value\n",
    "    model = Model(inputs=[mlp.input, cnn.input], outputs=x)\n",
    "\n",
    "    # using Stochastic Gradient Descent as optimizer and a categorical cross-entropy loss function\n",
    "    opt = SGD(learning_rate=0.001)\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    # save only the epoch with the highest accuracy in the validation set, by using the model checkpoint\n",
    "    earlyStopping = EarlyStopping(monitor='val_accuracy', patience=150, verbose=0, mode='max', restore_best_weights=True)\n",
    "\n",
    "    # fit the model and record running times\n",
    "    start = time.time()\n",
    "    model.fit([traits_BM_train, xtrain], ytrain, batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=([traits_BM_test, xtest], ytest),callbacks=[earlyStopping])\n",
    "    print (f'Time: {time.time() - start}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# function to train on the SNP only datasets\n",
    "def SNP_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test):\n",
    "    # convert labels to a categorical matrix of binary values (0 or 1). The number of rows is the length of the input vector (number of simulations) and the number of columns is the number of classes (3 scenarios).\n",
    "    ytest = np_utils.to_categorical(ytest, num_classes)\n",
    "    ytrain = np_utils.to_categorical(ytrain, num_classes)\n",
    "    # reshape the traits matrices to input them into the MLP\n",
    "    traits_BM_train=traits_BM_train.reshape((traits_BM_train.shape[0], (traits_BM_train.shape[1]*traits_BM_train.shape[2])))\n",
    "    traits_BM_test=traits_BM_test.reshape((traits_BM_test.shape[0], (traits_BM_test.shape[1]*traits_BM_test.shape[2])))\n",
    "    # Create the MLP, the CNN and the combined models\n",
    "    mlp = create_mlp(traits_BM_train)\n",
    "    cnn = create_cnn(xtest)\n",
    "    combinedInput = LinearW()([mlp.output, cnn.output])\n",
    "    \n",
    "    #Create the last layer for the SNP network\n",
    "    xCNN = Dense(num_classes, activation=\"softmax\")(cnn.output)\n",
    "    model = Model(inputs=cnn.input, outputs=xCNN)\n",
    "\n",
    "    # using Stochastic Gradient Descent as optimizer and a categorical cross-entropy loss function\n",
    "    opt = SGD(learning_rate=0.001)\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    # save only the epoch with the highest accuracy in the validation set, by using the model checkpoint\n",
    "    earlyStopping = EarlyStopping(monitor='val_accuracy', patience=150, verbose=0, mode='max', restore_best_weights=True)\n",
    "\n",
    "    # fit the model and record running times\n",
    "    start = time.time()\n",
    "    model.fit(xtrain, ytrain, batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(xtest, ytest),callbacks=[earlyStopping])\n",
    "    print (f'Time: {time.time() - start}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# function to train on the BM trait only datasets\n",
    "def BM_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test):\n",
    "    # convert labels to a categorical matrix of binary values (0 or 1). The number of rows is the length of the input vector (number of simulations) and the number of columns is the number of classes (3 scenarios).\n",
    "    ytest = np_utils.to_categorical(ytest, num_classes)\n",
    "    ytrain = np_utils.to_categorical(ytrain, num_classes)\n",
    "    # reshape the traits matrices to input them into the MLP\n",
    "    traits_BM_train=traits_BM_train.reshape((traits_BM_train.shape[0], (traits_BM_train.shape[1]*traits_BM_train.shape[2])))\n",
    "    traits_BM_test=traits_BM_test.reshape((traits_BM_test.shape[0], (traits_BM_test.shape[1]*traits_BM_test.shape[2])))\n",
    "    mlp = create_mlp(traits_BM_train)\n",
    "    #Create the last layer for the traits network\n",
    "    xMLP = Dense(num_classes, activation=\"softmax\")(mlp.output)\n",
    "    model = Model(inputs=mlp.input, outputs=xMLP)\n",
    "\n",
    "    # using Stochastic Gradient Descent as optimizer and a categorical cross-entropy loss function\n",
    "    opt = SGD(learning_rate=0.001)\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    # save only the epoch with the highest accuracy in the validation set, by using the model checkpoint\n",
    "    earlyStopping = EarlyStopping(monitor='val_accuracy', patience=150, verbose=0, mode='max', restore_best_weights=True)\n",
    "    # fit the model and record running times\n",
    "    start = time.time()\n",
    "    model.fit(traits_BM_train, ytrain, batch_size=batch_size,\n",
    "          epochs=epochs_traits,\n",
    "          verbose=1,\n",
    "          validation_data=(traits_BM_test, ytest),callbacks=[earlyStopping])\n",
    "    print (f'Time: {time.time() - start}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJgkHTL9Tddn",
    "outputId": "866e837e-0e7e-4f96-e10b-349e252d23bd",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1000, 60)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 998, 250)     45000       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 998, 250)    1000        ['conv1d[0][0]']                 \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 996, 250)     187500      ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 996, 250)    1000        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 994, 250)     187500      ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 994, 250)    1000        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 331, 250)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 82750)        0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " dense_input (InputLayer)       [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 125)          10343875    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 150)          450000      ['dense_input[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 125)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 150)         600         ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 125)          15750       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 150)          22500       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 125)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 150)         600         ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 50)           6300        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 50)           7550        ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 50)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " linear_w (LinearW)             (None, 50)           2           ['dense_2[0][0]',                \n",
      "                                                                  'activation[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 50)           2550        ['linear_w[0][0]']               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 3)            153         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,272,880\n",
      "Trainable params: 11,270,780\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 15s 124ms/step - loss: 13.1051 - accuracy: 0.4040 - val_loss: 13.0407 - val_accuracy: 0.4720\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.8737 - accuracy: 0.5404 - val_loss: 12.8509 - val_accuracy: 0.6559\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.7240 - accuracy: 0.6219 - val_loss: 12.6474 - val_accuracy: 0.7023\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.5993 - accuracy: 0.6755 - val_loss: 12.4839 - val_accuracy: 0.7244\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.4936 - accuracy: 0.7102 - val_loss: 12.3609 - val_accuracy: 0.7604\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.3762 - accuracy: 0.7570 - val_loss: 12.2182 - val_accuracy: 0.8180\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.2612 - accuracy: 0.7965 - val_loss: 12.0952 - val_accuracy: 0.8667\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.1447 - accuracy: 0.8339 - val_loss: 11.9610 - val_accuracy: 0.9173\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.0389 - accuracy: 0.8679 - val_loss: 11.8614 - val_accuracy: 0.9416\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.9465 - accuracy: 0.8909 - val_loss: 11.7655 - val_accuracy: 0.9620\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.8607 - accuracy: 0.9091 - val_loss: 11.6924 - val_accuracy: 0.9705\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.7708 - accuracy: 0.9302 - val_loss: 11.6228 - val_accuracy: 0.9787\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.7024 - accuracy: 0.9418 - val_loss: 11.5636 - val_accuracy: 0.9836\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 11.6392 - accuracy: 0.9479 - val_loss: 11.5091 - val_accuracy: 0.9871\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.5734 - accuracy: 0.9573 - val_loss: 11.4588 - val_accuracy: 0.9880\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.5144 - accuracy: 0.9627 - val_loss: 11.4076 - val_accuracy: 0.9916\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.4622 - accuracy: 0.9672 - val_loss: 11.3625 - val_accuracy: 0.9917\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.4078 - accuracy: 0.9714 - val_loss: 11.3166 - val_accuracy: 0.9925\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 11.3604 - accuracy: 0.9729 - val_loss: 11.2709 - val_accuracy: 0.9940\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.3106 - accuracy: 0.9738 - val_loss: 11.2249 - val_accuracy: 0.9955\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.2609 - accuracy: 0.9772 - val_loss: 11.1813 - val_accuracy: 0.9956\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.2103 - accuracy: 0.9805 - val_loss: 11.1395 - val_accuracy: 0.9955\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.1668 - accuracy: 0.9810 - val_loss: 11.0944 - val_accuracy: 0.9968\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.1224 - accuracy: 0.9824 - val_loss: 11.0527 - val_accuracy: 0.9968\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.0738 - accuracy: 0.9854 - val_loss: 11.0105 - val_accuracy: 0.9971\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.0292 - accuracy: 0.9856 - val_loss: 10.9691 - val_accuracy: 0.9969\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.9877 - accuracy: 0.9854 - val_loss: 10.9266 - val_accuracy: 0.9975\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.9427 - accuracy: 0.9872 - val_loss: 10.8862 - val_accuracy: 0.9973\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.8997 - accuracy: 0.9876 - val_loss: 10.8450 - val_accuracy: 0.9972\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.8578 - accuracy: 0.9885 - val_loss: 10.8023 - val_accuracy: 0.9979\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.8172 - accuracy: 0.9871 - val_loss: 10.7612 - val_accuracy: 0.9980\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.7705 - accuracy: 0.9899 - val_loss: 10.7207 - val_accuracy: 0.9979\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.7293 - accuracy: 0.9894 - val_loss: 10.6795 - val_accuracy: 0.9980\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.6862 - accuracy: 0.9898 - val_loss: 10.6388 - val_accuracy: 0.9981\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.6458 - accuracy: 0.9911 - val_loss: 10.5991 - val_accuracy: 0.9980\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.6064 - accuracy: 0.9904 - val_loss: 10.5599 - val_accuracy: 0.9975\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.5641 - accuracy: 0.9908 - val_loss: 10.5183 - val_accuracy: 0.9977\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.5217 - accuracy: 0.9924 - val_loss: 10.4780 - val_accuracy: 0.9979\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.4799 - accuracy: 0.9933 - val_loss: 10.4373 - val_accuracy: 0.9983\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.4397 - accuracy: 0.9925 - val_loss: 10.3980 - val_accuracy: 0.9981\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.3974 - accuracy: 0.9930 - val_loss: 10.3573 - val_accuracy: 0.9983\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.3591 - accuracy: 0.9932 - val_loss: 10.3174 - val_accuracy: 0.9981\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.3168 - accuracy: 0.9936 - val_loss: 10.2769 - val_accuracy: 0.9987\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.2787 - accuracy: 0.9934 - val_loss: 10.2381 - val_accuracy: 0.9984\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.2370 - accuracy: 0.9932 - val_loss: 10.1987 - val_accuracy: 0.9984\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.1968 - accuracy: 0.9943 - val_loss: 10.1585 - val_accuracy: 0.9987\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.1565 - accuracy: 0.9945 - val_loss: 10.1193 - val_accuracy: 0.9987\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.1170 - accuracy: 0.9941 - val_loss: 10.0811 - val_accuracy: 0.9984\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.0772 - accuracy: 0.9942 - val_loss: 10.0410 - val_accuracy: 0.9985\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.0389 - accuracy: 0.9939 - val_loss: 10.0017 - val_accuracy: 0.9988\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.9979 - accuracy: 0.9954 - val_loss: 9.9632 - val_accuracy: 0.9987\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.9586 - accuracy: 0.9951 - val_loss: 9.9245 - val_accuracy: 0.9985\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.9188 - accuracy: 0.9956 - val_loss: 9.8852 - val_accuracy: 0.9988\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.8810 - accuracy: 0.9950 - val_loss: 9.8468 - val_accuracy: 0.9984\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.8403 - accuracy: 0.9955 - val_loss: 9.8076 - val_accuracy: 0.9991\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.8014 - accuracy: 0.9956 - val_loss: 9.7695 - val_accuracy: 0.9987\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.7644 - accuracy: 0.9955 - val_loss: 9.7307 - val_accuracy: 0.9989\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.7250 - accuracy: 0.9952 - val_loss: 9.6918 - val_accuracy: 0.9992\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.6873 - accuracy: 0.9955 - val_loss: 9.6533 - val_accuracy: 0.9992\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.6492 - accuracy: 0.9950 - val_loss: 9.6162 - val_accuracy: 0.9988\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.6084 - accuracy: 0.9965 - val_loss: 9.5778 - val_accuracy: 0.9989\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.5706 - accuracy: 0.9963 - val_loss: 9.5391 - val_accuracy: 0.9992\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.5315 - accuracy: 0.9964 - val_loss: 9.5009 - val_accuracy: 0.9993\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.4941 - accuracy: 0.9963 - val_loss: 9.4635 - val_accuracy: 0.9992\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.4563 - accuracy: 0.9963 - val_loss: 9.4255 - val_accuracy: 0.9992\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.4178 - accuracy: 0.9964 - val_loss: 9.3884 - val_accuracy: 0.9992\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.3801 - accuracy: 0.9964 - val_loss: 9.3509 - val_accuracy: 0.9989\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.3421 - accuracy: 0.9967 - val_loss: 9.3130 - val_accuracy: 0.9992\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.3043 - accuracy: 0.9966 - val_loss: 9.2759 - val_accuracy: 0.9991\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.2683 - accuracy: 0.9961 - val_loss: 9.2387 - val_accuracy: 0.9989\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.2288 - accuracy: 0.9971 - val_loss: 9.2007 - val_accuracy: 0.9993\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.1931 - accuracy: 0.9968 - val_loss: 9.1632 - val_accuracy: 0.9993\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.1549 - accuracy: 0.9968 - val_loss: 9.1255 - val_accuracy: 0.9997\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.1178 - accuracy: 0.9972 - val_loss: 9.0898 - val_accuracy: 0.9992\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.0793 - accuracy: 0.9973 - val_loss: 9.0521 - val_accuracy: 0.9993\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.0424 - accuracy: 0.9977 - val_loss: 9.0151 - val_accuracy: 0.9993\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.0058 - accuracy: 0.9973 - val_loss: 8.9788 - val_accuracy: 0.9993\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.9681 - accuracy: 0.9980 - val_loss: 8.9427 - val_accuracy: 0.9992\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.9312 - accuracy: 0.9978 - val_loss: 8.9058 - val_accuracy: 0.9993\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.8956 - accuracy: 0.9974 - val_loss: 8.8697 - val_accuracy: 0.9993\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.8604 - accuracy: 0.9970 - val_loss: 8.8324 - val_accuracy: 0.9993\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.8225 - accuracy: 0.9977 - val_loss: 8.7967 - val_accuracy: 0.9993\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.7867 - accuracy: 0.9972 - val_loss: 8.7607 - val_accuracy: 0.9993\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.7514 - accuracy: 0.9970 - val_loss: 8.7237 - val_accuracy: 0.9993\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.7136 - accuracy: 0.9978 - val_loss: 8.6888 - val_accuracy: 0.9992\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.6778 - accuracy: 0.9976 - val_loss: 8.6525 - val_accuracy: 0.9993\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.6411 - accuracy: 0.9980 - val_loss: 8.6166 - val_accuracy: 0.9993\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.6050 - accuracy: 0.9980 - val_loss: 8.5808 - val_accuracy: 0.9993\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.5684 - accuracy: 0.9979 - val_loss: 8.5449 - val_accuracy: 0.9993\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.5340 - accuracy: 0.9979 - val_loss: 8.5090 - val_accuracy: 0.9993\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.4983 - accuracy: 0.9980 - val_loss: 8.4741 - val_accuracy: 0.9993\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.4620 - accuracy: 0.9976 - val_loss: 8.4385 - val_accuracy: 0.9993\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.4269 - accuracy: 0.9979 - val_loss: 8.4025 - val_accuracy: 0.9993\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.3910 - accuracy: 0.9978 - val_loss: 8.3683 - val_accuracy: 0.9989\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.3565 - accuracy: 0.9975 - val_loss: 8.3322 - val_accuracy: 0.9993\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.3208 - accuracy: 0.9980 - val_loss: 8.2972 - val_accuracy: 0.9993\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.2854 - accuracy: 0.9980 - val_loss: 8.2628 - val_accuracy: 0.9993\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.2505 - accuracy: 0.9983 - val_loss: 8.2277 - val_accuracy: 0.9993\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.2164 - accuracy: 0.9976 - val_loss: 8.1926 - val_accuracy: 0.9993\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.1798 - accuracy: 0.9987 - val_loss: 8.1579 - val_accuracy: 0.9993\n",
      "Time: 1039.7050700187683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 16:11:12.274724: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_100BM_1KSNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#Combined 100 BM, 1K SNPs\n",
    "################################################################################################################################################\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test  = train_test_split(y,X,traits_BM,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_BM_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_100BM_1KSNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fx3iXPj0Y_n4",
    "outputId": "e9d49bec-9d9b-4c56-adce-19aea5f35b6d",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1000, 60)]        0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 998, 250)          45000     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 998, 250)         1000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 996, 250)          187500    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 996, 250)         1000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 994, 250)          187500    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 994, 250)         1000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 331, 250)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 82750)             0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 125)               10343875  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 125)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 125)               15750     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 125)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                6300      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,789,078\n",
      "Trainable params: 10,787,578\n",
      "Non-trainable params: 1,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 12s 120ms/step - loss: 1.0959 - accuracy: 0.4847 - val_loss: 0.9545 - val_accuracy: 0.6260\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.8360 - accuracy: 0.6184 - val_loss: 0.8666 - val_accuracy: 0.5484\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.6706 - accuracy: 0.7044 - val_loss: 0.7034 - val_accuracy: 0.7131\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.5176 - accuracy: 0.7912 - val_loss: 0.4405 - val_accuracy: 0.8595\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.3877 - accuracy: 0.8503 - val_loss: 0.1986 - val_accuracy: 0.9611\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.2911 - accuracy: 0.8917 - val_loss: 0.1008 - val_accuracy: 0.9824\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.2258 - accuracy: 0.9204 - val_loss: 0.0657 - val_accuracy: 0.9856\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.1796 - accuracy: 0.9365 - val_loss: 0.0429 - val_accuracy: 0.9899\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.1515 - accuracy: 0.9496 - val_loss: 0.0312 - val_accuracy: 0.9925\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.1267 - accuracy: 0.9588 - val_loss: 0.0262 - val_accuracy: 0.9935\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 0.1080 - accuracy: 0.9652 - val_loss: 0.0223 - val_accuracy: 0.9941\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.1003 - accuracy: 0.9660 - val_loss: 0.0185 - val_accuracy: 0.9956\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0878 - accuracy: 0.9716 - val_loss: 0.0160 - val_accuracy: 0.9957\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0790 - accuracy: 0.9731 - val_loss: 0.0162 - val_accuracy: 0.9953\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0696 - accuracy: 0.9769 - val_loss: 0.0123 - val_accuracy: 0.9967\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0659 - accuracy: 0.9780 - val_loss: 0.0116 - val_accuracy: 0.9967\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0612 - accuracy: 0.9802 - val_loss: 0.0120 - val_accuracy: 0.9963\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0575 - accuracy: 0.9810 - val_loss: 0.0115 - val_accuracy: 0.9964\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0553 - accuracy: 0.9809 - val_loss: 0.0112 - val_accuracy: 0.9964\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0478 - accuracy: 0.9845 - val_loss: 0.0090 - val_accuracy: 0.9968\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0425 - accuracy: 0.9865 - val_loss: 0.0090 - val_accuracy: 0.9965\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0413 - accuracy: 0.9868 - val_loss: 0.0081 - val_accuracy: 0.9975\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0399 - accuracy: 0.9878 - val_loss: 0.0075 - val_accuracy: 0.9980\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0395 - accuracy: 0.9880 - val_loss: 0.0079 - val_accuracy: 0.9975\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0355 - accuracy: 0.9886 - val_loss: 0.0080 - val_accuracy: 0.9971\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0354 - accuracy: 0.9884 - val_loss: 0.0068 - val_accuracy: 0.9979\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0324 - accuracy: 0.9902 - val_loss: 0.0076 - val_accuracy: 0.9972\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0314 - accuracy: 0.9894 - val_loss: 0.0054 - val_accuracy: 0.9977\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 0.0068 - val_accuracy: 0.9976\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 0.0050 - val_accuracy: 0.9983\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0273 - accuracy: 0.9915 - val_loss: 0.0060 - val_accuracy: 0.9979\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0257 - accuracy: 0.9919 - val_loss: 0.0069 - val_accuracy: 0.9977\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0244 - accuracy: 0.9925 - val_loss: 0.0052 - val_accuracy: 0.9980\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.0051 - val_accuracy: 0.9980\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0230 - accuracy: 0.9931 - val_loss: 0.0058 - val_accuracy: 0.9979\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 0.0047 - val_accuracy: 0.9983\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 0.0045 - val_accuracy: 0.9984\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0220 - accuracy: 0.9930 - val_loss: 0.0050 - val_accuracy: 0.9983\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.0054 - val_accuracy: 0.9983\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 0.0037 - val_accuracy: 0.9988\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.0043 - val_accuracy: 0.9985\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.0051 - val_accuracy: 0.9981\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.0041 - val_accuracy: 0.9983\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0161 - accuracy: 0.9955 - val_loss: 0.0046 - val_accuracy: 0.9985\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 0.0050 - val_accuracy: 0.9983\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0156 - accuracy: 0.9955 - val_loss: 0.0035 - val_accuracy: 0.9989\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.0035 - val_accuracy: 0.9989\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.0042 - val_accuracy: 0.9987\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.0055 - val_accuracy: 0.9983\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0039 - val_accuracy: 0.9988\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0115 - accuracy: 0.9972 - val_loss: 0.0052 - val_accuracy: 0.9984\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0042 - val_accuracy: 0.9984\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.0042 - val_accuracy: 0.9985\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 0.0037 - val_accuracy: 0.9988\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.0042 - val_accuracy: 0.9984\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.0037 - val_accuracy: 0.9988\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0031 - val_accuracy: 0.9989\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0035 - val_accuracy: 0.9989\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0042 - val_accuracy: 0.9985\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0043 - val_accuracy: 0.9989\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.0028 - val_accuracy: 0.9993\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.0036 - val_accuracy: 0.9991\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.0036 - val_accuracy: 0.9991\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.0036 - val_accuracy: 0.9991\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0038 - val_accuracy: 0.9988\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.0039 - val_accuracy: 0.9989\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.0034 - val_accuracy: 0.9992\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.0029 - val_accuracy: 0.9992\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0034 - val_accuracy: 0.9987\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.0029 - val_accuracy: 0.9987\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0031 - val_accuracy: 0.9992\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0031 - val_accuracy: 0.9992\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.0031 - val_accuracy: 0.9992\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.0025 - val_accuracy: 0.9992\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0034 - val_accuracy: 0.9992\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.0029 - val_accuracy: 0.9992\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.0023 - val_accuracy: 0.9993\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0032 - val_accuracy: 0.9992\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.0031 - val_accuracy: 0.9992\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.0034 - val_accuracy: 0.9989\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.0032 - val_accuracy: 0.9989\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.0038 - val_accuracy: 0.9989\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0033 - val_accuracy: 0.9992\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.0032 - val_accuracy: 0.9992\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.0033 - val_accuracy: 0.9992\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0029 - val_accuracy: 0.9992\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0034 - val_accuracy: 0.9992\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 10s 112ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.0027 - val_accuracy: 0.9993\n",
      "Time: 1016.9153969287872\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_CNN_Model_1KSNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#1K SNPs only\n",
    "################################################################################################################################################\n",
    "# now repeat the analysis only for SNPs\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test  = train_test_split(y,X,traits_BM,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = SNP_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_CNN_Model_1KSNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xtQ2E4REN6GI",
    "outputId": "f8cbca89-08e3-4a4e-ea19-ac5f3ad16128",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15_input (InputLayer)  [(None, 3000)]           0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 150)               450000    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 150)               22500     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 50)                7550      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 481,403\n",
      "Trainable params: 480,803\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 13.4918 - accuracy: 0.3445 - val_loss: 13.2501 - val_accuracy: 0.3596\n",
      "Epoch 2/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.2763 - accuracy: 0.3953 - val_loss: 13.1496 - val_accuracy: 0.4080\n",
      "Epoch 3/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.1196 - accuracy: 0.4372 - val_loss: 13.0529 - val_accuracy: 0.4456\n",
      "Epoch 4/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.9948 - accuracy: 0.4730 - val_loss: 12.9631 - val_accuracy: 0.4779\n",
      "Epoch 5/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.8946 - accuracy: 0.5032 - val_loss: 12.8818 - val_accuracy: 0.5003\n",
      "Epoch 6/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.8066 - accuracy: 0.5280 - val_loss: 12.8078 - val_accuracy: 0.5176\n",
      "Epoch 7/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.7297 - accuracy: 0.5438 - val_loss: 12.7397 - val_accuracy: 0.5297\n",
      "Epoch 8/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.6592 - accuracy: 0.5604 - val_loss: 12.6756 - val_accuracy: 0.5372\n",
      "Epoch 9/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.5908 - accuracy: 0.5719 - val_loss: 12.6148 - val_accuracy: 0.5471\n",
      "Epoch 10/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.5253 - accuracy: 0.5868 - val_loss: 12.5562 - val_accuracy: 0.5548\n",
      "Epoch 11/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.4624 - accuracy: 0.5967 - val_loss: 12.4996 - val_accuracy: 0.5580\n",
      "Epoch 12/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.4038 - accuracy: 0.6056 - val_loss: 12.4445 - val_accuracy: 0.5639\n",
      "Epoch 13/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.3438 - accuracy: 0.6108 - val_loss: 12.3907 - val_accuracy: 0.5675\n",
      "Epoch 14/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.2862 - accuracy: 0.6213 - val_loss: 12.3382 - val_accuracy: 0.5727\n",
      "Epoch 15/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.2303 - accuracy: 0.6286 - val_loss: 12.2865 - val_accuracy: 0.5753\n",
      "Epoch 16/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.1738 - accuracy: 0.6360 - val_loss: 12.2359 - val_accuracy: 0.5773\n",
      "Epoch 17/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.1198 - accuracy: 0.6406 - val_loss: 12.1858 - val_accuracy: 0.5823\n",
      "Epoch 18/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.0660 - accuracy: 0.6492 - val_loss: 12.1363 - val_accuracy: 0.5844\n",
      "Epoch 19/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.0135 - accuracy: 0.6531 - val_loss: 12.0873 - val_accuracy: 0.5879\n",
      "Epoch 20/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.9605 - accuracy: 0.6621 - val_loss: 12.0390 - val_accuracy: 0.5897\n",
      "Epoch 21/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.9093 - accuracy: 0.6656 - val_loss: 11.9913 - val_accuracy: 0.5925\n",
      "Epoch 22/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.8587 - accuracy: 0.6720 - val_loss: 11.9441 - val_accuracy: 0.5951\n",
      "Epoch 23/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.8074 - accuracy: 0.6764 - val_loss: 11.8969 - val_accuracy: 0.5973\n",
      "Epoch 24/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.7577 - accuracy: 0.6807 - val_loss: 11.8504 - val_accuracy: 0.5996\n",
      "Epoch 25/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.7072 - accuracy: 0.6841 - val_loss: 11.8041 - val_accuracy: 0.6011\n",
      "Epoch 26/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.6579 - accuracy: 0.6928 - val_loss: 11.7584 - val_accuracy: 0.6017\n",
      "Epoch 27/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.6079 - accuracy: 0.6980 - val_loss: 11.7129 - val_accuracy: 0.6033\n",
      "Epoch 28/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.5586 - accuracy: 0.7014 - val_loss: 11.6677 - val_accuracy: 0.6036\n",
      "Epoch 29/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.5107 - accuracy: 0.7061 - val_loss: 11.6226 - val_accuracy: 0.6053\n",
      "Epoch 30/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.4626 - accuracy: 0.7116 - val_loss: 11.5778 - val_accuracy: 0.6065\n",
      "Epoch 31/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.4147 - accuracy: 0.7114 - val_loss: 11.5334 - val_accuracy: 0.6076\n",
      "Epoch 32/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.3671 - accuracy: 0.7168 - val_loss: 11.4892 - val_accuracy: 0.6087\n",
      "Epoch 33/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.3191 - accuracy: 0.7256 - val_loss: 11.4451 - val_accuracy: 0.6093\n",
      "Epoch 34/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.2720 - accuracy: 0.7254 - val_loss: 11.4015 - val_accuracy: 0.6104\n",
      "Epoch 35/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.2254 - accuracy: 0.7303 - val_loss: 11.3580 - val_accuracy: 0.6115\n",
      "Epoch 36/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.1773 - accuracy: 0.7366 - val_loss: 11.3146 - val_accuracy: 0.6145\n",
      "Epoch 37/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.1300 - accuracy: 0.7420 - val_loss: 11.2715 - val_accuracy: 0.6147\n",
      "Epoch 38/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.0851 - accuracy: 0.7424 - val_loss: 11.2285 - val_accuracy: 0.6173\n",
      "Epoch 39/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.0373 - accuracy: 0.7476 - val_loss: 11.1858 - val_accuracy: 0.6187\n",
      "Epoch 40/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.9921 - accuracy: 0.7504 - val_loss: 11.1432 - val_accuracy: 0.6205\n",
      "Epoch 41/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.9477 - accuracy: 0.7556 - val_loss: 11.1008 - val_accuracy: 0.6221\n",
      "Epoch 42/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.9011 - accuracy: 0.7606 - val_loss: 11.0585 - val_accuracy: 0.6235\n",
      "Epoch 43/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.8543 - accuracy: 0.7640 - val_loss: 11.0165 - val_accuracy: 0.6253\n",
      "Epoch 44/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.8099 - accuracy: 0.7686 - val_loss: 10.9747 - val_accuracy: 0.6255\n",
      "Epoch 45/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.7647 - accuracy: 0.7710 - val_loss: 10.9327 - val_accuracy: 0.6256\n",
      "Epoch 46/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.7191 - accuracy: 0.7762 - val_loss: 10.8911 - val_accuracy: 0.6268\n",
      "Epoch 47/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.6748 - accuracy: 0.7796 - val_loss: 10.8500 - val_accuracy: 0.6284\n",
      "Epoch 48/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.6293 - accuracy: 0.7824 - val_loss: 10.8085 - val_accuracy: 0.6305\n",
      "Epoch 49/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.5836 - accuracy: 0.7870 - val_loss: 10.7676 - val_accuracy: 0.6312\n",
      "Epoch 50/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.5396 - accuracy: 0.7897 - val_loss: 10.7265 - val_accuracy: 0.6324\n",
      "Epoch 51/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.4965 - accuracy: 0.7921 - val_loss: 10.6856 - val_accuracy: 0.6333\n",
      "Epoch 52/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.4514 - accuracy: 0.7950 - val_loss: 10.6451 - val_accuracy: 0.6343\n",
      "Epoch 53/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.4082 - accuracy: 0.7982 - val_loss: 10.6047 - val_accuracy: 0.6349\n",
      "Epoch 54/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.3637 - accuracy: 0.8021 - val_loss: 10.5643 - val_accuracy: 0.6355\n",
      "Epoch 55/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.3196 - accuracy: 0.8077 - val_loss: 10.5238 - val_accuracy: 0.6373\n",
      "Epoch 56/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.2769 - accuracy: 0.8084 - val_loss: 10.4839 - val_accuracy: 0.6391\n",
      "Epoch 57/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.2328 - accuracy: 0.8136 - val_loss: 10.4442 - val_accuracy: 0.6400\n",
      "Epoch 58/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.1902 - accuracy: 0.8161 - val_loss: 10.4042 - val_accuracy: 0.6419\n",
      "Epoch 59/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.1462 - accuracy: 0.8195 - val_loss: 10.3644 - val_accuracy: 0.6435\n",
      "Epoch 60/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.1029 - accuracy: 0.8214 - val_loss: 10.3247 - val_accuracy: 0.6437\n",
      "Epoch 61/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.0599 - accuracy: 0.8270 - val_loss: 10.2852 - val_accuracy: 0.6440\n",
      "Epoch 62/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.0169 - accuracy: 0.8292 - val_loss: 10.2459 - val_accuracy: 0.6455\n",
      "Epoch 63/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.9713 - accuracy: 0.8346 - val_loss: 10.2064 - val_accuracy: 0.6469\n",
      "Epoch 64/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.9289 - accuracy: 0.8353 - val_loss: 10.1675 - val_accuracy: 0.6475\n",
      "Epoch 65/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.8869 - accuracy: 0.8400 - val_loss: 10.1283 - val_accuracy: 0.6479\n",
      "Epoch 66/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.8459 - accuracy: 0.8412 - val_loss: 10.0895 - val_accuracy: 0.6492\n",
      "Epoch 67/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.8028 - accuracy: 0.8452 - val_loss: 10.0505 - val_accuracy: 0.6508\n",
      "Epoch 68/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.7607 - accuracy: 0.8482 - val_loss: 10.0117 - val_accuracy: 0.6521\n",
      "Epoch 69/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.7173 - accuracy: 0.8522 - val_loss: 9.9729 - val_accuracy: 0.6533\n",
      "Epoch 70/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.6752 - accuracy: 0.8534 - val_loss: 9.9344 - val_accuracy: 0.6547\n",
      "Epoch 71/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.6333 - accuracy: 0.8558 - val_loss: 9.8961 - val_accuracy: 0.6561\n",
      "Epoch 72/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.5916 - accuracy: 0.8613 - val_loss: 9.8578 - val_accuracy: 0.6567\n",
      "Epoch 73/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.5496 - accuracy: 0.8626 - val_loss: 9.8198 - val_accuracy: 0.6580\n",
      "Epoch 74/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.5085 - accuracy: 0.8660 - val_loss: 9.7816 - val_accuracy: 0.6588\n",
      "Epoch 75/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.4666 - accuracy: 0.8677 - val_loss: 9.7435 - val_accuracy: 0.6603\n",
      "Epoch 76/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.4248 - accuracy: 0.8726 - val_loss: 9.7058 - val_accuracy: 0.6608\n",
      "Epoch 77/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.3836 - accuracy: 0.8746 - val_loss: 9.6678 - val_accuracy: 0.6621\n",
      "Epoch 78/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.3442 - accuracy: 0.8745 - val_loss: 9.6301 - val_accuracy: 0.6621\n",
      "Epoch 79/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.3015 - accuracy: 0.8786 - val_loss: 9.5926 - val_accuracy: 0.6624\n",
      "Epoch 80/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.2607 - accuracy: 0.8796 - val_loss: 9.5553 - val_accuracy: 0.6636\n",
      "Epoch 81/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.2198 - accuracy: 0.8823 - val_loss: 9.5179 - val_accuracy: 0.6643\n",
      "Epoch 82/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.1768 - accuracy: 0.8904 - val_loss: 9.4809 - val_accuracy: 0.6656\n",
      "Epoch 83/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.1377 - accuracy: 0.8885 - val_loss: 9.4440 - val_accuracy: 0.6680\n",
      "Epoch 84/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.0981 - accuracy: 0.8907 - val_loss: 9.4069 - val_accuracy: 0.6684\n",
      "Epoch 85/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.0565 - accuracy: 0.8953 - val_loss: 9.3700 - val_accuracy: 0.6689\n",
      "Epoch 86/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.0157 - accuracy: 0.8967 - val_loss: 9.3333 - val_accuracy: 0.6703\n",
      "Epoch 87/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.9759 - accuracy: 0.9014 - val_loss: 9.2965 - val_accuracy: 0.6711\n",
      "Epoch 88/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.9335 - accuracy: 0.9029 - val_loss: 9.2602 - val_accuracy: 0.6715\n",
      "Epoch 89/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.8936 - accuracy: 0.9039 - val_loss: 9.2237 - val_accuracy: 0.6725\n",
      "Epoch 90/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.8543 - accuracy: 0.9076 - val_loss: 9.1874 - val_accuracy: 0.6736\n",
      "Epoch 91/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.8148 - accuracy: 0.9095 - val_loss: 9.1510 - val_accuracy: 0.6739\n",
      "Epoch 92/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.7762 - accuracy: 0.9102 - val_loss: 9.1150 - val_accuracy: 0.6751\n",
      "Epoch 93/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.7358 - accuracy: 0.9134 - val_loss: 9.0786 - val_accuracy: 0.6749\n",
      "Epoch 94/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.6958 - accuracy: 0.9165 - val_loss: 9.0426 - val_accuracy: 0.6765\n",
      "Epoch 95/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.6561 - accuracy: 0.9182 - val_loss: 9.0067 - val_accuracy: 0.6760\n",
      "Epoch 96/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.6188 - accuracy: 0.9187 - val_loss: 8.9712 - val_accuracy: 0.6776\n",
      "Epoch 97/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.5785 - accuracy: 0.9219 - val_loss: 8.9352 - val_accuracy: 0.6803\n",
      "Epoch 98/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.5400 - accuracy: 0.9237 - val_loss: 8.9001 - val_accuracy: 0.6803\n",
      "Epoch 99/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.5005 - accuracy: 0.9283 - val_loss: 8.8646 - val_accuracy: 0.6816\n",
      "Epoch 100/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.4611 - accuracy: 0.9287 - val_loss: 8.8293 - val_accuracy: 0.6828\n",
      "Epoch 101/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.4214 - accuracy: 0.9306 - val_loss: 8.7939 - val_accuracy: 0.6823\n",
      "Epoch 102/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.3839 - accuracy: 0.9327 - val_loss: 8.7585 - val_accuracy: 0.6840\n",
      "Epoch 103/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.3450 - accuracy: 0.9333 - val_loss: 8.7234 - val_accuracy: 0.6853\n",
      "Epoch 104/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.3074 - accuracy: 0.9356 - val_loss: 8.6882 - val_accuracy: 0.6861\n",
      "Epoch 105/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.2688 - accuracy: 0.9368 - val_loss: 8.6539 - val_accuracy: 0.6873\n",
      "Epoch 106/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.2305 - accuracy: 0.9400 - val_loss: 8.6189 - val_accuracy: 0.6883\n",
      "Epoch 107/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.1928 - accuracy: 0.9409 - val_loss: 8.5844 - val_accuracy: 0.6905\n",
      "Epoch 108/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.1557 - accuracy: 0.9428 - val_loss: 8.5498 - val_accuracy: 0.6917\n",
      "Epoch 109/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.1159 - accuracy: 0.9467 - val_loss: 8.5152 - val_accuracy: 0.6925\n",
      "Epoch 110/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.0801 - accuracy: 0.9473 - val_loss: 8.4807 - val_accuracy: 0.6933\n",
      "Epoch 111/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.0416 - accuracy: 0.9487 - val_loss: 8.4459 - val_accuracy: 0.6951\n",
      "Epoch 112/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.0037 - accuracy: 0.9504 - val_loss: 8.4116 - val_accuracy: 0.6960\n",
      "Epoch 113/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9641 - accuracy: 0.9538 - val_loss: 8.3774 - val_accuracy: 0.6976\n",
      "Epoch 114/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9286 - accuracy: 0.9555 - val_loss: 8.3437 - val_accuracy: 0.6985\n",
      "Epoch 115/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.8920 - accuracy: 0.9559 - val_loss: 8.3099 - val_accuracy: 0.7000\n",
      "Epoch 116/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.8553 - accuracy: 0.9576 - val_loss: 8.2755 - val_accuracy: 0.7001\n",
      "Epoch 117/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.8175 - accuracy: 0.9592 - val_loss: 8.2421 - val_accuracy: 0.7016\n",
      "Epoch 118/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.7817 - accuracy: 0.9585 - val_loss: 8.2080 - val_accuracy: 0.7031\n",
      "Epoch 119/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.7442 - accuracy: 0.9616 - val_loss: 8.1741 - val_accuracy: 0.7040\n",
      "Epoch 120/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.7075 - accuracy: 0.9637 - val_loss: 8.1402 - val_accuracy: 0.7049\n",
      "Epoch 121/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.6722 - accuracy: 0.9641 - val_loss: 8.1065 - val_accuracy: 0.7059\n",
      "Epoch 122/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.6357 - accuracy: 0.9648 - val_loss: 8.0733 - val_accuracy: 0.7079\n",
      "Epoch 123/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.6009 - accuracy: 0.9647 - val_loss: 8.0401 - val_accuracy: 0.7080\n",
      "Epoch 124/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.5637 - accuracy: 0.9674 - val_loss: 8.0066 - val_accuracy: 0.7088\n",
      "Epoch 125/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.5266 - accuracy: 0.9690 - val_loss: 7.9738 - val_accuracy: 0.7099\n",
      "Epoch 126/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4901 - accuracy: 0.9702 - val_loss: 7.9408 - val_accuracy: 0.7116\n",
      "Epoch 127/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4552 - accuracy: 0.9699 - val_loss: 7.9078 - val_accuracy: 0.7113\n",
      "Epoch 128/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4193 - accuracy: 0.9731 - val_loss: 7.8753 - val_accuracy: 0.7129\n",
      "Epoch 129/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.3842 - accuracy: 0.9744 - val_loss: 7.8422 - val_accuracy: 0.7129\n",
      "Epoch 130/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.3496 - accuracy: 0.9744 - val_loss: 7.8097 - val_accuracy: 0.7149\n",
      "Epoch 131/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.3138 - accuracy: 0.9760 - val_loss: 7.7767 - val_accuracy: 0.7157\n",
      "Epoch 132/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.2793 - accuracy: 0.9766 - val_loss: 7.7440 - val_accuracy: 0.7156\n",
      "Epoch 133/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.2442 - accuracy: 0.9779 - val_loss: 7.7115 - val_accuracy: 0.7163\n",
      "Epoch 134/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.2100 - accuracy: 0.9786 - val_loss: 7.6791 - val_accuracy: 0.7175\n",
      "Epoch 135/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1754 - accuracy: 0.9795 - val_loss: 7.6468 - val_accuracy: 0.7188\n",
      "Epoch 136/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1413 - accuracy: 0.9803 - val_loss: 7.6148 - val_accuracy: 0.7212\n",
      "Epoch 137/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1050 - accuracy: 0.9817 - val_loss: 7.5827 - val_accuracy: 0.7200\n",
      "Epoch 138/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0715 - accuracy: 0.9819 - val_loss: 7.5509 - val_accuracy: 0.7224\n",
      "Epoch 139/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0368 - accuracy: 0.9833 - val_loss: 7.5185 - val_accuracy: 0.7224\n",
      "Epoch 140/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0038 - accuracy: 0.9837 - val_loss: 7.4869 - val_accuracy: 0.7228\n",
      "Epoch 141/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9691 - accuracy: 0.9852 - val_loss: 7.4551 - val_accuracy: 0.7235\n",
      "Epoch 142/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9356 - accuracy: 0.9852 - val_loss: 7.4237 - val_accuracy: 0.7245\n",
      "Epoch 143/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9022 - accuracy: 0.9850 - val_loss: 7.3922 - val_accuracy: 0.7253\n",
      "Epoch 144/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8694 - accuracy: 0.9856 - val_loss: 7.3611 - val_accuracy: 0.7252\n",
      "Epoch 145/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8358 - accuracy: 0.9867 - val_loss: 7.3294 - val_accuracy: 0.7265\n",
      "Epoch 146/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8009 - accuracy: 0.9876 - val_loss: 7.2986 - val_accuracy: 0.7269\n",
      "Epoch 147/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7697 - accuracy: 0.9873 - val_loss: 7.2670 - val_accuracy: 0.7281\n",
      "Epoch 148/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7360 - accuracy: 0.9884 - val_loss: 7.2363 - val_accuracy: 0.7283\n",
      "Epoch 149/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7028 - accuracy: 0.9891 - val_loss: 7.2052 - val_accuracy: 0.7292\n",
      "Epoch 150/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6702 - accuracy: 0.9903 - val_loss: 7.1742 - val_accuracy: 0.7295\n",
      "Epoch 151/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6379 - accuracy: 0.9900 - val_loss: 7.1433 - val_accuracy: 0.7297\n",
      "Epoch 152/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6061 - accuracy: 0.9901 - val_loss: 7.1124 - val_accuracy: 0.7304\n",
      "Epoch 153/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5729 - accuracy: 0.9908 - val_loss: 7.0816 - val_accuracy: 0.7304\n",
      "Epoch 154/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5411 - accuracy: 0.9914 - val_loss: 7.0509 - val_accuracy: 0.7312\n",
      "Epoch 155/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5077 - accuracy: 0.9929 - val_loss: 7.0207 - val_accuracy: 0.7329\n",
      "Epoch 156/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4757 - accuracy: 0.9926 - val_loss: 6.9901 - val_accuracy: 0.7320\n",
      "Epoch 157/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4454 - accuracy: 0.9932 - val_loss: 6.9596 - val_accuracy: 0.7327\n",
      "Epoch 158/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4141 - accuracy: 0.9927 - val_loss: 6.9291 - val_accuracy: 0.7336\n",
      "Epoch 159/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3808 - accuracy: 0.9933 - val_loss: 6.8990 - val_accuracy: 0.7351\n",
      "Epoch 160/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3493 - accuracy: 0.9942 - val_loss: 6.8689 - val_accuracy: 0.7351\n",
      "Epoch 161/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3177 - accuracy: 0.9947 - val_loss: 6.8393 - val_accuracy: 0.7365\n",
      "Epoch 162/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2860 - accuracy: 0.9953 - val_loss: 6.8093 - val_accuracy: 0.7368\n",
      "Epoch 163/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2563 - accuracy: 0.9950 - val_loss: 6.7796 - val_accuracy: 0.7381\n",
      "Epoch 164/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2236 - accuracy: 0.9952 - val_loss: 6.7500 - val_accuracy: 0.7380\n",
      "Epoch 165/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1943 - accuracy: 0.9956 - val_loss: 6.7202 - val_accuracy: 0.7388\n",
      "Epoch 166/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1618 - accuracy: 0.9960 - val_loss: 6.6902 - val_accuracy: 0.7392\n",
      "Epoch 167/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1321 - accuracy: 0.9967 - val_loss: 6.6617 - val_accuracy: 0.7400\n",
      "Epoch 168/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1015 - accuracy: 0.9965 - val_loss: 6.6321 - val_accuracy: 0.7405\n",
      "Epoch 169/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0707 - accuracy: 0.9967 - val_loss: 6.6027 - val_accuracy: 0.7416\n",
      "Epoch 170/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0408 - accuracy: 0.9966 - val_loss: 6.5735 - val_accuracy: 0.7413\n",
      "Epoch 171/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0113 - accuracy: 0.9969 - val_loss: 6.5441 - val_accuracy: 0.7417\n",
      "Epoch 172/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9805 - accuracy: 0.9973 - val_loss: 6.5148 - val_accuracy: 0.7427\n",
      "Epoch 173/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9504 - accuracy: 0.9976 - val_loss: 6.4858 - val_accuracy: 0.7436\n",
      "Epoch 174/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9209 - accuracy: 0.9977 - val_loss: 6.4567 - val_accuracy: 0.7439\n",
      "Epoch 175/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8915 - accuracy: 0.9976 - val_loss: 6.4272 - val_accuracy: 0.7447\n",
      "Epoch 176/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8613 - accuracy: 0.9981 - val_loss: 6.3988 - val_accuracy: 0.7443\n",
      "Epoch 177/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8327 - accuracy: 0.9980 - val_loss: 6.3704 - val_accuracy: 0.7445\n",
      "Epoch 178/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8033 - accuracy: 0.9984 - val_loss: 6.3418 - val_accuracy: 0.7460\n",
      "Epoch 179/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7732 - accuracy: 0.9984 - val_loss: 6.3137 - val_accuracy: 0.7467\n",
      "Epoch 180/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7438 - accuracy: 0.9987 - val_loss: 6.2851 - val_accuracy: 0.7473\n",
      "Epoch 181/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7158 - accuracy: 0.9984 - val_loss: 6.2568 - val_accuracy: 0.7473\n",
      "Epoch 182/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6866 - accuracy: 0.9988 - val_loss: 6.2279 - val_accuracy: 0.7485\n",
      "Epoch 183/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6574 - accuracy: 0.9985 - val_loss: 6.2003 - val_accuracy: 0.7485\n",
      "Epoch 184/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6280 - accuracy: 0.9986 - val_loss: 6.1719 - val_accuracy: 0.7495\n",
      "Epoch 185/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6000 - accuracy: 0.9988 - val_loss: 6.1434 - val_accuracy: 0.7499\n",
      "Epoch 186/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5714 - accuracy: 0.9989 - val_loss: 6.1152 - val_accuracy: 0.7512\n",
      "Epoch 187/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5434 - accuracy: 0.9990 - val_loss: 6.0873 - val_accuracy: 0.7521\n",
      "Epoch 188/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5157 - accuracy: 0.9993 - val_loss: 6.0598 - val_accuracy: 0.7520\n",
      "Epoch 189/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4855 - accuracy: 0.9995 - val_loss: 6.0321 - val_accuracy: 0.7527\n",
      "Epoch 190/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4581 - accuracy: 0.9995 - val_loss: 6.0041 - val_accuracy: 0.7532\n",
      "Epoch 191/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4303 - accuracy: 0.9993 - val_loss: 5.9775 - val_accuracy: 0.7540\n",
      "Epoch 192/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4020 - accuracy: 0.9991 - val_loss: 5.9501 - val_accuracy: 0.7539\n",
      "Epoch 193/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3748 - accuracy: 0.9995 - val_loss: 5.9224 - val_accuracy: 0.7551\n",
      "Epoch 194/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3476 - accuracy: 0.9991 - val_loss: 5.8956 - val_accuracy: 0.7561\n",
      "Epoch 195/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3190 - accuracy: 0.9996 - val_loss: 5.8682 - val_accuracy: 0.7563\n",
      "Epoch 196/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2917 - accuracy: 0.9995 - val_loss: 5.8410 - val_accuracy: 0.7563\n",
      "Epoch 197/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2645 - accuracy: 0.9993 - val_loss: 5.8141 - val_accuracy: 0.7569\n",
      "Epoch 198/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2376 - accuracy: 0.9996 - val_loss: 5.7875 - val_accuracy: 0.7573\n",
      "Epoch 199/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2103 - accuracy: 0.9997 - val_loss: 5.7606 - val_accuracy: 0.7584\n",
      "Epoch 200/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1828 - accuracy: 0.9997 - val_loss: 5.7333 - val_accuracy: 0.7595\n",
      "Epoch 201/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1560 - accuracy: 0.9997 - val_loss: 5.7066 - val_accuracy: 0.7596\n",
      "Epoch 202/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1294 - accuracy: 0.9997 - val_loss: 5.6804 - val_accuracy: 0.7605\n",
      "Epoch 203/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1029 - accuracy: 0.9995 - val_loss: 5.6540 - val_accuracy: 0.7607\n",
      "Epoch 204/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0762 - accuracy: 0.9996 - val_loss: 5.6273 - val_accuracy: 0.7617\n",
      "Epoch 205/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0497 - accuracy: 0.9998 - val_loss: 5.6009 - val_accuracy: 0.7619\n",
      "Epoch 206/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0232 - accuracy: 0.9998 - val_loss: 5.5755 - val_accuracy: 0.7629\n",
      "Epoch 207/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9970 - accuracy: 0.9998 - val_loss: 5.5492 - val_accuracy: 0.7636\n",
      "Epoch 208/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9715 - accuracy: 0.9996 - val_loss: 5.5221 - val_accuracy: 0.7644\n",
      "Epoch 209/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9446 - accuracy: 0.9996 - val_loss: 5.4964 - val_accuracy: 0.7657\n",
      "Epoch 210/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9190 - accuracy: 0.9998 - val_loss: 5.4697 - val_accuracy: 0.7647\n",
      "Epoch 211/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8930 - accuracy: 0.9997 - val_loss: 5.4442 - val_accuracy: 0.7659\n",
      "Epoch 212/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8669 - accuracy: 0.9996 - val_loss: 5.4187 - val_accuracy: 0.7677\n",
      "Epoch 213/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8409 - accuracy: 0.9998 - val_loss: 5.3934 - val_accuracy: 0.7668\n",
      "Epoch 214/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8153 - accuracy: 0.9999 - val_loss: 5.3678 - val_accuracy: 0.7671\n",
      "Epoch 215/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7904 - accuracy: 0.9998 - val_loss: 5.3422 - val_accuracy: 0.7676\n",
      "Epoch 216/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7640 - accuracy: 0.9998 - val_loss: 5.3168 - val_accuracy: 0.7673\n",
      "Epoch 217/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7388 - accuracy: 0.9999 - val_loss: 5.2915 - val_accuracy: 0.7683\n",
      "Epoch 218/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7138 - accuracy: 0.9998 - val_loss: 5.2666 - val_accuracy: 0.7688\n",
      "Epoch 219/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6884 - accuracy: 0.9999 - val_loss: 5.2411 - val_accuracy: 0.7692\n",
      "Epoch 220/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6640 - accuracy: 1.0000 - val_loss: 5.2163 - val_accuracy: 0.7700\n",
      "Epoch 221/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6390 - accuracy: 0.9997 - val_loss: 5.1909 - val_accuracy: 0.7705\n",
      "Epoch 222/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6141 - accuracy: 1.0000 - val_loss: 5.1662 - val_accuracy: 0.7709\n",
      "Epoch 223/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5892 - accuracy: 0.9999 - val_loss: 5.1418 - val_accuracy: 0.7711\n",
      "Epoch 224/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5648 - accuracy: 0.9999 - val_loss: 5.1174 - val_accuracy: 0.7716\n",
      "Epoch 225/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5401 - accuracy: 0.9999 - val_loss: 5.0918 - val_accuracy: 0.7731\n",
      "Epoch 226/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5153 - accuracy: 0.9999 - val_loss: 5.0670 - val_accuracy: 0.7725\n",
      "Epoch 227/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4914 - accuracy: 0.9998 - val_loss: 5.0430 - val_accuracy: 0.7744\n",
      "Epoch 228/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4671 - accuracy: 0.9998 - val_loss: 5.0189 - val_accuracy: 0.7741\n",
      "Epoch 229/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4426 - accuracy: 0.9999 - val_loss: 4.9944 - val_accuracy: 0.7749\n",
      "Epoch 230/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4185 - accuracy: 0.9999 - val_loss: 4.9704 - val_accuracy: 0.7751\n",
      "Epoch 231/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3947 - accuracy: 1.0000 - val_loss: 4.9458 - val_accuracy: 0.7761\n",
      "Epoch 232/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3710 - accuracy: 1.0000 - val_loss: 4.9224 - val_accuracy: 0.7773\n",
      "Epoch 233/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3471 - accuracy: 1.0000 - val_loss: 4.8986 - val_accuracy: 0.7775\n",
      "Epoch 234/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3241 - accuracy: 1.0000 - val_loss: 4.8745 - val_accuracy: 0.7784\n",
      "Epoch 235/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2994 - accuracy: 0.9999 - val_loss: 4.8505 - val_accuracy: 0.7793\n",
      "Epoch 236/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2771 - accuracy: 0.9998 - val_loss: 4.8264 - val_accuracy: 0.7795\n",
      "Epoch 237/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2530 - accuracy: 1.0000 - val_loss: 4.8026 - val_accuracy: 0.7801\n",
      "Epoch 238/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2307 - accuracy: 1.0000 - val_loss: 4.7789 - val_accuracy: 0.7813\n",
      "Epoch 239/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2066 - accuracy: 0.9999 - val_loss: 4.7557 - val_accuracy: 0.7809\n",
      "Epoch 240/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1835 - accuracy: 1.0000 - val_loss: 4.7334 - val_accuracy: 0.7816\n",
      "Epoch 241/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1606 - accuracy: 1.0000 - val_loss: 4.7102 - val_accuracy: 0.7817\n",
      "Epoch 242/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1372 - accuracy: 1.0000 - val_loss: 4.6875 - val_accuracy: 0.7820\n",
      "Epoch 243/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1141 - accuracy: 1.0000 - val_loss: 4.6645 - val_accuracy: 0.7829\n",
      "Epoch 244/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0920 - accuracy: 1.0000 - val_loss: 4.6415 - val_accuracy: 0.7835\n",
      "Epoch 245/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0699 - accuracy: 1.0000 - val_loss: 4.6188 - val_accuracy: 0.7837\n",
      "Epoch 246/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0467 - accuracy: 1.0000 - val_loss: 4.5960 - val_accuracy: 0.7852\n",
      "Epoch 247/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0242 - accuracy: 1.0000 - val_loss: 4.5728 - val_accuracy: 0.7867\n",
      "Epoch 248/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0014 - accuracy: 1.0000 - val_loss: 4.5506 - val_accuracy: 0.7864\n",
      "Epoch 249/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9793 - accuracy: 1.0000 - val_loss: 4.5273 - val_accuracy: 0.7867\n",
      "Epoch 250/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9568 - accuracy: 1.0000 - val_loss: 4.5044 - val_accuracy: 0.7871\n",
      "Epoch 251/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9354 - accuracy: 1.0000 - val_loss: 4.4818 - val_accuracy: 0.7869\n",
      "Epoch 252/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9131 - accuracy: 0.9999 - val_loss: 4.4596 - val_accuracy: 0.7887\n",
      "Epoch 253/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8915 - accuracy: 0.9999 - val_loss: 4.4386 - val_accuracy: 0.7889\n",
      "Epoch 254/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8695 - accuracy: 1.0000 - val_loss: 4.4158 - val_accuracy: 0.7887\n",
      "Epoch 255/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8474 - accuracy: 1.0000 - val_loss: 4.3931 - val_accuracy: 0.7907\n",
      "Epoch 256/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8263 - accuracy: 1.0000 - val_loss: 4.3710 - val_accuracy: 0.7911\n",
      "Epoch 257/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8043 - accuracy: 0.9999 - val_loss: 4.3490 - val_accuracy: 0.7913\n",
      "Epoch 258/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7828 - accuracy: 1.0000 - val_loss: 4.3269 - val_accuracy: 0.7920\n",
      "Epoch 259/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7614 - accuracy: 1.0000 - val_loss: 4.3057 - val_accuracy: 0.7927\n",
      "Epoch 260/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7400 - accuracy: 1.0000 - val_loss: 4.2843 - val_accuracy: 0.7924\n",
      "Epoch 261/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7197 - accuracy: 1.0000 - val_loss: 4.2625 - val_accuracy: 0.7924\n",
      "Epoch 262/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6978 - accuracy: 1.0000 - val_loss: 4.2409 - val_accuracy: 0.7925\n",
      "Epoch 263/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6772 - accuracy: 1.0000 - val_loss: 4.2200 - val_accuracy: 0.7928\n",
      "Epoch 264/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6564 - accuracy: 1.0000 - val_loss: 4.1985 - val_accuracy: 0.7921\n",
      "Epoch 265/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6356 - accuracy: 0.9999 - val_loss: 4.1777 - val_accuracy: 0.7932\n",
      "Epoch 266/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6148 - accuracy: 1.0000 - val_loss: 4.1564 - val_accuracy: 0.7936\n",
      "Epoch 267/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5936 - accuracy: 1.0000 - val_loss: 4.1349 - val_accuracy: 0.7929\n",
      "Epoch 268/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5737 - accuracy: 1.0000 - val_loss: 4.1139 - val_accuracy: 0.7927\n",
      "Epoch 269/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5531 - accuracy: 1.0000 - val_loss: 4.0931 - val_accuracy: 0.7927\n",
      "Epoch 270/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5329 - accuracy: 1.0000 - val_loss: 4.0728 - val_accuracy: 0.7923\n",
      "Epoch 271/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5124 - accuracy: 1.0000 - val_loss: 4.0517 - val_accuracy: 0.7932\n",
      "Epoch 272/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4924 - accuracy: 1.0000 - val_loss: 4.0304 - val_accuracy: 0.7944\n",
      "Epoch 273/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4716 - accuracy: 1.0000 - val_loss: 4.0101 - val_accuracy: 0.7944\n",
      "Epoch 274/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4527 - accuracy: 1.0000 - val_loss: 3.9909 - val_accuracy: 0.7944\n",
      "Epoch 275/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4323 - accuracy: 1.0000 - val_loss: 3.9688 - val_accuracy: 0.7949\n",
      "Epoch 276/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4124 - accuracy: 1.0000 - val_loss: 3.9493 - val_accuracy: 0.7956\n",
      "Epoch 277/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3924 - accuracy: 1.0000 - val_loss: 3.9287 - val_accuracy: 0.7961\n",
      "Epoch 278/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3731 - accuracy: 1.0000 - val_loss: 3.9079 - val_accuracy: 0.7968\n",
      "Epoch 279/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3538 - accuracy: 1.0000 - val_loss: 3.8883 - val_accuracy: 0.7972\n",
      "Epoch 280/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3343 - accuracy: 1.0000 - val_loss: 3.8692 - val_accuracy: 0.7963\n",
      "Epoch 281/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3145 - accuracy: 1.0000 - val_loss: 3.8491 - val_accuracy: 0.7965\n",
      "Epoch 282/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2950 - accuracy: 1.0000 - val_loss: 3.8291 - val_accuracy: 0.7980\n",
      "Epoch 283/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2763 - accuracy: 1.0000 - val_loss: 3.8084 - val_accuracy: 0.7977\n",
      "Epoch 284/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2573 - accuracy: 1.0000 - val_loss: 3.7884 - val_accuracy: 0.7985\n",
      "Epoch 285/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2383 - accuracy: 1.0000 - val_loss: 3.7696 - val_accuracy: 0.7991\n",
      "Epoch 286/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2193 - accuracy: 1.0000 - val_loss: 3.7505 - val_accuracy: 0.7984\n",
      "Epoch 287/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2002 - accuracy: 1.0000 - val_loss: 3.7319 - val_accuracy: 0.7991\n",
      "Epoch 288/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1814 - accuracy: 1.0000 - val_loss: 3.7117 - val_accuracy: 0.8015\n",
      "Epoch 289/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1628 - accuracy: 1.0000 - val_loss: 3.6927 - val_accuracy: 0.8012\n",
      "Epoch 290/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1443 - accuracy: 1.0000 - val_loss: 3.6742 - val_accuracy: 0.8011\n",
      "Epoch 291/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1261 - accuracy: 1.0000 - val_loss: 3.6554 - val_accuracy: 0.8012\n",
      "Epoch 292/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1073 - accuracy: 1.0000 - val_loss: 3.6367 - val_accuracy: 0.8019\n",
      "Epoch 293/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0892 - accuracy: 1.0000 - val_loss: 3.6174 - val_accuracy: 0.8017\n",
      "Epoch 294/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0711 - accuracy: 1.0000 - val_loss: 3.5990 - val_accuracy: 0.8024\n",
      "Epoch 295/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0535 - accuracy: 1.0000 - val_loss: 3.5802 - val_accuracy: 0.8037\n",
      "Epoch 296/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0355 - accuracy: 1.0000 - val_loss: 3.5626 - val_accuracy: 0.8044\n",
      "Epoch 297/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0174 - accuracy: 1.0000 - val_loss: 3.5439 - val_accuracy: 0.8041\n",
      "Epoch 298/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9994 - accuracy: 1.0000 - val_loss: 3.5252 - val_accuracy: 0.8044\n",
      "Epoch 299/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9813 - accuracy: 1.0000 - val_loss: 3.5070 - val_accuracy: 0.8043\n",
      "Epoch 300/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9641 - accuracy: 1.0000 - val_loss: 3.4895 - val_accuracy: 0.8048\n",
      "Epoch 301/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9462 - accuracy: 1.0000 - val_loss: 3.4719 - val_accuracy: 0.8040\n",
      "Epoch 302/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9291 - accuracy: 1.0000 - val_loss: 3.4543 - val_accuracy: 0.8051\n",
      "Epoch 303/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9117 - accuracy: 1.0000 - val_loss: 3.4361 - val_accuracy: 0.8051\n",
      "Epoch 304/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8951 - accuracy: 1.0000 - val_loss: 3.4202 - val_accuracy: 0.8047\n",
      "Epoch 305/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8770 - accuracy: 1.0000 - val_loss: 3.4018 - val_accuracy: 0.8061\n",
      "Epoch 306/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8600 - accuracy: 1.0000 - val_loss: 3.3842 - val_accuracy: 0.8075\n",
      "Epoch 307/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8435 - accuracy: 1.0000 - val_loss: 3.3668 - val_accuracy: 0.8076\n",
      "Epoch 308/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8261 - accuracy: 1.0000 - val_loss: 3.3493 - val_accuracy: 0.8075\n",
      "Epoch 309/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8096 - accuracy: 1.0000 - val_loss: 3.3340 - val_accuracy: 0.8067\n",
      "Epoch 310/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7931 - accuracy: 1.0000 - val_loss: 3.3157 - val_accuracy: 0.8087\n",
      "Epoch 311/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7761 - accuracy: 1.0000 - val_loss: 3.2979 - val_accuracy: 0.8087\n",
      "Epoch 312/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7595 - accuracy: 1.0000 - val_loss: 3.2808 - val_accuracy: 0.8089\n",
      "Epoch 313/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7432 - accuracy: 1.0000 - val_loss: 3.2645 - val_accuracy: 0.8081\n",
      "Epoch 314/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7271 - accuracy: 1.0000 - val_loss: 3.2477 - val_accuracy: 0.8079\n",
      "Epoch 315/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7101 - accuracy: 1.0000 - val_loss: 3.2305 - val_accuracy: 0.8087\n",
      "Epoch 316/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6941 - accuracy: 1.0000 - val_loss: 3.2132 - val_accuracy: 0.8083\n",
      "Epoch 317/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6775 - accuracy: 1.0000 - val_loss: 3.1964 - val_accuracy: 0.8077\n",
      "Epoch 318/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6619 - accuracy: 1.0000 - val_loss: 3.1803 - val_accuracy: 0.8080\n",
      "Epoch 319/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6457 - accuracy: 1.0000 - val_loss: 3.1636 - val_accuracy: 0.8099\n",
      "Epoch 320/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6304 - accuracy: 1.0000 - val_loss: 3.1480 - val_accuracy: 0.8099\n",
      "Epoch 321/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6146 - accuracy: 1.0000 - val_loss: 3.1324 - val_accuracy: 0.8097\n",
      "Epoch 322/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5990 - accuracy: 0.9999 - val_loss: 3.1172 - val_accuracy: 0.8104\n",
      "Epoch 323/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5836 - accuracy: 1.0000 - val_loss: 3.1029 - val_accuracy: 0.8109\n",
      "Epoch 324/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5675 - accuracy: 1.0000 - val_loss: 3.0854 - val_accuracy: 0.8105\n",
      "Epoch 325/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5527 - accuracy: 0.9999 - val_loss: 3.0689 - val_accuracy: 0.8104\n",
      "Epoch 326/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5373 - accuracy: 1.0000 - val_loss: 3.0538 - val_accuracy: 0.8112\n",
      "Epoch 327/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5220 - accuracy: 1.0000 - val_loss: 3.0386 - val_accuracy: 0.8115\n",
      "Epoch 328/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5069 - accuracy: 1.0000 - val_loss: 3.0228 - val_accuracy: 0.8117\n",
      "Epoch 329/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4921 - accuracy: 1.0000 - val_loss: 3.0078 - val_accuracy: 0.8121\n",
      "Epoch 330/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4771 - accuracy: 1.0000 - val_loss: 2.9913 - val_accuracy: 0.8136\n",
      "Epoch 331/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4626 - accuracy: 1.0000 - val_loss: 2.9773 - val_accuracy: 0.8128\n",
      "Epoch 332/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4476 - accuracy: 1.0000 - val_loss: 2.9618 - val_accuracy: 0.8129\n",
      "Epoch 333/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4332 - accuracy: 1.0000 - val_loss: 2.9482 - val_accuracy: 0.8128\n",
      "Epoch 334/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4186 - accuracy: 1.0000 - val_loss: 2.9339 - val_accuracy: 0.8131\n",
      "Epoch 335/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4043 - accuracy: 1.0000 - val_loss: 2.9173 - val_accuracy: 0.8152\n",
      "Epoch 336/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3898 - accuracy: 1.0000 - val_loss: 2.9034 - val_accuracy: 0.8136\n",
      "Epoch 337/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3755 - accuracy: 1.0000 - val_loss: 2.8900 - val_accuracy: 0.8144\n",
      "Epoch 338/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3613 - accuracy: 1.0000 - val_loss: 2.8757 - val_accuracy: 0.8152\n",
      "Epoch 339/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3470 - accuracy: 1.0000 - val_loss: 2.8602 - val_accuracy: 0.8157\n",
      "Epoch 340/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3335 - accuracy: 1.0000 - val_loss: 2.8471 - val_accuracy: 0.8160\n",
      "Epoch 341/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3190 - accuracy: 1.0000 - val_loss: 2.8317 - val_accuracy: 0.8161\n",
      "Epoch 342/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3056 - accuracy: 1.0000 - val_loss: 2.8167 - val_accuracy: 0.8176\n",
      "Epoch 343/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2914 - accuracy: 1.0000 - val_loss: 2.8047 - val_accuracy: 0.8168\n",
      "Epoch 344/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2780 - accuracy: 1.0000 - val_loss: 2.7910 - val_accuracy: 0.8173\n",
      "Epoch 345/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2645 - accuracy: 1.0000 - val_loss: 2.7783 - val_accuracy: 0.8179\n",
      "Epoch 346/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2516 - accuracy: 1.0000 - val_loss: 2.7635 - val_accuracy: 0.8185\n",
      "Epoch 347/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2378 - accuracy: 1.0000 - val_loss: 2.7481 - val_accuracy: 0.8195\n",
      "Epoch 348/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2247 - accuracy: 1.0000 - val_loss: 2.7357 - val_accuracy: 0.8195\n",
      "Epoch 349/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2119 - accuracy: 1.0000 - val_loss: 2.7229 - val_accuracy: 0.8207\n",
      "Epoch 350/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1984 - accuracy: 1.0000 - val_loss: 2.7104 - val_accuracy: 0.8199\n",
      "Epoch 351/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1854 - accuracy: 1.0000 - val_loss: 2.6970 - val_accuracy: 0.8208\n",
      "Epoch 352/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1728 - accuracy: 1.0000 - val_loss: 2.6843 - val_accuracy: 0.8212\n",
      "Epoch 353/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1593 - accuracy: 1.0000 - val_loss: 2.6711 - val_accuracy: 0.8207\n",
      "Epoch 354/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1465 - accuracy: 1.0000 - val_loss: 2.6571 - val_accuracy: 0.8201\n",
      "Epoch 355/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1345 - accuracy: 1.0000 - val_loss: 2.6442 - val_accuracy: 0.8219\n",
      "Epoch 356/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1213 - accuracy: 1.0000 - val_loss: 2.6314 - val_accuracy: 0.8211\n",
      "Epoch 357/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1094 - accuracy: 1.0000 - val_loss: 2.6199 - val_accuracy: 0.8211\n",
      "Epoch 358/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0964 - accuracy: 1.0000 - val_loss: 2.6078 - val_accuracy: 0.8211\n",
      "Epoch 359/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0847 - accuracy: 1.0000 - val_loss: 2.5963 - val_accuracy: 0.8216\n",
      "Epoch 360/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0723 - accuracy: 1.0000 - val_loss: 2.5820 - val_accuracy: 0.8223\n",
      "Epoch 361/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0599 - accuracy: 1.0000 - val_loss: 2.5693 - val_accuracy: 0.8224\n",
      "Epoch 362/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0477 - accuracy: 1.0000 - val_loss: 2.5569 - val_accuracy: 0.8217\n",
      "Epoch 363/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0372 - accuracy: 0.9999 - val_loss: 2.5491 - val_accuracy: 0.8223\n",
      "Epoch 364/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0249 - accuracy: 1.0000 - val_loss: 2.5327 - val_accuracy: 0.8227\n",
      "Epoch 365/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0132 - accuracy: 1.0000 - val_loss: 2.5200 - val_accuracy: 0.8212\n",
      "Epoch 366/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0015 - accuracy: 1.0000 - val_loss: 2.5080 - val_accuracy: 0.8228\n",
      "Epoch 367/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9895 - accuracy: 1.0000 - val_loss: 2.4956 - val_accuracy: 0.8244\n",
      "Epoch 368/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9784 - accuracy: 1.0000 - val_loss: 2.4832 - val_accuracy: 0.8227\n",
      "Epoch 369/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9668 - accuracy: 1.0000 - val_loss: 2.4741 - val_accuracy: 0.8233\n",
      "Epoch 370/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9553 - accuracy: 1.0000 - val_loss: 2.4611 - val_accuracy: 0.8224\n",
      "Epoch 371/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9448 - accuracy: 1.0000 - val_loss: 2.4499 - val_accuracy: 0.8235\n",
      "Epoch 372/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9335 - accuracy: 1.0000 - val_loss: 2.4381 - val_accuracy: 0.8244\n",
      "Epoch 373/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9230 - accuracy: 1.0000 - val_loss: 2.4278 - val_accuracy: 0.8235\n",
      "Epoch 374/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9122 - accuracy: 1.0000 - val_loss: 2.4185 - val_accuracy: 0.8224\n",
      "Epoch 375/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9013 - accuracy: 1.0000 - val_loss: 2.4057 - val_accuracy: 0.8253\n",
      "Epoch 376/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8897 - accuracy: 1.0000 - val_loss: 2.3959 - val_accuracy: 0.8236\n",
      "Epoch 377/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8793 - accuracy: 1.0000 - val_loss: 2.3875 - val_accuracy: 0.8232\n",
      "Epoch 378/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8684 - accuracy: 1.0000 - val_loss: 2.3703 - val_accuracy: 0.8249\n",
      "Epoch 379/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8585 - accuracy: 1.0000 - val_loss: 2.3588 - val_accuracy: 0.8245\n",
      "Epoch 380/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8477 - accuracy: 1.0000 - val_loss: 2.3488 - val_accuracy: 0.8260\n",
      "Epoch 381/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8379 - accuracy: 1.0000 - val_loss: 2.3425 - val_accuracy: 0.8264\n",
      "Epoch 382/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8278 - accuracy: 1.0000 - val_loss: 2.3297 - val_accuracy: 0.8273\n",
      "Epoch 383/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8178 - accuracy: 1.0000 - val_loss: 2.3179 - val_accuracy: 0.8268\n",
      "Epoch 384/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8072 - accuracy: 1.0000 - val_loss: 2.3127 - val_accuracy: 0.8259\n",
      "Epoch 385/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7971 - accuracy: 1.0000 - val_loss: 2.2978 - val_accuracy: 0.8272\n",
      "Epoch 386/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7884 - accuracy: 1.0000 - val_loss: 2.2882 - val_accuracy: 0.8284\n",
      "Epoch 387/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7778 - accuracy: 1.0000 - val_loss: 2.2771 - val_accuracy: 0.8291\n",
      "Epoch 388/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7686 - accuracy: 1.0000 - val_loss: 2.2740 - val_accuracy: 0.8273\n",
      "Epoch 389/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7592 - accuracy: 1.0000 - val_loss: 2.2592 - val_accuracy: 0.8308\n",
      "Epoch 390/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7493 - accuracy: 1.0000 - val_loss: 2.2497 - val_accuracy: 0.8300\n",
      "Epoch 391/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7399 - accuracy: 1.0000 - val_loss: 2.2509 - val_accuracy: 0.8267\n",
      "Epoch 392/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7710 - accuracy: 0.9912 - val_loss: 2.6979 - val_accuracy: 0.7652\n",
      "Epoch 393/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0130 - accuracy: 0.9350 - val_loss: 2.4357 - val_accuracy: 0.8140\n",
      "Epoch 394/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8969 - accuracy: 0.9773 - val_loss: 2.3439 - val_accuracy: 0.8279\n",
      "Epoch 395/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8307 - accuracy: 0.9947 - val_loss: 2.2758 - val_accuracy: 0.8423\n",
      "Epoch 396/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7837 - accuracy: 0.9997 - val_loss: 2.2265 - val_accuracy: 0.8475\n",
      "Epoch 397/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7493 - accuracy: 1.0000 - val_loss: 2.1966 - val_accuracy: 0.8467\n",
      "Epoch 398/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7240 - accuracy: 1.0000 - val_loss: 2.1767 - val_accuracy: 0.8456\n",
      "Epoch 399/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7036 - accuracy: 1.0000 - val_loss: 2.1580 - val_accuracy: 0.8465\n",
      "Epoch 400/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6872 - accuracy: 1.0000 - val_loss: 2.1418 - val_accuracy: 0.8468\n",
      "Epoch 401/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6735 - accuracy: 1.0000 - val_loss: 2.1276 - val_accuracy: 0.8464\n",
      "Epoch 402/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6608 - accuracy: 1.0000 - val_loss: 2.1200 - val_accuracy: 0.8461\n",
      "Epoch 403/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6502 - accuracy: 1.0000 - val_loss: 2.1088 - val_accuracy: 0.8457\n",
      "Epoch 404/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6402 - accuracy: 1.0000 - val_loss: 2.0984 - val_accuracy: 0.8460\n",
      "Epoch 405/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6302 - accuracy: 1.0000 - val_loss: 2.0896 - val_accuracy: 0.8449\n",
      "Epoch 406/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6213 - accuracy: 1.0000 - val_loss: 2.0831 - val_accuracy: 0.8451\n",
      "Epoch 407/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6132 - accuracy: 1.0000 - val_loss: 2.0755 - val_accuracy: 0.8475\n",
      "Epoch 408/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6043 - accuracy: 1.0000 - val_loss: 2.0644 - val_accuracy: 0.8453\n",
      "Epoch 409/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5959 - accuracy: 1.0000 - val_loss: 2.0641 - val_accuracy: 0.8445\n",
      "Epoch 410/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5894 - accuracy: 1.0000 - val_loss: 2.0526 - val_accuracy: 0.8440\n",
      "Epoch 411/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5793 - accuracy: 1.0000 - val_loss: 2.0408 - val_accuracy: 0.8455\n",
      "Epoch 412/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5718 - accuracy: 1.0000 - val_loss: 2.0365 - val_accuracy: 0.8468\n",
      "Epoch 413/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5641 - accuracy: 1.0000 - val_loss: 2.0301 - val_accuracy: 0.8449\n",
      "Epoch 414/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5598 - accuracy: 0.9999 - val_loss: 2.0314 - val_accuracy: 0.8428\n",
      "Epoch 415/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5518 - accuracy: 1.0000 - val_loss: 2.0110 - val_accuracy: 0.8459\n",
      "Epoch 416/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5427 - accuracy: 1.0000 - val_loss: 2.0088 - val_accuracy: 0.8460\n",
      "Epoch 417/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5488 - accuracy: 0.9967 - val_loss: 2.6750 - val_accuracy: 0.7604\n",
      "Epoch 418/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0971 - accuracy: 0.8708 - val_loss: 2.5311 - val_accuracy: 0.7632\n",
      "Epoch 419/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8052 - accuracy: 0.9636 - val_loss: 2.1387 - val_accuracy: 0.8485\n",
      "Epoch 420/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7083 - accuracy: 0.9924 - val_loss: 2.0865 - val_accuracy: 0.8531\n",
      "Epoch 421/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6553 - accuracy: 0.9994 - val_loss: 2.0659 - val_accuracy: 0.8540\n",
      "Epoch 422/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6176 - accuracy: 1.0000 - val_loss: 2.0361 - val_accuracy: 0.8529\n",
      "Epoch 423/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5878 - accuracy: 1.0000 - val_loss: 2.0078 - val_accuracy: 0.8531\n",
      "Epoch 424/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5636 - accuracy: 1.0000 - val_loss: 1.9785 - val_accuracy: 0.8560\n",
      "Epoch 425/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5428 - accuracy: 1.0000 - val_loss: 1.9500 - val_accuracy: 0.8581\n",
      "Epoch 426/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5253 - accuracy: 1.0000 - val_loss: 1.9312 - val_accuracy: 0.8587\n",
      "Epoch 427/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5098 - accuracy: 1.0000 - val_loss: 1.9105 - val_accuracy: 0.8591\n",
      "Epoch 428/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4971 - accuracy: 1.0000 - val_loss: 1.8934 - val_accuracy: 0.8623\n",
      "Epoch 429/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4852 - accuracy: 1.0000 - val_loss: 1.8806 - val_accuracy: 0.8648\n",
      "Epoch 430/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4764 - accuracy: 1.0000 - val_loss: 1.8702 - val_accuracy: 0.8647\n",
      "Epoch 431/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4667 - accuracy: 1.0000 - val_loss: 1.8662 - val_accuracy: 0.8643\n",
      "Epoch 432/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4591 - accuracy: 1.0000 - val_loss: 1.8565 - val_accuracy: 0.8663\n",
      "Epoch 433/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4510 - accuracy: 1.0000 - val_loss: 1.8645 - val_accuracy: 0.8625\n",
      "Epoch 434/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4450 - accuracy: 1.0000 - val_loss: 1.8465 - val_accuracy: 0.8653\n",
      "Epoch 435/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4385 - accuracy: 1.0000 - val_loss: 1.8452 - val_accuracy: 0.8651\n",
      "Epoch 436/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8478 - accuracy: 0.9031 - val_loss: 2.7491 - val_accuracy: 0.6819\n",
      "Epoch 437/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7854 - accuracy: 0.9370 - val_loss: 2.1193 - val_accuracy: 0.8377\n",
      "Epoch 438/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6553 - accuracy: 0.9831 - val_loss: 1.9850 - val_accuracy: 0.8649\n",
      "Epoch 439/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5896 - accuracy: 0.9973 - val_loss: 1.9477 - val_accuracy: 0.8673\n",
      "Epoch 440/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5456 - accuracy: 0.9998 - val_loss: 1.9290 - val_accuracy: 0.8605\n",
      "Epoch 441/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5121 - accuracy: 1.0000 - val_loss: 1.8994 - val_accuracy: 0.8645\n",
      "Epoch 442/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4853 - accuracy: 1.0000 - val_loss: 1.8711 - val_accuracy: 0.8665\n",
      "Epoch 443/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4636 - accuracy: 1.0000 - val_loss: 1.8432 - val_accuracy: 0.8707\n",
      "Epoch 444/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4446 - accuracy: 1.0000 - val_loss: 1.8177 - val_accuracy: 0.8731\n",
      "Epoch 445/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4286 - accuracy: 1.0000 - val_loss: 1.7951 - val_accuracy: 0.8761\n",
      "Epoch 446/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4151 - accuracy: 1.0000 - val_loss: 1.7817 - val_accuracy: 0.8757\n",
      "Epoch 447/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4037 - accuracy: 1.0000 - val_loss: 1.7600 - val_accuracy: 0.8791\n",
      "Epoch 448/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3942 - accuracy: 1.0000 - val_loss: 1.7486 - val_accuracy: 0.8797\n",
      "Epoch 449/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3864 - accuracy: 1.0000 - val_loss: 1.7439 - val_accuracy: 0.8797\n",
      "Epoch 450/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3777 - accuracy: 1.0000 - val_loss: 1.7309 - val_accuracy: 0.8804\n",
      "Epoch 451/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3698 - accuracy: 1.0000 - val_loss: 1.7252 - val_accuracy: 0.8805\n",
      "Epoch 452/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6062 - accuracy: 0.9423 - val_loss: 3.3284 - val_accuracy: 0.5953\n",
      "Epoch 453/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8095 - accuracy: 0.9022 - val_loss: 2.1868 - val_accuracy: 0.7961\n",
      "Epoch 454/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6191 - accuracy: 0.9756 - val_loss: 1.9119 - val_accuracy: 0.8701\n",
      "Epoch 455/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5425 - accuracy: 0.9956 - val_loss: 1.8663 - val_accuracy: 0.8760\n",
      "Epoch 456/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4961 - accuracy: 0.9997 - val_loss: 1.8496 - val_accuracy: 0.8737\n",
      "Epoch 457/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4593 - accuracy: 1.0000 - val_loss: 1.8233 - val_accuracy: 0.8735\n",
      "Epoch 458/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4317 - accuracy: 1.0000 - val_loss: 1.7952 - val_accuracy: 0.8751\n",
      "Epoch 459/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4083 - accuracy: 1.0000 - val_loss: 1.7660 - val_accuracy: 0.8769\n",
      "Epoch 460/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3881 - accuracy: 1.0000 - val_loss: 1.7404 - val_accuracy: 0.8805\n",
      "Epoch 461/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3715 - accuracy: 1.0000 - val_loss: 1.7115 - val_accuracy: 0.8849\n",
      "Epoch 462/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3581 - accuracy: 1.0000 - val_loss: 1.6915 - val_accuracy: 0.8860\n",
      "Epoch 463/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3460 - accuracy: 1.0000 - val_loss: 1.6777 - val_accuracy: 0.8903\n",
      "Epoch 464/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3362 - accuracy: 1.0000 - val_loss: 1.6675 - val_accuracy: 0.8901\n",
      "Epoch 465/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3304 - accuracy: 1.0000 - val_loss: 1.6471 - val_accuracy: 0.8917\n",
      "Epoch 466/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3247 - accuracy: 0.9997 - val_loss: 1.6770 - val_accuracy: 0.8839\n",
      "Epoch 467/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7920 - accuracy: 0.8880 - val_loss: 2.5253 - val_accuracy: 0.7007\n",
      "Epoch 468/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6243 - accuracy: 0.9563 - val_loss: 1.9135 - val_accuracy: 0.8636\n",
      "Epoch 469/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5131 - accuracy: 0.9913 - val_loss: 1.8143 - val_accuracy: 0.8803\n",
      "Epoch 470/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4585 - accuracy: 0.9991 - val_loss: 1.7885 - val_accuracy: 0.8829\n",
      "Epoch 471/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4203 - accuracy: 1.0000 - val_loss: 1.7675 - val_accuracy: 0.8779\n",
      "Epoch 472/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3896 - accuracy: 1.0000 - val_loss: 1.7387 - val_accuracy: 0.8803\n",
      "Epoch 473/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3646 - accuracy: 1.0000 - val_loss: 1.7113 - val_accuracy: 0.8821\n",
      "Epoch 474/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3450 - accuracy: 1.0000 - val_loss: 1.6819 - val_accuracy: 0.8867\n",
      "Epoch 475/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3278 - accuracy: 1.0000 - val_loss: 1.6555 - val_accuracy: 0.8891\n",
      "Epoch 476/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3141 - accuracy: 1.0000 - val_loss: 1.6321 - val_accuracy: 0.8932\n",
      "Epoch 477/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3021 - accuracy: 1.0000 - val_loss: 1.6187 - val_accuracy: 0.8949\n",
      "Epoch 478/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3007 - accuracy: 0.9988 - val_loss: 1.8593 - val_accuracy: 0.8445\n",
      "Epoch 479/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7102 - accuracy: 0.9012 - val_loss: 2.2827 - val_accuracy: 0.7537\n",
      "Epoch 480/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5378 - accuracy: 0.9701 - val_loss: 1.7870 - val_accuracy: 0.8833\n",
      "Epoch 481/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4535 - accuracy: 0.9944 - val_loss: 1.7193 - val_accuracy: 0.8957\n",
      "Epoch 482/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4061 - accuracy: 0.9995 - val_loss: 1.7033 - val_accuracy: 0.8903\n",
      "Epoch 483/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3696 - accuracy: 1.0000 - val_loss: 1.6809 - val_accuracy: 0.8865\n",
      "Epoch 484/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3413 - accuracy: 1.0000 - val_loss: 1.6551 - val_accuracy: 0.8907\n",
      "Epoch 485/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3191 - accuracy: 1.0000 - val_loss: 1.6290 - val_accuracy: 0.8944\n",
      "Epoch 486/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3010 - accuracy: 1.0000 - val_loss: 1.6044 - val_accuracy: 0.8959\n",
      "Epoch 487/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2876 - accuracy: 1.0000 - val_loss: 1.5863 - val_accuracy: 0.8999\n",
      "Epoch 488/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2742 - accuracy: 1.0000 - val_loss: 1.5660 - val_accuracy: 0.9033\n",
      "Epoch 489/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2650 - accuracy: 1.0000 - val_loss: 1.5566 - val_accuracy: 0.9037\n",
      "Epoch 490/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2578 - accuracy: 0.9999 - val_loss: 1.5427 - val_accuracy: 0.9057\n",
      "Epoch 491/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3687 - accuracy: 0.9712 - val_loss: 2.7674 - val_accuracy: 0.6573\n",
      "Epoch 492/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6229 - accuracy: 0.9219 - val_loss: 1.9436 - val_accuracy: 0.8196\n",
      "Epoch 493/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4704 - accuracy: 0.9803 - val_loss: 1.6839 - val_accuracy: 0.9023\n",
      "Epoch 494/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3981 - accuracy: 0.9980 - val_loss: 1.6485 - val_accuracy: 0.9032\n",
      "Epoch 495/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3549 - accuracy: 0.9999 - val_loss: 1.6329 - val_accuracy: 0.8984\n",
      "Epoch 496/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3219 - accuracy: 1.0000 - val_loss: 1.6129 - val_accuracy: 0.8968\n",
      "Epoch 497/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2969 - accuracy: 1.0000 - val_loss: 1.5936 - val_accuracy: 0.8988\n",
      "Epoch 498/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2764 - accuracy: 1.0000 - val_loss: 1.5687 - val_accuracy: 0.9013\n",
      "Epoch 499/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2595 - accuracy: 1.0000 - val_loss: 1.5447 - val_accuracy: 0.9025\n",
      "Epoch 500/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2455 - accuracy: 1.0000 - val_loss: 1.5254 - val_accuracy: 0.9060\n",
      "Time: 184.39550280570984\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Traits_Model_100BM.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#100 BM\n",
    "################################################################################################################################################\n",
    "# now repeat the analysis only for traits\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test  = train_test_split(y,X,traits_BM,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = BM_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Traits_Model_100BM.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4qH4j8KaN7Oo",
    "outputId": "e3a7e271-cf46-4e81-c30c-ceaf4f51447c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 50, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 48, 250)      45000       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 48, 250)     1000        ['conv1d_6[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 46, 250)      187500      ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 46, 250)     1000        ['conv1d_7[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 44, 250)      187500      ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 44, 250)     1000        ['conv1d_8[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 14, 250)     0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 3500)         0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dense_19_input (InputLayer)    [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 125)          437625      ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 150)          450000      ['dense_19_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 125)          0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 150)         600         ['dense_19[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 125)          15750       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 150)          22500       ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 125)          0           ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 150)         600         ['dense_20[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 50)           6300        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 50)           7550        ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 50)           0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_2 (LinearW)           (None, 50)           2           ['dense_21[0][0]',               \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 50)           2550        ['linear_w_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 3)            153         ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,366,630\n",
      "Trainable params: 1,364,530\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 4s 16ms/step - loss: 13.2157 - accuracy: 0.3441 - val_loss: 13.0983 - val_accuracy: 0.3640\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 13.1069 - accuracy: 0.3793 - val_loss: 13.0323 - val_accuracy: 0.4089\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 13.0133 - accuracy: 0.4179 - val_loss: 12.9443 - val_accuracy: 0.4789\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.9326 - accuracy: 0.4431 - val_loss: 12.8447 - val_accuracy: 0.5487\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.8562 - accuracy: 0.4804 - val_loss: 12.7472 - val_accuracy: 0.5949\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.7752 - accuracy: 0.5087 - val_loss: 12.6543 - val_accuracy: 0.6279\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.6951 - accuracy: 0.5450 - val_loss: 12.5686 - val_accuracy: 0.6472\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.6198 - accuracy: 0.5647 - val_loss: 12.4875 - val_accuracy: 0.6605\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.5459 - accuracy: 0.5856 - val_loss: 12.4107 - val_accuracy: 0.6755\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.4766 - accuracy: 0.6060 - val_loss: 12.3365 - val_accuracy: 0.6881\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.4063 - accuracy: 0.6188 - val_loss: 12.2659 - val_accuracy: 0.7011\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.3377 - accuracy: 0.6376 - val_loss: 12.1964 - val_accuracy: 0.7155\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.2704 - accuracy: 0.6500 - val_loss: 12.1265 - val_accuracy: 0.7285\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.2002 - accuracy: 0.6623 - val_loss: 12.0590 - val_accuracy: 0.7401\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.1383 - accuracy: 0.6788 - val_loss: 11.9923 - val_accuracy: 0.7504\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.0778 - accuracy: 0.6895 - val_loss: 11.9238 - val_accuracy: 0.7652\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.0058 - accuracy: 0.7070 - val_loss: 11.8560 - val_accuracy: 0.7769\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.9436 - accuracy: 0.7102 - val_loss: 11.7891 - val_accuracy: 0.7889\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.8815 - accuracy: 0.7277 - val_loss: 11.7238 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.8151 - accuracy: 0.7410 - val_loss: 11.6565 - val_accuracy: 0.8108\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.7513 - accuracy: 0.7535 - val_loss: 11.5916 - val_accuracy: 0.8220\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.6860 - accuracy: 0.7632 - val_loss: 11.5274 - val_accuracy: 0.8317\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.6169 - accuracy: 0.7776 - val_loss: 11.4643 - val_accuracy: 0.8412\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.5553 - accuracy: 0.7843 - val_loss: 11.4003 - val_accuracy: 0.8539\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.4938 - accuracy: 0.7970 - val_loss: 11.3396 - val_accuracy: 0.8620\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.4287 - accuracy: 0.8089 - val_loss: 11.2804 - val_accuracy: 0.8704\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.3714 - accuracy: 0.8191 - val_loss: 11.2218 - val_accuracy: 0.8783\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.3115 - accuracy: 0.8270 - val_loss: 11.1644 - val_accuracy: 0.8873\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.2516 - accuracy: 0.8366 - val_loss: 11.1089 - val_accuracy: 0.8939\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.1917 - accuracy: 0.8445 - val_loss: 11.0544 - val_accuracy: 0.8988\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.1356 - accuracy: 0.8533 - val_loss: 11.0006 - val_accuracy: 0.9041\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.0781 - accuracy: 0.8584 - val_loss: 10.9477 - val_accuracy: 0.9095\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.0261 - accuracy: 0.8653 - val_loss: 10.8965 - val_accuracy: 0.9131\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.9715 - accuracy: 0.8730 - val_loss: 10.8459 - val_accuracy: 0.9165\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.9232 - accuracy: 0.8763 - val_loss: 10.7962 - val_accuracy: 0.9200\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.8727 - accuracy: 0.8786 - val_loss: 10.7466 - val_accuracy: 0.9244\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.8126 - accuracy: 0.8887 - val_loss: 10.6974 - val_accuracy: 0.9283\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.7623 - accuracy: 0.8941 - val_loss: 10.6481 - val_accuracy: 0.9328\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.7159 - accuracy: 0.8966 - val_loss: 10.6000 - val_accuracy: 0.9375\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.6705 - accuracy: 0.8992 - val_loss: 10.5538 - val_accuracy: 0.9392\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.6187 - accuracy: 0.9037 - val_loss: 10.5070 - val_accuracy: 0.9415\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.5666 - accuracy: 0.9082 - val_loss: 10.4613 - val_accuracy: 0.9431\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.5187 - accuracy: 0.9142 - val_loss: 10.4154 - val_accuracy: 0.9467\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.4760 - accuracy: 0.9141 - val_loss: 10.3701 - val_accuracy: 0.9485\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.4230 - accuracy: 0.9198 - val_loss: 10.3257 - val_accuracy: 0.9505\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.3810 - accuracy: 0.9207 - val_loss: 10.2820 - val_accuracy: 0.9516\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.3376 - accuracy: 0.9232 - val_loss: 10.2375 - val_accuracy: 0.9517\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.2895 - accuracy: 0.9248 - val_loss: 10.1939 - val_accuracy: 0.9540\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.2438 - accuracy: 0.9279 - val_loss: 10.1503 - val_accuracy: 0.9552\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.1996 - accuracy: 0.9314 - val_loss: 10.1086 - val_accuracy: 0.9564\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.1579 - accuracy: 0.9324 - val_loss: 10.0656 - val_accuracy: 0.9573\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.1147 - accuracy: 0.9321 - val_loss: 10.0229 - val_accuracy: 0.9584\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.0671 - accuracy: 0.9392 - val_loss: 9.9807 - val_accuracy: 0.9595\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.0268 - accuracy: 0.9371 - val_loss: 9.9386 - val_accuracy: 0.9607\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.9857 - accuracy: 0.9393 - val_loss: 9.8977 - val_accuracy: 0.9613\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.9381 - accuracy: 0.9414 - val_loss: 9.8563 - val_accuracy: 0.9621\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.8954 - accuracy: 0.9438 - val_loss: 9.8153 - val_accuracy: 0.9637\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.8550 - accuracy: 0.9443 - val_loss: 9.7743 - val_accuracy: 0.9645\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.8170 - accuracy: 0.9444 - val_loss: 9.7331 - val_accuracy: 0.9657\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.7708 - accuracy: 0.9475 - val_loss: 9.6934 - val_accuracy: 0.9660\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.7288 - accuracy: 0.9481 - val_loss: 9.6533 - val_accuracy: 0.9668\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.6882 - accuracy: 0.9511 - val_loss: 9.6128 - val_accuracy: 0.9679\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.6491 - accuracy: 0.9517 - val_loss: 9.5736 - val_accuracy: 0.9681\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.6097 - accuracy: 0.9510 - val_loss: 9.5342 - val_accuracy: 0.9685\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.5657 - accuracy: 0.9552 - val_loss: 9.4944 - val_accuracy: 0.9696\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.5288 - accuracy: 0.9536 - val_loss: 9.4560 - val_accuracy: 0.9693\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.4851 - accuracy: 0.9534 - val_loss: 9.4176 - val_accuracy: 0.9696\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.4451 - accuracy: 0.9564 - val_loss: 9.3779 - val_accuracy: 0.9711\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.4073 - accuracy: 0.9554 - val_loss: 9.3389 - val_accuracy: 0.9717\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.3710 - accuracy: 0.9560 - val_loss: 9.3003 - val_accuracy: 0.9721\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.3309 - accuracy: 0.9589 - val_loss: 9.2617 - val_accuracy: 0.9728\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2902 - accuracy: 0.9585 - val_loss: 9.2241 - val_accuracy: 0.9731\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2526 - accuracy: 0.9601 - val_loss: 9.1868 - val_accuracy: 0.9728\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2123 - accuracy: 0.9592 - val_loss: 9.1480 - val_accuracy: 0.9737\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.1697 - accuracy: 0.9628 - val_loss: 9.1102 - val_accuracy: 0.9747\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.1316 - accuracy: 0.9624 - val_loss: 9.0722 - val_accuracy: 0.9751\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0935 - accuracy: 0.9622 - val_loss: 9.0346 - val_accuracy: 0.9749\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0540 - accuracy: 0.9643 - val_loss: 8.9975 - val_accuracy: 0.9756\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0207 - accuracy: 0.9621 - val_loss: 8.9599 - val_accuracy: 0.9763\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.9788 - accuracy: 0.9654 - val_loss: 8.9234 - val_accuracy: 0.9763\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.9438 - accuracy: 0.9643 - val_loss: 8.8856 - val_accuracy: 0.9771\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.9036 - accuracy: 0.9658 - val_loss: 8.8490 - val_accuracy: 0.9767\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.8680 - accuracy: 0.9646 - val_loss: 8.8126 - val_accuracy: 0.9768\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.8279 - accuracy: 0.9658 - val_loss: 8.7755 - val_accuracy: 0.9771\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7935 - accuracy: 0.9648 - val_loss: 8.7390 - val_accuracy: 0.9767\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7569 - accuracy: 0.9664 - val_loss: 8.7022 - val_accuracy: 0.9771\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7164 - accuracy: 0.9679 - val_loss: 8.6658 - val_accuracy: 0.9771\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.6816 - accuracy: 0.9674 - val_loss: 8.6285 - val_accuracy: 0.9777\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.6435 - accuracy: 0.9688 - val_loss: 8.5917 - val_accuracy: 0.9783\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.6055 - accuracy: 0.9686 - val_loss: 8.5562 - val_accuracy: 0.9781\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.5653 - accuracy: 0.9704 - val_loss: 8.5209 - val_accuracy: 0.9780\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.5318 - accuracy: 0.9699 - val_loss: 8.4858 - val_accuracy: 0.9776\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4944 - accuracy: 0.9712 - val_loss: 8.4498 - val_accuracy: 0.9777\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4603 - accuracy: 0.9687 - val_loss: 8.4131 - val_accuracy: 0.9781\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4242 - accuracy: 0.9700 - val_loss: 8.3773 - val_accuracy: 0.9792\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3879 - accuracy: 0.9709 - val_loss: 8.3426 - val_accuracy: 0.9787\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3496 - accuracy: 0.9713 - val_loss: 8.3072 - val_accuracy: 0.9792\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3160 - accuracy: 0.9718 - val_loss: 8.2729 - val_accuracy: 0.9784\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.2781 - accuracy: 0.9730 - val_loss: 8.2374 - val_accuracy: 0.9784\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.2448 - accuracy: 0.9723 - val_loss: 8.2023 - val_accuracy: 0.9793\n",
      "Time: 102.1455147266388\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_100BM_50SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#100 BM, 50 SNPs\n",
    "################################################################################################################################################\n",
    "# subset the SNPs\n",
    "X50=X[:,0:50,:]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test  = train_test_split(y,X50,traits_BM,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_BM_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_100BM_50SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FAJQnqGnbfMw",
    "outputId": "56595f5f-53ce-4d02-8057-b542a6d5c766",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 50, 60)]          0         \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 48, 250)           45000     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 48, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 46, 250)           187500    \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 46, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 44, 250)           187500    \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 44, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 14, 250)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 3500)              0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 125)               437625    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 125)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 125)               15750     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 125)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 50)                6300      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 882,828\n",
      "Trainable params: 881,328\n",
      "Non-trainable params: 1,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 2s 12ms/step - loss: 1.4450 - accuracy: 0.3960 - val_loss: 1.0405 - val_accuracy: 0.5057\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 1.1207 - accuracy: 0.4585 - val_loss: 0.9560 - val_accuracy: 0.5945\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 1.0288 - accuracy: 0.5041 - val_loss: 0.8701 - val_accuracy: 0.6596\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.9607 - accuracy: 0.5416 - val_loss: 0.7945 - val_accuracy: 0.6948\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.9095 - accuracy: 0.5667 - val_loss: 0.7347 - val_accuracy: 0.7191\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.8696 - accuracy: 0.5905 - val_loss: 0.6840 - val_accuracy: 0.7393\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.8199 - accuracy: 0.6209 - val_loss: 0.6378 - val_accuracy: 0.7584\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.7825 - accuracy: 0.6424 - val_loss: 0.5933 - val_accuracy: 0.7819\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.7415 - accuracy: 0.6632 - val_loss: 0.5486 - val_accuracy: 0.8003\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.6997 - accuracy: 0.6926 - val_loss: 0.5066 - val_accuracy: 0.8183\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.6537 - accuracy: 0.7104 - val_loss: 0.4639 - val_accuracy: 0.8304\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.6217 - accuracy: 0.7287 - val_loss: 0.4270 - val_accuracy: 0.8451\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.5878 - accuracy: 0.7489 - val_loss: 0.3923 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.5468 - accuracy: 0.7707 - val_loss: 0.3605 - val_accuracy: 0.8699\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.5154 - accuracy: 0.7816 - val_loss: 0.3297 - val_accuracy: 0.8780\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.4801 - accuracy: 0.8003 - val_loss: 0.3042 - val_accuracy: 0.8885\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.4510 - accuracy: 0.8156 - val_loss: 0.2821 - val_accuracy: 0.8987\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.4282 - accuracy: 0.8310 - val_loss: 0.2624 - val_accuracy: 0.9061\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.4092 - accuracy: 0.8388 - val_loss: 0.2426 - val_accuracy: 0.9176\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.3745 - accuracy: 0.8530 - val_loss: 0.2260 - val_accuracy: 0.9231\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.3621 - accuracy: 0.8582 - val_loss: 0.2094 - val_accuracy: 0.9296\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.3372 - accuracy: 0.8712 - val_loss: 0.1959 - val_accuracy: 0.9352\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.3229 - accuracy: 0.8759 - val_loss: 0.1849 - val_accuracy: 0.9391\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.3152 - accuracy: 0.8794 - val_loss: 0.1766 - val_accuracy: 0.9413\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.2920 - accuracy: 0.8900 - val_loss: 0.1691 - val_accuracy: 0.9429\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.2852 - accuracy: 0.8916 - val_loss: 0.1589 - val_accuracy: 0.9468\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.2714 - accuracy: 0.8989 - val_loss: 0.1519 - val_accuracy: 0.9496\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.2625 - accuracy: 0.9055 - val_loss: 0.1448 - val_accuracy: 0.9521\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.2483 - accuracy: 0.9085 - val_loss: 0.1383 - val_accuracy: 0.9549\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.2401 - accuracy: 0.9119 - val_loss: 0.1340 - val_accuracy: 0.9555\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.2324 - accuracy: 0.9143 - val_loss: 0.1276 - val_accuracy: 0.9580\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.2296 - accuracy: 0.9166 - val_loss: 0.1226 - val_accuracy: 0.9591\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.2187 - accuracy: 0.9208 - val_loss: 0.1187 - val_accuracy: 0.9601\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.2152 - accuracy: 0.9249 - val_loss: 0.1146 - val_accuracy: 0.9613\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.2086 - accuracy: 0.9257 - val_loss: 0.1112 - val_accuracy: 0.9624\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1987 - accuracy: 0.9299 - val_loss: 0.1091 - val_accuracy: 0.9627\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1909 - accuracy: 0.9333 - val_loss: 0.1057 - val_accuracy: 0.9639\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1888 - accuracy: 0.9337 - val_loss: 0.1024 - val_accuracy: 0.9648\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1818 - accuracy: 0.9367 - val_loss: 0.0995 - val_accuracy: 0.9661\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1778 - accuracy: 0.9384 - val_loss: 0.0964 - val_accuracy: 0.9664\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1778 - accuracy: 0.9381 - val_loss: 0.0949 - val_accuracy: 0.9668\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1714 - accuracy: 0.9397 - val_loss: 0.0927 - val_accuracy: 0.9673\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1657 - accuracy: 0.9431 - val_loss: 0.0908 - val_accuracy: 0.9687\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1646 - accuracy: 0.9440 - val_loss: 0.0894 - val_accuracy: 0.9685\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1629 - accuracy: 0.9441 - val_loss: 0.0876 - val_accuracy: 0.9693\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1536 - accuracy: 0.9473 - val_loss: 0.0880 - val_accuracy: 0.9692\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1543 - accuracy: 0.9476 - val_loss: 0.0854 - val_accuracy: 0.9696\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1486 - accuracy: 0.9470 - val_loss: 0.0846 - val_accuracy: 0.9696\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 0.1416 - accuracy: 0.9512 - val_loss: 0.0827 - val_accuracy: 0.9709\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1461 - accuracy: 0.9522 - val_loss: 0.0802 - val_accuracy: 0.9719\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1402 - accuracy: 0.9521 - val_loss: 0.0787 - val_accuracy: 0.9723\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1336 - accuracy: 0.9552 - val_loss: 0.0785 - val_accuracy: 0.9725\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 0.1326 - accuracy: 0.9556 - val_loss: 0.0761 - val_accuracy: 0.9736\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1331 - accuracy: 0.9541 - val_loss: 0.0752 - val_accuracy: 0.9736\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1339 - accuracy: 0.9542 - val_loss: 0.0742 - val_accuracy: 0.9745\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 0.1266 - accuracy: 0.9576 - val_loss: 0.0732 - val_accuracy: 0.9744\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 0.1251 - accuracy: 0.9585 - val_loss: 0.0735 - val_accuracy: 0.9740\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 0.1165 - accuracy: 0.9608 - val_loss: 0.0710 - val_accuracy: 0.9757\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1223 - accuracy: 0.9600 - val_loss: 0.0723 - val_accuracy: 0.9745\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1160 - accuracy: 0.9602 - val_loss: 0.0704 - val_accuracy: 0.9756\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1200 - accuracy: 0.9586 - val_loss: 0.0702 - val_accuracy: 0.9756\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1155 - accuracy: 0.9600 - val_loss: 0.0681 - val_accuracy: 0.9765\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1142 - accuracy: 0.9611 - val_loss: 0.0669 - val_accuracy: 0.9772\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1101 - accuracy: 0.9626 - val_loss: 0.0662 - val_accuracy: 0.9771\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1085 - accuracy: 0.9656 - val_loss: 0.0660 - val_accuracy: 0.9769\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1089 - accuracy: 0.9642 - val_loss: 0.0661 - val_accuracy: 0.9771\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1073 - accuracy: 0.9646 - val_loss: 0.0651 - val_accuracy: 0.9771\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1097 - accuracy: 0.9636 - val_loss: 0.0640 - val_accuracy: 0.9773\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1026 - accuracy: 0.9656 - val_loss: 0.0642 - val_accuracy: 0.9777\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0966 - accuracy: 0.9691 - val_loss: 0.0628 - val_accuracy: 0.9776\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1018 - accuracy: 0.9651 - val_loss: 0.0614 - val_accuracy: 0.9785\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0975 - accuracy: 0.9678 - val_loss: 0.0615 - val_accuracy: 0.9781\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0962 - accuracy: 0.9694 - val_loss: 0.0613 - val_accuracy: 0.9787\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0929 - accuracy: 0.9690 - val_loss: 0.0608 - val_accuracy: 0.9788\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0952 - accuracy: 0.9690 - val_loss: 0.0606 - val_accuracy: 0.9788\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0910 - accuracy: 0.9703 - val_loss: 0.0601 - val_accuracy: 0.9792\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0913 - accuracy: 0.9689 - val_loss: 0.0594 - val_accuracy: 0.9792\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0915 - accuracy: 0.9715 - val_loss: 0.0604 - val_accuracy: 0.9789\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0877 - accuracy: 0.9707 - val_loss: 0.0582 - val_accuracy: 0.9796\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0874 - accuracy: 0.9724 - val_loss: 0.0585 - val_accuracy: 0.9801\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0883 - accuracy: 0.9714 - val_loss: 0.0577 - val_accuracy: 0.9800\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0861 - accuracy: 0.9723 - val_loss: 0.0568 - val_accuracy: 0.9804\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0831 - accuracy: 0.9731 - val_loss: 0.0572 - val_accuracy: 0.9805\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0865 - accuracy: 0.9704 - val_loss: 0.0570 - val_accuracy: 0.9808\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0843 - accuracy: 0.9728 - val_loss: 0.0578 - val_accuracy: 0.9803\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0837 - accuracy: 0.9739 - val_loss: 0.0562 - val_accuracy: 0.9808\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0808 - accuracy: 0.9744 - val_loss: 0.0561 - val_accuracy: 0.9808\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0803 - accuracy: 0.9720 - val_loss: 0.0553 - val_accuracy: 0.9811\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0801 - accuracy: 0.9724 - val_loss: 0.0563 - val_accuracy: 0.9809\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0792 - accuracy: 0.9749 - val_loss: 0.0559 - val_accuracy: 0.9807\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0801 - accuracy: 0.9738 - val_loss: 0.0555 - val_accuracy: 0.9808\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0779 - accuracy: 0.9745 - val_loss: 0.0556 - val_accuracy: 0.9812\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0730 - accuracy: 0.9768 - val_loss: 0.0551 - val_accuracy: 0.9815\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0773 - accuracy: 0.9746 - val_loss: 0.0553 - val_accuracy: 0.9816\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0758 - accuracy: 0.9747 - val_loss: 0.0541 - val_accuracy: 0.9815\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0707 - accuracy: 0.9768 - val_loss: 0.0554 - val_accuracy: 0.9816\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0710 - accuracy: 0.9762 - val_loss: 0.0540 - val_accuracy: 0.9816\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0750 - accuracy: 0.9756 - val_loss: 0.0525 - val_accuracy: 0.9817\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0746 - accuracy: 0.9747 - val_loss: 0.0529 - val_accuracy: 0.9821\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0704 - accuracy: 0.9761 - val_loss: 0.0537 - val_accuracy: 0.9819\n",
      "Time: 85.45744299888611\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_CNN_Model_50SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#50 SNPs\n",
    "################################################################################################################################################\n",
    "# now repeat the analysis only for SNPs\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test  = train_test_split(y,X50,traits_BM,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = SNP_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_CNN_Model_50SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oXWI7orOx8zC",
    "outputId": "bcddbd4d-6a68-4a69-92c5-584813aa5198",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 50, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 48, 250)      45000       ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 48, 250)     1000        ['conv1d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 46, 250)      187500      ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 46, 250)     1000        ['conv1d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 44, 250)      187500      ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 44, 250)     1000        ['conv1d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 14, 250)     0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 3500)         0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " dense_34_input (InputLayer)    [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 125)          437625      ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 150)          450000      ['dense_34_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 125)          0           ['dense_37[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 150)         600         ['dense_34[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 125)          15750       ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 150)          22500       ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 125)          0           ['dense_38[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 150)         600         ['dense_35[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 50)           6300        ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 50)           7550        ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 50)           0           ['dense_39[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_4 (LinearW)           (None, 50)           2           ['dense_36[0][0]',               \n",
      "                                                                  'activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 50)           2550        ['linear_w_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 3)            153         ['dense_40[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,366,630\n",
      "Trainable params: 1,364,530\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 3s 16ms/step - loss: 13.1987 - accuracy: 0.3244 - val_loss: 13.1289 - val_accuracy: 0.2941\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 13.1071 - accuracy: 0.3657 - val_loss: 13.0607 - val_accuracy: 0.3505\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 13.0258 - accuracy: 0.4015 - val_loss: 12.9761 - val_accuracy: 0.4395\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.9519 - accuracy: 0.4306 - val_loss: 12.8866 - val_accuracy: 0.5116\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.8768 - accuracy: 0.4597 - val_loss: 12.7979 - val_accuracy: 0.5672\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.8013 - accuracy: 0.4920 - val_loss: 12.7132 - val_accuracy: 0.6055\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.7288 - accuracy: 0.5176 - val_loss: 12.6332 - val_accuracy: 0.6280\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.6531 - accuracy: 0.5477 - val_loss: 12.5561 - val_accuracy: 0.6440\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.5842 - accuracy: 0.5658 - val_loss: 12.4823 - val_accuracy: 0.6533\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.5131 - accuracy: 0.5813 - val_loss: 12.4122 - val_accuracy: 0.6596\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.4497 - accuracy: 0.5967 - val_loss: 12.3451 - val_accuracy: 0.6656\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.3870 - accuracy: 0.6064 - val_loss: 12.2813 - val_accuracy: 0.6741\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.3243 - accuracy: 0.6213 - val_loss: 12.2193 - val_accuracy: 0.6804\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.2632 - accuracy: 0.6304 - val_loss: 12.1582 - val_accuracy: 0.6877\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.2087 - accuracy: 0.6356 - val_loss: 12.0975 - val_accuracy: 0.6955\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.1460 - accuracy: 0.6454 - val_loss: 12.0381 - val_accuracy: 0.7037\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.0862 - accuracy: 0.6552 - val_loss: 11.9805 - val_accuracy: 0.7087\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.0311 - accuracy: 0.6660 - val_loss: 11.9220 - val_accuracy: 0.7169\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.9742 - accuracy: 0.6739 - val_loss: 11.8633 - val_accuracy: 0.7263\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.9103 - accuracy: 0.6875 - val_loss: 11.8056 - val_accuracy: 0.7341\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.8623 - accuracy: 0.6865 - val_loss: 11.7487 - val_accuracy: 0.7432\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.8047 - accuracy: 0.6979 - val_loss: 11.6917 - val_accuracy: 0.7517\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.7490 - accuracy: 0.7073 - val_loss: 11.6346 - val_accuracy: 0.7580\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.6873 - accuracy: 0.7155 - val_loss: 11.5755 - val_accuracy: 0.7693\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.6361 - accuracy: 0.7235 - val_loss: 11.5190 - val_accuracy: 0.7803\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.5762 - accuracy: 0.7334 - val_loss: 11.4603 - val_accuracy: 0.7907\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.5255 - accuracy: 0.7385 - val_loss: 11.4012 - val_accuracy: 0.8015\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.4603 - accuracy: 0.7501 - val_loss: 11.3425 - val_accuracy: 0.8104\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.4066 - accuracy: 0.7559 - val_loss: 11.2848 - val_accuracy: 0.8200\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.3486 - accuracy: 0.7681 - val_loss: 11.2270 - val_accuracy: 0.8288\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.2937 - accuracy: 0.7719 - val_loss: 11.1676 - val_accuracy: 0.8387\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.2295 - accuracy: 0.7874 - val_loss: 11.1085 - val_accuracy: 0.8487\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.1758 - accuracy: 0.7926 - val_loss: 11.0524 - val_accuracy: 0.8556\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.1216 - accuracy: 0.8006 - val_loss: 10.9940 - val_accuracy: 0.8659\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.0606 - accuracy: 0.8111 - val_loss: 10.9367 - val_accuracy: 0.8743\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.0020 - accuracy: 0.8203 - val_loss: 10.8824 - val_accuracy: 0.8805\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.9529 - accuracy: 0.8252 - val_loss: 10.8267 - val_accuracy: 0.8868\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.8917 - accuracy: 0.8343 - val_loss: 10.7727 - val_accuracy: 0.8909\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.8444 - accuracy: 0.8379 - val_loss: 10.7201 - val_accuracy: 0.8963\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.7863 - accuracy: 0.8487 - val_loss: 10.6662 - val_accuracy: 0.9032\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.7379 - accuracy: 0.8532 - val_loss: 10.6160 - val_accuracy: 0.9068\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.6771 - accuracy: 0.8627 - val_loss: 10.5645 - val_accuracy: 0.9124\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.6250 - accuracy: 0.8672 - val_loss: 10.5151 - val_accuracy: 0.9151\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.5783 - accuracy: 0.8724 - val_loss: 10.4655 - val_accuracy: 0.9183\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.5212 - accuracy: 0.8769 - val_loss: 10.4161 - val_accuracy: 0.9221\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.4750 - accuracy: 0.8834 - val_loss: 10.3674 - val_accuracy: 0.9259\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.4210 - accuracy: 0.8890 - val_loss: 10.3198 - val_accuracy: 0.9289\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.3787 - accuracy: 0.8893 - val_loss: 10.2724 - val_accuracy: 0.9324\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.3260 - accuracy: 0.8968 - val_loss: 10.2256 - val_accuracy: 0.9347\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.2788 - accuracy: 0.8997 - val_loss: 10.1789 - val_accuracy: 0.9376\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.2281 - accuracy: 0.9044 - val_loss: 10.1330 - val_accuracy: 0.9397\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.1846 - accuracy: 0.9080 - val_loss: 10.0871 - val_accuracy: 0.9423\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.1384 - accuracy: 0.9120 - val_loss: 10.0433 - val_accuracy: 0.9431\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.0948 - accuracy: 0.9133 - val_loss: 9.9987 - val_accuracy: 0.9459\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.0493 - accuracy: 0.9181 - val_loss: 9.9549 - val_accuracy: 0.9475\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.0020 - accuracy: 0.9208 - val_loss: 9.9105 - val_accuracy: 0.9499\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.9610 - accuracy: 0.9230 - val_loss: 9.8684 - val_accuracy: 0.9512\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.9106 - accuracy: 0.9256 - val_loss: 9.8245 - val_accuracy: 0.9539\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.8691 - accuracy: 0.9268 - val_loss: 9.7826 - val_accuracy: 0.9547\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.8260 - accuracy: 0.9287 - val_loss: 9.7399 - val_accuracy: 0.9565\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.7818 - accuracy: 0.9312 - val_loss: 9.6985 - val_accuracy: 0.9576\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.7389 - accuracy: 0.9332 - val_loss: 9.6579 - val_accuracy: 0.9580\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.6939 - accuracy: 0.9357 - val_loss: 9.6150 - val_accuracy: 0.9612\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.6528 - accuracy: 0.9376 - val_loss: 9.5746 - val_accuracy: 0.9620\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.6081 - accuracy: 0.9392 - val_loss: 9.5333 - val_accuracy: 0.9629\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.5667 - accuracy: 0.9409 - val_loss: 9.4935 - val_accuracy: 0.9643\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.5273 - accuracy: 0.9425 - val_loss: 9.4526 - val_accuracy: 0.9648\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.4900 - accuracy: 0.9428 - val_loss: 9.4112 - val_accuracy: 0.9655\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.4456 - accuracy: 0.9464 - val_loss: 9.3708 - val_accuracy: 0.9665\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.4064 - accuracy: 0.9463 - val_loss: 9.3335 - val_accuracy: 0.9669\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.3616 - accuracy: 0.9488 - val_loss: 9.2941 - val_accuracy: 0.9677\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.3211 - accuracy: 0.9498 - val_loss: 9.2542 - val_accuracy: 0.9683\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2887 - accuracy: 0.9479 - val_loss: 9.2149 - val_accuracy: 0.9683\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2430 - accuracy: 0.9507 - val_loss: 9.1760 - val_accuracy: 0.9693\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2010 - accuracy: 0.9520 - val_loss: 9.1383 - val_accuracy: 0.9700\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.1635 - accuracy: 0.9529 - val_loss: 9.1000 - val_accuracy: 0.9700\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.1252 - accuracy: 0.9537 - val_loss: 9.0622 - val_accuracy: 0.9699\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0866 - accuracy: 0.9555 - val_loss: 9.0231 - val_accuracy: 0.9709\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0463 - accuracy: 0.9563 - val_loss: 8.9848 - val_accuracy: 0.9717\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0068 - accuracy: 0.9576 - val_loss: 8.9469 - val_accuracy: 0.9719\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.9720 - accuracy: 0.9558 - val_loss: 8.9098 - val_accuracy: 0.9721\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.9304 - accuracy: 0.9579 - val_loss: 8.8722 - val_accuracy: 0.9723\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.8914 - accuracy: 0.9588 - val_loss: 8.8348 - val_accuracy: 0.9723\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.8518 - accuracy: 0.9602 - val_loss: 8.7984 - val_accuracy: 0.9727\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.8131 - accuracy: 0.9612 - val_loss: 8.7598 - val_accuracy: 0.9732\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7766 - accuracy: 0.9616 - val_loss: 8.7234 - val_accuracy: 0.9733\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7402 - accuracy: 0.9626 - val_loss: 8.6873 - val_accuracy: 0.9731\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7055 - accuracy: 0.9623 - val_loss: 8.6497 - val_accuracy: 0.9737\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.6632 - accuracy: 0.9644 - val_loss: 8.6124 - val_accuracy: 0.9740\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.6274 - accuracy: 0.9641 - val_loss: 8.5769 - val_accuracy: 0.9740\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.5937 - accuracy: 0.9635 - val_loss: 8.5400 - val_accuracy: 0.9749\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.5555 - accuracy: 0.9645 - val_loss: 8.5045 - val_accuracy: 0.9753\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.5152 - accuracy: 0.9664 - val_loss: 8.4676 - val_accuracy: 0.9757\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4786 - accuracy: 0.9654 - val_loss: 8.4311 - val_accuracy: 0.9767\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4415 - accuracy: 0.9665 - val_loss: 8.3968 - val_accuracy: 0.9763\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4058 - accuracy: 0.9676 - val_loss: 8.3603 - val_accuracy: 0.9768\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3700 - accuracy: 0.9676 - val_loss: 8.3245 - val_accuracy: 0.9773\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3364 - accuracy: 0.9660 - val_loss: 8.2899 - val_accuracy: 0.9772\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.2986 - accuracy: 0.9673 - val_loss: 8.2541 - val_accuracy: 0.9773\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.2626 - accuracy: 0.9685 - val_loss: 8.2198 - val_accuracy: 0.9769\n",
      "Time: 101.06225919723511\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_50BM_50SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#50 BM, 50 SNPs\n",
    "################################################################################################################################################\n",
    "# subset the traits\n",
    "traits_BM50=traits_BM[:,0:50,:]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test  = train_test_split(y,X50,traits_BM50,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_BM_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_50BM_50SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MjNgaOT_0wnm",
    "outputId": "cc57356e-a594-420b-c4b3-f1687276fcac",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42_input (InputLayer)  [(None, 3000)]           0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 150)               450000    \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 150)               22500     \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 50)                7550      \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 481,403\n",
      "Trainable params: 480,803\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 13.3987 - accuracy: 0.3461 - val_loss: 13.1989 - val_accuracy: 0.3651\n",
      "Epoch 2/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.2174 - accuracy: 0.4100 - val_loss: 13.1180 - val_accuracy: 0.4183\n",
      "Epoch 3/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.0811 - accuracy: 0.4622 - val_loss: 13.0317 - val_accuracy: 0.4652\n",
      "Epoch 4/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.9710 - accuracy: 0.4978 - val_loss: 12.9497 - val_accuracy: 0.4961\n",
      "Epoch 5/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.8782 - accuracy: 0.5241 - val_loss: 12.8735 - val_accuracy: 0.5171\n",
      "Epoch 6/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.7960 - accuracy: 0.5456 - val_loss: 12.8027 - val_accuracy: 0.5344\n",
      "Epoch 7/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.7194 - accuracy: 0.5616 - val_loss: 12.7363 - val_accuracy: 0.5476\n",
      "Epoch 8/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.6473 - accuracy: 0.5813 - val_loss: 12.6735 - val_accuracy: 0.5595\n",
      "Epoch 9/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.5794 - accuracy: 0.5897 - val_loss: 12.6134 - val_accuracy: 0.5660\n",
      "Epoch 10/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.5140 - accuracy: 0.5999 - val_loss: 12.5557 - val_accuracy: 0.5689\n",
      "Epoch 11/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.4518 - accuracy: 0.6088 - val_loss: 12.4999 - val_accuracy: 0.5749\n",
      "Epoch 12/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.3906 - accuracy: 0.6204 - val_loss: 12.4454 - val_accuracy: 0.5785\n",
      "Epoch 13/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.3308 - accuracy: 0.6284 - val_loss: 12.3924 - val_accuracy: 0.5833\n",
      "Epoch 14/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.2733 - accuracy: 0.6346 - val_loss: 12.3405 - val_accuracy: 0.5859\n",
      "Epoch 15/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.2174 - accuracy: 0.6418 - val_loss: 12.2894 - val_accuracy: 0.5884\n",
      "Epoch 16/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.1610 - accuracy: 0.6492 - val_loss: 12.2393 - val_accuracy: 0.5917\n",
      "Epoch 17/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.1070 - accuracy: 0.6554 - val_loss: 12.1899 - val_accuracy: 0.5941\n",
      "Epoch 18/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.0530 - accuracy: 0.6638 - val_loss: 12.1409 - val_accuracy: 0.5960\n",
      "Epoch 19/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.9995 - accuracy: 0.6675 - val_loss: 12.0926 - val_accuracy: 0.5984\n",
      "Epoch 20/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.9468 - accuracy: 0.6740 - val_loss: 12.0449 - val_accuracy: 0.5997\n",
      "Epoch 21/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.8938 - accuracy: 0.6798 - val_loss: 11.9976 - val_accuracy: 0.6008\n",
      "Epoch 22/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.8435 - accuracy: 0.6854 - val_loss: 11.9507 - val_accuracy: 0.6032\n",
      "Epoch 23/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.7920 - accuracy: 0.6941 - val_loss: 11.9043 - val_accuracy: 0.6056\n",
      "Epoch 24/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.7411 - accuracy: 0.6981 - val_loss: 11.8580 - val_accuracy: 0.6080\n",
      "Epoch 25/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.6919 - accuracy: 0.7022 - val_loss: 11.8123 - val_accuracy: 0.6101\n",
      "Epoch 26/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.6389 - accuracy: 0.7092 - val_loss: 11.7669 - val_accuracy: 0.6116\n",
      "Epoch 27/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.5914 - accuracy: 0.7120 - val_loss: 11.7217 - val_accuracy: 0.6128\n",
      "Epoch 28/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.5419 - accuracy: 0.7179 - val_loss: 11.6769 - val_accuracy: 0.6152\n",
      "Epoch 29/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.4931 - accuracy: 0.7237 - val_loss: 11.6321 - val_accuracy: 0.6163\n",
      "Epoch 30/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.4429 - accuracy: 0.7295 - val_loss: 11.5878 - val_accuracy: 0.6165\n",
      "Epoch 31/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.3964 - accuracy: 0.7317 - val_loss: 11.5436 - val_accuracy: 0.6173\n",
      "Epoch 32/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.3470 - accuracy: 0.7370 - val_loss: 11.4997 - val_accuracy: 0.6189\n",
      "Epoch 33/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.2987 - accuracy: 0.7432 - val_loss: 11.4561 - val_accuracy: 0.6208\n",
      "Epoch 34/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.2512 - accuracy: 0.7480 - val_loss: 11.4127 - val_accuracy: 0.6224\n",
      "Epoch 35/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.2042 - accuracy: 0.7511 - val_loss: 11.3694 - val_accuracy: 0.6232\n",
      "Epoch 36/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.1581 - accuracy: 0.7538 - val_loss: 11.3265 - val_accuracy: 0.6260\n",
      "Epoch 37/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.1100 - accuracy: 0.7612 - val_loss: 11.2835 - val_accuracy: 0.6269\n",
      "Epoch 38/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.0632 - accuracy: 0.7651 - val_loss: 11.2407 - val_accuracy: 0.6287\n",
      "Epoch 39/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.0168 - accuracy: 0.7695 - val_loss: 11.1982 - val_accuracy: 0.6293\n",
      "Epoch 40/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.9691 - accuracy: 0.7752 - val_loss: 11.1560 - val_accuracy: 0.6300\n",
      "Epoch 41/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.9231 - accuracy: 0.7778 - val_loss: 11.1138 - val_accuracy: 0.6316\n",
      "Epoch 42/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.8776 - accuracy: 0.7830 - val_loss: 11.0719 - val_accuracy: 0.6323\n",
      "Epoch 43/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.8311 - accuracy: 0.7848 - val_loss: 11.0302 - val_accuracy: 0.6329\n",
      "Epoch 44/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.7849 - accuracy: 0.7919 - val_loss: 10.9887 - val_accuracy: 0.6341\n",
      "Epoch 45/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.7391 - accuracy: 0.7946 - val_loss: 10.9472 - val_accuracy: 0.6348\n",
      "Epoch 46/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.6945 - accuracy: 0.7982 - val_loss: 10.9057 - val_accuracy: 0.6355\n",
      "Epoch 47/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.6499 - accuracy: 0.8031 - val_loss: 10.8645 - val_accuracy: 0.6372\n",
      "Epoch 48/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.6048 - accuracy: 0.8069 - val_loss: 10.8235 - val_accuracy: 0.6384\n",
      "Epoch 49/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.5602 - accuracy: 0.8104 - val_loss: 10.7824 - val_accuracy: 0.6404\n",
      "Epoch 50/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.5152 - accuracy: 0.8127 - val_loss: 10.7416 - val_accuracy: 0.6416\n",
      "Epoch 51/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.4693 - accuracy: 0.8154 - val_loss: 10.7009 - val_accuracy: 0.6425\n",
      "Epoch 52/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.4250 - accuracy: 0.8189 - val_loss: 10.6605 - val_accuracy: 0.6437\n",
      "Epoch 53/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.3796 - accuracy: 0.8243 - val_loss: 10.6201 - val_accuracy: 0.6440\n",
      "Epoch 54/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.3364 - accuracy: 0.8280 - val_loss: 10.5799 - val_accuracy: 0.6456\n",
      "Epoch 55/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.2918 - accuracy: 0.8301 - val_loss: 10.5398 - val_accuracy: 0.6455\n",
      "Epoch 56/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.2466 - accuracy: 0.8354 - val_loss: 10.5000 - val_accuracy: 0.6461\n",
      "Epoch 57/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.2030 - accuracy: 0.8364 - val_loss: 10.4601 - val_accuracy: 0.6464\n",
      "Epoch 58/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.1596 - accuracy: 0.8402 - val_loss: 10.4203 - val_accuracy: 0.6477\n",
      "Epoch 59/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.1175 - accuracy: 0.8436 - val_loss: 10.3807 - val_accuracy: 0.6495\n",
      "Epoch 60/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.0727 - accuracy: 0.8478 - val_loss: 10.3413 - val_accuracy: 0.6500\n",
      "Epoch 61/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.0299 - accuracy: 0.8504 - val_loss: 10.3020 - val_accuracy: 0.6507\n",
      "Epoch 62/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.9861 - accuracy: 0.8533 - val_loss: 10.2629 - val_accuracy: 0.6524\n",
      "Epoch 63/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.9413 - accuracy: 0.8582 - val_loss: 10.2238 - val_accuracy: 0.6524\n",
      "Epoch 64/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.8999 - accuracy: 0.8612 - val_loss: 10.1849 - val_accuracy: 0.6544\n",
      "Epoch 65/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.8585 - accuracy: 0.8637 - val_loss: 10.1459 - val_accuracy: 0.6553\n",
      "Epoch 66/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.8151 - accuracy: 0.8656 - val_loss: 10.1070 - val_accuracy: 0.6568\n",
      "Epoch 67/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.7729 - accuracy: 0.8675 - val_loss: 10.0683 - val_accuracy: 0.6576\n",
      "Epoch 68/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.7283 - accuracy: 0.8728 - val_loss: 10.0298 - val_accuracy: 0.6581\n",
      "Epoch 69/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.6878 - accuracy: 0.8765 - val_loss: 9.9912 - val_accuracy: 0.6597\n",
      "Epoch 70/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.6435 - accuracy: 0.8784 - val_loss: 9.9529 - val_accuracy: 0.6605\n",
      "Epoch 71/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.6033 - accuracy: 0.8803 - val_loss: 9.9149 - val_accuracy: 0.6612\n",
      "Epoch 72/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.5603 - accuracy: 0.8829 - val_loss: 9.8766 - val_accuracy: 0.6623\n",
      "Epoch 73/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.5189 - accuracy: 0.8874 - val_loss: 9.8383 - val_accuracy: 0.6628\n",
      "Epoch 74/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.4753 - accuracy: 0.8906 - val_loss: 9.8006 - val_accuracy: 0.6633\n",
      "Epoch 75/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.4347 - accuracy: 0.8922 - val_loss: 9.7629 - val_accuracy: 0.6640\n",
      "Epoch 76/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.3913 - accuracy: 0.8986 - val_loss: 9.7250 - val_accuracy: 0.6636\n",
      "Epoch 77/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.3520 - accuracy: 0.8971 - val_loss: 9.6874 - val_accuracy: 0.6661\n",
      "Epoch 78/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.3105 - accuracy: 0.9016 - val_loss: 9.6502 - val_accuracy: 0.6664\n",
      "Epoch 79/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.2689 - accuracy: 0.9038 - val_loss: 9.6129 - val_accuracy: 0.6668\n",
      "Epoch 80/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.2282 - accuracy: 0.9042 - val_loss: 9.5755 - val_accuracy: 0.6673\n",
      "Epoch 81/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.1874 - accuracy: 0.9076 - val_loss: 9.5385 - val_accuracy: 0.6679\n",
      "Epoch 82/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.1467 - accuracy: 0.9107 - val_loss: 9.5014 - val_accuracy: 0.6691\n",
      "Epoch 83/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.1054 - accuracy: 0.9130 - val_loss: 9.4642 - val_accuracy: 0.6697\n",
      "Epoch 84/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.0634 - accuracy: 0.9165 - val_loss: 9.4269 - val_accuracy: 0.6713\n",
      "Epoch 85/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.0232 - accuracy: 0.9166 - val_loss: 9.3902 - val_accuracy: 0.6723\n",
      "Epoch 86/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.9844 - accuracy: 0.9194 - val_loss: 9.3532 - val_accuracy: 0.6739\n",
      "Epoch 87/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.9455 - accuracy: 0.9212 - val_loss: 9.3169 - val_accuracy: 0.6756\n",
      "Epoch 88/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.9025 - accuracy: 0.9251 - val_loss: 9.2802 - val_accuracy: 0.6764\n",
      "Epoch 89/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.8639 - accuracy: 0.9279 - val_loss: 9.2435 - val_accuracy: 0.6776\n",
      "Epoch 90/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.8235 - accuracy: 0.9271 - val_loss: 9.2073 - val_accuracy: 0.6784\n",
      "Epoch 91/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.7850 - accuracy: 0.9296 - val_loss: 9.1709 - val_accuracy: 0.6787\n",
      "Epoch 92/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.7438 - accuracy: 0.9313 - val_loss: 9.1349 - val_accuracy: 0.6805\n",
      "Epoch 93/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.7043 - accuracy: 0.9335 - val_loss: 9.0986 - val_accuracy: 0.6821\n",
      "Epoch 94/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.6651 - accuracy: 0.9366 - val_loss: 9.0626 - val_accuracy: 0.6820\n",
      "Epoch 95/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.6270 - accuracy: 0.9361 - val_loss: 9.0271 - val_accuracy: 0.6828\n",
      "Epoch 96/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.5868 - accuracy: 0.9395 - val_loss: 8.9910 - val_accuracy: 0.6839\n",
      "Epoch 97/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.5474 - accuracy: 0.9413 - val_loss: 8.9551 - val_accuracy: 0.6851\n",
      "Epoch 98/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.5087 - accuracy: 0.9431 - val_loss: 8.9196 - val_accuracy: 0.6857\n",
      "Epoch 99/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.4708 - accuracy: 0.9447 - val_loss: 8.8845 - val_accuracy: 0.6863\n",
      "Epoch 100/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.4321 - accuracy: 0.9458 - val_loss: 8.8488 - val_accuracy: 0.6873\n",
      "Epoch 101/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.3954 - accuracy: 0.9472 - val_loss: 8.8139 - val_accuracy: 0.6880\n",
      "Epoch 102/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.3550 - accuracy: 0.9496 - val_loss: 8.7783 - val_accuracy: 0.6887\n",
      "Epoch 103/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.3159 - accuracy: 0.9514 - val_loss: 8.7429 - val_accuracy: 0.6896\n",
      "Epoch 104/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.2789 - accuracy: 0.9532 - val_loss: 8.7078 - val_accuracy: 0.6905\n",
      "Epoch 105/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.2411 - accuracy: 0.9535 - val_loss: 8.6727 - val_accuracy: 0.6916\n",
      "Epoch 106/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.2023 - accuracy: 0.9566 - val_loss: 8.6378 - val_accuracy: 0.6919\n",
      "Epoch 107/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.1660 - accuracy: 0.9559 - val_loss: 8.6032 - val_accuracy: 0.6927\n",
      "Epoch 108/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.1275 - accuracy: 0.9591 - val_loss: 8.5683 - val_accuracy: 0.6933\n",
      "Epoch 109/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.0889 - accuracy: 0.9605 - val_loss: 8.5339 - val_accuracy: 0.6951\n",
      "Epoch 110/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.0544 - accuracy: 0.9607 - val_loss: 8.4991 - val_accuracy: 0.6955\n",
      "Epoch 111/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.0166 - accuracy: 0.9627 - val_loss: 8.4645 - val_accuracy: 0.6961\n",
      "Epoch 112/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9790 - accuracy: 0.9653 - val_loss: 8.4305 - val_accuracy: 0.6976\n",
      "Epoch 113/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9405 - accuracy: 0.9663 - val_loss: 8.3961 - val_accuracy: 0.6984\n",
      "Epoch 114/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9048 - accuracy: 0.9675 - val_loss: 8.3620 - val_accuracy: 0.6993\n",
      "Epoch 115/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.8681 - accuracy: 0.9678 - val_loss: 8.3277 - val_accuracy: 0.7007\n",
      "Epoch 116/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.8323 - accuracy: 0.9697 - val_loss: 8.2943 - val_accuracy: 0.7012\n",
      "Epoch 117/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.7943 - accuracy: 0.9716 - val_loss: 8.2603 - val_accuracy: 0.7024\n",
      "Epoch 118/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.7579 - accuracy: 0.9741 - val_loss: 8.2261 - val_accuracy: 0.7033\n",
      "Epoch 119/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.7215 - accuracy: 0.9744 - val_loss: 8.1925 - val_accuracy: 0.7052\n",
      "Epoch 120/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.6850 - accuracy: 0.9742 - val_loss: 8.1589 - val_accuracy: 0.7064\n",
      "Epoch 121/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.6497 - accuracy: 0.9751 - val_loss: 8.1255 - val_accuracy: 0.7063\n",
      "Epoch 122/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.6149 - accuracy: 0.9769 - val_loss: 8.0920 - val_accuracy: 0.7088\n",
      "Epoch 123/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.5779 - accuracy: 0.9780 - val_loss: 8.0588 - val_accuracy: 0.7092\n",
      "Epoch 124/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.5440 - accuracy: 0.9782 - val_loss: 8.0255 - val_accuracy: 0.7108\n",
      "Epoch 125/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.5073 - accuracy: 0.9789 - val_loss: 7.9923 - val_accuracy: 0.7109\n",
      "Epoch 126/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4720 - accuracy: 0.9810 - val_loss: 7.9591 - val_accuracy: 0.7120\n",
      "Epoch 127/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4368 - accuracy: 0.9809 - val_loss: 7.9265 - val_accuracy: 0.7131\n",
      "Epoch 128/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4018 - accuracy: 0.9825 - val_loss: 7.8933 - val_accuracy: 0.7132\n",
      "Epoch 129/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.3667 - accuracy: 0.9831 - val_loss: 7.8605 - val_accuracy: 0.7151\n",
      "Epoch 130/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.3326 - accuracy: 0.9829 - val_loss: 7.8278 - val_accuracy: 0.7151\n",
      "Epoch 131/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.2965 - accuracy: 0.9839 - val_loss: 7.7951 - val_accuracy: 0.7172\n",
      "Epoch 132/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.2631 - accuracy: 0.9845 - val_loss: 7.7629 - val_accuracy: 0.7183\n",
      "Epoch 133/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.2273 - accuracy: 0.9860 - val_loss: 7.7302 - val_accuracy: 0.7185\n",
      "Epoch 134/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1938 - accuracy: 0.9853 - val_loss: 7.6975 - val_accuracy: 0.7201\n",
      "Epoch 135/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1595 - accuracy: 0.9865 - val_loss: 7.6651 - val_accuracy: 0.7212\n",
      "Epoch 136/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1259 - accuracy: 0.9877 - val_loss: 7.6325 - val_accuracy: 0.7217\n",
      "Epoch 137/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0921 - accuracy: 0.9880 - val_loss: 7.6005 - val_accuracy: 0.7231\n",
      "Epoch 138/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0574 - accuracy: 0.9884 - val_loss: 7.5687 - val_accuracy: 0.7239\n",
      "Epoch 139/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0243 - accuracy: 0.9892 - val_loss: 7.5367 - val_accuracy: 0.7248\n",
      "Epoch 140/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9916 - accuracy: 0.9892 - val_loss: 7.5048 - val_accuracy: 0.7256\n",
      "Epoch 141/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9568 - accuracy: 0.9907 - val_loss: 7.4731 - val_accuracy: 0.7253\n",
      "Epoch 142/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9248 - accuracy: 0.9902 - val_loss: 7.4417 - val_accuracy: 0.7257\n",
      "Epoch 143/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8917 - accuracy: 0.9898 - val_loss: 7.4100 - val_accuracy: 0.7265\n",
      "Epoch 144/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8588 - accuracy: 0.9908 - val_loss: 7.3789 - val_accuracy: 0.7276\n",
      "Epoch 145/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8255 - accuracy: 0.9916 - val_loss: 7.3469 - val_accuracy: 0.7279\n",
      "Epoch 146/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7922 - accuracy: 0.9922 - val_loss: 7.3161 - val_accuracy: 0.7285\n",
      "Epoch 147/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7592 - accuracy: 0.9930 - val_loss: 7.2853 - val_accuracy: 0.7292\n",
      "Epoch 148/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7273 - accuracy: 0.9929 - val_loss: 7.2538 - val_accuracy: 0.7300\n",
      "Epoch 149/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6945 - accuracy: 0.9934 - val_loss: 7.2225 - val_accuracy: 0.7303\n",
      "Epoch 150/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6629 - accuracy: 0.9931 - val_loss: 7.1918 - val_accuracy: 0.7311\n",
      "Epoch 151/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6294 - accuracy: 0.9946 - val_loss: 7.1608 - val_accuracy: 0.7317\n",
      "Epoch 152/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5983 - accuracy: 0.9940 - val_loss: 7.1293 - val_accuracy: 0.7332\n",
      "Epoch 153/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5661 - accuracy: 0.9948 - val_loss: 7.0991 - val_accuracy: 0.7344\n",
      "Epoch 154/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5341 - accuracy: 0.9952 - val_loss: 7.0680 - val_accuracy: 0.7343\n",
      "Epoch 155/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5023 - accuracy: 0.9957 - val_loss: 7.0382 - val_accuracy: 0.7356\n",
      "Epoch 156/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4716 - accuracy: 0.9955 - val_loss: 7.0077 - val_accuracy: 0.7363\n",
      "Epoch 157/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4393 - accuracy: 0.9957 - val_loss: 6.9770 - val_accuracy: 0.7360\n",
      "Epoch 158/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4075 - accuracy: 0.9960 - val_loss: 6.9464 - val_accuracy: 0.7375\n",
      "Epoch 159/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3758 - accuracy: 0.9965 - val_loss: 6.9164 - val_accuracy: 0.7387\n",
      "Epoch 160/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3450 - accuracy: 0.9962 - val_loss: 6.8864 - val_accuracy: 0.7387\n",
      "Epoch 161/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3148 - accuracy: 0.9958 - val_loss: 6.8561 - val_accuracy: 0.7381\n",
      "Epoch 162/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2832 - accuracy: 0.9968 - val_loss: 6.8261 - val_accuracy: 0.7393\n",
      "Epoch 163/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2530 - accuracy: 0.9969 - val_loss: 6.7968 - val_accuracy: 0.7391\n",
      "Epoch 164/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2223 - accuracy: 0.9976 - val_loss: 6.7672 - val_accuracy: 0.7403\n",
      "Epoch 165/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1916 - accuracy: 0.9975 - val_loss: 6.7377 - val_accuracy: 0.7415\n",
      "Epoch 166/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1598 - accuracy: 0.9976 - val_loss: 6.7076 - val_accuracy: 0.7419\n",
      "Epoch 167/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1303 - accuracy: 0.9979 - val_loss: 6.6781 - val_accuracy: 0.7431\n",
      "Epoch 168/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0999 - accuracy: 0.9981 - val_loss: 6.6490 - val_accuracy: 0.7441\n",
      "Epoch 169/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0711 - accuracy: 0.9979 - val_loss: 6.6191 - val_accuracy: 0.7456\n",
      "Epoch 170/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0408 - accuracy: 0.9983 - val_loss: 6.5905 - val_accuracy: 0.7453\n",
      "Epoch 171/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0102 - accuracy: 0.9983 - val_loss: 6.5609 - val_accuracy: 0.7457\n",
      "Epoch 172/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9802 - accuracy: 0.9984 - val_loss: 6.5318 - val_accuracy: 0.7463\n",
      "Epoch 173/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9504 - accuracy: 0.9987 - val_loss: 6.5025 - val_accuracy: 0.7469\n",
      "Epoch 174/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9216 - accuracy: 0.9986 - val_loss: 6.4740 - val_accuracy: 0.7479\n",
      "Epoch 175/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8923 - accuracy: 0.9989 - val_loss: 6.4450 - val_accuracy: 0.7485\n",
      "Epoch 176/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8628 - accuracy: 0.9985 - val_loss: 6.4163 - val_accuracy: 0.7496\n",
      "Epoch 177/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8340 - accuracy: 0.9986 - val_loss: 6.3877 - val_accuracy: 0.7492\n",
      "Epoch 178/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8043 - accuracy: 0.9988 - val_loss: 6.3588 - val_accuracy: 0.7493\n",
      "Epoch 179/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7757 - accuracy: 0.9991 - val_loss: 6.3305 - val_accuracy: 0.7497\n",
      "Epoch 180/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7465 - accuracy: 0.9987 - val_loss: 6.3024 - val_accuracy: 0.7503\n",
      "Epoch 181/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7172 - accuracy: 0.9992 - val_loss: 6.2738 - val_accuracy: 0.7508\n",
      "Epoch 182/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6889 - accuracy: 0.9992 - val_loss: 6.2456 - val_accuracy: 0.7524\n",
      "Epoch 183/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6609 - accuracy: 0.9990 - val_loss: 6.2178 - val_accuracy: 0.7527\n",
      "Epoch 184/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6318 - accuracy: 0.9995 - val_loss: 6.1891 - val_accuracy: 0.7543\n",
      "Epoch 185/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6035 - accuracy: 0.9993 - val_loss: 6.1610 - val_accuracy: 0.7537\n",
      "Epoch 186/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5756 - accuracy: 0.9995 - val_loss: 6.1336 - val_accuracy: 0.7545\n",
      "Epoch 187/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5471 - accuracy: 0.9995 - val_loss: 6.1059 - val_accuracy: 0.7547\n",
      "Epoch 188/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5192 - accuracy: 0.9994 - val_loss: 6.0780 - val_accuracy: 0.7549\n",
      "Epoch 189/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4908 - accuracy: 0.9995 - val_loss: 6.0498 - val_accuracy: 0.7551\n",
      "Epoch 190/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4626 - accuracy: 0.9996 - val_loss: 6.0219 - val_accuracy: 0.7564\n",
      "Epoch 191/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4353 - accuracy: 0.9995 - val_loss: 5.9955 - val_accuracy: 0.7567\n",
      "Epoch 192/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4074 - accuracy: 0.9997 - val_loss: 5.9679 - val_accuracy: 0.7575\n",
      "Epoch 193/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3805 - accuracy: 0.9996 - val_loss: 5.9405 - val_accuracy: 0.7575\n",
      "Epoch 194/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3520 - accuracy: 0.9997 - val_loss: 5.9136 - val_accuracy: 0.7581\n",
      "Epoch 195/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3245 - accuracy: 0.9998 - val_loss: 5.8862 - val_accuracy: 0.7592\n",
      "Epoch 196/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2975 - accuracy: 0.9996 - val_loss: 5.8590 - val_accuracy: 0.7596\n",
      "Epoch 197/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2704 - accuracy: 0.9996 - val_loss: 5.8319 - val_accuracy: 0.7593\n",
      "Epoch 198/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2429 - accuracy: 0.9998 - val_loss: 5.8055 - val_accuracy: 0.7600\n",
      "Epoch 199/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2165 - accuracy: 0.9998 - val_loss: 5.7781 - val_accuracy: 0.7604\n",
      "Epoch 200/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1893 - accuracy: 0.9999 - val_loss: 5.7513 - val_accuracy: 0.7607\n",
      "Epoch 201/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1627 - accuracy: 0.9999 - val_loss: 5.7255 - val_accuracy: 0.7609\n",
      "Epoch 202/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1363 - accuracy: 0.9997 - val_loss: 5.6988 - val_accuracy: 0.7625\n",
      "Epoch 203/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1096 - accuracy: 0.9997 - val_loss: 5.6723 - val_accuracy: 0.7631\n",
      "Epoch 204/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0837 - accuracy: 0.9996 - val_loss: 5.6455 - val_accuracy: 0.7641\n",
      "Epoch 205/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0572 - accuracy: 0.9998 - val_loss: 5.6192 - val_accuracy: 0.7647\n",
      "Epoch 206/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0305 - accuracy: 0.9999 - val_loss: 5.5935 - val_accuracy: 0.7647\n",
      "Epoch 207/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0050 - accuracy: 0.9999 - val_loss: 5.5672 - val_accuracy: 0.7659\n",
      "Epoch 208/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9781 - accuracy: 0.9998 - val_loss: 5.5417 - val_accuracy: 0.7669\n",
      "Epoch 209/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9530 - accuracy: 0.9997 - val_loss: 5.5169 - val_accuracy: 0.7672\n",
      "Epoch 210/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9269 - accuracy: 0.9999 - val_loss: 5.4903 - val_accuracy: 0.7669\n",
      "Epoch 211/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9008 - accuracy: 0.9997 - val_loss: 5.4649 - val_accuracy: 0.7680\n",
      "Epoch 212/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8750 - accuracy: 0.9999 - val_loss: 5.4393 - val_accuracy: 0.7685\n",
      "Epoch 213/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8497 - accuracy: 0.9999 - val_loss: 5.4139 - val_accuracy: 0.7700\n",
      "Epoch 214/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8245 - accuracy: 0.9999 - val_loss: 5.3883 - val_accuracy: 0.7691\n",
      "Epoch 215/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7986 - accuracy: 1.0000 - val_loss: 5.3629 - val_accuracy: 0.7696\n",
      "Epoch 216/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7728 - accuracy: 1.0000 - val_loss: 5.3370 - val_accuracy: 0.7707\n",
      "Epoch 217/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7485 - accuracy: 0.9999 - val_loss: 5.3116 - val_accuracy: 0.7701\n",
      "Epoch 218/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7232 - accuracy: 1.0000 - val_loss: 5.2875 - val_accuracy: 0.7701\n",
      "Epoch 219/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6983 - accuracy: 0.9999 - val_loss: 5.2630 - val_accuracy: 0.7716\n",
      "Epoch 220/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6728 - accuracy: 1.0000 - val_loss: 5.2375 - val_accuracy: 0.7715\n",
      "Epoch 221/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6485 - accuracy: 0.9999 - val_loss: 5.2124 - val_accuracy: 0.7720\n",
      "Epoch 222/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6244 - accuracy: 0.9998 - val_loss: 5.1873 - val_accuracy: 0.7717\n",
      "Epoch 223/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5994 - accuracy: 1.0000 - val_loss: 5.1621 - val_accuracy: 0.7713\n",
      "Epoch 224/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5745 - accuracy: 1.0000 - val_loss: 5.1379 - val_accuracy: 0.7723\n",
      "Epoch 225/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5499 - accuracy: 0.9999 - val_loss: 5.1139 - val_accuracy: 0.7724\n",
      "Epoch 226/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5258 - accuracy: 0.9999 - val_loss: 5.0891 - val_accuracy: 0.7740\n",
      "Epoch 227/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5013 - accuracy: 1.0000 - val_loss: 5.0644 - val_accuracy: 0.7747\n",
      "Epoch 228/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4774 - accuracy: 1.0000 - val_loss: 5.0403 - val_accuracy: 0.7749\n",
      "Epoch 229/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4531 - accuracy: 1.0000 - val_loss: 5.0159 - val_accuracy: 0.7752\n",
      "Epoch 230/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4293 - accuracy: 1.0000 - val_loss: 4.9924 - val_accuracy: 0.7745\n",
      "Epoch 231/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4057 - accuracy: 1.0000 - val_loss: 4.9679 - val_accuracy: 0.7748\n",
      "Epoch 232/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3816 - accuracy: 1.0000 - val_loss: 4.9445 - val_accuracy: 0.7763\n",
      "Epoch 233/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3580 - accuracy: 1.0000 - val_loss: 4.9209 - val_accuracy: 0.7769\n",
      "Epoch 234/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3340 - accuracy: 1.0000 - val_loss: 4.8968 - val_accuracy: 0.7769\n",
      "Epoch 235/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3110 - accuracy: 1.0000 - val_loss: 4.8730 - val_accuracy: 0.7767\n",
      "Epoch 236/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2875 - accuracy: 1.0000 - val_loss: 4.8495 - val_accuracy: 0.7793\n",
      "Epoch 237/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2635 - accuracy: 1.0000 - val_loss: 4.8259 - val_accuracy: 0.7792\n",
      "Epoch 238/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2405 - accuracy: 1.0000 - val_loss: 4.8028 - val_accuracy: 0.7788\n",
      "Epoch 239/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2173 - accuracy: 1.0000 - val_loss: 4.7785 - val_accuracy: 0.7799\n",
      "Epoch 240/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1946 - accuracy: 1.0000 - val_loss: 4.7554 - val_accuracy: 0.7808\n",
      "Epoch 241/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1711 - accuracy: 1.0000 - val_loss: 4.7328 - val_accuracy: 0.7817\n",
      "Epoch 242/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1485 - accuracy: 1.0000 - val_loss: 4.7097 - val_accuracy: 0.7804\n",
      "Epoch 243/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1262 - accuracy: 0.9999 - val_loss: 4.6871 - val_accuracy: 0.7820\n",
      "Epoch 244/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1038 - accuracy: 1.0000 - val_loss: 4.6643 - val_accuracy: 0.7825\n",
      "Epoch 245/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0808 - accuracy: 1.0000 - val_loss: 4.6413 - val_accuracy: 0.7824\n",
      "Epoch 246/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0584 - accuracy: 1.0000 - val_loss: 4.6193 - val_accuracy: 0.7824\n",
      "Epoch 247/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0360 - accuracy: 1.0000 - val_loss: 4.5969 - val_accuracy: 0.7837\n",
      "Epoch 248/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0139 - accuracy: 0.9999 - val_loss: 4.5737 - val_accuracy: 0.7836\n",
      "Epoch 249/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9907 - accuracy: 1.0000 - val_loss: 4.5509 - val_accuracy: 0.7839\n",
      "Epoch 250/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9686 - accuracy: 1.0000 - val_loss: 4.5285 - val_accuracy: 0.7839\n",
      "Epoch 251/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9469 - accuracy: 1.0000 - val_loss: 4.5063 - val_accuracy: 0.7843\n",
      "Epoch 252/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9247 - accuracy: 1.0000 - val_loss: 4.4844 - val_accuracy: 0.7853\n",
      "Epoch 253/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9030 - accuracy: 1.0000 - val_loss: 4.4624 - val_accuracy: 0.7853\n",
      "Epoch 254/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8812 - accuracy: 1.0000 - val_loss: 4.4402 - val_accuracy: 0.7863\n",
      "Epoch 255/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8597 - accuracy: 1.0000 - val_loss: 4.4179 - val_accuracy: 0.7871\n",
      "Epoch 256/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8387 - accuracy: 1.0000 - val_loss: 4.3963 - val_accuracy: 0.7871\n",
      "Epoch 257/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8165 - accuracy: 1.0000 - val_loss: 4.3747 - val_accuracy: 0.7883\n",
      "Epoch 258/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7949 - accuracy: 1.0000 - val_loss: 4.3530 - val_accuracy: 0.7883\n",
      "Epoch 259/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7740 - accuracy: 1.0000 - val_loss: 4.3314 - val_accuracy: 0.7881\n",
      "Epoch 260/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7532 - accuracy: 0.9999 - val_loss: 4.3098 - val_accuracy: 0.7887\n",
      "Epoch 261/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7318 - accuracy: 1.0000 - val_loss: 4.2882 - val_accuracy: 0.7887\n",
      "Epoch 262/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7108 - accuracy: 1.0000 - val_loss: 4.2666 - val_accuracy: 0.7899\n",
      "Epoch 263/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6892 - accuracy: 1.0000 - val_loss: 4.2455 - val_accuracy: 0.7903\n",
      "Epoch 264/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6685 - accuracy: 1.0000 - val_loss: 4.2247 - val_accuracy: 0.7897\n",
      "Epoch 265/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6481 - accuracy: 1.0000 - val_loss: 4.2025 - val_accuracy: 0.7923\n",
      "Epoch 266/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6273 - accuracy: 1.0000 - val_loss: 4.1830 - val_accuracy: 0.7923\n",
      "Epoch 267/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6064 - accuracy: 1.0000 - val_loss: 4.1621 - val_accuracy: 0.7917\n",
      "Epoch 268/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5859 - accuracy: 1.0000 - val_loss: 4.1411 - val_accuracy: 0.7933\n",
      "Epoch 269/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5655 - accuracy: 1.0000 - val_loss: 4.1203 - val_accuracy: 0.7936\n",
      "Epoch 270/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5452 - accuracy: 1.0000 - val_loss: 4.0995 - val_accuracy: 0.7945\n",
      "Epoch 271/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5249 - accuracy: 1.0000 - val_loss: 4.0789 - val_accuracy: 0.7933\n",
      "Epoch 272/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5050 - accuracy: 1.0000 - val_loss: 4.0586 - val_accuracy: 0.7935\n",
      "Epoch 273/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4852 - accuracy: 1.0000 - val_loss: 4.0381 - val_accuracy: 0.7937\n",
      "Epoch 274/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4647 - accuracy: 1.0000 - val_loss: 4.0173 - val_accuracy: 0.7947\n",
      "Epoch 275/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4448 - accuracy: 1.0000 - val_loss: 3.9974 - val_accuracy: 0.7963\n",
      "Epoch 276/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4253 - accuracy: 1.0000 - val_loss: 3.9761 - val_accuracy: 0.7968\n",
      "Epoch 277/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4055 - accuracy: 1.0000 - val_loss: 3.9565 - val_accuracy: 0.7972\n",
      "Epoch 278/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3858 - accuracy: 1.0000 - val_loss: 3.9360 - val_accuracy: 0.7979\n",
      "Epoch 279/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3659 - accuracy: 1.0000 - val_loss: 3.9167 - val_accuracy: 0.7988\n",
      "Epoch 280/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3467 - accuracy: 1.0000 - val_loss: 3.8972 - val_accuracy: 0.7984\n",
      "Epoch 281/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3271 - accuracy: 1.0000 - val_loss: 3.8771 - val_accuracy: 0.7991\n",
      "Epoch 282/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3084 - accuracy: 1.0000 - val_loss: 3.8582 - val_accuracy: 0.7996\n",
      "Epoch 283/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2892 - accuracy: 1.0000 - val_loss: 3.8390 - val_accuracy: 0.7996\n",
      "Epoch 284/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2701 - accuracy: 1.0000 - val_loss: 3.8191 - val_accuracy: 0.8008\n",
      "Epoch 285/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2511 - accuracy: 1.0000 - val_loss: 3.7997 - val_accuracy: 0.8015\n",
      "Epoch 286/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2319 - accuracy: 1.0000 - val_loss: 3.7803 - val_accuracy: 0.8019\n",
      "Epoch 287/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2139 - accuracy: 1.0000 - val_loss: 3.7607 - val_accuracy: 0.8024\n",
      "Epoch 288/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1950 - accuracy: 1.0000 - val_loss: 3.7422 - val_accuracy: 0.8029\n",
      "Epoch 289/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1762 - accuracy: 1.0000 - val_loss: 3.7228 - val_accuracy: 0.8048\n",
      "Epoch 290/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1575 - accuracy: 1.0000 - val_loss: 3.7043 - val_accuracy: 0.8048\n",
      "Epoch 291/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1391 - accuracy: 1.0000 - val_loss: 3.6860 - val_accuracy: 0.8056\n",
      "Epoch 292/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1210 - accuracy: 1.0000 - val_loss: 3.6664 - val_accuracy: 0.8061\n",
      "Epoch 293/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1026 - accuracy: 1.0000 - val_loss: 3.6471 - val_accuracy: 0.8063\n",
      "Epoch 294/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0851 - accuracy: 1.0000 - val_loss: 3.6288 - val_accuracy: 0.8067\n",
      "Epoch 295/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0659 - accuracy: 1.0000 - val_loss: 3.6110 - val_accuracy: 0.8076\n",
      "Epoch 296/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0485 - accuracy: 1.0000 - val_loss: 3.5924 - val_accuracy: 0.8068\n",
      "Epoch 297/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0308 - accuracy: 1.0000 - val_loss: 3.5742 - val_accuracy: 0.8079\n",
      "Epoch 298/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0126 - accuracy: 1.0000 - val_loss: 3.5561 - val_accuracy: 0.8075\n",
      "Epoch 299/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9952 - accuracy: 1.0000 - val_loss: 3.5380 - val_accuracy: 0.8079\n",
      "Epoch 300/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9773 - accuracy: 1.0000 - val_loss: 3.5223 - val_accuracy: 0.8072\n",
      "Epoch 301/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9598 - accuracy: 1.0000 - val_loss: 3.5027 - val_accuracy: 0.8080\n",
      "Epoch 302/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9427 - accuracy: 1.0000 - val_loss: 3.4849 - val_accuracy: 0.8091\n",
      "Epoch 303/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9252 - accuracy: 1.0000 - val_loss: 3.4673 - val_accuracy: 0.8083\n",
      "Epoch 304/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9074 - accuracy: 1.0000 - val_loss: 3.4499 - val_accuracy: 0.8088\n",
      "Epoch 305/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8906 - accuracy: 0.9999 - val_loss: 3.4322 - val_accuracy: 0.8085\n",
      "Epoch 306/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8736 - accuracy: 1.0000 - val_loss: 3.4152 - val_accuracy: 0.8088\n",
      "Epoch 307/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8565 - accuracy: 1.0000 - val_loss: 3.3968 - val_accuracy: 0.8083\n",
      "Epoch 308/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8394 - accuracy: 1.0000 - val_loss: 3.3798 - val_accuracy: 0.8080\n",
      "Epoch 309/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8230 - accuracy: 0.9999 - val_loss: 3.3613 - val_accuracy: 0.8089\n",
      "Epoch 310/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8059 - accuracy: 1.0000 - val_loss: 3.3462 - val_accuracy: 0.8103\n",
      "Epoch 311/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7892 - accuracy: 1.0000 - val_loss: 3.3277 - val_accuracy: 0.8113\n",
      "Epoch 312/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7730 - accuracy: 1.0000 - val_loss: 3.3117 - val_accuracy: 0.8113\n",
      "Epoch 313/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7562 - accuracy: 1.0000 - val_loss: 3.2947 - val_accuracy: 0.8116\n",
      "Epoch 314/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7404 - accuracy: 1.0000 - val_loss: 3.2779 - val_accuracy: 0.8131\n",
      "Epoch 315/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7233 - accuracy: 1.0000 - val_loss: 3.2606 - val_accuracy: 0.8141\n",
      "Epoch 316/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7080 - accuracy: 1.0000 - val_loss: 3.2446 - val_accuracy: 0.8136\n",
      "Epoch 317/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6912 - accuracy: 1.0000 - val_loss: 3.2283 - val_accuracy: 0.8144\n",
      "Epoch 318/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6755 - accuracy: 1.0000 - val_loss: 3.2116 - val_accuracy: 0.8148\n",
      "Epoch 319/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6592 - accuracy: 1.0000 - val_loss: 3.1950 - val_accuracy: 0.8145\n",
      "Epoch 320/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6433 - accuracy: 1.0000 - val_loss: 3.1799 - val_accuracy: 0.8145\n",
      "Epoch 321/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6274 - accuracy: 1.0000 - val_loss: 3.1627 - val_accuracy: 0.8147\n",
      "Epoch 322/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6119 - accuracy: 1.0000 - val_loss: 3.1478 - val_accuracy: 0.8135\n",
      "Epoch 323/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5968 - accuracy: 0.9999 - val_loss: 3.1334 - val_accuracy: 0.8131\n",
      "Epoch 324/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5812 - accuracy: 1.0000 - val_loss: 3.1148 - val_accuracy: 0.8148\n",
      "Epoch 325/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5662 - accuracy: 1.0000 - val_loss: 3.0984 - val_accuracy: 0.8129\n",
      "Epoch 326/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5509 - accuracy: 1.0000 - val_loss: 3.0831 - val_accuracy: 0.8139\n",
      "Epoch 327/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5353 - accuracy: 1.0000 - val_loss: 3.0673 - val_accuracy: 0.8128\n",
      "Epoch 328/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5202 - accuracy: 1.0000 - val_loss: 3.0516 - val_accuracy: 0.8131\n",
      "Epoch 329/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5052 - accuracy: 1.0000 - val_loss: 3.0356 - val_accuracy: 0.8136\n",
      "Epoch 330/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4901 - accuracy: 1.0000 - val_loss: 3.0216 - val_accuracy: 0.8127\n",
      "Epoch 331/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4759 - accuracy: 1.0000 - val_loss: 3.0067 - val_accuracy: 0.8133\n",
      "Epoch 332/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4608 - accuracy: 1.0000 - val_loss: 2.9921 - val_accuracy: 0.8140\n",
      "Epoch 333/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4464 - accuracy: 0.9999 - val_loss: 2.9755 - val_accuracy: 0.8139\n",
      "Epoch 334/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4318 - accuracy: 1.0000 - val_loss: 2.9603 - val_accuracy: 0.8145\n",
      "Epoch 335/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4170 - accuracy: 1.0000 - val_loss: 2.9466 - val_accuracy: 0.8148\n",
      "Epoch 336/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4026 - accuracy: 1.0000 - val_loss: 2.9316 - val_accuracy: 0.8148\n",
      "Epoch 337/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3885 - accuracy: 1.0000 - val_loss: 2.9168 - val_accuracy: 0.8149\n",
      "Epoch 338/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3742 - accuracy: 1.0000 - val_loss: 2.9029 - val_accuracy: 0.8159\n",
      "Epoch 339/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3599 - accuracy: 1.0000 - val_loss: 2.8873 - val_accuracy: 0.8161\n",
      "Epoch 340/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3463 - accuracy: 1.0000 - val_loss: 2.8742 - val_accuracy: 0.8151\n",
      "Epoch 341/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3325 - accuracy: 1.0000 - val_loss: 2.8603 - val_accuracy: 0.8168\n",
      "Epoch 342/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3183 - accuracy: 1.0000 - val_loss: 2.8459 - val_accuracy: 0.8165\n",
      "Epoch 343/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3049 - accuracy: 1.0000 - val_loss: 2.8299 - val_accuracy: 0.8180\n",
      "Epoch 344/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2912 - accuracy: 1.0000 - val_loss: 2.8163 - val_accuracy: 0.8176\n",
      "Epoch 345/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2771 - accuracy: 1.0000 - val_loss: 2.8005 - val_accuracy: 0.8184\n",
      "Epoch 346/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2639 - accuracy: 1.0000 - val_loss: 2.7865 - val_accuracy: 0.8195\n",
      "Epoch 347/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2503 - accuracy: 1.0000 - val_loss: 2.7725 - val_accuracy: 0.8193\n",
      "Epoch 348/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2388 - accuracy: 0.9999 - val_loss: 2.7591 - val_accuracy: 0.8199\n",
      "Epoch 349/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2242 - accuracy: 1.0000 - val_loss: 2.7445 - val_accuracy: 0.8195\n",
      "Epoch 350/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2107 - accuracy: 1.0000 - val_loss: 2.7310 - val_accuracy: 0.8199\n",
      "Epoch 351/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1976 - accuracy: 1.0000 - val_loss: 2.7182 - val_accuracy: 0.8200\n",
      "Epoch 352/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1848 - accuracy: 1.0000 - val_loss: 2.7063 - val_accuracy: 0.8201\n",
      "Epoch 353/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1719 - accuracy: 1.0000 - val_loss: 2.6930 - val_accuracy: 0.8211\n",
      "Epoch 354/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1590 - accuracy: 1.0000 - val_loss: 2.6768 - val_accuracy: 0.8205\n",
      "Epoch 355/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1462 - accuracy: 1.0000 - val_loss: 2.6663 - val_accuracy: 0.8199\n",
      "Epoch 356/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1339 - accuracy: 1.0000 - val_loss: 2.6536 - val_accuracy: 0.8196\n",
      "Epoch 357/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1211 - accuracy: 1.0000 - val_loss: 2.6406 - val_accuracy: 0.8209\n",
      "Epoch 358/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1092 - accuracy: 1.0000 - val_loss: 2.6271 - val_accuracy: 0.8200\n",
      "Epoch 359/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0965 - accuracy: 1.0000 - val_loss: 2.6153 - val_accuracy: 0.8217\n",
      "Epoch 360/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0849 - accuracy: 1.0000 - val_loss: 2.6006 - val_accuracy: 0.8207\n",
      "Epoch 361/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0728 - accuracy: 1.0000 - val_loss: 2.5892 - val_accuracy: 0.8216\n",
      "Epoch 362/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0605 - accuracy: 1.0000 - val_loss: 2.5769 - val_accuracy: 0.8204\n",
      "Epoch 363/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0486 - accuracy: 1.0000 - val_loss: 2.5641 - val_accuracy: 0.8216\n",
      "Epoch 364/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0364 - accuracy: 1.0000 - val_loss: 2.5510 - val_accuracy: 0.8209\n",
      "Epoch 365/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0247 - accuracy: 1.0000 - val_loss: 2.5384 - val_accuracy: 0.8205\n",
      "Epoch 366/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0132 - accuracy: 1.0000 - val_loss: 2.5262 - val_accuracy: 0.8220\n",
      "Epoch 367/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0017 - accuracy: 1.0000 - val_loss: 2.5115 - val_accuracy: 0.8217\n",
      "Epoch 368/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9899 - accuracy: 1.0000 - val_loss: 2.5021 - val_accuracy: 0.8220\n",
      "Epoch 369/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9794 - accuracy: 1.0000 - val_loss: 2.4979 - val_accuracy: 0.8197\n",
      "Epoch 370/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9682 - accuracy: 1.0000 - val_loss: 2.4789 - val_accuracy: 0.8221\n",
      "Epoch 371/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9560 - accuracy: 1.0000 - val_loss: 2.4674 - val_accuracy: 0.8227\n",
      "Epoch 372/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9455 - accuracy: 1.0000 - val_loss: 2.4549 - val_accuracy: 0.8228\n",
      "Epoch 373/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9336 - accuracy: 1.0000 - val_loss: 2.4402 - val_accuracy: 0.8239\n",
      "Epoch 374/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9236 - accuracy: 1.0000 - val_loss: 2.4308 - val_accuracy: 0.8236\n",
      "Epoch 375/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9123 - accuracy: 1.0000 - val_loss: 2.4229 - val_accuracy: 0.8232\n",
      "Epoch 376/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9011 - accuracy: 1.0000 - val_loss: 2.4109 - val_accuracy: 0.8235\n",
      "Epoch 377/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8910 - accuracy: 1.0000 - val_loss: 2.4001 - val_accuracy: 0.8247\n",
      "Epoch 378/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8798 - accuracy: 1.0000 - val_loss: 2.3909 - val_accuracy: 0.8236\n",
      "Epoch 379/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8695 - accuracy: 1.0000 - val_loss: 2.3803 - val_accuracy: 0.8236\n",
      "Epoch 380/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8598 - accuracy: 1.0000 - val_loss: 2.3721 - val_accuracy: 0.8212\n",
      "Epoch 381/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8495 - accuracy: 1.0000 - val_loss: 2.3557 - val_accuracy: 0.8229\n",
      "Epoch 382/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8389 - accuracy: 1.0000 - val_loss: 2.3464 - val_accuracy: 0.8227\n",
      "Epoch 383/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8288 - accuracy: 1.0000 - val_loss: 2.3386 - val_accuracy: 0.8247\n",
      "Epoch 384/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8186 - accuracy: 1.0000 - val_loss: 2.3278 - val_accuracy: 0.8220\n",
      "Epoch 385/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8099 - accuracy: 1.0000 - val_loss: 2.3148 - val_accuracy: 0.8251\n",
      "Epoch 386/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7987 - accuracy: 1.0000 - val_loss: 2.3053 - val_accuracy: 0.8249\n",
      "Epoch 387/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7896 - accuracy: 1.0000 - val_loss: 2.2987 - val_accuracy: 0.8253\n",
      "Epoch 388/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7796 - accuracy: 1.0000 - val_loss: 2.2898 - val_accuracy: 0.8236\n",
      "Epoch 389/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7695 - accuracy: 1.0000 - val_loss: 2.2747 - val_accuracy: 0.8260\n",
      "Epoch 390/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7596 - accuracy: 1.0000 - val_loss: 2.2658 - val_accuracy: 0.8256\n",
      "Epoch 391/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7506 - accuracy: 1.0000 - val_loss: 2.2583 - val_accuracy: 0.8248\n",
      "Epoch 392/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7423 - accuracy: 0.9999 - val_loss: 2.2616 - val_accuracy: 0.8247\n",
      "Epoch 393/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7710 - accuracy: 0.9926 - val_loss: 3.0130 - val_accuracy: 0.7443\n",
      "Epoch 394/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1039 - accuracy: 0.9180 - val_loss: 2.5350 - val_accuracy: 0.8039\n",
      "Epoch 395/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9272 - accuracy: 0.9726 - val_loss: 2.3438 - val_accuracy: 0.8313\n",
      "Epoch 396/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8445 - accuracy: 0.9954 - val_loss: 2.2653 - val_accuracy: 0.8429\n",
      "Epoch 397/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7979 - accuracy: 0.9996 - val_loss: 2.2497 - val_accuracy: 0.8436\n",
      "Epoch 398/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7644 - accuracy: 1.0000 - val_loss: 2.2082 - val_accuracy: 0.8460\n",
      "Epoch 399/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7376 - accuracy: 1.0000 - val_loss: 2.1776 - val_accuracy: 0.8495\n",
      "Epoch 400/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7154 - accuracy: 1.0000 - val_loss: 2.1550 - val_accuracy: 0.8480\n",
      "Epoch 401/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6985 - accuracy: 1.0000 - val_loss: 2.1383 - val_accuracy: 0.8484\n",
      "Epoch 402/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6824 - accuracy: 1.0000 - val_loss: 2.1206 - val_accuracy: 0.8508\n",
      "Epoch 403/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6690 - accuracy: 1.0000 - val_loss: 2.1073 - val_accuracy: 0.8511\n",
      "Epoch 404/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6569 - accuracy: 1.0000 - val_loss: 2.1008 - val_accuracy: 0.8508\n",
      "Epoch 405/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6459 - accuracy: 1.0000 - val_loss: 2.0916 - val_accuracy: 0.8501\n",
      "Epoch 406/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6370 - accuracy: 1.0000 - val_loss: 2.0813 - val_accuracy: 0.8513\n",
      "Epoch 407/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6268 - accuracy: 1.0000 - val_loss: 2.0780 - val_accuracy: 0.8488\n",
      "Epoch 408/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6181 - accuracy: 1.0000 - val_loss: 2.0680 - val_accuracy: 0.8499\n",
      "Epoch 409/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6096 - accuracy: 1.0000 - val_loss: 2.0629 - val_accuracy: 0.8495\n",
      "Epoch 410/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6009 - accuracy: 1.0000 - val_loss: 2.0552 - val_accuracy: 0.8481\n",
      "Epoch 411/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5936 - accuracy: 1.0000 - val_loss: 2.0475 - val_accuracy: 0.8492\n",
      "Epoch 412/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5845 - accuracy: 1.0000 - val_loss: 2.0418 - val_accuracy: 0.8473\n",
      "Epoch 413/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5777 - accuracy: 1.0000 - val_loss: 2.0426 - val_accuracy: 0.8457\n",
      "Epoch 414/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5715 - accuracy: 0.9999 - val_loss: 2.0396 - val_accuracy: 0.8435\n",
      "Epoch 415/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5643 - accuracy: 1.0000 - val_loss: 2.0173 - val_accuracy: 0.8495\n",
      "Epoch 416/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5536 - accuracy: 1.0000 - val_loss: 2.0140 - val_accuracy: 0.8473\n",
      "Epoch 417/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5461 - accuracy: 1.0000 - val_loss: 2.0116 - val_accuracy: 0.8456\n",
      "Epoch 418/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5437 - accuracy: 0.9990 - val_loss: 2.4543 - val_accuracy: 0.7829\n",
      "Epoch 419/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1247 - accuracy: 0.8701 - val_loss: 2.4751 - val_accuracy: 0.7701\n",
      "Epoch 420/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8225 - accuracy: 0.9591 - val_loss: 2.1635 - val_accuracy: 0.8441\n",
      "Epoch 421/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7172 - accuracy: 0.9920 - val_loss: 2.0965 - val_accuracy: 0.8500\n",
      "Epoch 422/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6645 - accuracy: 0.9992 - val_loss: 2.0691 - val_accuracy: 0.8535\n",
      "Epoch 423/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6250 - accuracy: 1.0000 - val_loss: 2.0413 - val_accuracy: 0.8568\n",
      "Epoch 424/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5948 - accuracy: 1.0000 - val_loss: 2.0121 - val_accuracy: 0.8589\n",
      "Epoch 425/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5707 - accuracy: 1.0000 - val_loss: 1.9800 - val_accuracy: 0.8607\n",
      "Epoch 426/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5496 - accuracy: 1.0000 - val_loss: 1.9592 - val_accuracy: 0.8636\n",
      "Epoch 427/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5317 - accuracy: 1.0000 - val_loss: 1.9322 - val_accuracy: 0.8691\n",
      "Epoch 428/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5170 - accuracy: 1.0000 - val_loss: 1.9152 - val_accuracy: 0.8683\n",
      "Epoch 429/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5039 - accuracy: 1.0000 - val_loss: 1.9029 - val_accuracy: 0.8691\n",
      "Epoch 430/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4924 - accuracy: 1.0000 - val_loss: 1.8858 - val_accuracy: 0.8693\n",
      "Epoch 431/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4830 - accuracy: 1.0000 - val_loss: 1.8767 - val_accuracy: 0.8700\n",
      "Epoch 432/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4729 - accuracy: 1.0000 - val_loss: 1.8700 - val_accuracy: 0.8683\n",
      "Epoch 433/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4660 - accuracy: 0.9998 - val_loss: 1.8994 - val_accuracy: 0.8583\n",
      "Epoch 434/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8847 - accuracy: 0.9037 - val_loss: 2.5162 - val_accuracy: 0.7392\n",
      "Epoch 435/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7591 - accuracy: 0.9514 - val_loss: 2.0744 - val_accuracy: 0.8516\n",
      "Epoch 436/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6444 - accuracy: 0.9895 - val_loss: 1.9979 - val_accuracy: 0.8669\n",
      "Epoch 437/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5919 - accuracy: 0.9984 - val_loss: 1.9590 - val_accuracy: 0.8673\n",
      "Epoch 438/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5496 - accuracy: 1.0000 - val_loss: 1.9352 - val_accuracy: 0.8680\n",
      "Epoch 439/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5187 - accuracy: 1.0000 - val_loss: 1.9055 - val_accuracy: 0.8685\n",
      "Epoch 440/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4944 - accuracy: 1.0000 - val_loss: 1.8770 - val_accuracy: 0.8704\n",
      "Epoch 441/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4734 - accuracy: 1.0000 - val_loss: 1.8500 - val_accuracy: 0.8735\n",
      "Epoch 442/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4567 - accuracy: 1.0000 - val_loss: 1.8281 - val_accuracy: 0.8761\n",
      "Epoch 443/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4422 - accuracy: 1.0000 - val_loss: 1.8030 - val_accuracy: 0.8796\n",
      "Epoch 444/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4293 - accuracy: 1.0000 - val_loss: 1.7910 - val_accuracy: 0.8821\n",
      "Epoch 445/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4199 - accuracy: 1.0000 - val_loss: 1.7774 - val_accuracy: 0.8839\n",
      "Epoch 446/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4104 - accuracy: 1.0000 - val_loss: 1.7630 - val_accuracy: 0.8852\n",
      "Epoch 447/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4028 - accuracy: 1.0000 - val_loss: 1.7576 - val_accuracy: 0.8856\n",
      "Epoch 448/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3958 - accuracy: 1.0000 - val_loss: 1.7541 - val_accuracy: 0.8864\n",
      "Epoch 449/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5542 - accuracy: 0.9634 - val_loss: 3.2014 - val_accuracy: 0.6343\n",
      "Epoch 450/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8145 - accuracy: 0.9069 - val_loss: 2.1973 - val_accuracy: 0.8027\n",
      "Epoch 451/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6260 - accuracy: 0.9770 - val_loss: 1.8989 - val_accuracy: 0.8735\n",
      "Epoch 452/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5522 - accuracy: 0.9953 - val_loss: 1.8835 - val_accuracy: 0.8725\n",
      "Epoch 453/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5054 - accuracy: 0.9998 - val_loss: 1.8451 - val_accuracy: 0.8769\n",
      "Epoch 454/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4701 - accuracy: 1.0000 - val_loss: 1.8225 - val_accuracy: 0.8771\n",
      "Epoch 455/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4422 - accuracy: 1.0000 - val_loss: 1.7926 - val_accuracy: 0.8803\n",
      "Epoch 456/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4201 - accuracy: 1.0000 - val_loss: 1.7669 - val_accuracy: 0.8819\n",
      "Epoch 457/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4019 - accuracy: 1.0000 - val_loss: 1.7427 - val_accuracy: 0.8867\n",
      "Epoch 458/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3861 - accuracy: 1.0000 - val_loss: 1.7201 - val_accuracy: 0.8892\n",
      "Epoch 459/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3738 - accuracy: 1.0000 - val_loss: 1.6996 - val_accuracy: 0.8899\n",
      "Epoch 460/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3626 - accuracy: 1.0000 - val_loss: 1.6884 - val_accuracy: 0.8904\n",
      "Epoch 461/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3546 - accuracy: 1.0000 - val_loss: 1.6784 - val_accuracy: 0.8907\n",
      "Epoch 462/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4268 - accuracy: 0.9803 - val_loss: 2.8763 - val_accuracy: 0.6736\n",
      "Epoch 463/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7790 - accuracy: 0.9017 - val_loss: 2.1611 - val_accuracy: 0.7947\n",
      "Epoch 464/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5846 - accuracy: 0.9736 - val_loss: 1.8332 - val_accuracy: 0.8845\n",
      "Epoch 465/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5092 - accuracy: 0.9951 - val_loss: 1.7939 - val_accuracy: 0.8844\n",
      "Epoch 466/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4624 - accuracy: 0.9996 - val_loss: 1.7726 - val_accuracy: 0.8861\n",
      "Epoch 467/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4257 - accuracy: 1.0000 - val_loss: 1.7518 - val_accuracy: 0.8835\n",
      "Epoch 468/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3976 - accuracy: 1.0000 - val_loss: 1.7256 - val_accuracy: 0.8872\n",
      "Epoch 469/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3756 - accuracy: 1.0000 - val_loss: 1.6997 - val_accuracy: 0.8903\n",
      "Epoch 470/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3571 - accuracy: 1.0000 - val_loss: 1.6806 - val_accuracy: 0.8904\n",
      "Epoch 471/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3419 - accuracy: 1.0000 - val_loss: 1.6575 - val_accuracy: 0.8964\n",
      "Epoch 472/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3304 - accuracy: 1.0000 - val_loss: 1.6276 - val_accuracy: 0.8992\n",
      "Epoch 473/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3185 - accuracy: 1.0000 - val_loss: 1.6112 - val_accuracy: 0.9016\n",
      "Epoch 474/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3105 - accuracy: 1.0000 - val_loss: 1.6012 - val_accuracy: 0.9033\n",
      "Epoch 475/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3030 - accuracy: 1.0000 - val_loss: 1.5927 - val_accuracy: 0.9035\n",
      "Epoch 476/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5699 - accuracy: 0.9351 - val_loss: 2.9709 - val_accuracy: 0.6384\n",
      "Epoch 477/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6334 - accuracy: 0.9402 - val_loss: 1.9343 - val_accuracy: 0.8411\n",
      "Epoch 478/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5136 - accuracy: 0.9821 - val_loss: 1.7627 - val_accuracy: 0.8879\n",
      "Epoch 479/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4489 - accuracy: 0.9978 - val_loss: 1.7477 - val_accuracy: 0.8857\n",
      "Epoch 480/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4072 - accuracy: 0.9998 - val_loss: 1.7221 - val_accuracy: 0.8851\n",
      "Epoch 481/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3740 - accuracy: 1.0000 - val_loss: 1.6964 - val_accuracy: 0.8881\n",
      "Epoch 482/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3483 - accuracy: 1.0000 - val_loss: 1.6671 - val_accuracy: 0.8897\n",
      "Epoch 483/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3272 - accuracy: 1.0000 - val_loss: 1.6403 - val_accuracy: 0.8929\n",
      "Epoch 484/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3101 - accuracy: 1.0000 - val_loss: 1.6178 - val_accuracy: 0.8960\n",
      "Epoch 485/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2958 - accuracy: 1.0000 - val_loss: 1.5956 - val_accuracy: 0.8975\n",
      "Epoch 486/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2866 - accuracy: 1.0000 - val_loss: 1.5778 - val_accuracy: 0.9051\n",
      "Epoch 487/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2766 - accuracy: 1.0000 - val_loss: 1.5657 - val_accuracy: 0.9047\n",
      "Epoch 488/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2825 - accuracy: 0.9976 - val_loss: 1.7973 - val_accuracy: 0.8551\n",
      "Epoch 489/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6653 - accuracy: 0.9087 - val_loss: 2.2505 - val_accuracy: 0.7601\n",
      "Epoch 490/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5170 - accuracy: 0.9688 - val_loss: 1.7766 - val_accuracy: 0.8815\n",
      "Epoch 491/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4405 - accuracy: 0.9933 - val_loss: 1.6541 - val_accuracy: 0.9096\n",
      "Epoch 492/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3880 - accuracy: 0.9995 - val_loss: 1.6365 - val_accuracy: 0.9045\n",
      "Epoch 493/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3511 - accuracy: 1.0000 - val_loss: 1.6193 - val_accuracy: 0.9016\n",
      "Epoch 494/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3221 - accuracy: 1.0000 - val_loss: 1.5974 - val_accuracy: 0.9021\n",
      "Epoch 495/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2999 - accuracy: 1.0000 - val_loss: 1.5765 - val_accuracy: 0.9053\n",
      "Epoch 496/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2817 - accuracy: 1.0000 - val_loss: 1.5638 - val_accuracy: 0.9032\n",
      "Epoch 497/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2675 - accuracy: 1.0000 - val_loss: 1.5409 - val_accuracy: 0.9064\n",
      "Epoch 498/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2561 - accuracy: 1.0000 - val_loss: 1.5248 - val_accuracy: 0.9085\n",
      "Epoch 499/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2456 - accuracy: 1.0000 - val_loss: 1.5246 - val_accuracy: 0.9065\n",
      "Epoch 500/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4302 - accuracy: 0.9520 - val_loss: 2.5458 - val_accuracy: 0.6939\n",
      "Time: 183.94047164916992\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Traits_Model_50BM.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#50 BM\n",
    "################################################################################################################################################\n",
    "# now repeat the analysis only for traits\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test  = train_test_split(y,X50,traits_BM50,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = BM_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Traits_Model_50BM.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Delete after running\n",
    "\n",
    "# subset the SNPs\n",
    "X50=X[:,0:50,:]\n",
    "\n",
    "# subset the traits\n",
    "traits_BM50=traits_BM[:,0:50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jLWVlN8g82lD",
    "outputId": "c3c68070-c6f3-483f-a16b-c54b05973f0c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 20, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 18, 250)      45000       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 18, 250)     1000        ['conv1d[0][0]']                 \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 16, 250)      187500      ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, 250)     1000        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 14, 250)      187500      ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 14, 250)     1000        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 4, 250)       0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1000)         0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " dense_input (InputLayer)       [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 125)          125125      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 150)          450000      ['dense_input[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 125)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 150)         600         ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 125)          15750       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 150)          22500       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 125)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 150)         600         ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 50)           6300        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 50)           7550        ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 50)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " linear_w (LinearW)             (None, 50)           2           ['dense_2[0][0]',                \n",
      "                                                                  'activation[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 50)           2550        ['linear_w[0][0]']               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 3)            153         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,054,130\n",
      "Trainable params: 1,052,030\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 5s 12ms/step - loss: 13.2674 - accuracy: 0.3416 - val_loss: 13.1552 - val_accuracy: 0.3347\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 13.1595 - accuracy: 0.3646 - val_loss: 13.0951 - val_accuracy: 0.3624\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 13.0846 - accuracy: 0.3871 - val_loss: 13.0258 - val_accuracy: 0.4045\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 13.0206 - accuracy: 0.4029 - val_loss: 12.9536 - val_accuracy: 0.4491\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.9484 - accuracy: 0.4322 - val_loss: 12.8839 - val_accuracy: 0.4867\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.8862 - accuracy: 0.4459 - val_loss: 12.8158 - val_accuracy: 0.5244\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.8223 - accuracy: 0.4676 - val_loss: 12.7501 - val_accuracy: 0.5576\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.7561 - accuracy: 0.4943 - val_loss: 12.6850 - val_accuracy: 0.5849\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.6945 - accuracy: 0.5116 - val_loss: 12.6203 - val_accuracy: 0.6096\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.6391 - accuracy: 0.5208 - val_loss: 12.5561 - val_accuracy: 0.6291\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.5738 - accuracy: 0.5430 - val_loss: 12.4930 - val_accuracy: 0.6456\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.5122 - accuracy: 0.5637 - val_loss: 12.4302 - val_accuracy: 0.6596\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.4523 - accuracy: 0.5717 - val_loss: 12.3679 - val_accuracy: 0.6717\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.3944 - accuracy: 0.5886 - val_loss: 12.3077 - val_accuracy: 0.6808\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.3338 - accuracy: 0.6006 - val_loss: 12.2477 - val_accuracy: 0.6881\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.2762 - accuracy: 0.6093 - val_loss: 12.1884 - val_accuracy: 0.6943\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.2190 - accuracy: 0.6192 - val_loss: 12.1301 - val_accuracy: 0.6961\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.1657 - accuracy: 0.6278 - val_loss: 12.0729 - val_accuracy: 0.7031\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.1109 - accuracy: 0.6351 - val_loss: 12.0160 - val_accuracy: 0.7083\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.0544 - accuracy: 0.6434 - val_loss: 11.9594 - val_accuracy: 0.7133\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.9952 - accuracy: 0.6570 - val_loss: 11.9034 - val_accuracy: 0.7184\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.9392 - accuracy: 0.6628 - val_loss: 11.8481 - val_accuracy: 0.7232\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.8820 - accuracy: 0.6712 - val_loss: 11.7926 - val_accuracy: 0.7269\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.8335 - accuracy: 0.6768 - val_loss: 11.7377 - val_accuracy: 0.7321\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.7758 - accuracy: 0.6853 - val_loss: 11.6818 - val_accuracy: 0.7387\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.7256 - accuracy: 0.6876 - val_loss: 11.6271 - val_accuracy: 0.7436\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.6731 - accuracy: 0.6921 - val_loss: 11.5726 - val_accuracy: 0.7495\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.6160 - accuracy: 0.7050 - val_loss: 11.5171 - val_accuracy: 0.7567\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.5634 - accuracy: 0.7112 - val_loss: 11.4623 - val_accuracy: 0.7629\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.5037 - accuracy: 0.7201 - val_loss: 11.4073 - val_accuracy: 0.7687\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.4529 - accuracy: 0.7228 - val_loss: 11.3523 - val_accuracy: 0.7736\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.4031 - accuracy: 0.7316 - val_loss: 11.2972 - val_accuracy: 0.7803\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.3450 - accuracy: 0.7360 - val_loss: 11.2429 - val_accuracy: 0.7867\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.2905 - accuracy: 0.7441 - val_loss: 11.1886 - val_accuracy: 0.7901\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.2376 - accuracy: 0.7500 - val_loss: 11.1343 - val_accuracy: 0.7984\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.1860 - accuracy: 0.7531 - val_loss: 11.0803 - val_accuracy: 0.8040\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.1308 - accuracy: 0.7671 - val_loss: 11.0269 - val_accuracy: 0.8100\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.0776 - accuracy: 0.7680 - val_loss: 10.9741 - val_accuracy: 0.8140\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.0302 - accuracy: 0.7714 - val_loss: 10.9216 - val_accuracy: 0.8197\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.9763 - accuracy: 0.7764 - val_loss: 10.8695 - val_accuracy: 0.8225\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.9198 - accuracy: 0.7844 - val_loss: 10.8177 - val_accuracy: 0.8276\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.8739 - accuracy: 0.7925 - val_loss: 10.7670 - val_accuracy: 0.8315\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.8206 - accuracy: 0.7950 - val_loss: 10.7162 - val_accuracy: 0.8368\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.7672 - accuracy: 0.8021 - val_loss: 10.6666 - val_accuracy: 0.8400\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.7179 - accuracy: 0.8083 - val_loss: 10.6169 - val_accuracy: 0.8443\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.6670 - accuracy: 0.8143 - val_loss: 10.5683 - val_accuracy: 0.8473\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.6202 - accuracy: 0.8152 - val_loss: 10.5206 - val_accuracy: 0.8493\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.5733 - accuracy: 0.8155 - val_loss: 10.4734 - val_accuracy: 0.8529\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.5224 - accuracy: 0.8207 - val_loss: 10.4259 - val_accuracy: 0.8552\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.4770 - accuracy: 0.8269 - val_loss: 10.3796 - val_accuracy: 0.8575\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.4248 - accuracy: 0.8304 - val_loss: 10.3339 - val_accuracy: 0.8608\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.3751 - accuracy: 0.8369 - val_loss: 10.2883 - val_accuracy: 0.8635\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.3350 - accuracy: 0.8359 - val_loss: 10.2435 - val_accuracy: 0.8651\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.2850 - accuracy: 0.8405 - val_loss: 10.1987 - val_accuracy: 0.8676\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.2381 - accuracy: 0.8450 - val_loss: 10.1546 - val_accuracy: 0.8709\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.1943 - accuracy: 0.8483 - val_loss: 10.1112 - val_accuracy: 0.8727\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.1503 - accuracy: 0.8500 - val_loss: 10.0681 - val_accuracy: 0.8733\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.1033 - accuracy: 0.8540 - val_loss: 10.0249 - val_accuracy: 0.8756\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.0583 - accuracy: 0.8566 - val_loss: 9.9821 - val_accuracy: 0.8772\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.0100 - accuracy: 0.8616 - val_loss: 9.9400 - val_accuracy: 0.8776\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.9710 - accuracy: 0.8639 - val_loss: 9.8970 - val_accuracy: 0.8795\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.9252 - accuracy: 0.8672 - val_loss: 9.8549 - val_accuracy: 0.8817\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.8783 - accuracy: 0.8699 - val_loss: 9.8133 - val_accuracy: 0.8829\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.8413 - accuracy: 0.8695 - val_loss: 9.7720 - val_accuracy: 0.8847\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.7941 - accuracy: 0.8715 - val_loss: 9.7310 - val_accuracy: 0.8861\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.7529 - accuracy: 0.8733 - val_loss: 9.6892 - val_accuracy: 0.8876\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.7137 - accuracy: 0.8736 - val_loss: 9.6489 - val_accuracy: 0.8892\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.6713 - accuracy: 0.8780 - val_loss: 9.6080 - val_accuracy: 0.8912\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.6292 - accuracy: 0.8767 - val_loss: 9.5677 - val_accuracy: 0.8925\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.5823 - accuracy: 0.8814 - val_loss: 9.5267 - val_accuracy: 0.8945\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.5436 - accuracy: 0.8833 - val_loss: 9.4875 - val_accuracy: 0.8952\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.5033 - accuracy: 0.8866 - val_loss: 9.4475 - val_accuracy: 0.8968\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.4616 - accuracy: 0.8837 - val_loss: 9.4081 - val_accuracy: 0.8980\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.4230 - accuracy: 0.8862 - val_loss: 9.3686 - val_accuracy: 0.8985\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.3815 - accuracy: 0.8892 - val_loss: 9.3293 - val_accuracy: 0.9003\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.3339 - accuracy: 0.8932 - val_loss: 9.2905 - val_accuracy: 0.9004\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.2980 - accuracy: 0.8914 - val_loss: 9.2519 - val_accuracy: 0.9005\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.2599 - accuracy: 0.8944 - val_loss: 9.2130 - val_accuracy: 0.9019\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.2151 - accuracy: 0.8964 - val_loss: 9.1740 - val_accuracy: 0.9032\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.1830 - accuracy: 0.8950 - val_loss: 9.1358 - val_accuracy: 0.9040\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.1408 - accuracy: 0.8991 - val_loss: 9.0968 - val_accuracy: 0.9056\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.1043 - accuracy: 0.8977 - val_loss: 9.0595 - val_accuracy: 0.9056\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.0620 - accuracy: 0.9003 - val_loss: 9.0207 - val_accuracy: 0.9071\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.0255 - accuracy: 0.8983 - val_loss: 8.9842 - val_accuracy: 0.9071\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.9833 - accuracy: 0.9008 - val_loss: 8.9469 - val_accuracy: 0.9069\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.9430 - accuracy: 0.9030 - val_loss: 8.9093 - val_accuracy: 0.9073\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.9057 - accuracy: 0.9044 - val_loss: 8.8721 - val_accuracy: 0.9077\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.8681 - accuracy: 0.9052 - val_loss: 8.8342 - val_accuracy: 0.9089\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.8305 - accuracy: 0.9063 - val_loss: 8.7976 - val_accuracy: 0.9089\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.7891 - accuracy: 0.9083 - val_loss: 8.7611 - val_accuracy: 0.9088\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.7474 - accuracy: 0.9107 - val_loss: 8.7234 - val_accuracy: 0.9095\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.7174 - accuracy: 0.9096 - val_loss: 8.6861 - val_accuracy: 0.9100\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.6779 - accuracy: 0.9113 - val_loss: 8.6503 - val_accuracy: 0.9107\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.6395 - accuracy: 0.9116 - val_loss: 8.6145 - val_accuracy: 0.9099\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.6039 - accuracy: 0.9112 - val_loss: 8.5772 - val_accuracy: 0.9117\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.5649 - accuracy: 0.9127 - val_loss: 8.5425 - val_accuracy: 0.9115\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.5258 - accuracy: 0.9144 - val_loss: 8.5049 - val_accuracy: 0.9112\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.4870 - accuracy: 0.9168 - val_loss: 8.4694 - val_accuracy: 0.9111\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.4508 - accuracy: 0.9182 - val_loss: 8.4332 - val_accuracy: 0.9128\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.4153 - accuracy: 0.9162 - val_loss: 8.3976 - val_accuracy: 0.9129\n",
      "Time: 74.45006847381592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 11:44:22.531179: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_50BM_20SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#50 BM, 20 SNPs\n",
    "################################################################################################################################################\n",
    "\n",
    "# subset the SNPs\n",
    "X20=X[:,0:20,:]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test  = train_test_split(y,X20,traits_BM50,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_BM_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_50BM_20SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bEdmwcQucO_e",
    "outputId": "c2e4f49f-7b71-4206-f474-e9a0d9da3edb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 20, 60)]          0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 18, 250)           45000     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 18, 250)          1000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 16, 250)           187500    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 16, 250)          1000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 14, 250)           187500    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 14, 250)          1000      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 4, 250)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 125)               125125    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 125)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 125)               15750     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 125)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                6300      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 570,328\n",
      "Trainable params: 568,828\n",
      "Non-trainable params: 1,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 2s 8ms/step - loss: 1.5512 - accuracy: 0.3678 - val_loss: 1.0498 - val_accuracy: 0.5089\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 1.2357 - accuracy: 0.4283 - val_loss: 0.9891 - val_accuracy: 0.5624\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.1240 - accuracy: 0.4684 - val_loss: 0.9224 - val_accuracy: 0.5973\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0644 - accuracy: 0.4860 - val_loss: 0.8721 - val_accuracy: 0.6284\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.0181 - accuracy: 0.5099 - val_loss: 0.8356 - val_accuracy: 0.6496\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.9710 - accuracy: 0.5365 - val_loss: 0.8044 - val_accuracy: 0.6681\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.9392 - accuracy: 0.5525 - val_loss: 0.7768 - val_accuracy: 0.6848\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.9098 - accuracy: 0.5712 - val_loss: 0.7508 - val_accuracy: 0.6944\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8814 - accuracy: 0.5832 - val_loss: 0.7244 - val_accuracy: 0.7095\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8552 - accuracy: 0.5994 - val_loss: 0.6974 - val_accuracy: 0.7231\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8319 - accuracy: 0.6144 - val_loss: 0.6734 - val_accuracy: 0.7357\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.8037 - accuracy: 0.6273 - val_loss: 0.6476 - val_accuracy: 0.7492\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7644 - accuracy: 0.6535 - val_loss: 0.6191 - val_accuracy: 0.7583\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7511 - accuracy: 0.6598 - val_loss: 0.5927 - val_accuracy: 0.7712\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.7225 - accuracy: 0.6738 - val_loss: 0.5671 - val_accuracy: 0.7812\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6949 - accuracy: 0.6912 - val_loss: 0.5438 - val_accuracy: 0.7913\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6757 - accuracy: 0.7028 - val_loss: 0.5209 - val_accuracy: 0.8009\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6520 - accuracy: 0.7161 - val_loss: 0.5001 - val_accuracy: 0.8076\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6352 - accuracy: 0.7213 - val_loss: 0.4803 - val_accuracy: 0.8153\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.6094 - accuracy: 0.7356 - val_loss: 0.4624 - val_accuracy: 0.8217\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5921 - accuracy: 0.7437 - val_loss: 0.4467 - val_accuracy: 0.8264\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5710 - accuracy: 0.7560 - val_loss: 0.4325 - val_accuracy: 0.8324\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5591 - accuracy: 0.7586 - val_loss: 0.4195 - val_accuracy: 0.8393\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5439 - accuracy: 0.7683 - val_loss: 0.4070 - val_accuracy: 0.8459\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5311 - accuracy: 0.7762 - val_loss: 0.3968 - val_accuracy: 0.8513\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5228 - accuracy: 0.7784 - val_loss: 0.3870 - val_accuracy: 0.8539\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5078 - accuracy: 0.7890 - val_loss: 0.3789 - val_accuracy: 0.8557\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4964 - accuracy: 0.7918 - val_loss: 0.3700 - val_accuracy: 0.8577\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4879 - accuracy: 0.7966 - val_loss: 0.3624 - val_accuracy: 0.8605\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.8051 - val_loss: 0.3563 - val_accuracy: 0.8621\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.8102 - val_loss: 0.3491 - val_accuracy: 0.8651\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.8108 - val_loss: 0.3428 - val_accuracy: 0.8668\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.8155 - val_loss: 0.3366 - val_accuracy: 0.8703\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.8177 - val_loss: 0.3318 - val_accuracy: 0.8719\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.8235 - val_loss: 0.3269 - val_accuracy: 0.8740\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.8281 - val_loss: 0.3220 - val_accuracy: 0.8765\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.8290 - val_loss: 0.3181 - val_accuracy: 0.8784\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8341 - val_loss: 0.3132 - val_accuracy: 0.8799\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8361 - val_loss: 0.3089 - val_accuracy: 0.8825\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8398 - val_loss: 0.3055 - val_accuracy: 0.8831\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8442 - val_loss: 0.3026 - val_accuracy: 0.8837\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8462 - val_loss: 0.2995 - val_accuracy: 0.8852\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8463 - val_loss: 0.2934 - val_accuracy: 0.8871\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8507 - val_loss: 0.2912 - val_accuracy: 0.8881\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3703 - accuracy: 0.8559 - val_loss: 0.2873 - val_accuracy: 0.8893\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3669 - accuracy: 0.8547 - val_loss: 0.2851 - val_accuracy: 0.8909\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3710 - accuracy: 0.8569 - val_loss: 0.2818 - val_accuracy: 0.8911\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3577 - accuracy: 0.8616 - val_loss: 0.2788 - val_accuracy: 0.8928\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3529 - accuracy: 0.8616 - val_loss: 0.2771 - val_accuracy: 0.8947\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3479 - accuracy: 0.8619 - val_loss: 0.2761 - val_accuracy: 0.8947\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3466 - accuracy: 0.8645 - val_loss: 0.2729 - val_accuracy: 0.8955\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3476 - accuracy: 0.8644 - val_loss: 0.2697 - val_accuracy: 0.8964\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8692 - val_loss: 0.2670 - val_accuracy: 0.8981\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8700 - val_loss: 0.2658 - val_accuracy: 0.8988\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8726 - val_loss: 0.2619 - val_accuracy: 0.9007\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.3249 - accuracy: 0.8740 - val_loss: 0.2609 - val_accuracy: 0.9012\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3189 - accuracy: 0.8779 - val_loss: 0.2588 - val_accuracy: 0.9020\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.3203 - accuracy: 0.8780 - val_loss: 0.2566 - val_accuracy: 0.9028\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3145 - accuracy: 0.8792 - val_loss: 0.2554 - val_accuracy: 0.9028\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.3139 - accuracy: 0.8799 - val_loss: 0.2537 - val_accuracy: 0.9043\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3146 - accuracy: 0.8790 - val_loss: 0.2517 - val_accuracy: 0.9056\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3100 - accuracy: 0.8792 - val_loss: 0.2501 - val_accuracy: 0.9056\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.3046 - accuracy: 0.8835 - val_loss: 0.2485 - val_accuracy: 0.9063\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.3068 - accuracy: 0.8818 - val_loss: 0.2476 - val_accuracy: 0.9067\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.2926 - accuracy: 0.8876 - val_loss: 0.2461 - val_accuracy: 0.9068\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2945 - accuracy: 0.8876 - val_loss: 0.2440 - val_accuracy: 0.9075\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.2950 - accuracy: 0.8894 - val_loss: 0.2436 - val_accuracy: 0.9077\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2876 - accuracy: 0.8903 - val_loss: 0.2417 - val_accuracy: 0.9083\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2844 - accuracy: 0.8923 - val_loss: 0.2406 - val_accuracy: 0.9097\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2824 - accuracy: 0.8908 - val_loss: 0.2408 - val_accuracy: 0.9093\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2828 - accuracy: 0.8936 - val_loss: 0.2385 - val_accuracy: 0.9099\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2776 - accuracy: 0.8968 - val_loss: 0.2381 - val_accuracy: 0.9109\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2807 - accuracy: 0.8942 - val_loss: 0.2367 - val_accuracy: 0.9112\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2795 - accuracy: 0.8943 - val_loss: 0.2356 - val_accuracy: 0.9113\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2757 - accuracy: 0.8968 - val_loss: 0.2352 - val_accuracy: 0.9121\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2679 - accuracy: 0.8995 - val_loss: 0.2344 - val_accuracy: 0.9115\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2700 - accuracy: 0.8979 - val_loss: 0.2345 - val_accuracy: 0.9112\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2738 - accuracy: 0.8976 - val_loss: 0.2328 - val_accuracy: 0.9115\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 0s 6ms/step - loss: 0.2627 - accuracy: 0.9019 - val_loss: 0.2319 - val_accuracy: 0.9128\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2648 - accuracy: 0.9005 - val_loss: 0.2320 - val_accuracy: 0.9125\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2603 - accuracy: 0.9016 - val_loss: 0.2309 - val_accuracy: 0.9131\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2586 - accuracy: 0.9033 - val_loss: 0.2306 - val_accuracy: 0.9141\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2587 - accuracy: 0.9028 - val_loss: 0.2298 - val_accuracy: 0.9140\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2531 - accuracy: 0.9056 - val_loss: 0.2282 - val_accuracy: 0.9141\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2496 - accuracy: 0.9050 - val_loss: 0.2272 - val_accuracy: 0.9156\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2503 - accuracy: 0.9073 - val_loss: 0.2273 - val_accuracy: 0.9156\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2475 - accuracy: 0.9086 - val_loss: 0.2264 - val_accuracy: 0.9152\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2451 - accuracy: 0.9092 - val_loss: 0.2265 - val_accuracy: 0.9145\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2432 - accuracy: 0.9076 - val_loss: 0.2253 - val_accuracy: 0.9153\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2461 - accuracy: 0.9081 - val_loss: 0.2247 - val_accuracy: 0.9160\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2432 - accuracy: 0.9100 - val_loss: 0.2242 - val_accuracy: 0.9168\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2393 - accuracy: 0.9102 - val_loss: 0.2242 - val_accuracy: 0.9160\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2409 - accuracy: 0.9113 - val_loss: 0.2229 - val_accuracy: 0.9163\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2381 - accuracy: 0.9108 - val_loss: 0.2240 - val_accuracy: 0.9159\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2362 - accuracy: 0.9135 - val_loss: 0.2223 - val_accuracy: 0.9163\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2384 - accuracy: 0.9108 - val_loss: 0.2228 - val_accuracy: 0.9161\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2267 - accuracy: 0.9155 - val_loss: 0.2217 - val_accuracy: 0.9171\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2296 - accuracy: 0.9152 - val_loss: 0.2234 - val_accuracy: 0.9164\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2331 - accuracy: 0.9137 - val_loss: 0.2204 - val_accuracy: 0.9175\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.2276 - accuracy: 0.9153 - val_loss: 0.2207 - val_accuracy: 0.9175\n",
      "Time: 50.30513286590576\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_CNN_Model_20SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#20 SNPs\n",
    "################################################################################################################################################\n",
    "# now repeat the analysis only for SNPs\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test  = train_test_split(y,X20,traits_BM50,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = SNP_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_CNN_Model_20SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XEmClYK43qOR",
    "outputId": "e9608731-3cff-4696-bf90-9e11050f09e1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15_input (InputLayer)  [(None, 1000)]           0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 150)               150000    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 150)               22500     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 50)                7550      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 181,403\n",
      "Trainable params: 180,803\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 8.9590 - accuracy: 0.3824 - val_loss: 8.7988 - val_accuracy: 0.3756\n",
      "Epoch 2/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.8309 - accuracy: 0.4252 - val_loss: 8.7494 - val_accuracy: 0.4240\n",
      "Epoch 3/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.7434 - accuracy: 0.4586 - val_loss: 8.6996 - val_accuracy: 0.4636\n",
      "Epoch 4/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.6748 - accuracy: 0.4859 - val_loss: 8.6512 - val_accuracy: 0.4919\n",
      "Epoch 5/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.6174 - accuracy: 0.5040 - val_loss: 8.6060 - val_accuracy: 0.5116\n",
      "Epoch 6/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.5675 - accuracy: 0.5184 - val_loss: 8.5647 - val_accuracy: 0.5228\n",
      "Epoch 7/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.5274 - accuracy: 0.5330 - val_loss: 8.5265 - val_accuracy: 0.5312\n",
      "Epoch 8/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.4874 - accuracy: 0.5413 - val_loss: 8.4914 - val_accuracy: 0.5396\n",
      "Epoch 9/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.4498 - accuracy: 0.5529 - val_loss: 8.4587 - val_accuracy: 0.5445\n",
      "Epoch 10/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.4163 - accuracy: 0.5591 - val_loss: 8.4280 - val_accuracy: 0.5499\n",
      "Epoch 11/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.3838 - accuracy: 0.5660 - val_loss: 8.3989 - val_accuracy: 0.5539\n",
      "Epoch 12/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.3535 - accuracy: 0.5717 - val_loss: 8.3713 - val_accuracy: 0.5573\n",
      "Epoch 13/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.3247 - accuracy: 0.5773 - val_loss: 8.3448 - val_accuracy: 0.5613\n",
      "Epoch 14/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.2961 - accuracy: 0.5827 - val_loss: 8.3192 - val_accuracy: 0.5643\n",
      "Epoch 15/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.2706 - accuracy: 0.5860 - val_loss: 8.2944 - val_accuracy: 0.5667\n",
      "Epoch 16/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.2433 - accuracy: 0.5872 - val_loss: 8.2706 - val_accuracy: 0.5669\n",
      "Epoch 17/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.2201 - accuracy: 0.5928 - val_loss: 8.2472 - val_accuracy: 0.5707\n",
      "Epoch 18/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.1942 - accuracy: 0.5960 - val_loss: 8.2245 - val_accuracy: 0.5724\n",
      "Epoch 19/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.1704 - accuracy: 0.5975 - val_loss: 8.2023 - val_accuracy: 0.5737\n",
      "Epoch 20/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.1470 - accuracy: 0.5997 - val_loss: 8.1804 - val_accuracy: 0.5751\n",
      "Epoch 21/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.1229 - accuracy: 0.6028 - val_loss: 8.1590 - val_accuracy: 0.5759\n",
      "Epoch 22/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.1025 - accuracy: 0.6066 - val_loss: 8.1379 - val_accuracy: 0.5769\n",
      "Epoch 23/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.0786 - accuracy: 0.6092 - val_loss: 8.1173 - val_accuracy: 0.5779\n",
      "Epoch 24/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.0568 - accuracy: 0.6133 - val_loss: 8.0969 - val_accuracy: 0.5797\n",
      "Epoch 25/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.0345 - accuracy: 0.6140 - val_loss: 8.0768 - val_accuracy: 0.5801\n",
      "Epoch 26/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.0126 - accuracy: 0.6208 - val_loss: 8.0569 - val_accuracy: 0.5800\n",
      "Epoch 27/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.9933 - accuracy: 0.6208 - val_loss: 8.0373 - val_accuracy: 0.5815\n",
      "Epoch 28/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.9718 - accuracy: 0.6224 - val_loss: 8.0179 - val_accuracy: 0.5843\n",
      "Epoch 29/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.9526 - accuracy: 0.6217 - val_loss: 7.9989 - val_accuracy: 0.5849\n",
      "Epoch 30/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.9300 - accuracy: 0.6253 - val_loss: 7.9797 - val_accuracy: 0.5859\n",
      "Epoch 31/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.9118 - accuracy: 0.6296 - val_loss: 7.9610 - val_accuracy: 0.5863\n",
      "Epoch 32/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.8917 - accuracy: 0.6293 - val_loss: 7.9424 - val_accuracy: 0.5869\n",
      "Epoch 33/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.8719 - accuracy: 0.6305 - val_loss: 7.9239 - val_accuracy: 0.5883\n",
      "Epoch 34/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.8516 - accuracy: 0.6340 - val_loss: 7.9056 - val_accuracy: 0.5877\n",
      "Epoch 35/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.8322 - accuracy: 0.6356 - val_loss: 7.8874 - val_accuracy: 0.5888\n",
      "Epoch 36/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.8121 - accuracy: 0.6355 - val_loss: 7.8692 - val_accuracy: 0.5891\n",
      "Epoch 37/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.7943 - accuracy: 0.6390 - val_loss: 7.8513 - val_accuracy: 0.5885\n",
      "Epoch 38/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.7738 - accuracy: 0.6408 - val_loss: 7.8335 - val_accuracy: 0.5881\n",
      "Epoch 39/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.7559 - accuracy: 0.6405 - val_loss: 7.8158 - val_accuracy: 0.5873\n",
      "Epoch 40/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.7381 - accuracy: 0.6416 - val_loss: 7.7981 - val_accuracy: 0.5876\n",
      "Epoch 41/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.7172 - accuracy: 0.6479 - val_loss: 7.7806 - val_accuracy: 0.5883\n",
      "Epoch 42/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.6995 - accuracy: 0.6477 - val_loss: 7.7632 - val_accuracy: 0.5892\n",
      "Epoch 43/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.6795 - accuracy: 0.6540 - val_loss: 7.7458 - val_accuracy: 0.5893\n",
      "Epoch 44/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.6629 - accuracy: 0.6524 - val_loss: 7.7288 - val_accuracy: 0.5896\n",
      "Epoch 45/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.6439 - accuracy: 0.6555 - val_loss: 7.7116 - val_accuracy: 0.5904\n",
      "Epoch 46/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.6256 - accuracy: 0.6544 - val_loss: 7.6944 - val_accuracy: 0.5907\n",
      "Epoch 47/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.6076 - accuracy: 0.6563 - val_loss: 7.6775 - val_accuracy: 0.5908\n",
      "Epoch 48/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5889 - accuracy: 0.6571 - val_loss: 7.6606 - val_accuracy: 0.5920\n",
      "Epoch 49/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5720 - accuracy: 0.6591 - val_loss: 7.6438 - val_accuracy: 0.5924\n",
      "Epoch 50/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5526 - accuracy: 0.6631 - val_loss: 7.6272 - val_accuracy: 0.5924\n",
      "Epoch 51/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5360 - accuracy: 0.6642 - val_loss: 7.6105 - val_accuracy: 0.5935\n",
      "Epoch 52/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5171 - accuracy: 0.6667 - val_loss: 7.5938 - val_accuracy: 0.5939\n",
      "Epoch 53/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5011 - accuracy: 0.6660 - val_loss: 7.5774 - val_accuracy: 0.5941\n",
      "Epoch 54/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.4814 - accuracy: 0.6664 - val_loss: 7.5608 - val_accuracy: 0.5940\n",
      "Epoch 55/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.4649 - accuracy: 0.6675 - val_loss: 7.5445 - val_accuracy: 0.5932\n",
      "Epoch 56/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.4474 - accuracy: 0.6672 - val_loss: 7.5283 - val_accuracy: 0.5936\n",
      "Epoch 57/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.4295 - accuracy: 0.6720 - val_loss: 7.5118 - val_accuracy: 0.5940\n",
      "Epoch 58/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.4129 - accuracy: 0.6720 - val_loss: 7.4956 - val_accuracy: 0.5943\n",
      "Epoch 59/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.3939 - accuracy: 0.6776 - val_loss: 7.4795 - val_accuracy: 0.5948\n",
      "Epoch 60/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.3758 - accuracy: 0.6780 - val_loss: 7.4631 - val_accuracy: 0.5951\n",
      "Epoch 61/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.3594 - accuracy: 0.6783 - val_loss: 7.4472 - val_accuracy: 0.5951\n",
      "Epoch 62/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.3415 - accuracy: 0.6791 - val_loss: 7.4313 - val_accuracy: 0.5952\n",
      "Epoch 63/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.3251 - accuracy: 0.6816 - val_loss: 7.4152 - val_accuracy: 0.5960\n",
      "Epoch 64/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.3087 - accuracy: 0.6818 - val_loss: 7.3992 - val_accuracy: 0.5959\n",
      "Epoch 65/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2908 - accuracy: 0.6831 - val_loss: 7.3836 - val_accuracy: 0.5968\n",
      "Epoch 66/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2743 - accuracy: 0.6824 - val_loss: 7.3677 - val_accuracy: 0.5963\n",
      "Epoch 67/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2568 - accuracy: 0.6853 - val_loss: 7.3517 - val_accuracy: 0.5973\n",
      "Epoch 68/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2407 - accuracy: 0.6853 - val_loss: 7.3359 - val_accuracy: 0.5969\n",
      "Epoch 69/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2235 - accuracy: 0.6904 - val_loss: 7.3204 - val_accuracy: 0.5967\n",
      "Epoch 70/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2061 - accuracy: 0.6891 - val_loss: 7.3046 - val_accuracy: 0.5963\n",
      "Epoch 71/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1887 - accuracy: 0.6918 - val_loss: 7.2890 - val_accuracy: 0.5972\n",
      "Epoch 72/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1724 - accuracy: 0.6913 - val_loss: 7.2734 - val_accuracy: 0.5979\n",
      "Epoch 73/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1566 - accuracy: 0.6920 - val_loss: 7.2579 - val_accuracy: 0.5980\n",
      "Epoch 74/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1388 - accuracy: 0.6940 - val_loss: 7.2424 - val_accuracy: 0.5989\n",
      "Epoch 75/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1233 - accuracy: 0.6957 - val_loss: 7.2270 - val_accuracy: 0.5985\n",
      "Epoch 76/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1056 - accuracy: 0.6956 - val_loss: 7.2115 - val_accuracy: 0.5991\n",
      "Epoch 77/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0895 - accuracy: 0.6986 - val_loss: 7.1960 - val_accuracy: 0.6000\n",
      "Epoch 78/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0722 - accuracy: 0.6985 - val_loss: 7.1808 - val_accuracy: 0.5999\n",
      "Epoch 79/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0554 - accuracy: 0.7000 - val_loss: 7.1654 - val_accuracy: 0.5991\n",
      "Epoch 80/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0385 - accuracy: 0.7015 - val_loss: 7.1501 - val_accuracy: 0.5989\n",
      "Epoch 81/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0211 - accuracy: 0.7042 - val_loss: 7.1349 - val_accuracy: 0.5993\n",
      "Epoch 82/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0051 - accuracy: 0.7041 - val_loss: 7.1196 - val_accuracy: 0.5993\n",
      "Epoch 83/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9909 - accuracy: 0.7055 - val_loss: 7.1046 - val_accuracy: 0.5997\n",
      "Epoch 84/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9726 - accuracy: 0.7082 - val_loss: 7.0893 - val_accuracy: 0.6003\n",
      "Epoch 85/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9569 - accuracy: 0.7088 - val_loss: 7.0744 - val_accuracy: 0.6009\n",
      "Epoch 86/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9416 - accuracy: 0.7108 - val_loss: 7.0590 - val_accuracy: 0.6009\n",
      "Epoch 87/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9246 - accuracy: 0.7120 - val_loss: 7.0440 - val_accuracy: 0.6012\n",
      "Epoch 88/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9075 - accuracy: 0.7117 - val_loss: 7.0290 - val_accuracy: 0.6019\n",
      "Epoch 89/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8917 - accuracy: 0.7131 - val_loss: 7.0140 - val_accuracy: 0.6011\n",
      "Epoch 90/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8750 - accuracy: 0.7132 - val_loss: 6.9991 - val_accuracy: 0.6009\n",
      "Epoch 91/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8605 - accuracy: 0.7134 - val_loss: 6.9842 - val_accuracy: 0.6011\n",
      "Epoch 92/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8420 - accuracy: 0.7170 - val_loss: 6.9692 - val_accuracy: 0.6008\n",
      "Epoch 93/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8260 - accuracy: 0.7185 - val_loss: 6.9544 - val_accuracy: 0.6012\n",
      "Epoch 94/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8128 - accuracy: 0.7162 - val_loss: 6.9396 - val_accuracy: 0.6003\n",
      "Epoch 95/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7941 - accuracy: 0.7212 - val_loss: 6.9248 - val_accuracy: 0.5999\n",
      "Epoch 96/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7775 - accuracy: 0.7213 - val_loss: 6.9100 - val_accuracy: 0.5993\n",
      "Epoch 97/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7633 - accuracy: 0.7225 - val_loss: 6.8952 - val_accuracy: 0.5999\n",
      "Epoch 98/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7458 - accuracy: 0.7244 - val_loss: 6.8807 - val_accuracy: 0.6011\n",
      "Epoch 99/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7305 - accuracy: 0.7237 - val_loss: 6.8659 - val_accuracy: 0.6009\n",
      "Epoch 100/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7135 - accuracy: 0.7275 - val_loss: 6.8513 - val_accuracy: 0.6015\n",
      "Epoch 101/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6983 - accuracy: 0.7257 - val_loss: 6.8367 - val_accuracy: 0.6011\n",
      "Epoch 102/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6843 - accuracy: 0.7263 - val_loss: 6.8220 - val_accuracy: 0.6003\n",
      "Epoch 103/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6673 - accuracy: 0.7268 - val_loss: 6.8075 - val_accuracy: 0.6015\n",
      "Epoch 104/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6515 - accuracy: 0.7296 - val_loss: 6.7929 - val_accuracy: 0.6007\n",
      "Epoch 105/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6364 - accuracy: 0.7285 - val_loss: 6.7785 - val_accuracy: 0.6008\n",
      "Epoch 106/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6190 - accuracy: 0.7331 - val_loss: 6.7638 - val_accuracy: 0.6015\n",
      "Epoch 107/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6037 - accuracy: 0.7318 - val_loss: 6.7495 - val_accuracy: 0.6013\n",
      "Epoch 108/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5881 - accuracy: 0.7320 - val_loss: 6.7352 - val_accuracy: 0.6011\n",
      "Epoch 109/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5729 - accuracy: 0.7351 - val_loss: 6.7208 - val_accuracy: 0.6012\n",
      "Epoch 110/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5551 - accuracy: 0.7373 - val_loss: 6.7066 - val_accuracy: 0.6007\n",
      "Epoch 111/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5402 - accuracy: 0.7351 - val_loss: 6.6921 - val_accuracy: 0.6013\n",
      "Epoch 112/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5234 - accuracy: 0.7395 - val_loss: 6.6781 - val_accuracy: 0.6008\n",
      "Epoch 113/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5086 - accuracy: 0.7411 - val_loss: 6.6637 - val_accuracy: 0.6021\n",
      "Epoch 114/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4919 - accuracy: 0.7408 - val_loss: 6.6496 - val_accuracy: 0.6021\n",
      "Epoch 115/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4785 - accuracy: 0.7402 - val_loss: 6.6354 - val_accuracy: 0.6019\n",
      "Epoch 116/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4627 - accuracy: 0.7416 - val_loss: 6.6213 - val_accuracy: 0.6025\n",
      "Epoch 117/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4469 - accuracy: 0.7451 - val_loss: 6.6070 - val_accuracy: 0.6023\n",
      "Epoch 118/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4322 - accuracy: 0.7439 - val_loss: 6.5928 - val_accuracy: 0.6028\n",
      "Epoch 119/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4162 - accuracy: 0.7450 - val_loss: 6.5789 - val_accuracy: 0.6021\n",
      "Epoch 120/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4005 - accuracy: 0.7443 - val_loss: 6.5649 - val_accuracy: 0.6020\n",
      "Epoch 121/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3828 - accuracy: 0.7487 - val_loss: 6.5508 - val_accuracy: 0.6021\n",
      "Epoch 122/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3690 - accuracy: 0.7497 - val_loss: 6.5370 - val_accuracy: 0.6019\n",
      "Epoch 123/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3547 - accuracy: 0.7511 - val_loss: 6.5229 - val_accuracy: 0.6028\n",
      "Epoch 124/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3382 - accuracy: 0.7487 - val_loss: 6.5087 - val_accuracy: 0.6032\n",
      "Epoch 125/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3218 - accuracy: 0.7532 - val_loss: 6.4947 - val_accuracy: 0.6027\n",
      "Epoch 126/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3084 - accuracy: 0.7536 - val_loss: 6.4810 - val_accuracy: 0.6027\n",
      "Epoch 127/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2923 - accuracy: 0.7541 - val_loss: 6.4672 - val_accuracy: 0.6035\n",
      "Epoch 128/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2774 - accuracy: 0.7561 - val_loss: 6.4534 - val_accuracy: 0.6031\n",
      "Epoch 129/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2638 - accuracy: 0.7550 - val_loss: 6.4396 - val_accuracy: 0.6035\n",
      "Epoch 130/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2477 - accuracy: 0.7584 - val_loss: 6.4259 - val_accuracy: 0.6035\n",
      "Epoch 131/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2310 - accuracy: 0.7589 - val_loss: 6.4124 - val_accuracy: 0.6036\n",
      "Epoch 132/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2167 - accuracy: 0.7608 - val_loss: 6.3987 - val_accuracy: 0.6035\n",
      "Epoch 133/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2021 - accuracy: 0.7606 - val_loss: 6.3849 - val_accuracy: 0.6032\n",
      "Epoch 134/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.1857 - accuracy: 0.7616 - val_loss: 6.3713 - val_accuracy: 0.6041\n",
      "Epoch 135/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.1699 - accuracy: 0.7629 - val_loss: 6.3576 - val_accuracy: 0.6035\n",
      "Epoch 136/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.1581 - accuracy: 0.7631 - val_loss: 6.3438 - val_accuracy: 0.6028\n",
      "Epoch 137/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.1420 - accuracy: 0.7632 - val_loss: 6.3304 - val_accuracy: 0.6032\n",
      "Epoch 138/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.1256 - accuracy: 0.7665 - val_loss: 6.3167 - val_accuracy: 0.6025\n",
      "Epoch 139/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.1109 - accuracy: 0.7658 - val_loss: 6.3035 - val_accuracy: 0.6029\n",
      "Epoch 140/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.0971 - accuracy: 0.7652 - val_loss: 6.2899 - val_accuracy: 0.6037\n",
      "Epoch 141/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.0807 - accuracy: 0.7702 - val_loss: 6.2764 - val_accuracy: 0.6048\n",
      "Epoch 142/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.0670 - accuracy: 0.7691 - val_loss: 6.2628 - val_accuracy: 0.6043\n",
      "Epoch 143/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.0516 - accuracy: 0.7707 - val_loss: 6.2495 - val_accuracy: 0.6043\n",
      "Epoch 144/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.0356 - accuracy: 0.7724 - val_loss: 6.2359 - val_accuracy: 0.6041\n",
      "Epoch 145/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.0198 - accuracy: 0.7731 - val_loss: 6.2225 - val_accuracy: 0.6048\n",
      "Epoch 146/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.0051 - accuracy: 0.7735 - val_loss: 6.2091 - val_accuracy: 0.6048\n",
      "Epoch 147/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.9917 - accuracy: 0.7772 - val_loss: 6.1954 - val_accuracy: 0.6044\n",
      "Epoch 148/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.9767 - accuracy: 0.7786 - val_loss: 6.1822 - val_accuracy: 0.6047\n",
      "Epoch 149/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.9619 - accuracy: 0.7796 - val_loss: 6.1690 - val_accuracy: 0.6045\n",
      "Epoch 150/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.9469 - accuracy: 0.7782 - val_loss: 6.1560 - val_accuracy: 0.6041\n",
      "Epoch 151/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.9320 - accuracy: 0.7780 - val_loss: 6.1425 - val_accuracy: 0.6051\n",
      "Epoch 152/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.9164 - accuracy: 0.7796 - val_loss: 6.1292 - val_accuracy: 0.6052\n",
      "Epoch 153/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.9037 - accuracy: 0.7796 - val_loss: 6.1158 - val_accuracy: 0.6057\n",
      "Epoch 154/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.8889 - accuracy: 0.7782 - val_loss: 6.1028 - val_accuracy: 0.6057\n",
      "Epoch 155/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.8723 - accuracy: 0.7834 - val_loss: 6.0898 - val_accuracy: 0.6061\n",
      "Epoch 156/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.8578 - accuracy: 0.7852 - val_loss: 6.0768 - val_accuracy: 0.6063\n",
      "Epoch 157/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.8427 - accuracy: 0.7874 - val_loss: 6.0638 - val_accuracy: 0.6060\n",
      "Epoch 158/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.8304 - accuracy: 0.7856 - val_loss: 6.0506 - val_accuracy: 0.6060\n",
      "Epoch 159/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.8138 - accuracy: 0.7861 - val_loss: 6.0374 - val_accuracy: 0.6067\n",
      "Epoch 160/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.8000 - accuracy: 0.7865 - val_loss: 6.0245 - val_accuracy: 0.6065\n",
      "Epoch 161/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.7856 - accuracy: 0.7881 - val_loss: 6.0114 - val_accuracy: 0.6073\n",
      "Epoch 162/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.7698 - accuracy: 0.7896 - val_loss: 5.9983 - val_accuracy: 0.6079\n",
      "Epoch 163/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.7570 - accuracy: 0.7895 - val_loss: 5.9853 - val_accuracy: 0.6076\n",
      "Epoch 164/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.7408 - accuracy: 0.7924 - val_loss: 5.9722 - val_accuracy: 0.6068\n",
      "Epoch 165/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.7269 - accuracy: 0.7942 - val_loss: 5.9594 - val_accuracy: 0.6073\n",
      "Epoch 166/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.7118 - accuracy: 0.7961 - val_loss: 5.9468 - val_accuracy: 0.6071\n",
      "Epoch 167/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.6974 - accuracy: 0.7958 - val_loss: 5.9339 - val_accuracy: 0.6069\n",
      "Epoch 168/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.6832 - accuracy: 0.7937 - val_loss: 5.9212 - val_accuracy: 0.6072\n",
      "Epoch 169/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.6690 - accuracy: 0.7948 - val_loss: 5.9083 - val_accuracy: 0.6065\n",
      "Epoch 170/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.6547 - accuracy: 0.7983 - val_loss: 5.8953 - val_accuracy: 0.6059\n",
      "Epoch 171/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.6401 - accuracy: 0.7980 - val_loss: 5.8826 - val_accuracy: 0.6060\n",
      "Epoch 172/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.6261 - accuracy: 0.7988 - val_loss: 5.8699 - val_accuracy: 0.6061\n",
      "Epoch 173/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.6098 - accuracy: 0.8029 - val_loss: 5.8572 - val_accuracy: 0.6057\n",
      "Epoch 174/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.5977 - accuracy: 0.8016 - val_loss: 5.8446 - val_accuracy: 0.6055\n",
      "Epoch 175/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.5839 - accuracy: 0.7998 - val_loss: 5.8319 - val_accuracy: 0.6048\n",
      "Epoch 176/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.5678 - accuracy: 0.8046 - val_loss: 5.8192 - val_accuracy: 0.6053\n",
      "Epoch 177/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.5530 - accuracy: 0.8048 - val_loss: 5.8066 - val_accuracy: 0.6047\n",
      "Epoch 178/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.5393 - accuracy: 0.8053 - val_loss: 5.7940 - val_accuracy: 0.6047\n",
      "Epoch 179/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.5264 - accuracy: 0.8051 - val_loss: 5.7814 - val_accuracy: 0.6048\n",
      "Epoch 180/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.5105 - accuracy: 0.8092 - val_loss: 5.7691 - val_accuracy: 0.6047\n",
      "Epoch 181/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.4958 - accuracy: 0.8086 - val_loss: 5.7564 - val_accuracy: 0.6051\n",
      "Epoch 182/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.4827 - accuracy: 0.8099 - val_loss: 5.7439 - val_accuracy: 0.6047\n",
      "Epoch 183/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.4691 - accuracy: 0.8105 - val_loss: 5.7315 - val_accuracy: 0.6051\n",
      "Epoch 184/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.4541 - accuracy: 0.8114 - val_loss: 5.7189 - val_accuracy: 0.6052\n",
      "Epoch 185/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.4420 - accuracy: 0.8112 - val_loss: 5.7065 - val_accuracy: 0.6053\n",
      "Epoch 186/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.4279 - accuracy: 0.8108 - val_loss: 5.6940 - val_accuracy: 0.6064\n",
      "Epoch 187/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.4133 - accuracy: 0.8133 - val_loss: 5.6818 - val_accuracy: 0.6063\n",
      "Epoch 188/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.3969 - accuracy: 0.8159 - val_loss: 5.6694 - val_accuracy: 0.6060\n",
      "Epoch 189/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.3830 - accuracy: 0.8137 - val_loss: 5.6571 - val_accuracy: 0.6071\n",
      "Epoch 190/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.3713 - accuracy: 0.8159 - val_loss: 5.6447 - val_accuracy: 0.6060\n",
      "Epoch 191/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.3571 - accuracy: 0.8192 - val_loss: 5.6324 - val_accuracy: 0.6067\n",
      "Epoch 192/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.3437 - accuracy: 0.8160 - val_loss: 5.6201 - val_accuracy: 0.6068\n",
      "Epoch 193/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.3302 - accuracy: 0.8172 - val_loss: 5.6080 - val_accuracy: 0.6067\n",
      "Epoch 194/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.3154 - accuracy: 0.8207 - val_loss: 5.5958 - val_accuracy: 0.6077\n",
      "Epoch 195/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.3007 - accuracy: 0.8210 - val_loss: 5.5836 - val_accuracy: 0.6068\n",
      "Epoch 196/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.2856 - accuracy: 0.8228 - val_loss: 5.5717 - val_accuracy: 0.6064\n",
      "Epoch 197/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.2744 - accuracy: 0.8199 - val_loss: 5.5595 - val_accuracy: 0.6061\n",
      "Epoch 198/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.2599 - accuracy: 0.8222 - val_loss: 5.5473 - val_accuracy: 0.6064\n",
      "Epoch 199/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.2436 - accuracy: 0.8248 - val_loss: 5.5352 - val_accuracy: 0.6064\n",
      "Epoch 200/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.2310 - accuracy: 0.8243 - val_loss: 5.5231 - val_accuracy: 0.6064\n",
      "Epoch 201/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.2162 - accuracy: 0.8277 - val_loss: 5.5109 - val_accuracy: 0.6063\n",
      "Epoch 202/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.2032 - accuracy: 0.8277 - val_loss: 5.4989 - val_accuracy: 0.6061\n",
      "Epoch 203/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.1918 - accuracy: 0.8273 - val_loss: 5.4871 - val_accuracy: 0.6060\n",
      "Epoch 204/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.1755 - accuracy: 0.8309 - val_loss: 5.4750 - val_accuracy: 0.6064\n",
      "Epoch 205/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.1620 - accuracy: 0.8310 - val_loss: 5.4631 - val_accuracy: 0.6065\n",
      "Epoch 206/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.1469 - accuracy: 0.8321 - val_loss: 5.4512 - val_accuracy: 0.6077\n",
      "Epoch 207/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.1352 - accuracy: 0.8333 - val_loss: 5.4393 - val_accuracy: 0.6081\n",
      "Epoch 208/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.1198 - accuracy: 0.8342 - val_loss: 5.4271 - val_accuracy: 0.6084\n",
      "Epoch 209/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.1068 - accuracy: 0.8368 - val_loss: 5.4154 - val_accuracy: 0.6081\n",
      "Epoch 210/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.0925 - accuracy: 0.8367 - val_loss: 5.4037 - val_accuracy: 0.6088\n",
      "Epoch 211/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.0800 - accuracy: 0.8350 - val_loss: 5.3921 - val_accuracy: 0.6087\n",
      "Epoch 212/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.0669 - accuracy: 0.8397 - val_loss: 5.3801 - val_accuracy: 0.6095\n",
      "Epoch 213/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.0538 - accuracy: 0.8396 - val_loss: 5.3686 - val_accuracy: 0.6091\n",
      "Epoch 214/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.0391 - accuracy: 0.8386 - val_loss: 5.3567 - val_accuracy: 0.6093\n",
      "Epoch 215/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.0249 - accuracy: 0.8400 - val_loss: 5.3451 - val_accuracy: 0.6080\n",
      "Epoch 216/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.0118 - accuracy: 0.8399 - val_loss: 5.3334 - val_accuracy: 0.6081\n",
      "Epoch 217/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.9978 - accuracy: 0.8452 - val_loss: 5.3219 - val_accuracy: 0.6080\n",
      "Epoch 218/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.9850 - accuracy: 0.8443 - val_loss: 5.3103 - val_accuracy: 0.6069\n",
      "Epoch 219/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.9732 - accuracy: 0.8441 - val_loss: 5.2987 - val_accuracy: 0.6092\n",
      "Epoch 220/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.9576 - accuracy: 0.8446 - val_loss: 5.2871 - val_accuracy: 0.6096\n",
      "Epoch 221/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.9461 - accuracy: 0.8470 - val_loss: 5.2756 - val_accuracy: 0.6092\n",
      "Epoch 222/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.9323 - accuracy: 0.8437 - val_loss: 5.2642 - val_accuracy: 0.6093\n",
      "Epoch 223/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.9188 - accuracy: 0.8471 - val_loss: 5.2526 - val_accuracy: 0.6095\n",
      "Epoch 224/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.9050 - accuracy: 0.8469 - val_loss: 5.2413 - val_accuracy: 0.6097\n",
      "Epoch 225/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.8917 - accuracy: 0.8480 - val_loss: 5.2300 - val_accuracy: 0.6100\n",
      "Epoch 226/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.8789 - accuracy: 0.8485 - val_loss: 5.2183 - val_accuracy: 0.6105\n",
      "Epoch 227/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.8657 - accuracy: 0.8492 - val_loss: 5.2072 - val_accuracy: 0.6107\n",
      "Epoch 228/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.8511 - accuracy: 0.8528 - val_loss: 5.1959 - val_accuracy: 0.6111\n",
      "Epoch 229/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.8377 - accuracy: 0.8532 - val_loss: 5.1845 - val_accuracy: 0.6104\n",
      "Epoch 230/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.8244 - accuracy: 0.8564 - val_loss: 5.1733 - val_accuracy: 0.6105\n",
      "Epoch 231/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.8118 - accuracy: 0.8537 - val_loss: 5.1618 - val_accuracy: 0.6100\n",
      "Epoch 232/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.7990 - accuracy: 0.8555 - val_loss: 5.1508 - val_accuracy: 0.6099\n",
      "Epoch 233/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.7861 - accuracy: 0.8562 - val_loss: 5.1396 - val_accuracy: 0.6109\n",
      "Epoch 234/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.7728 - accuracy: 0.8583 - val_loss: 5.1282 - val_accuracy: 0.6100\n",
      "Epoch 235/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.7582 - accuracy: 0.8590 - val_loss: 5.1173 - val_accuracy: 0.6107\n",
      "Epoch 236/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.7443 - accuracy: 0.8585 - val_loss: 5.1060 - val_accuracy: 0.6105\n",
      "Epoch 237/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.7319 - accuracy: 0.8607 - val_loss: 5.0949 - val_accuracy: 0.6101\n",
      "Epoch 238/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.7207 - accuracy: 0.8601 - val_loss: 5.0838 - val_accuracy: 0.6108\n",
      "Epoch 239/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.7047 - accuracy: 0.8658 - val_loss: 5.0730 - val_accuracy: 0.6101\n",
      "Epoch 240/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.6916 - accuracy: 0.8648 - val_loss: 5.0619 - val_accuracy: 0.6100\n",
      "Epoch 241/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.6806 - accuracy: 0.8629 - val_loss: 5.0510 - val_accuracy: 0.6104\n",
      "Epoch 242/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.6658 - accuracy: 0.8673 - val_loss: 5.0397 - val_accuracy: 0.6093\n",
      "Epoch 243/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.6556 - accuracy: 0.8649 - val_loss: 5.0291 - val_accuracy: 0.6101\n",
      "Epoch 244/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.6424 - accuracy: 0.8661 - val_loss: 5.0178 - val_accuracy: 0.6097\n",
      "Epoch 245/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.6299 - accuracy: 0.8678 - val_loss: 5.0070 - val_accuracy: 0.6100\n",
      "Epoch 246/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.6174 - accuracy: 0.8690 - val_loss: 4.9961 - val_accuracy: 0.6092\n",
      "Epoch 247/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.6018 - accuracy: 0.8689 - val_loss: 4.9852 - val_accuracy: 0.6097\n",
      "Epoch 248/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.5915 - accuracy: 0.8707 - val_loss: 4.9747 - val_accuracy: 0.6096\n",
      "Epoch 249/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.5757 - accuracy: 0.8709 - val_loss: 4.9637 - val_accuracy: 0.6088\n",
      "Epoch 250/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.5629 - accuracy: 0.8723 - val_loss: 4.9530 - val_accuracy: 0.6084\n",
      "Epoch 251/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.5518 - accuracy: 0.8739 - val_loss: 4.9422 - val_accuracy: 0.6085\n",
      "Epoch 252/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.5381 - accuracy: 0.8740 - val_loss: 4.9317 - val_accuracy: 0.6081\n",
      "Epoch 253/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.5257 - accuracy: 0.8746 - val_loss: 4.9211 - val_accuracy: 0.6081\n",
      "Epoch 254/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.5124 - accuracy: 0.8749 - val_loss: 4.9104 - val_accuracy: 0.6085\n",
      "Epoch 255/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.4985 - accuracy: 0.8762 - val_loss: 4.8997 - val_accuracy: 0.6091\n",
      "Epoch 256/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.4867 - accuracy: 0.8763 - val_loss: 4.8892 - val_accuracy: 0.6092\n",
      "Epoch 257/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.4740 - accuracy: 0.8771 - val_loss: 4.8786 - val_accuracy: 0.6096\n",
      "Epoch 258/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.4598 - accuracy: 0.8789 - val_loss: 4.8679 - val_accuracy: 0.6084\n",
      "Epoch 259/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.4486 - accuracy: 0.8792 - val_loss: 4.8575 - val_accuracy: 0.6085\n",
      "Epoch 260/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.4355 - accuracy: 0.8804 - val_loss: 4.8468 - val_accuracy: 0.6097\n",
      "Epoch 261/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.4239 - accuracy: 0.8819 - val_loss: 4.8364 - val_accuracy: 0.6099\n",
      "Epoch 262/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.4114 - accuracy: 0.8826 - val_loss: 4.8258 - val_accuracy: 0.6099\n",
      "Epoch 263/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.3969 - accuracy: 0.8848 - val_loss: 4.8153 - val_accuracy: 0.6096\n",
      "Epoch 264/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.3845 - accuracy: 0.8853 - val_loss: 4.8047 - val_accuracy: 0.6097\n",
      "Epoch 265/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.3693 - accuracy: 0.8861 - val_loss: 4.7940 - val_accuracy: 0.6097\n",
      "Epoch 266/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.3597 - accuracy: 0.8868 - val_loss: 4.7838 - val_accuracy: 0.6097\n",
      "Epoch 267/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.3487 - accuracy: 0.8874 - val_loss: 4.7739 - val_accuracy: 0.6091\n",
      "Epoch 268/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.3344 - accuracy: 0.8899 - val_loss: 4.7633 - val_accuracy: 0.6091\n",
      "Epoch 269/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.3225 - accuracy: 0.8886 - val_loss: 4.7532 - val_accuracy: 0.6093\n",
      "Epoch 270/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.3095 - accuracy: 0.8895 - val_loss: 4.7430 - val_accuracy: 0.6095\n",
      "Epoch 271/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.2960 - accuracy: 0.8915 - val_loss: 4.7328 - val_accuracy: 0.6101\n",
      "Epoch 272/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.2845 - accuracy: 0.8923 - val_loss: 4.7222 - val_accuracy: 0.6099\n",
      "Epoch 273/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.2739 - accuracy: 0.8915 - val_loss: 4.7119 - val_accuracy: 0.6096\n",
      "Epoch 274/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.2601 - accuracy: 0.8927 - val_loss: 4.7020 - val_accuracy: 0.6097\n",
      "Epoch 275/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.2473 - accuracy: 0.8940 - val_loss: 4.6922 - val_accuracy: 0.6103\n",
      "Epoch 276/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.2343 - accuracy: 0.8960 - val_loss: 4.6819 - val_accuracy: 0.6104\n",
      "Epoch 277/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.2222 - accuracy: 0.8967 - val_loss: 4.6718 - val_accuracy: 0.6107\n",
      "Epoch 278/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.2122 - accuracy: 0.8970 - val_loss: 4.6617 - val_accuracy: 0.6099\n",
      "Epoch 279/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.1972 - accuracy: 0.8977 - val_loss: 4.6516 - val_accuracy: 0.6105\n",
      "Epoch 280/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.1862 - accuracy: 0.8980 - val_loss: 4.6415 - val_accuracy: 0.6109\n",
      "Epoch 281/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.1715 - accuracy: 0.8991 - val_loss: 4.6312 - val_accuracy: 0.6115\n",
      "Epoch 282/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.1604 - accuracy: 0.8981 - val_loss: 4.6214 - val_accuracy: 0.6100\n",
      "Epoch 283/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.1476 - accuracy: 0.9037 - val_loss: 4.6113 - val_accuracy: 0.6105\n",
      "Epoch 284/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.1357 - accuracy: 0.9028 - val_loss: 4.6013 - val_accuracy: 0.6096\n",
      "Epoch 285/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.1236 - accuracy: 0.9025 - val_loss: 4.5918 - val_accuracy: 0.6103\n",
      "Epoch 286/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.1134 - accuracy: 0.9025 - val_loss: 4.5820 - val_accuracy: 0.6099\n",
      "Epoch 287/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.1010 - accuracy: 0.9057 - val_loss: 4.5716 - val_accuracy: 0.6100\n",
      "Epoch 288/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.0890 - accuracy: 0.9070 - val_loss: 4.5621 - val_accuracy: 0.6099\n",
      "Epoch 289/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.0745 - accuracy: 0.9052 - val_loss: 4.5523 - val_accuracy: 0.6103\n",
      "Epoch 290/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.0644 - accuracy: 0.9060 - val_loss: 4.5423 - val_accuracy: 0.6095\n",
      "Epoch 291/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.0507 - accuracy: 0.9089 - val_loss: 4.5328 - val_accuracy: 0.6107\n",
      "Epoch 292/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.0363 - accuracy: 0.9105 - val_loss: 4.5231 - val_accuracy: 0.6100\n",
      "Epoch 293/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.0254 - accuracy: 0.9106 - val_loss: 4.5136 - val_accuracy: 0.6107\n",
      "Epoch 294/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.0135 - accuracy: 0.9130 - val_loss: 4.5039 - val_accuracy: 0.6112\n",
      "Epoch 295/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.0041 - accuracy: 0.9098 - val_loss: 4.4945 - val_accuracy: 0.6108\n",
      "Epoch 296/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.9908 - accuracy: 0.9119 - val_loss: 4.4849 - val_accuracy: 0.6107\n",
      "Epoch 297/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.9782 - accuracy: 0.9127 - val_loss: 4.4750 - val_accuracy: 0.6111\n",
      "Epoch 298/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.9654 - accuracy: 0.9149 - val_loss: 4.4655 - val_accuracy: 0.6104\n",
      "Epoch 299/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.9531 - accuracy: 0.9147 - val_loss: 4.4559 - val_accuracy: 0.6109\n",
      "Epoch 300/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.9420 - accuracy: 0.9150 - val_loss: 4.4461 - val_accuracy: 0.6103\n",
      "Epoch 301/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.9306 - accuracy: 0.9150 - val_loss: 4.4371 - val_accuracy: 0.6108\n",
      "Epoch 302/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.9177 - accuracy: 0.9171 - val_loss: 4.4277 - val_accuracy: 0.6099\n",
      "Epoch 303/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.9050 - accuracy: 0.9191 - val_loss: 4.4179 - val_accuracy: 0.6099\n",
      "Epoch 304/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.8947 - accuracy: 0.9191 - val_loss: 4.4090 - val_accuracy: 0.6099\n",
      "Epoch 305/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.8814 - accuracy: 0.9205 - val_loss: 4.3998 - val_accuracy: 0.6103\n",
      "Epoch 306/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.8704 - accuracy: 0.9216 - val_loss: 4.3906 - val_accuracy: 0.6103\n",
      "Epoch 307/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.8604 - accuracy: 0.9208 - val_loss: 4.3814 - val_accuracy: 0.6101\n",
      "Epoch 308/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.8461 - accuracy: 0.9214 - val_loss: 4.3716 - val_accuracy: 0.6119\n",
      "Epoch 309/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.8344 - accuracy: 0.9244 - val_loss: 4.3624 - val_accuracy: 0.6105\n",
      "Epoch 310/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.8223 - accuracy: 0.9241 - val_loss: 4.3534 - val_accuracy: 0.6105\n",
      "Epoch 311/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.8120 - accuracy: 0.9252 - val_loss: 4.3442 - val_accuracy: 0.6109\n",
      "Epoch 312/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.7991 - accuracy: 0.9277 - val_loss: 4.3352 - val_accuracy: 0.6112\n",
      "Epoch 313/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.7874 - accuracy: 0.9271 - val_loss: 4.3263 - val_accuracy: 0.6117\n",
      "Epoch 314/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.7763 - accuracy: 0.9267 - val_loss: 4.3169 - val_accuracy: 0.6124\n",
      "Epoch 315/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.7653 - accuracy: 0.9259 - val_loss: 4.3083 - val_accuracy: 0.6132\n",
      "Epoch 316/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.7521 - accuracy: 0.9286 - val_loss: 4.2990 - val_accuracy: 0.6119\n",
      "Epoch 317/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.7420 - accuracy: 0.9307 - val_loss: 4.2903 - val_accuracy: 0.6129\n",
      "Epoch 318/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.7290 - accuracy: 0.9296 - val_loss: 4.2813 - val_accuracy: 0.6127\n",
      "Epoch 319/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.7177 - accuracy: 0.9296 - val_loss: 4.2722 - val_accuracy: 0.6124\n",
      "Epoch 320/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.7068 - accuracy: 0.9312 - val_loss: 4.2631 - val_accuracy: 0.6125\n",
      "Epoch 321/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.6952 - accuracy: 0.9329 - val_loss: 4.2546 - val_accuracy: 0.6127\n",
      "Epoch 322/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.6813 - accuracy: 0.9350 - val_loss: 4.2455 - val_accuracy: 0.6129\n",
      "Epoch 323/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.6709 - accuracy: 0.9346 - val_loss: 4.2364 - val_accuracy: 0.6127\n",
      "Epoch 324/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.6597 - accuracy: 0.9348 - val_loss: 4.2276 - val_accuracy: 0.6127\n",
      "Epoch 325/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.6490 - accuracy: 0.9356 - val_loss: 4.2196 - val_accuracy: 0.6133\n",
      "Epoch 326/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.6370 - accuracy: 0.9357 - val_loss: 4.2109 - val_accuracy: 0.6121\n",
      "Epoch 327/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.6236 - accuracy: 0.9370 - val_loss: 4.2018 - val_accuracy: 0.6131\n",
      "Epoch 328/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.6138 - accuracy: 0.9373 - val_loss: 4.1936 - val_accuracy: 0.6123\n",
      "Epoch 329/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.6037 - accuracy: 0.9367 - val_loss: 4.1848 - val_accuracy: 0.6124\n",
      "Epoch 330/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.5921 - accuracy: 0.9368 - val_loss: 4.1763 - val_accuracy: 0.6140\n",
      "Epoch 331/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.5798 - accuracy: 0.9400 - val_loss: 4.1678 - val_accuracy: 0.6129\n",
      "Epoch 332/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.5694 - accuracy: 0.9388 - val_loss: 4.1591 - val_accuracy: 0.6124\n",
      "Epoch 333/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.5574 - accuracy: 0.9412 - val_loss: 4.1502 - val_accuracy: 0.6129\n",
      "Epoch 334/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.5447 - accuracy: 0.9433 - val_loss: 4.1415 - val_accuracy: 0.6125\n",
      "Epoch 335/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.5361 - accuracy: 0.9416 - val_loss: 4.1336 - val_accuracy: 0.6135\n",
      "Epoch 336/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.5230 - accuracy: 0.9428 - val_loss: 4.1250 - val_accuracy: 0.6135\n",
      "Epoch 337/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.5121 - accuracy: 0.9441 - val_loss: 4.1168 - val_accuracy: 0.6135\n",
      "Epoch 338/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.5010 - accuracy: 0.9434 - val_loss: 4.1086 - val_accuracy: 0.6136\n",
      "Epoch 339/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.4884 - accuracy: 0.9481 - val_loss: 4.0999 - val_accuracy: 0.6132\n",
      "Epoch 340/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.4768 - accuracy: 0.9471 - val_loss: 4.0916 - val_accuracy: 0.6141\n",
      "Epoch 341/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.4682 - accuracy: 0.9464 - val_loss: 4.0836 - val_accuracy: 0.6141\n",
      "Epoch 342/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.4567 - accuracy: 0.9475 - val_loss: 4.0748 - val_accuracy: 0.6140\n",
      "Epoch 343/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.4446 - accuracy: 0.9492 - val_loss: 4.0665 - val_accuracy: 0.6156\n",
      "Epoch 344/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.4330 - accuracy: 0.9498 - val_loss: 4.0583 - val_accuracy: 0.6155\n",
      "Epoch 345/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.4217 - accuracy: 0.9498 - val_loss: 4.0505 - val_accuracy: 0.6152\n",
      "Epoch 346/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.4122 - accuracy: 0.9490 - val_loss: 4.0423 - val_accuracy: 0.6161\n",
      "Epoch 347/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.4002 - accuracy: 0.9517 - val_loss: 4.0345 - val_accuracy: 0.6159\n",
      "Epoch 348/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.3903 - accuracy: 0.9504 - val_loss: 4.0265 - val_accuracy: 0.6159\n",
      "Epoch 349/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.3791 - accuracy: 0.9523 - val_loss: 4.0184 - val_accuracy: 0.6159\n",
      "Epoch 350/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.3670 - accuracy: 0.9541 - val_loss: 4.0105 - val_accuracy: 0.6160\n",
      "Epoch 351/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.3556 - accuracy: 0.9560 - val_loss: 4.0026 - val_accuracy: 0.6153\n",
      "Epoch 352/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.3454 - accuracy: 0.9544 - val_loss: 3.9948 - val_accuracy: 0.6156\n",
      "Epoch 353/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.3349 - accuracy: 0.9554 - val_loss: 3.9867 - val_accuracy: 0.6153\n",
      "Epoch 354/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.3240 - accuracy: 0.9569 - val_loss: 3.9785 - val_accuracy: 0.6153\n",
      "Epoch 355/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.3142 - accuracy: 0.9578 - val_loss: 3.9704 - val_accuracy: 0.6152\n",
      "Epoch 356/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.3008 - accuracy: 0.9578 - val_loss: 3.9622 - val_accuracy: 0.6165\n",
      "Epoch 357/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.2912 - accuracy: 0.9579 - val_loss: 3.9547 - val_accuracy: 0.6164\n",
      "Epoch 358/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.2807 - accuracy: 0.9599 - val_loss: 3.9470 - val_accuracy: 0.6160\n",
      "Epoch 359/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.2701 - accuracy: 0.9588 - val_loss: 3.9391 - val_accuracy: 0.6165\n",
      "Epoch 360/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.2598 - accuracy: 0.9576 - val_loss: 3.9308 - val_accuracy: 0.6160\n",
      "Epoch 361/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.2476 - accuracy: 0.9604 - val_loss: 3.9240 - val_accuracy: 0.6165\n",
      "Epoch 362/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.2376 - accuracy: 0.9604 - val_loss: 3.9173 - val_accuracy: 0.6152\n",
      "Epoch 363/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.2254 - accuracy: 0.9619 - val_loss: 3.9094 - val_accuracy: 0.6148\n",
      "Epoch 364/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.2148 - accuracy: 0.9635 - val_loss: 3.9013 - val_accuracy: 0.6159\n",
      "Epoch 365/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.2038 - accuracy: 0.9647 - val_loss: 3.8940 - val_accuracy: 0.6151\n",
      "Epoch 366/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.1946 - accuracy: 0.9629 - val_loss: 3.8858 - val_accuracy: 0.6152\n",
      "Epoch 367/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.1841 - accuracy: 0.9640 - val_loss: 3.8787 - val_accuracy: 0.6152\n",
      "Epoch 368/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.1722 - accuracy: 0.9653 - val_loss: 3.8708 - val_accuracy: 0.6151\n",
      "Epoch 369/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.1618 - accuracy: 0.9649 - val_loss: 3.8637 - val_accuracy: 0.6152\n",
      "Epoch 370/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.1519 - accuracy: 0.9661 - val_loss: 3.8561 - val_accuracy: 0.6136\n",
      "Epoch 371/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.1405 - accuracy: 0.9661 - val_loss: 3.8490 - val_accuracy: 0.6140\n",
      "Epoch 372/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.1307 - accuracy: 0.9671 - val_loss: 3.8420 - val_accuracy: 0.6137\n",
      "Epoch 373/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.1188 - accuracy: 0.9688 - val_loss: 3.8342 - val_accuracy: 0.6136\n",
      "Epoch 374/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.1095 - accuracy: 0.9692 - val_loss: 3.8274 - val_accuracy: 0.6136\n",
      "Epoch 375/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.0978 - accuracy: 0.9714 - val_loss: 3.8200 - val_accuracy: 0.6135\n",
      "Epoch 376/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.0911 - accuracy: 0.9691 - val_loss: 3.8133 - val_accuracy: 0.6149\n",
      "Epoch 377/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.0794 - accuracy: 0.9685 - val_loss: 3.8052 - val_accuracy: 0.6139\n",
      "Epoch 378/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.0665 - accuracy: 0.9722 - val_loss: 3.7985 - val_accuracy: 0.6144\n",
      "Epoch 379/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.0594 - accuracy: 0.9689 - val_loss: 3.7911 - val_accuracy: 0.6129\n",
      "Epoch 380/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.0471 - accuracy: 0.9723 - val_loss: 3.7841 - val_accuracy: 0.6140\n",
      "Epoch 381/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.0370 - accuracy: 0.9717 - val_loss: 3.7770 - val_accuracy: 0.6131\n",
      "Epoch 382/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.0254 - accuracy: 0.9731 - val_loss: 3.7692 - val_accuracy: 0.6129\n",
      "Epoch 383/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.0156 - accuracy: 0.9743 - val_loss: 3.7634 - val_accuracy: 0.6145\n",
      "Epoch 384/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.0065 - accuracy: 0.9738 - val_loss: 3.7563 - val_accuracy: 0.6140\n",
      "Epoch 385/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.9973 - accuracy: 0.9744 - val_loss: 3.7491 - val_accuracy: 0.6143\n",
      "Epoch 386/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.9861 - accuracy: 0.9748 - val_loss: 3.7426 - val_accuracy: 0.6151\n",
      "Epoch 387/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.9759 - accuracy: 0.9752 - val_loss: 3.7350 - val_accuracy: 0.6144\n",
      "Epoch 388/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.9651 - accuracy: 0.9757 - val_loss: 3.7282 - val_accuracy: 0.6139\n",
      "Epoch 389/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.9552 - accuracy: 0.9771 - val_loss: 3.7222 - val_accuracy: 0.6155\n",
      "Epoch 390/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.9448 - accuracy: 0.9766 - val_loss: 3.7161 - val_accuracy: 0.6155\n",
      "Epoch 391/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.9350 - accuracy: 0.9775 - val_loss: 3.7088 - val_accuracy: 0.6143\n",
      "Epoch 392/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.9272 - accuracy: 0.9764 - val_loss: 3.7018 - val_accuracy: 0.6147\n",
      "Epoch 393/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.9168 - accuracy: 0.9771 - val_loss: 3.6957 - val_accuracy: 0.6139\n",
      "Epoch 394/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.9043 - accuracy: 0.9788 - val_loss: 3.6893 - val_accuracy: 0.6139\n",
      "Epoch 395/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.8944 - accuracy: 0.9799 - val_loss: 3.6821 - val_accuracy: 0.6133\n",
      "Epoch 396/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.8852 - accuracy: 0.9802 - val_loss: 3.6753 - val_accuracy: 0.6151\n",
      "Epoch 397/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.8743 - accuracy: 0.9803 - val_loss: 3.6688 - val_accuracy: 0.6141\n",
      "Epoch 398/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.8653 - accuracy: 0.9806 - val_loss: 3.6628 - val_accuracy: 0.6143\n",
      "Epoch 399/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.8554 - accuracy: 0.9810 - val_loss: 3.6554 - val_accuracy: 0.6149\n",
      "Epoch 400/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.8451 - accuracy: 0.9814 - val_loss: 3.6487 - val_accuracy: 0.6136\n",
      "Epoch 401/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.8356 - accuracy: 0.9813 - val_loss: 3.6425 - val_accuracy: 0.6141\n",
      "Epoch 402/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.8257 - accuracy: 0.9826 - val_loss: 3.6365 - val_accuracy: 0.6151\n",
      "Epoch 403/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.8166 - accuracy: 0.9827 - val_loss: 3.6289 - val_accuracy: 0.6127\n",
      "Epoch 404/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.8074 - accuracy: 0.9829 - val_loss: 3.6228 - val_accuracy: 0.6140\n",
      "Epoch 405/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.7989 - accuracy: 0.9816 - val_loss: 3.6168 - val_accuracy: 0.6136\n",
      "Epoch 406/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.7873 - accuracy: 0.9829 - val_loss: 3.6104 - val_accuracy: 0.6123\n",
      "Epoch 407/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.7769 - accuracy: 0.9841 - val_loss: 3.6035 - val_accuracy: 0.6109\n",
      "Epoch 408/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.7676 - accuracy: 0.9851 - val_loss: 3.5972 - val_accuracy: 0.6132\n",
      "Epoch 409/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.7577 - accuracy: 0.9860 - val_loss: 3.5915 - val_accuracy: 0.6113\n",
      "Epoch 410/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.7507 - accuracy: 0.9837 - val_loss: 3.5858 - val_accuracy: 0.6117\n",
      "Epoch 411/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.7384 - accuracy: 0.9854 - val_loss: 3.5795 - val_accuracy: 0.6121\n",
      "Epoch 412/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.7293 - accuracy: 0.9863 - val_loss: 3.5727 - val_accuracy: 0.6105\n",
      "Epoch 413/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.7205 - accuracy: 0.9860 - val_loss: 3.5670 - val_accuracy: 0.6125\n",
      "Epoch 414/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.7102 - accuracy: 0.9861 - val_loss: 3.5612 - val_accuracy: 0.6117\n",
      "Epoch 415/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.7041 - accuracy: 0.9851 - val_loss: 3.5556 - val_accuracy: 0.6121\n",
      "Epoch 416/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.6916 - accuracy: 0.9871 - val_loss: 3.5487 - val_accuracy: 0.6128\n",
      "Epoch 417/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.6803 - accuracy: 0.9885 - val_loss: 3.5422 - val_accuracy: 0.6119\n",
      "Epoch 418/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.6731 - accuracy: 0.9876 - val_loss: 3.5364 - val_accuracy: 0.6119\n",
      "Epoch 419/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.6645 - accuracy: 0.9874 - val_loss: 3.5306 - val_accuracy: 0.6097\n",
      "Epoch 420/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.6548 - accuracy: 0.9889 - val_loss: 3.5243 - val_accuracy: 0.6100\n",
      "Epoch 421/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.6441 - accuracy: 0.9892 - val_loss: 3.5183 - val_accuracy: 0.6104\n",
      "Epoch 422/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.6365 - accuracy: 0.9885 - val_loss: 3.5127 - val_accuracy: 0.6096\n",
      "Epoch 423/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.6248 - accuracy: 0.9901 - val_loss: 3.5067 - val_accuracy: 0.6105\n",
      "Epoch 424/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.6179 - accuracy: 0.9895 - val_loss: 3.4999 - val_accuracy: 0.6100\n",
      "Epoch 425/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.6083 - accuracy: 0.9893 - val_loss: 3.4948 - val_accuracy: 0.6108\n",
      "Epoch 426/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.6001 - accuracy: 0.9893 - val_loss: 3.4894 - val_accuracy: 0.6107\n",
      "Epoch 427/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.5893 - accuracy: 0.9911 - val_loss: 3.4839 - val_accuracy: 0.6103\n",
      "Epoch 428/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.5802 - accuracy: 0.9906 - val_loss: 3.4774 - val_accuracy: 0.6115\n",
      "Epoch 429/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.5703 - accuracy: 0.9914 - val_loss: 3.4730 - val_accuracy: 0.6120\n",
      "Epoch 430/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.5624 - accuracy: 0.9906 - val_loss: 3.4661 - val_accuracy: 0.6109\n",
      "Epoch 431/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.5522 - accuracy: 0.9921 - val_loss: 3.4604 - val_accuracy: 0.6119\n",
      "Epoch 432/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.5429 - accuracy: 0.9915 - val_loss: 3.4541 - val_accuracy: 0.6113\n",
      "Epoch 433/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.5359 - accuracy: 0.9915 - val_loss: 3.4496 - val_accuracy: 0.6117\n",
      "Epoch 434/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.5272 - accuracy: 0.9915 - val_loss: 3.4438 - val_accuracy: 0.6115\n",
      "Epoch 435/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.5173 - accuracy: 0.9922 - val_loss: 3.4385 - val_accuracy: 0.6116\n",
      "Epoch 436/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.5082 - accuracy: 0.9929 - val_loss: 3.4332 - val_accuracy: 0.6103\n",
      "Epoch 437/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.5001 - accuracy: 0.9923 - val_loss: 3.4270 - val_accuracy: 0.6111\n",
      "Epoch 438/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.4921 - accuracy: 0.9914 - val_loss: 3.4222 - val_accuracy: 0.6096\n",
      "Epoch 439/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.4812 - accuracy: 0.9935 - val_loss: 3.4170 - val_accuracy: 0.6088\n",
      "Epoch 440/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.4723 - accuracy: 0.9934 - val_loss: 3.4108 - val_accuracy: 0.6095\n",
      "Epoch 441/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.4633 - accuracy: 0.9930 - val_loss: 3.4063 - val_accuracy: 0.6095\n",
      "Epoch 442/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.4554 - accuracy: 0.9937 - val_loss: 3.4008 - val_accuracy: 0.6095\n",
      "Epoch 443/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.4459 - accuracy: 0.9937 - val_loss: 3.3959 - val_accuracy: 0.6076\n",
      "Epoch 444/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.4370 - accuracy: 0.9943 - val_loss: 3.3892 - val_accuracy: 0.6095\n",
      "Epoch 445/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.4298 - accuracy: 0.9935 - val_loss: 3.3841 - val_accuracy: 0.6093\n",
      "Epoch 446/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.4197 - accuracy: 0.9950 - val_loss: 3.3787 - val_accuracy: 0.6084\n",
      "Epoch 447/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.4110 - accuracy: 0.9945 - val_loss: 3.3739 - val_accuracy: 0.6071\n",
      "Epoch 448/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.4031 - accuracy: 0.9950 - val_loss: 3.3687 - val_accuracy: 0.6080\n",
      "Epoch 449/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.3954 - accuracy: 0.9937 - val_loss: 3.3636 - val_accuracy: 0.6072\n",
      "Epoch 450/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.3860 - accuracy: 0.9948 - val_loss: 3.3583 - val_accuracy: 0.6069\n",
      "Epoch 451/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.3774 - accuracy: 0.9947 - val_loss: 3.3540 - val_accuracy: 0.6068\n",
      "Epoch 452/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.3685 - accuracy: 0.9945 - val_loss: 3.3479 - val_accuracy: 0.6061\n",
      "Epoch 453/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.3606 - accuracy: 0.9953 - val_loss: 3.3426 - val_accuracy: 0.6065\n",
      "Epoch 454/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.3518 - accuracy: 0.9956 - val_loss: 3.3374 - val_accuracy: 0.6060\n",
      "Epoch 455/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.3434 - accuracy: 0.9956 - val_loss: 3.3319 - val_accuracy: 0.6065\n",
      "Epoch 456/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.3340 - accuracy: 0.9957 - val_loss: 3.3266 - val_accuracy: 0.6053\n",
      "Epoch 457/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.3263 - accuracy: 0.9959 - val_loss: 3.3215 - val_accuracy: 0.6059\n",
      "Epoch 458/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.3183 - accuracy: 0.9961 - val_loss: 3.3162 - val_accuracy: 0.6061\n",
      "Epoch 459/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.3087 - accuracy: 0.9960 - val_loss: 3.3102 - val_accuracy: 0.6052\n",
      "Epoch 460/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.3007 - accuracy: 0.9960 - val_loss: 3.3061 - val_accuracy: 0.6064\n",
      "Epoch 461/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.2925 - accuracy: 0.9969 - val_loss: 3.3018 - val_accuracy: 0.6059\n",
      "Epoch 462/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.2829 - accuracy: 0.9960 - val_loss: 3.2962 - val_accuracy: 0.6060\n",
      "Epoch 463/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.2759 - accuracy: 0.9961 - val_loss: 3.2906 - val_accuracy: 0.6048\n",
      "Epoch 464/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.2672 - accuracy: 0.9965 - val_loss: 3.2855 - val_accuracy: 0.6056\n",
      "Epoch 465/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.2597 - accuracy: 0.9965 - val_loss: 3.2811 - val_accuracy: 0.6055\n",
      "Epoch 466/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.2527 - accuracy: 0.9962 - val_loss: 3.2752 - val_accuracy: 0.6049\n",
      "Epoch 467/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.2451 - accuracy: 0.9965 - val_loss: 3.2710 - val_accuracy: 0.6057\n",
      "Epoch 468/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.2356 - accuracy: 0.9968 - val_loss: 3.2662 - val_accuracy: 0.6061\n",
      "Epoch 469/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.2276 - accuracy: 0.9972 - val_loss: 3.2601 - val_accuracy: 0.6068\n",
      "Epoch 470/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.2185 - accuracy: 0.9970 - val_loss: 3.2560 - val_accuracy: 0.6064\n",
      "Epoch 471/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.2098 - accuracy: 0.9975 - val_loss: 3.2511 - val_accuracy: 0.6056\n",
      "Epoch 472/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.2035 - accuracy: 0.9973 - val_loss: 3.2474 - val_accuracy: 0.6068\n",
      "Epoch 473/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.1945 - accuracy: 0.9973 - val_loss: 3.2429 - val_accuracy: 0.6061\n",
      "Epoch 474/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.1859 - accuracy: 0.9977 - val_loss: 3.2383 - val_accuracy: 0.6059\n",
      "Epoch 475/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.1800 - accuracy: 0.9968 - val_loss: 3.2333 - val_accuracy: 0.6051\n",
      "Epoch 476/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.1728 - accuracy: 0.9969 - val_loss: 3.2286 - val_accuracy: 0.6049\n",
      "Epoch 477/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.1631 - accuracy: 0.9981 - val_loss: 3.2241 - val_accuracy: 0.6040\n",
      "Epoch 478/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.1542 - accuracy: 0.9979 - val_loss: 3.2176 - val_accuracy: 0.6040\n",
      "Epoch 479/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.1471 - accuracy: 0.9976 - val_loss: 3.2138 - val_accuracy: 0.6055\n",
      "Epoch 480/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.1380 - accuracy: 0.9982 - val_loss: 3.2087 - val_accuracy: 0.6040\n",
      "Epoch 481/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.1301 - accuracy: 0.9977 - val_loss: 3.2030 - val_accuracy: 0.6047\n",
      "Epoch 482/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.1244 - accuracy: 0.9974 - val_loss: 3.1983 - val_accuracy: 0.6044\n",
      "Epoch 483/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.1146 - accuracy: 0.9983 - val_loss: 3.1948 - val_accuracy: 0.6055\n",
      "Epoch 484/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.1072 - accuracy: 0.9982 - val_loss: 3.1891 - val_accuracy: 0.6043\n",
      "Epoch 485/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.1009 - accuracy: 0.9981 - val_loss: 3.1857 - val_accuracy: 0.6032\n",
      "Epoch 486/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.0917 - accuracy: 0.9982 - val_loss: 3.1810 - val_accuracy: 0.6044\n",
      "Epoch 487/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.0838 - accuracy: 0.9983 - val_loss: 3.1781 - val_accuracy: 0.6041\n",
      "Epoch 488/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.0786 - accuracy: 0.9976 - val_loss: 3.1729 - val_accuracy: 0.6037\n",
      "Epoch 489/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.0705 - accuracy: 0.9984 - val_loss: 3.1670 - val_accuracy: 0.6028\n",
      "Epoch 490/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.0618 - accuracy: 0.9986 - val_loss: 3.1632 - val_accuracy: 0.6035\n",
      "Epoch 491/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.0533 - accuracy: 0.9987 - val_loss: 3.1574 - val_accuracy: 0.6033\n",
      "Epoch 492/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.0476 - accuracy: 0.9974 - val_loss: 3.1546 - val_accuracy: 0.6041\n",
      "Epoch 493/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.0408 - accuracy: 0.9979 - val_loss: 3.1512 - val_accuracy: 0.6039\n",
      "Epoch 494/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.0326 - accuracy: 0.9986 - val_loss: 3.1468 - val_accuracy: 0.6020\n",
      "Epoch 495/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.0233 - accuracy: 0.9989 - val_loss: 3.1411 - val_accuracy: 0.6045\n",
      "Epoch 496/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.0168 - accuracy: 0.9986 - val_loss: 3.1376 - val_accuracy: 0.6036\n",
      "Epoch 497/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.0098 - accuracy: 0.9986 - val_loss: 3.1323 - val_accuracy: 0.6053\n",
      "Epoch 498/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.0035 - accuracy: 0.9979 - val_loss: 3.1298 - val_accuracy: 0.6049\n",
      "Epoch 499/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 1.9950 - accuracy: 0.9990 - val_loss: 3.1231 - val_accuracy: 0.6044\n",
      "Epoch 500/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 1.9868 - accuracy: 0.9988 - val_loss: 3.1183 - val_accuracy: 0.6037\n",
      "Time: 147.9459719657898\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Traits_Model_10BM.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#10 BM\n",
    "################################################################################################################################################\n",
    "# subset the traits\n",
    "traits_BM10=traits_BM[:,0:10,:]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test  = train_test_split(y,X20,traits_BM10,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = BM_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Traits_Model_10BM.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bgPi-7r52xv",
    "outputId": "f4a9b09a-fd6c-4dea-fc89-52562b8ed27c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 20, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 18, 250)      45000       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 18, 250)     1000        ['conv1d_6[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 16, 250)      187500      ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 16, 250)     1000        ['conv1d_7[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 14, 250)      187500      ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 14, 250)     1000        ['conv1d_8[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 4, 250)      0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 1000)         0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dense_19_input (InputLayer)    [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 125)          125125      ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 150)          150000      ['dense_19_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 125)          0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 150)         600         ['dense_19[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 125)          15750       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 150)          22500       ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 125)          0           ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 150)         600         ['dense_20[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 50)           6300        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 50)           7550        ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 50)           0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_2 (LinearW)           (None, 50)           2           ['dense_21[0][0]',               \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 50)           2550        ['linear_w_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 3)            153         ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 754,130\n",
      "Trainable params: 752,030\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 2s 11ms/step - loss: 8.8790 - accuracy: 0.3310 - val_loss: 8.7489 - val_accuracy: 0.3655\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.7768 - accuracy: 0.3735 - val_loss: 8.6942 - val_accuracy: 0.4181\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.7059 - accuracy: 0.4104 - val_loss: 8.6270 - val_accuracy: 0.4881\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.6505 - accuracy: 0.4370 - val_loss: 8.5638 - val_accuracy: 0.5380\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.6054 - accuracy: 0.4649 - val_loss: 8.5103 - val_accuracy: 0.5713\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.5651 - accuracy: 0.4852 - val_loss: 8.4663 - val_accuracy: 0.5953\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.5229 - accuracy: 0.5072 - val_loss: 8.4276 - val_accuracy: 0.6133\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.4861 - accuracy: 0.5234 - val_loss: 8.3926 - val_accuracy: 0.6233\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.4535 - accuracy: 0.5370 - val_loss: 8.3597 - val_accuracy: 0.6304\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.4137 - accuracy: 0.5565 - val_loss: 8.3292 - val_accuracy: 0.6404\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.3838 - accuracy: 0.5667 - val_loss: 8.2984 - val_accuracy: 0.6469\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.3582 - accuracy: 0.5701 - val_loss: 8.2701 - val_accuracy: 0.6517\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.3235 - accuracy: 0.5896 - val_loss: 8.2419 - val_accuracy: 0.6539\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.2974 - accuracy: 0.5933 - val_loss: 8.2147 - val_accuracy: 0.6584\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.2671 - accuracy: 0.6034 - val_loss: 8.1879 - val_accuracy: 0.6624\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.2432 - accuracy: 0.6051 - val_loss: 8.1615 - val_accuracy: 0.6677\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.2128 - accuracy: 0.6180 - val_loss: 8.1360 - val_accuracy: 0.6713\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.1883 - accuracy: 0.6178 - val_loss: 8.1105 - val_accuracy: 0.6756\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.1683 - accuracy: 0.6230 - val_loss: 8.0859 - val_accuracy: 0.6760\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.1356 - accuracy: 0.6351 - val_loss: 8.0609 - val_accuracy: 0.6781\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.1111 - accuracy: 0.6387 - val_loss: 8.0361 - val_accuracy: 0.6825\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.0844 - accuracy: 0.6428 - val_loss: 8.0120 - val_accuracy: 0.6848\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.0551 - accuracy: 0.6508 - val_loss: 7.9877 - val_accuracy: 0.6869\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.0332 - accuracy: 0.6565 - val_loss: 7.9640 - val_accuracy: 0.6893\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.0144 - accuracy: 0.6600 - val_loss: 7.9394 - val_accuracy: 0.6935\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.9888 - accuracy: 0.6608 - val_loss: 7.9160 - val_accuracy: 0.6955\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.9661 - accuracy: 0.6653 - val_loss: 7.8918 - val_accuracy: 0.7007\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.9377 - accuracy: 0.6714 - val_loss: 7.8685 - val_accuracy: 0.7033\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.9137 - accuracy: 0.6743 - val_loss: 7.8446 - val_accuracy: 0.7055\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.8898 - accuracy: 0.6819 - val_loss: 7.8207 - val_accuracy: 0.7095\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.8618 - accuracy: 0.6853 - val_loss: 7.7963 - val_accuracy: 0.7143\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.8374 - accuracy: 0.6938 - val_loss: 7.7721 - val_accuracy: 0.7181\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.8097 - accuracy: 0.6974 - val_loss: 7.7474 - val_accuracy: 0.7232\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.7897 - accuracy: 0.7009 - val_loss: 7.7236 - val_accuracy: 0.7265\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.7662 - accuracy: 0.7048 - val_loss: 7.6991 - val_accuracy: 0.7320\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.7438 - accuracy: 0.7091 - val_loss: 7.6746 - val_accuracy: 0.7367\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.7194 - accuracy: 0.7112 - val_loss: 7.6507 - val_accuracy: 0.7401\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.6889 - accuracy: 0.7184 - val_loss: 7.6268 - val_accuracy: 0.7436\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.6706 - accuracy: 0.7202 - val_loss: 7.6019 - val_accuracy: 0.7473\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.6487 - accuracy: 0.7227 - val_loss: 7.5779 - val_accuracy: 0.7525\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.6214 - accuracy: 0.7284 - val_loss: 7.5540 - val_accuracy: 0.7563\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.5952 - accuracy: 0.7366 - val_loss: 7.5289 - val_accuracy: 0.7631\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.5729 - accuracy: 0.7356 - val_loss: 7.5052 - val_accuracy: 0.7663\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.5453 - accuracy: 0.7439 - val_loss: 7.4800 - val_accuracy: 0.7703\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.5228 - accuracy: 0.7445 - val_loss: 7.4567 - val_accuracy: 0.7737\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.5008 - accuracy: 0.7530 - val_loss: 7.4323 - val_accuracy: 0.7784\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.4706 - accuracy: 0.7623 - val_loss: 7.4087 - val_accuracy: 0.7825\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.4499 - accuracy: 0.7623 - val_loss: 7.3841 - val_accuracy: 0.7888\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.4284 - accuracy: 0.7633 - val_loss: 7.3604 - val_accuracy: 0.7941\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.4076 - accuracy: 0.7666 - val_loss: 7.3361 - val_accuracy: 0.7972\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.3779 - accuracy: 0.7742 - val_loss: 7.3127 - val_accuracy: 0.8020\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.3607 - accuracy: 0.7767 - val_loss: 7.2900 - val_accuracy: 0.8053\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.3347 - accuracy: 0.7788 - val_loss: 7.2674 - val_accuracy: 0.8091\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.3123 - accuracy: 0.7812 - val_loss: 7.2432 - val_accuracy: 0.8161\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.2911 - accuracy: 0.7863 - val_loss: 7.2219 - val_accuracy: 0.8183\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.2661 - accuracy: 0.7932 - val_loss: 7.1994 - val_accuracy: 0.8212\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.2427 - accuracy: 0.7976 - val_loss: 7.1781 - val_accuracy: 0.8233\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.2222 - accuracy: 0.7994 - val_loss: 7.1549 - val_accuracy: 0.8265\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.1972 - accuracy: 0.8035 - val_loss: 7.1330 - val_accuracy: 0.8296\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.1780 - accuracy: 0.8049 - val_loss: 7.1125 - val_accuracy: 0.8345\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.1593 - accuracy: 0.8076 - val_loss: 7.0908 - val_accuracy: 0.8391\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.1310 - accuracy: 0.8140 - val_loss: 7.0696 - val_accuracy: 0.8431\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.1116 - accuracy: 0.8195 - val_loss: 7.0478 - val_accuracy: 0.8469\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.0963 - accuracy: 0.8164 - val_loss: 7.0273 - val_accuracy: 0.8501\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.0755 - accuracy: 0.8200 - val_loss: 7.0073 - val_accuracy: 0.8533\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.0475 - accuracy: 0.8276 - val_loss: 6.9859 - val_accuracy: 0.8559\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.0322 - accuracy: 0.8280 - val_loss: 6.9662 - val_accuracy: 0.8593\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.0072 - accuracy: 0.8312 - val_loss: 6.9451 - val_accuracy: 0.8611\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.9928 - accuracy: 0.8320 - val_loss: 6.9254 - val_accuracy: 0.8627\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.9671 - accuracy: 0.8379 - val_loss: 6.9050 - val_accuracy: 0.8652\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.9450 - accuracy: 0.8427 - val_loss: 6.8857 - val_accuracy: 0.8661\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.9220 - accuracy: 0.8435 - val_loss: 6.8658 - val_accuracy: 0.8695\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.9057 - accuracy: 0.8478 - val_loss: 6.8468 - val_accuracy: 0.8712\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.8863 - accuracy: 0.8485 - val_loss: 6.8268 - val_accuracy: 0.8747\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.8655 - accuracy: 0.8510 - val_loss: 6.8095 - val_accuracy: 0.8765\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.8499 - accuracy: 0.8488 - val_loss: 6.7889 - val_accuracy: 0.8800\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.8273 - accuracy: 0.8555 - val_loss: 6.7705 - val_accuracy: 0.8809\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.8071 - accuracy: 0.8575 - val_loss: 6.7524 - val_accuracy: 0.8829\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.7889 - accuracy: 0.8590 - val_loss: 6.7332 - val_accuracy: 0.8851\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.7680 - accuracy: 0.8632 - val_loss: 6.7129 - val_accuracy: 0.8872\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.7483 - accuracy: 0.8644 - val_loss: 6.6934 - val_accuracy: 0.8889\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.7310 - accuracy: 0.8679 - val_loss: 6.6768 - val_accuracy: 0.8912\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.7096 - accuracy: 0.8719 - val_loss: 6.6585 - val_accuracy: 0.8927\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.6959 - accuracy: 0.8701 - val_loss: 6.6396 - val_accuracy: 0.8945\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.6749 - accuracy: 0.8720 - val_loss: 6.6226 - val_accuracy: 0.8956\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.6571 - accuracy: 0.8748 - val_loss: 6.6049 - val_accuracy: 0.8972\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.6380 - accuracy: 0.8774 - val_loss: 6.5887 - val_accuracy: 0.8979\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.6236 - accuracy: 0.8765 - val_loss: 6.5703 - val_accuracy: 0.8991\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.6018 - accuracy: 0.8781 - val_loss: 6.5526 - val_accuracy: 0.9016\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.5861 - accuracy: 0.8812 - val_loss: 6.5346 - val_accuracy: 0.9021\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.5670 - accuracy: 0.8823 - val_loss: 6.5175 - val_accuracy: 0.9031\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.5469 - accuracy: 0.8839 - val_loss: 6.4994 - val_accuracy: 0.9032\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.5273 - accuracy: 0.8868 - val_loss: 6.4857 - val_accuracy: 0.9027\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.5116 - accuracy: 0.8862 - val_loss: 6.4689 - val_accuracy: 0.9039\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4928 - accuracy: 0.8905 - val_loss: 6.4516 - val_accuracy: 0.9049\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4754 - accuracy: 0.8883 - val_loss: 6.4354 - val_accuracy: 0.9045\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4645 - accuracy: 0.8903 - val_loss: 6.4177 - val_accuracy: 0.9057\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4404 - accuracy: 0.8940 - val_loss: 6.3996 - val_accuracy: 0.9079\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4217 - accuracy: 0.8971 - val_loss: 6.3858 - val_accuracy: 0.9061\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4076 - accuracy: 0.8948 - val_loss: 6.3682 - val_accuracy: 0.9084\n",
      "Time: 65.21813917160034\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_10BM_20SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#20SNPS, 10 BM\n",
    "################################################################################################################################################xtrain, xtest = X[int(len(y)*.25):], X[:int(len(y)*.25)]\n",
    "# now do the combined the analysis\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test  = train_test_split(y,X20,traits_BM10,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_BM_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_10BM_20SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vaUOW_lb4205",
    "outputId": "7e6d4bf0-a71c-44bf-c7b0-dda8e33ccbea",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 1000, 60)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 998, 250)     45000       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 998, 250)    1000        ['conv1d_9[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 996, 250)     187500      ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 996, 250)    1000        ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 994, 250)     187500      ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 994, 250)    1000        ['conv1d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 331, 250)    0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 82750)        0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " dense_27_input (InputLayer)    [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 125)          10343875    ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 150)          150000      ['dense_27_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 125)          0           ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 150)         600         ['dense_27[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 125)          15750       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 150)          22500       ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 125)          0           ['dense_31[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 150)         600         ['dense_28[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 50)           6300        ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 50)           7550        ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 50)           0           ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_3 (LinearW)           (None, 50)           2           ['dense_29[0][0]',               \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 50)           2550        ['linear_w_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 3)            153         ['dense_33[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,972,880\n",
      "Trainable params: 10,970,780\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 13s 126ms/step - loss: 8.6862 - accuracy: 0.4706 - val_loss: 8.6579 - val_accuracy: 0.5584\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 8.4883 - accuracy: 0.5966 - val_loss: 8.4869 - val_accuracy: 0.6720\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.3599 - accuracy: 0.6584 - val_loss: 8.2989 - val_accuracy: 0.7500\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.2534 - accuracy: 0.7115 - val_loss: 8.1283 - val_accuracy: 0.8216\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.1551 - accuracy: 0.7589 - val_loss: 7.9819 - val_accuracy: 0.8908\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.0559 - accuracy: 0.8026 - val_loss: 7.8565 - val_accuracy: 0.9208\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.9698 - accuracy: 0.8384 - val_loss: 7.7683 - val_accuracy: 0.9453\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.8854 - accuracy: 0.8718 - val_loss: 7.6976 - val_accuracy: 0.9600\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.8149 - accuracy: 0.8979 - val_loss: 7.6391 - val_accuracy: 0.9707\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.7546 - accuracy: 0.9158 - val_loss: 7.5935 - val_accuracy: 0.9804\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.7001 - accuracy: 0.9311 - val_loss: 7.5535 - val_accuracy: 0.9844\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.6556 - accuracy: 0.9446 - val_loss: 7.5233 - val_accuracy: 0.9871\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.6162 - accuracy: 0.9522 - val_loss: 7.4953 - val_accuracy: 0.9895\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.5813 - accuracy: 0.9586 - val_loss: 7.4702 - val_accuracy: 0.9912\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.5488 - accuracy: 0.9625 - val_loss: 7.4520 - val_accuracy: 0.9907\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 7.5209 - accuracy: 0.9666 - val_loss: 7.4267 - val_accuracy: 0.9945\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.4936 - accuracy: 0.9699 - val_loss: 7.4109 - val_accuracy: 0.9932\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.4713 - accuracy: 0.9725 - val_loss: 7.3915 - val_accuracy: 0.9948\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.4461 - accuracy: 0.9755 - val_loss: 7.3736 - val_accuracy: 0.9947\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 7.4255 - accuracy: 0.9781 - val_loss: 7.3551 - val_accuracy: 0.9955\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.4054 - accuracy: 0.9785 - val_loss: 7.3376 - val_accuracy: 0.9963\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.3836 - accuracy: 0.9792 - val_loss: 7.3202 - val_accuracy: 0.9971\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.3607 - accuracy: 0.9816 - val_loss: 7.3038 - val_accuracy: 0.9969\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.3429 - accuracy: 0.9825 - val_loss: 7.2870 - val_accuracy: 0.9976\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.3241 - accuracy: 0.9841 - val_loss: 7.2718 - val_accuracy: 0.9969\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 7.3057 - accuracy: 0.9853 - val_loss: 7.2535 - val_accuracy: 0.9983\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.2878 - accuracy: 0.9848 - val_loss: 7.2381 - val_accuracy: 0.9980\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 7.2687 - accuracy: 0.9867 - val_loss: 7.2229 - val_accuracy: 0.9976\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 7.2477 - accuracy: 0.9887 - val_loss: 7.2050 - val_accuracy: 0.9985\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 7.2308 - accuracy: 0.9885 - val_loss: 7.1886 - val_accuracy: 0.9985\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 7.2139 - accuracy: 0.9893 - val_loss: 7.1738 - val_accuracy: 0.9981\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 7.1963 - accuracy: 0.9904 - val_loss: 7.1585 - val_accuracy: 0.9981\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 7.1808 - accuracy: 0.9896 - val_loss: 7.1409 - val_accuracy: 0.9987\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 7.1620 - accuracy: 0.9904 - val_loss: 7.1258 - val_accuracy: 0.9987\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 7.1470 - accuracy: 0.9914 - val_loss: 7.1106 - val_accuracy: 0.9987\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 7.1281 - accuracy: 0.9916 - val_loss: 7.0951 - val_accuracy: 0.9984\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 7.1119 - accuracy: 0.9920 - val_loss: 7.0780 - val_accuracy: 0.9987\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 7.0951 - accuracy: 0.9913 - val_loss: 7.0627 - val_accuracy: 0.9988\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 7.0798 - accuracy: 0.9917 - val_loss: 7.0466 - val_accuracy: 0.9989\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 7.0615 - accuracy: 0.9927 - val_loss: 7.0313 - val_accuracy: 0.9988\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.0450 - accuracy: 0.9927 - val_loss: 7.0157 - val_accuracy: 0.9989\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 7.0310 - accuracy: 0.9921 - val_loss: 7.0008 - val_accuracy: 0.9989\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 7.0130 - accuracy: 0.9932 - val_loss: 6.9847 - val_accuracy: 0.9989\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.9951 - accuracy: 0.9945 - val_loss: 6.9698 - val_accuracy: 0.9989\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.9822 - accuracy: 0.9932 - val_loss: 6.9540 - val_accuracy: 0.9991\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.9663 - accuracy: 0.9935 - val_loss: 6.9387 - val_accuracy: 0.9988\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.9484 - accuracy: 0.9948 - val_loss: 6.9227 - val_accuracy: 0.9992\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.9320 - accuracy: 0.9943 - val_loss: 6.9085 - val_accuracy: 0.9991\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.9174 - accuracy: 0.9944 - val_loss: 6.8925 - val_accuracy: 0.9991\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 6.9016 - accuracy: 0.9938 - val_loss: 6.8762 - val_accuracy: 0.9993\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.8873 - accuracy: 0.9940 - val_loss: 6.8611 - val_accuracy: 0.9992\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.8691 - accuracy: 0.9946 - val_loss: 6.8461 - val_accuracy: 0.9991\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.8538 - accuracy: 0.9949 - val_loss: 6.8317 - val_accuracy: 0.9991\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.8369 - accuracy: 0.9959 - val_loss: 6.8155 - val_accuracy: 0.9992\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.8235 - accuracy: 0.9951 - val_loss: 6.8013 - val_accuracy: 0.9991\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.8077 - accuracy: 0.9952 - val_loss: 6.7858 - val_accuracy: 0.9992\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.7929 - accuracy: 0.9946 - val_loss: 6.7703 - val_accuracy: 0.9992\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.7770 - accuracy: 0.9945 - val_loss: 6.7545 - val_accuracy: 0.9995\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.7604 - accuracy: 0.9954 - val_loss: 6.7395 - val_accuracy: 0.9993\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.7448 - accuracy: 0.9958 - val_loss: 6.7242 - val_accuracy: 0.9993\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.7290 - accuracy: 0.9963 - val_loss: 6.7095 - val_accuracy: 0.9992\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.7140 - accuracy: 0.9958 - val_loss: 6.6944 - val_accuracy: 0.9995\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.6988 - accuracy: 0.9963 - val_loss: 6.6787 - val_accuracy: 0.9995\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.6811 - accuracy: 0.9969 - val_loss: 6.6644 - val_accuracy: 0.9992\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.6697 - accuracy: 0.9957 - val_loss: 6.6486 - val_accuracy: 0.9995\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.6514 - accuracy: 0.9969 - val_loss: 6.6339 - val_accuracy: 0.9995\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.6382 - accuracy: 0.9966 - val_loss: 6.6184 - val_accuracy: 0.9995\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 6.6232 - accuracy: 0.9957 - val_loss: 6.6032 - val_accuracy: 0.9997\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.6083 - accuracy: 0.9960 - val_loss: 6.5881 - val_accuracy: 0.9997\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.5914 - accuracy: 0.9968 - val_loss: 6.5737 - val_accuracy: 0.9995\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.5758 - accuracy: 0.9974 - val_loss: 6.5588 - val_accuracy: 0.9995\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.5629 - accuracy: 0.9962 - val_loss: 6.5437 - val_accuracy: 0.9995\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.5484 - accuracy: 0.9960 - val_loss: 6.5289 - val_accuracy: 0.9995\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.5317 - accuracy: 0.9968 - val_loss: 6.5144 - val_accuracy: 0.9995\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.5153 - accuracy: 0.9972 - val_loss: 6.4993 - val_accuracy: 0.9995\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.5018 - accuracy: 0.9970 - val_loss: 6.4850 - val_accuracy: 0.9993\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.4874 - accuracy: 0.9967 - val_loss: 6.4695 - val_accuracy: 0.9995\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.4721 - accuracy: 0.9968 - val_loss: 6.4543 - val_accuracy: 0.9996\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.4574 - accuracy: 0.9972 - val_loss: 6.4397 - val_accuracy: 0.9995\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.4412 - accuracy: 0.9977 - val_loss: 6.4253 - val_accuracy: 0.9995\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.4269 - accuracy: 0.9968 - val_loss: 6.4106 - val_accuracy: 0.9995\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.4129 - accuracy: 0.9966 - val_loss: 6.3954 - val_accuracy: 0.9995\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.3965 - accuracy: 0.9976 - val_loss: 6.3815 - val_accuracy: 0.9995\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.3823 - accuracy: 0.9970 - val_loss: 6.3661 - val_accuracy: 0.9996\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.3674 - accuracy: 0.9976 - val_loss: 6.3517 - val_accuracy: 0.9995\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.3538 - accuracy: 0.9970 - val_loss: 6.3375 - val_accuracy: 0.9995\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 6.3379 - accuracy: 0.9977 - val_loss: 6.3224 - val_accuracy: 0.9995\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.3228 - accuracy: 0.9973 - val_loss: 6.3081 - val_accuracy: 0.9995\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.3076 - accuracy: 0.9976 - val_loss: 6.2933 - val_accuracy: 0.9995\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.2935 - accuracy: 0.9978 - val_loss: 6.2786 - val_accuracy: 0.9995\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.2781 - accuracy: 0.9978 - val_loss: 6.2638 - val_accuracy: 0.9996\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.2641 - accuracy: 0.9979 - val_loss: 6.2494 - val_accuracy: 0.9995\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.2492 - accuracy: 0.9979 - val_loss: 6.2351 - val_accuracy: 0.9995\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.2352 - accuracy: 0.9976 - val_loss: 6.2204 - val_accuracy: 0.9996\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.2196 - accuracy: 0.9981 - val_loss: 6.2059 - val_accuracy: 0.9996\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.2067 - accuracy: 0.9979 - val_loss: 6.1911 - val_accuracy: 0.9996\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.1904 - accuracy: 0.9978 - val_loss: 6.1770 - val_accuracy: 0.9995\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.1771 - accuracy: 0.9976 - val_loss: 6.1625 - val_accuracy: 0.9996\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.1616 - accuracy: 0.9981 - val_loss: 6.1486 - val_accuracy: 0.9995\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 6.1479 - accuracy: 0.9977 - val_loss: 6.1340 - val_accuracy: 0.9995\n",
      "Time: 1070.0079193115234\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_10BM_1KSNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#1KSNPS, 10 BM\n",
    "################################################################################################################################################xtrain, xtest = X[int(len(y)*.25):], X[:int(len(y)*.25)]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test  = train_test_split(y,X,traits_BM10,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_BM_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_10BM_1KSNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JmdPZdxV699k",
    "outputId": "24794726-b4d5-461c-c2eb-9b72a4ac084c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 1000, 60)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 998, 250)     45000       ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 998, 250)    1000        ['conv1d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 996, 250)     187500      ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 996, 250)    1000        ['conv1d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 994, 250)     187500      ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 994, 250)    1000        ['conv1d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 331, 250)    0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 82750)        0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " dense_35_input (InputLayer)    [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 125)          10343875    ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 150)          450000      ['dense_35_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 125)          0           ['dense_38[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 150)         600         ['dense_35[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 125)          15750       ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 150)          22500       ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 125)          0           ['dense_39[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 150)         600         ['dense_36[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 50)           6300        ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 50)           7550        ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 50)           0           ['dense_40[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_4 (LinearW)           (None, 50)           2           ['dense_37[0][0]',               \n",
      "                                                                  'activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 50)           2550        ['linear_w_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_42 (Dense)               (None, 3)            153         ['dense_41[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,272,880\n",
      "Trainable params: 11,270,780\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 13s 128ms/step - loss: 13.2106 - accuracy: 0.4260 - val_loss: 13.1117 - val_accuracy: 0.4756\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 12.9373 - accuracy: 0.5636 - val_loss: 12.9226 - val_accuracy: 0.6309\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 12.7530 - accuracy: 0.6446 - val_loss: 12.6919 - val_accuracy: 0.7605\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 12.5965 - accuracy: 0.7072 - val_loss: 12.4641 - val_accuracy: 0.8589\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 12.4413 - accuracy: 0.7664 - val_loss: 12.2697 - val_accuracy: 0.9227\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 12.3029 - accuracy: 0.8172 - val_loss: 12.1069 - val_accuracy: 0.9491\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 12.1862 - accuracy: 0.8516 - val_loss: 11.9877 - val_accuracy: 0.9637\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 12.0674 - accuracy: 0.8880 - val_loss: 11.8873 - val_accuracy: 0.9731\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 11.9822 - accuracy: 0.9053 - val_loss: 11.8110 - val_accuracy: 0.9835\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.8936 - accuracy: 0.9248 - val_loss: 11.7381 - val_accuracy: 0.9868\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.8194 - accuracy: 0.9381 - val_loss: 11.6763 - val_accuracy: 0.9904\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.7513 - accuracy: 0.9471 - val_loss: 11.6214 - val_accuracy: 0.9900\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.6906 - accuracy: 0.9550 - val_loss: 11.5679 - val_accuracy: 0.9920\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 11.6277 - accuracy: 0.9618 - val_loss: 11.5170 - val_accuracy: 0.9948\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.5711 - accuracy: 0.9644 - val_loss: 11.4678 - val_accuracy: 0.9951\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.5188 - accuracy: 0.9684 - val_loss: 11.4211 - val_accuracy: 0.9953\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.4679 - accuracy: 0.9710 - val_loss: 11.3762 - val_accuracy: 0.9953\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 11.4145 - accuracy: 0.9743 - val_loss: 11.3301 - val_accuracy: 0.9968\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.3658 - accuracy: 0.9775 - val_loss: 11.2854 - val_accuracy: 0.9976\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.3214 - accuracy: 0.9772 - val_loss: 11.2432 - val_accuracy: 0.9968\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.2727 - accuracy: 0.9800 - val_loss: 11.1999 - val_accuracy: 0.9975\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.2290 - accuracy: 0.9793 - val_loss: 11.1556 - val_accuracy: 0.9980\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.1781 - accuracy: 0.9856 - val_loss: 11.1134 - val_accuracy: 0.9979\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 11.1352 - accuracy: 0.9844 - val_loss: 11.0710 - val_accuracy: 0.9981\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.0927 - accuracy: 0.9837 - val_loss: 11.0286 - val_accuracy: 0.9984\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.0465 - accuracy: 0.9862 - val_loss: 10.9872 - val_accuracy: 0.9983\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.0039 - accuracy: 0.9857 - val_loss: 10.9451 - val_accuracy: 0.9987\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 10.9597 - accuracy: 0.9879 - val_loss: 10.9032 - val_accuracy: 0.9988\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.9166 - accuracy: 0.9883 - val_loss: 10.8623 - val_accuracy: 0.9988\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.8717 - accuracy: 0.9892 - val_loss: 10.8206 - val_accuracy: 0.9988\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.8311 - accuracy: 0.9897 - val_loss: 10.7798 - val_accuracy: 0.9988\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.7893 - accuracy: 0.9907 - val_loss: 10.7388 - val_accuracy: 0.9988\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.7480 - accuracy: 0.9892 - val_loss: 10.6981 - val_accuracy: 0.9988\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.7052 - accuracy: 0.9902 - val_loss: 10.6574 - val_accuracy: 0.9988\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.6657 - accuracy: 0.9906 - val_loss: 10.6177 - val_accuracy: 0.9988\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.6206 - accuracy: 0.9921 - val_loss: 10.5764 - val_accuracy: 0.9989\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.5782 - accuracy: 0.9928 - val_loss: 10.5369 - val_accuracy: 0.9988\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.5387 - accuracy: 0.9920 - val_loss: 10.4961 - val_accuracy: 0.9988\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.5006 - accuracy: 0.9916 - val_loss: 10.4559 - val_accuracy: 0.9988\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.4576 - accuracy: 0.9925 - val_loss: 10.4160 - val_accuracy: 0.9988\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.4184 - accuracy: 0.9931 - val_loss: 10.3769 - val_accuracy: 0.9988\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.3752 - accuracy: 0.9934 - val_loss: 10.3359 - val_accuracy: 0.9992\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.3359 - accuracy: 0.9939 - val_loss: 10.2972 - val_accuracy: 0.9988\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.2948 - accuracy: 0.9941 - val_loss: 10.2567 - val_accuracy: 0.9991\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.2568 - accuracy: 0.9936 - val_loss: 10.2176 - val_accuracy: 0.9989\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.2137 - accuracy: 0.9949 - val_loss: 10.1780 - val_accuracy: 0.9989\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.1749 - accuracy: 0.9945 - val_loss: 10.1386 - val_accuracy: 0.9989\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.1350 - accuracy: 0.9949 - val_loss: 10.0995 - val_accuracy: 0.9989\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 10.0966 - accuracy: 0.9943 - val_loss: 10.0598 - val_accuracy: 0.9992\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.0549 - accuracy: 0.9955 - val_loss: 10.0210 - val_accuracy: 0.9992\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.0163 - accuracy: 0.9947 - val_loss: 9.9820 - val_accuracy: 0.9992\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.9762 - accuracy: 0.9953 - val_loss: 9.9449 - val_accuracy: 0.9987\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.9400 - accuracy: 0.9945 - val_loss: 9.9046 - val_accuracy: 0.9992\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.8976 - accuracy: 0.9959 - val_loss: 9.8665 - val_accuracy: 0.9991\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.8602 - accuracy: 0.9956 - val_loss: 9.8276 - val_accuracy: 0.9991\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.8198 - accuracy: 0.9959 - val_loss: 9.7892 - val_accuracy: 0.9991\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.7822 - accuracy: 0.9956 - val_loss: 9.7500 - val_accuracy: 0.9993\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 9.7436 - accuracy: 0.9958 - val_loss: 9.7124 - val_accuracy: 0.9991\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.7054 - accuracy: 0.9952 - val_loss: 9.6737 - val_accuracy: 0.9993\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.6659 - accuracy: 0.9962 - val_loss: 9.6357 - val_accuracy: 0.9992\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.6275 - accuracy: 0.9967 - val_loss: 9.5975 - val_accuracy: 0.9993\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.5895 - accuracy: 0.9962 - val_loss: 9.5595 - val_accuracy: 0.9992\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.5514 - accuracy: 0.9963 - val_loss: 9.5214 - val_accuracy: 0.9993\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.5143 - accuracy: 0.9960 - val_loss: 9.4842 - val_accuracy: 0.9991\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.4747 - accuracy: 0.9970 - val_loss: 9.4458 - val_accuracy: 0.9995\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.4396 - accuracy: 0.9959 - val_loss: 9.4079 - val_accuracy: 0.9996\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.4000 - accuracy: 0.9963 - val_loss: 9.3706 - val_accuracy: 0.9996\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.3616 - accuracy: 0.9970 - val_loss: 9.3341 - val_accuracy: 0.9991\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.3250 - accuracy: 0.9969 - val_loss: 9.2957 - val_accuracy: 0.9996\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.2859 - accuracy: 0.9970 - val_loss: 9.2586 - val_accuracy: 0.9996\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.2495 - accuracy: 0.9964 - val_loss: 9.2223 - val_accuracy: 0.9991\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.2118 - accuracy: 0.9969 - val_loss: 9.1842 - val_accuracy: 0.9993\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.1724 - accuracy: 0.9979 - val_loss: 9.1473 - val_accuracy: 0.9992\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.1374 - accuracy: 0.9969 - val_loss: 9.1104 - val_accuracy: 0.9992\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 9.1016 - accuracy: 0.9964 - val_loss: 9.0736 - val_accuracy: 0.9992\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.0644 - accuracy: 0.9973 - val_loss: 9.0370 - val_accuracy: 0.9992\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.0258 - accuracy: 0.9976 - val_loss: 8.9997 - val_accuracy: 0.9996\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.9893 - accuracy: 0.9972 - val_loss: 8.9638 - val_accuracy: 0.9992\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.9535 - accuracy: 0.9972 - val_loss: 8.9266 - val_accuracy: 0.9996\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.9165 - accuracy: 0.9976 - val_loss: 8.8908 - val_accuracy: 0.9992\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.8806 - accuracy: 0.9974 - val_loss: 8.8535 - val_accuracy: 0.9996\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.8427 - accuracy: 0.9974 - val_loss: 8.8182 - val_accuracy: 0.9993\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.8072 - accuracy: 0.9975 - val_loss: 8.7822 - val_accuracy: 0.9991\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.7717 - accuracy: 0.9973 - val_loss: 8.7455 - val_accuracy: 0.9996\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.7346 - accuracy: 0.9977 - val_loss: 8.7093 - val_accuracy: 0.9996\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.6982 - accuracy: 0.9977 - val_loss: 8.6735 - val_accuracy: 0.9996\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.6624 - accuracy: 0.9978 - val_loss: 8.6379 - val_accuracy: 0.9996\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.6271 - accuracy: 0.9975 - val_loss: 8.6022 - val_accuracy: 0.9996\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.5900 - accuracy: 0.9979 - val_loss: 8.5669 - val_accuracy: 0.9992\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.5545 - accuracy: 0.9980 - val_loss: 8.5313 - val_accuracy: 0.9992\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.5193 - accuracy: 0.9978 - val_loss: 8.4955 - val_accuracy: 0.9996\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.4833 - accuracy: 0.9984 - val_loss: 8.4598 - val_accuracy: 0.9996\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.4483 - accuracy: 0.9980 - val_loss: 8.4252 - val_accuracy: 0.9992\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.4139 - accuracy: 0.9978 - val_loss: 8.3896 - val_accuracy: 0.9996\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.3776 - accuracy: 0.9979 - val_loss: 8.3543 - val_accuracy: 0.9996\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.3418 - accuracy: 0.9982 - val_loss: 8.3193 - val_accuracy: 0.9996\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.3069 - accuracy: 0.9983 - val_loss: 8.2841 - val_accuracy: 0.9996\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.2725 - accuracy: 0.9981 - val_loss: 8.2492 - val_accuracy: 0.9996\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.2365 - accuracy: 0.9984 - val_loss: 8.2144 - val_accuracy: 0.9996\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.2021 - accuracy: 0.9980 - val_loss: 8.1800 - val_accuracy: 0.9996\n",
      "Time: 1072.9308259487152\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_50BM_1KSNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#1KSNPS, 50 BM\n",
    "################################################################################################################################################xtrain, xtest = X[int(len(y)*.25):], X[:int(len(y)*.25)]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test  = train_test_split(y,X,traits_BM50,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_BM_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_50BM_1KSNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJEoto5M8aSf",
    "outputId": "7290e350-be84-4343-aa34-4edd082e4249",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 50, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 48, 250)      45000       ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 48, 250)     1000        ['conv1d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 46, 250)      187500      ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 46, 250)     1000        ['conv1d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 44, 250)      187500      ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 44, 250)     1000        ['conv1d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 250)     0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 3500)         0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " dense_43_input (InputLayer)    [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, 125)          437625      ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_43 (Dense)               (None, 150)          150000      ['dense_43_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 125)          0           ['dense_46[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 150)         600         ['dense_43[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 125)          15750       ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 150)          22500       ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 125)          0           ['dense_47[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 150)         600         ['dense_44[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 50)           6300        ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " dense_45 (Dense)               (None, 50)           7550        ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 50)           0           ['dense_48[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_5 (LinearW)           (None, 50)           2           ['dense_45[0][0]',               \n",
      "                                                                  'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " dense_49 (Dense)               (None, 50)           2550        ['linear_w_5[0][0]']             \n",
      "                                                                                                  \n",
      " dense_50 (Dense)               (None, 3)            153         ['dense_49[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,066,630\n",
      "Trainable params: 1,064,530\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 3s 14ms/step - loss: 8.8416 - accuracy: 0.3684 - val_loss: 8.7452 - val_accuracy: 0.3885\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.7469 - accuracy: 0.4112 - val_loss: 8.6890 - val_accuracy: 0.4621\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.6836 - accuracy: 0.4478 - val_loss: 8.6165 - val_accuracy: 0.5331\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.6303 - accuracy: 0.4758 - val_loss: 8.5451 - val_accuracy: 0.5727\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.5742 - accuracy: 0.5118 - val_loss: 8.4778 - val_accuracy: 0.6095\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.5190 - accuracy: 0.5398 - val_loss: 8.4170 - val_accuracy: 0.6313\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.4675 - accuracy: 0.5647 - val_loss: 8.3619 - val_accuracy: 0.6520\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.4197 - accuracy: 0.5884 - val_loss: 8.3137 - val_accuracy: 0.6653\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.3789 - accuracy: 0.6004 - val_loss: 8.2680 - val_accuracy: 0.6795\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.3330 - accuracy: 0.6203 - val_loss: 8.2249 - val_accuracy: 0.6919\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.2950 - accuracy: 0.6306 - val_loss: 8.1830 - val_accuracy: 0.7049\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.2544 - accuracy: 0.6428 - val_loss: 8.1458 - val_accuracy: 0.7113\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.2192 - accuracy: 0.6526 - val_loss: 8.1078 - val_accuracy: 0.7229\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.1848 - accuracy: 0.6635 - val_loss: 8.0732 - val_accuracy: 0.7285\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.1470 - accuracy: 0.6784 - val_loss: 8.0374 - val_accuracy: 0.7409\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.1143 - accuracy: 0.6892 - val_loss: 8.0035 - val_accuracy: 0.7491\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.0814 - accuracy: 0.6955 - val_loss: 7.9697 - val_accuracy: 0.7593\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.0471 - accuracy: 0.7034 - val_loss: 7.9346 - val_accuracy: 0.7701\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.0168 - accuracy: 0.7111 - val_loss: 7.9008 - val_accuracy: 0.7803\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.9780 - accuracy: 0.7201 - val_loss: 7.8662 - val_accuracy: 0.7897\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.9493 - accuracy: 0.7274 - val_loss: 7.8324 - val_accuracy: 0.7993\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.9149 - accuracy: 0.7391 - val_loss: 7.7968 - val_accuracy: 0.8107\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.8836 - accuracy: 0.7482 - val_loss: 7.7639 - val_accuracy: 0.8201\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.8493 - accuracy: 0.7580 - val_loss: 7.7297 - val_accuracy: 0.8300\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.8171 - accuracy: 0.7655 - val_loss: 7.6953 - val_accuracy: 0.8421\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.7808 - accuracy: 0.7780 - val_loss: 7.6614 - val_accuracy: 0.8527\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.7467 - accuracy: 0.7869 - val_loss: 7.6280 - val_accuracy: 0.8603\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.7182 - accuracy: 0.7968 - val_loss: 7.5958 - val_accuracy: 0.8663\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.6815 - accuracy: 0.8045 - val_loss: 7.5633 - val_accuracy: 0.8736\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.6520 - accuracy: 0.8098 - val_loss: 7.5316 - val_accuracy: 0.8795\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.6220 - accuracy: 0.8207 - val_loss: 7.5005 - val_accuracy: 0.8852\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.5893 - accuracy: 0.8305 - val_loss: 7.4710 - val_accuracy: 0.8904\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.5567 - accuracy: 0.8382 - val_loss: 7.4414 - val_accuracy: 0.8967\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.5280 - accuracy: 0.8412 - val_loss: 7.4116 - val_accuracy: 0.9005\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.4986 - accuracy: 0.8496 - val_loss: 7.3841 - val_accuracy: 0.9057\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.4711 - accuracy: 0.8585 - val_loss: 7.3560 - val_accuracy: 0.9101\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.4413 - accuracy: 0.8605 - val_loss: 7.3294 - val_accuracy: 0.9157\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.4157 - accuracy: 0.8673 - val_loss: 7.3042 - val_accuracy: 0.9193\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.3899 - accuracy: 0.8714 - val_loss: 7.2787 - val_accuracy: 0.9223\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.3617 - accuracy: 0.8788 - val_loss: 7.2527 - val_accuracy: 0.9271\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.3327 - accuracy: 0.8864 - val_loss: 7.2279 - val_accuracy: 0.9315\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.3095 - accuracy: 0.8894 - val_loss: 7.2038 - val_accuracy: 0.9344\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.2816 - accuracy: 0.8959 - val_loss: 7.1808 - val_accuracy: 0.9369\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.2608 - accuracy: 0.8981 - val_loss: 7.1585 - val_accuracy: 0.9395\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.2320 - accuracy: 0.9041 - val_loss: 7.1365 - val_accuracy: 0.9407\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.2124 - accuracy: 0.9045 - val_loss: 7.1140 - val_accuracy: 0.9437\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.1891 - accuracy: 0.9083 - val_loss: 7.0916 - val_accuracy: 0.9473\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.1634 - accuracy: 0.9137 - val_loss: 7.0705 - val_accuracy: 0.9496\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.1434 - accuracy: 0.9171 - val_loss: 7.0509 - val_accuracy: 0.9503\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.1179 - accuracy: 0.9205 - val_loss: 7.0287 - val_accuracy: 0.9533\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.0982 - accuracy: 0.9228 - val_loss: 7.0093 - val_accuracy: 0.9544\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.0749 - accuracy: 0.9225 - val_loss: 6.9882 - val_accuracy: 0.9569\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.0561 - accuracy: 0.9265 - val_loss: 6.9686 - val_accuracy: 0.9583\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.0343 - accuracy: 0.9282 - val_loss: 6.9495 - val_accuracy: 0.9597\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.0100 - accuracy: 0.9322 - val_loss: 6.9307 - val_accuracy: 0.9607\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.9908 - accuracy: 0.9348 - val_loss: 6.9125 - val_accuracy: 0.9617\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.9695 - accuracy: 0.9364 - val_loss: 6.8943 - val_accuracy: 0.9624\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.9543 - accuracy: 0.9376 - val_loss: 6.8762 - val_accuracy: 0.9637\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.9349 - accuracy: 0.9377 - val_loss: 6.8576 - val_accuracy: 0.9644\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.9148 - accuracy: 0.9429 - val_loss: 6.8390 - val_accuracy: 0.9648\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.8981 - accuracy: 0.9409 - val_loss: 6.8218 - val_accuracy: 0.9667\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.8775 - accuracy: 0.9436 - val_loss: 6.8045 - val_accuracy: 0.9675\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.8588 - accuracy: 0.9417 - val_loss: 6.7881 - val_accuracy: 0.9677\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.8393 - accuracy: 0.9445 - val_loss: 6.7715 - val_accuracy: 0.9684\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.8231 - accuracy: 0.9469 - val_loss: 6.7540 - val_accuracy: 0.9685\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.8044 - accuracy: 0.9473 - val_loss: 6.7360 - val_accuracy: 0.9695\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7870 - accuracy: 0.9496 - val_loss: 6.7191 - val_accuracy: 0.9699\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7664 - accuracy: 0.9510 - val_loss: 6.7029 - val_accuracy: 0.9704\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7473 - accuracy: 0.9520 - val_loss: 6.6872 - val_accuracy: 0.9704\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7336 - accuracy: 0.9515 - val_loss: 6.6706 - val_accuracy: 0.9709\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7136 - accuracy: 0.9540 - val_loss: 6.6535 - val_accuracy: 0.9716\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6967 - accuracy: 0.9543 - val_loss: 6.6378 - val_accuracy: 0.9713\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6824 - accuracy: 0.9550 - val_loss: 6.6214 - val_accuracy: 0.9725\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6585 - accuracy: 0.9585 - val_loss: 6.6069 - val_accuracy: 0.9719\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6466 - accuracy: 0.9568 - val_loss: 6.5895 - val_accuracy: 0.9727\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6301 - accuracy: 0.9581 - val_loss: 6.5730 - val_accuracy: 0.9736\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6154 - accuracy: 0.9576 - val_loss: 6.5568 - val_accuracy: 0.9745\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5898 - accuracy: 0.9609 - val_loss: 6.5421 - val_accuracy: 0.9736\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5775 - accuracy: 0.9600 - val_loss: 6.5275 - val_accuracy: 0.9733\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5571 - accuracy: 0.9620 - val_loss: 6.5113 - val_accuracy: 0.9749\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5449 - accuracy: 0.9613 - val_loss: 6.4955 - val_accuracy: 0.9755\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5293 - accuracy: 0.9608 - val_loss: 6.4794 - val_accuracy: 0.9759\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5136 - accuracy: 0.9627 - val_loss: 6.4652 - val_accuracy: 0.9755\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5021 - accuracy: 0.9604 - val_loss: 6.4477 - val_accuracy: 0.9775\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4794 - accuracy: 0.9625 - val_loss: 6.4333 - val_accuracy: 0.9771\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4634 - accuracy: 0.9642 - val_loss: 6.4175 - val_accuracy: 0.9776\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4480 - accuracy: 0.9653 - val_loss: 6.4021 - val_accuracy: 0.9781\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4313 - accuracy: 0.9660 - val_loss: 6.3883 - val_accuracy: 0.9775\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4144 - accuracy: 0.9671 - val_loss: 6.3731 - val_accuracy: 0.9777\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4000 - accuracy: 0.9668 - val_loss: 6.3578 - val_accuracy: 0.9779\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3882 - accuracy: 0.9648 - val_loss: 6.3441 - val_accuracy: 0.9776\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3687 - accuracy: 0.9685 - val_loss: 6.3267 - val_accuracy: 0.9788\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3546 - accuracy: 0.9664 - val_loss: 6.3128 - val_accuracy: 0.9785\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3376 - accuracy: 0.9685 - val_loss: 6.2975 - val_accuracy: 0.9788\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3207 - accuracy: 0.9680 - val_loss: 6.2819 - val_accuracy: 0.9792\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3039 - accuracy: 0.9683 - val_loss: 6.2675 - val_accuracy: 0.9792\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.2880 - accuracy: 0.9688 - val_loss: 6.2531 - val_accuracy: 0.9789\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.2755 - accuracy: 0.9690 - val_loss: 6.2386 - val_accuracy: 0.9793\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.2603 - accuracy: 0.9696 - val_loss: 6.2235 - val_accuracy: 0.9793\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.2436 - accuracy: 0.9705 - val_loss: 6.2089 - val_accuracy: 0.9796\n",
      "Time: 93.27097296714783\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_10BM_50SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#50SNPS, 10 BM\n",
    "################################################################################################################################################xtrain, xtest = X[int(len(y)*.25):], X[:int(len(y)*.25)]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test  = train_test_split(y,X50,traits_BM10,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_BM_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_10BM_50SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "140ckPa_9PWp",
    "outputId": "bb768895-b1dd-407e-f900-7dbecb80755b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 20, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 18, 250)      45000       ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 18, 250)     1000        ['conv1d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 16, 250)      187500      ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 16, 250)     1000        ['conv1d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 14, 250)      187500      ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 14, 250)     1000        ['conv1d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 4, 250)      0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 1000)         0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " dense_51_input (InputLayer)    [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_54 (Dense)               (None, 125)          125125      ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " dense_51 (Dense)               (None, 150)          450000      ['dense_51_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 125)          0           ['dense_54[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 150)         600         ['dense_51[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_55 (Dense)               (None, 125)          15750       ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dense_52 (Dense)               (None, 150)          22500       ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 125)          0           ['dense_55[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 150)         600         ['dense_52[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_56 (Dense)               (None, 50)           6300        ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " dense_53 (Dense)               (None, 50)           7550        ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 50)           0           ['dense_56[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_6 (LinearW)           (None, 50)           2           ['dense_53[0][0]',               \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " dense_57 (Dense)               (None, 50)           2550        ['linear_w_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_58 (Dense)               (None, 3)            153         ['dense_57[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,054,130\n",
      "Trainable params: 1,052,030\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 2s 12ms/step - loss: 13.3444 - accuracy: 0.3374 - val_loss: 13.1682 - val_accuracy: 0.3224\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 13.1650 - accuracy: 0.3574 - val_loss: 13.1019 - val_accuracy: 0.3393\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 13.0887 - accuracy: 0.3764 - val_loss: 13.0344 - val_accuracy: 0.3691\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 13.0261 - accuracy: 0.3900 - val_loss: 12.9688 - val_accuracy: 0.4009\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.9632 - accuracy: 0.4064 - val_loss: 12.9044 - val_accuracy: 0.4361\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.9036 - accuracy: 0.4184 - val_loss: 12.8420 - val_accuracy: 0.4632\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.8418 - accuracy: 0.4408 - val_loss: 12.7793 - val_accuracy: 0.4921\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.7841 - accuracy: 0.4554 - val_loss: 12.7167 - val_accuracy: 0.5201\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.7189 - accuracy: 0.4816 - val_loss: 12.6536 - val_accuracy: 0.5484\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.6610 - accuracy: 0.4972 - val_loss: 12.5894 - val_accuracy: 0.5811\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.6006 - accuracy: 0.5159 - val_loss: 12.5245 - val_accuracy: 0.6059\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.5396 - accuracy: 0.5313 - val_loss: 12.4590 - val_accuracy: 0.6269\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.4765 - accuracy: 0.5495 - val_loss: 12.3923 - val_accuracy: 0.6440\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.4158 - accuracy: 0.5623 - val_loss: 12.3260 - val_accuracy: 0.6596\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.3565 - accuracy: 0.5745 - val_loss: 12.2601 - val_accuracy: 0.6723\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.2904 - accuracy: 0.5945 - val_loss: 12.1939 - val_accuracy: 0.6821\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.2280 - accuracy: 0.6054 - val_loss: 12.1296 - val_accuracy: 0.6933\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.1681 - accuracy: 0.6204 - val_loss: 12.0667 - val_accuracy: 0.7012\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.1103 - accuracy: 0.6300 - val_loss: 12.0048 - val_accuracy: 0.7091\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.0538 - accuracy: 0.6344 - val_loss: 11.9441 - val_accuracy: 0.7164\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.9939 - accuracy: 0.6417 - val_loss: 11.8844 - val_accuracy: 0.7203\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.9310 - accuracy: 0.6614 - val_loss: 11.8259 - val_accuracy: 0.7267\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.8760 - accuracy: 0.6671 - val_loss: 11.7688 - val_accuracy: 0.7327\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.8215 - accuracy: 0.6739 - val_loss: 11.7117 - val_accuracy: 0.7375\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.7638 - accuracy: 0.6864 - val_loss: 11.6551 - val_accuracy: 0.7452\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.7090 - accuracy: 0.6931 - val_loss: 11.5990 - val_accuracy: 0.7528\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.6506 - accuracy: 0.6982 - val_loss: 11.5432 - val_accuracy: 0.7560\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.5979 - accuracy: 0.7059 - val_loss: 11.4876 - val_accuracy: 0.7624\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.5447 - accuracy: 0.7110 - val_loss: 11.4324 - val_accuracy: 0.7707\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.4904 - accuracy: 0.7208 - val_loss: 11.3773 - val_accuracy: 0.7780\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.4391 - accuracy: 0.7258 - val_loss: 11.3219 - val_accuracy: 0.7852\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.3801 - accuracy: 0.7319 - val_loss: 11.2676 - val_accuracy: 0.7912\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.3234 - accuracy: 0.7415 - val_loss: 11.2138 - val_accuracy: 0.7963\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.2711 - accuracy: 0.7464 - val_loss: 11.1595 - val_accuracy: 0.8013\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.2136 - accuracy: 0.7560 - val_loss: 11.1062 - val_accuracy: 0.8052\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.1669 - accuracy: 0.7579 - val_loss: 11.0535 - val_accuracy: 0.8119\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.1103 - accuracy: 0.7687 - val_loss: 11.0005 - val_accuracy: 0.8165\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.0607 - accuracy: 0.7740 - val_loss: 10.9483 - val_accuracy: 0.8217\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.0064 - accuracy: 0.7799 - val_loss: 10.8968 - val_accuracy: 0.8271\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.9558 - accuracy: 0.7834 - val_loss: 10.8466 - val_accuracy: 0.8304\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.9056 - accuracy: 0.7905 - val_loss: 10.7965 - val_accuracy: 0.8344\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.8560 - accuracy: 0.7952 - val_loss: 10.7478 - val_accuracy: 0.8381\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.8043 - accuracy: 0.7969 - val_loss: 10.6974 - val_accuracy: 0.8428\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.7582 - accuracy: 0.7989 - val_loss: 10.6499 - val_accuracy: 0.8463\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.7102 - accuracy: 0.8046 - val_loss: 10.6033 - val_accuracy: 0.8487\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.6550 - accuracy: 0.8110 - val_loss: 10.5561 - val_accuracy: 0.8515\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.6108 - accuracy: 0.8149 - val_loss: 10.5097 - val_accuracy: 0.8539\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.5591 - accuracy: 0.8218 - val_loss: 10.4639 - val_accuracy: 0.8565\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.5104 - accuracy: 0.8265 - val_loss: 10.4178 - val_accuracy: 0.8600\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.4650 - accuracy: 0.8280 - val_loss: 10.3728 - val_accuracy: 0.8627\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.4240 - accuracy: 0.8271 - val_loss: 10.3282 - val_accuracy: 0.8649\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.3736 - accuracy: 0.8343 - val_loss: 10.2836 - val_accuracy: 0.8664\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.3295 - accuracy: 0.8349 - val_loss: 10.2404 - val_accuracy: 0.8688\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.2831 - accuracy: 0.8384 - val_loss: 10.1975 - val_accuracy: 0.8707\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.2413 - accuracy: 0.8403 - val_loss: 10.1541 - val_accuracy: 0.8727\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.1961 - accuracy: 0.8449 - val_loss: 10.1117 - val_accuracy: 0.8727\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.1541 - accuracy: 0.8445 - val_loss: 10.0686 - val_accuracy: 0.8763\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.1096 - accuracy: 0.8455 - val_loss: 10.0261 - val_accuracy: 0.8773\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.0680 - accuracy: 0.8484 - val_loss: 9.9840 - val_accuracy: 0.8789\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.0262 - accuracy: 0.8513 - val_loss: 9.9423 - val_accuracy: 0.8799\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.9786 - accuracy: 0.8531 - val_loss: 9.9005 - val_accuracy: 0.8811\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.9317 - accuracy: 0.8580 - val_loss: 9.8604 - val_accuracy: 0.8816\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.8903 - accuracy: 0.8596 - val_loss: 9.8181 - val_accuracy: 0.8832\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.8482 - accuracy: 0.8621 - val_loss: 9.7775 - val_accuracy: 0.8851\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.8031 - accuracy: 0.8656 - val_loss: 9.7372 - val_accuracy: 0.8860\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.7642 - accuracy: 0.8656 - val_loss: 9.6965 - val_accuracy: 0.8877\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.7274 - accuracy: 0.8639 - val_loss: 9.6568 - val_accuracy: 0.8884\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.6804 - accuracy: 0.8721 - val_loss: 9.6173 - val_accuracy: 0.8889\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.6376 - accuracy: 0.8737 - val_loss: 9.5782 - val_accuracy: 0.8895\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.5967 - accuracy: 0.8741 - val_loss: 9.5363 - val_accuracy: 0.8920\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.5593 - accuracy: 0.8758 - val_loss: 9.4973 - val_accuracy: 0.8935\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.5159 - accuracy: 0.8778 - val_loss: 9.4584 - val_accuracy: 0.8935\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.4726 - accuracy: 0.8802 - val_loss: 9.4188 - val_accuracy: 0.8941\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.4309 - accuracy: 0.8823 - val_loss: 9.3798 - val_accuracy: 0.8945\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.3925 - accuracy: 0.8851 - val_loss: 9.3410 - val_accuracy: 0.8951\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.3554 - accuracy: 0.8835 - val_loss: 9.3013 - val_accuracy: 0.8960\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.3150 - accuracy: 0.8849 - val_loss: 9.2634 - val_accuracy: 0.8960\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.2733 - accuracy: 0.8892 - val_loss: 9.2238 - val_accuracy: 0.8968\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.2330 - accuracy: 0.8874 - val_loss: 9.1855 - val_accuracy: 0.8968\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.1880 - accuracy: 0.8928 - val_loss: 9.1479 - val_accuracy: 0.8988\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.1565 - accuracy: 0.8907 - val_loss: 9.1093 - val_accuracy: 0.8987\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.1191 - accuracy: 0.8909 - val_loss: 9.0716 - val_accuracy: 0.8997\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.0786 - accuracy: 0.8918 - val_loss: 9.0341 - val_accuracy: 0.8996\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.0372 - accuracy: 0.8965 - val_loss: 8.9956 - val_accuracy: 0.9000\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.9980 - accuracy: 0.8956 - val_loss: 8.9580 - val_accuracy: 0.9012\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.9588 - accuracy: 0.8992 - val_loss: 8.9209 - val_accuracy: 0.9012\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.9217 - accuracy: 0.8969 - val_loss: 8.8836 - val_accuracy: 0.9024\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.8795 - accuracy: 0.9017 - val_loss: 8.8463 - val_accuracy: 0.9031\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.8433 - accuracy: 0.8992 - val_loss: 8.8094 - val_accuracy: 0.9029\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.7998 - accuracy: 0.9044 - val_loss: 8.7721 - val_accuracy: 0.9032\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.7665 - accuracy: 0.9048 - val_loss: 8.7360 - val_accuracy: 0.9032\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.7265 - accuracy: 0.9048 - val_loss: 8.6985 - val_accuracy: 0.9045\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.6909 - accuracy: 0.9044 - val_loss: 8.6618 - val_accuracy: 0.9049\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.6558 - accuracy: 0.9052 - val_loss: 8.6263 - val_accuracy: 0.9051\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.6173 - accuracy: 0.9048 - val_loss: 8.5895 - val_accuracy: 0.9057\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.5786 - accuracy: 0.9091 - val_loss: 8.5533 - val_accuracy: 0.9064\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.5402 - accuracy: 0.9091 - val_loss: 8.5166 - val_accuracy: 0.9069\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.4993 - accuracy: 0.9117 - val_loss: 8.4807 - val_accuracy: 0.9069\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.4678 - accuracy: 0.9107 - val_loss: 8.4449 - val_accuracy: 0.9069\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.4276 - accuracy: 0.9128 - val_loss: 8.4107 - val_accuracy: 0.9072\n",
      "Time: 71.9052038192749\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_100BM_20SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#20SNPS, 100 BM\n",
    "################################################################################################################################################xtrain, xtest = X[int(len(y)*.25):], X[:int(len(y)*.25)]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test  = train_test_split(y,X20,traits_BM,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_BM_subset(ytrain, ytest, xtrain, xtest, traits_BM_train, traits_BM_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_100BM_20SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################################\n",
    "# Now repeat with traits simulated under the OU model.\n",
    "################################################################################################################################################\n",
    "\n",
    "# Since we will run the analysis on several subsets, define a function for training on each data subsets (Combined datasets, SNP only and OU traits only).\n",
    "\n",
    "# function to train on the combined datasets\n",
    "def combined_OU_subset(ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test):\n",
    "    # convert labels to a categorical matrix of binary values (0 or 1). The number of rows is the length of the input vector (number of simulations) and the number of columns is the number of classes (3 scenarios).\n",
    "    ytest = np_utils.to_categorical(ytest, num_classes)\n",
    "    ytrain = np_utils.to_categorical(ytrain, num_classes)\n",
    "    # reshape the traits matrices to input them into the MLP\n",
    "    traits_OU_train=traits_OU_train.reshape((traits_OU_train.shape[0], (traits_OU_train.shape[1]*traits_OU_train.shape[2])))\n",
    "    traits_OU_test=traits_OU_test.reshape((traits_OU_test.shape[0], (traits_OU_test.shape[1]*traits_OU_test.shape[2])))\n",
    "    # Create the MLP, the CNN and the combined models\n",
    "    mlp = create_mlp(traits_OU_train)\n",
    "    cnn = create_cnn(xtest)\n",
    "    combinedInput = LinearW()([mlp.output, cnn.output])\n",
    "\n",
    "    # The final fully-connected layer head will have two dense layers (one relu and one softmax)\n",
    "    x = Dense(50, activation=\"relu\")(combinedInput)\n",
    "    x = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    # The final model accepts numerical data on the MLP input and images on the CNN input, outputting a single value\n",
    "    model = Model(inputs=[mlp.input, cnn.input], outputs=x)\n",
    "\n",
    "    # using Stochastic Gradient Descent as optimizer and a categorical cross-entropy loss function\n",
    "    opt = SGD(learning_rate=0.001)\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    # save only the epoch with the highest accuracy in the validation set, by using the model checkpoint\n",
    "    earlyStopping = EarlyStopping(monitor='val_accuracy', patience=150, verbose=0, mode='max', restore_best_weights=True)\n",
    "\n",
    "    # fit the model and record running times\n",
    "    start = time.time()\n",
    "    model.fit([traits_OU_train, xtrain], ytrain, batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=([traits_OU_test, xtest], ytest),callbacks=[earlyStopping])\n",
    "    print (f'Time: {time.time() - start}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# function to train on the OU trait only datasets\n",
    "def OU_subset(ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test):\n",
    "    # convert labels to a categorical matrix of binary values (0 or 1). The number of rows is the length of the input vector (number of simulations) and the number of columns is the number of classes (3 scenarios).\n",
    "    ytest = np_utils.to_categorical(ytest, num_classes)\n",
    "    ytrain = np_utils.to_categorical(ytrain, num_classes)\n",
    "    # reshape the traits matrices to input them into the MLP\n",
    "    traits_OU_train=traits_OU_train.reshape((traits_OU_train.shape[0], (traits_OU_train.shape[1]*traits_OU_train.shape[2])))\n",
    "    traits_OU_test=traits_OU_test.reshape((traits_OU_test.shape[0], (traits_OU_test.shape[1]*traits_OU_test.shape[2])))\n",
    "    mlp = create_mlp(traits_OU_train)\n",
    "    #Create the last layer for the traits network\n",
    "    xMLP = Dense(num_classes, activation=\"softmax\")(mlp.output)\n",
    "    model = Model(inputs=mlp.input, outputs=xMLP)\n",
    "\n",
    "    # using Stochastic Gradient Descent as optimizer and a categorical cross-entropy loss function\n",
    "    opt = SGD(learning_rate=0.001)\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    # save only the epoch with the highest accuracy in the validation set, by using the model checkpoint\n",
    "    earlyStopping = EarlyStopping(monitor='val_accuracy', patience=150, verbose=0, mode='max', restore_best_weights=True)\n",
    "    # fit the model and record running times\n",
    "    start = time.time()\n",
    "    model.fit(traits_OU_train, ytrain, batch_size=batch_size,\n",
    "          epochs=epochs_traits,\n",
    "          verbose=1,\n",
    "          validation_data=(traits_OU_test, ytest),callbacks=[earlyStopping])\n",
    "    print (f'Time: {time.time() - start}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9nDx2HPbIjP",
    "outputId": "52b8a6cf-2974-4111-c935-9939c722adb9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000 30000\n"
     ]
    }
   ],
   "source": [
    "# load the traits simulated under the OU model for the 3 scenarios. \n",
    "traits_OU = []\n",
    "traits_OU = np.loadtxt(\"./traits/traits_OU.txt\").reshape(30000,-1,100)\n",
    "# transform into a NumPy array. \n",
    "traits_OU = np.array(traits_OU)\n",
    "\n",
    "# standard scale the continuous (OU) traits\n",
    "scalers_OU = {}\n",
    "for i in range(traits_OU.shape[2]):\n",
    "    scalers_OU[i] = StandardScaler(copy=False)\n",
    "    traits_OU[:, :, i] = scalers_OU[i].fit_transform(traits_OU[:, :, i]) \n",
    "\n",
    "# load the SNPs simulated for the 3 scenarios. \n",
    "u1 = np.load(\"./trainingSims/Model_1sp.npz\",mmap_mode='r')\n",
    "u2 = np.load(\"./trainingSims/Model_2sp.npz\",mmap_mode='r')\n",
    "u3 = np.load(\"./trainingSims/Model_3sp.npz\",mmap_mode='r')\n",
    "\n",
    "# combine the loaded SNPs in a single NumPy array.\n",
    "X=np.concatenate((u1['Model_1sp'],u2['Model_2sp'],u3['Model_3sp']),axis=0)\n",
    "\n",
    "#transform major alleles in -1 and minor in 1\n",
    "for arr,array in enumerate(X):\n",
    "    for idx,row in enumerate(array):\n",
    "        if np.count_nonzero(row) > len(row)/2:\n",
    "            X[arr][idx][X[arr][idx] == 1] = -1\n",
    "            X[arr][idx][X[arr][idx] == 0] = 1\n",
    "        else:\n",
    "            X[arr][idx][X[arr][idx] == 0] = -1\n",
    "            \n",
    "# create a label vector in the same order as the simulations.\n",
    "y=[0 for i in range(len(u1['Model_1sp']))]\n",
    "y.extend([1 for i in range(len(u2['Model_2sp']))])\n",
    "y.extend([2 for i in range(len(u3['Model_3sp']))])\n",
    "y = np.array(y)\n",
    "\n",
    "# make sure labels, SNP and traits matrices all have the same length.\n",
    "print (len(X), len(y), len(traits_OU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJgkHTL9Tddn",
    "outputId": "1484c604-68b9-4104-f544-9d715256a035",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 1000, 60)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 998, 250)     45000       ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 998, 250)    1000        ['conv1d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 996, 250)     187500      ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 996, 250)    1000        ['conv1d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 994, 250)     187500      ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 994, 250)    1000        ['conv1d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPooling1D)  (None, 331, 250)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 82750)        0           ['max_pooling1d_7[0][0]']        \n",
      "                                                                                                  \n",
      " dense_59_input (InputLayer)    [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_62 (Dense)               (None, 125)          10343875    ['flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_59 (Dense)               (None, 150)          450000      ['dense_59_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 125)          0           ['dense_62[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 150)         600         ['dense_59[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_63 (Dense)               (None, 125)          15750       ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dense_60 (Dense)               (None, 150)          22500       ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 125)          0           ['dense_63[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 150)         600         ['dense_60[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_64 (Dense)               (None, 50)           6300        ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " dense_61 (Dense)               (None, 50)           7550        ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 50)           0           ['dense_64[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_7 (LinearW)           (None, 50)           2           ['dense_61[0][0]',               \n",
      "                                                                  'activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " dense_65 (Dense)               (None, 50)           2550        ['linear_w_7[0][0]']             \n",
      "                                                                                                  \n",
      " dense_66 (Dense)               (None, 3)            153         ['dense_65[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,272,880\n",
      "Trainable params: 11,270,780\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 13s 127ms/step - loss: 13.2537 - accuracy: 0.3441 - val_loss: 13.1025 - val_accuracy: 0.3544\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 13.0257 - accuracy: 0.4437 - val_loss: 12.9720 - val_accuracy: 0.5219\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 12.8708 - accuracy: 0.5340 - val_loss: 12.7787 - val_accuracy: 0.6597\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 12.7277 - accuracy: 0.6076 - val_loss: 12.5994 - val_accuracy: 0.7111\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 12.5961 - accuracy: 0.6659 - val_loss: 12.4468 - val_accuracy: 0.7452\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 12.4818 - accuracy: 0.7036 - val_loss: 12.3002 - val_accuracy: 0.8053\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 12.3556 - accuracy: 0.7509 - val_loss: 12.1579 - val_accuracy: 0.8617\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 12.2400 - accuracy: 0.7883 - val_loss: 12.0386 - val_accuracy: 0.9048\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 12.1254 - accuracy: 0.8288 - val_loss: 11.9214 - val_accuracy: 0.9341\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 12.0211 - accuracy: 0.8575 - val_loss: 11.8236 - val_accuracy: 0.9565\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.9278 - accuracy: 0.8857 - val_loss: 11.7430 - val_accuracy: 0.9671\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.8371 - accuracy: 0.9054 - val_loss: 11.6705 - val_accuracy: 0.9748\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.7600 - accuracy: 0.9212 - val_loss: 11.6028 - val_accuracy: 0.9805\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.6924 - accuracy: 0.9297 - val_loss: 11.5457 - val_accuracy: 0.9827\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.6244 - accuracy: 0.9414 - val_loss: 11.4905 - val_accuracy: 0.9853\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.5598 - accuracy: 0.9507 - val_loss: 11.4369 - val_accuracy: 0.9883\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.5034 - accuracy: 0.9540 - val_loss: 11.3858 - val_accuracy: 0.9916\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.4500 - accuracy: 0.9590 - val_loss: 11.3363 - val_accuracy: 0.9941\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.3939 - accuracy: 0.9657 - val_loss: 11.2920 - val_accuracy: 0.9937\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.3492 - accuracy: 0.9655 - val_loss: 11.2467 - val_accuracy: 0.9945\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.2934 - accuracy: 0.9707 - val_loss: 11.2007 - val_accuracy: 0.9951\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.2484 - accuracy: 0.9709 - val_loss: 11.1599 - val_accuracy: 0.9941\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.1978 - accuracy: 0.9763 - val_loss: 11.1146 - val_accuracy: 0.9957\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.1513 - accuracy: 0.9777 - val_loss: 11.0729 - val_accuracy: 0.9955\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.1053 - accuracy: 0.9796 - val_loss: 11.0306 - val_accuracy: 0.9956\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.0590 - accuracy: 0.9793 - val_loss: 10.9864 - val_accuracy: 0.9969\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.0133 - accuracy: 0.9812 - val_loss: 10.9433 - val_accuracy: 0.9975\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.9692 - accuracy: 0.9817 - val_loss: 10.9016 - val_accuracy: 0.9977\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 10.9256 - accuracy: 0.9824 - val_loss: 10.8593 - val_accuracy: 0.9979\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.8784 - accuracy: 0.9857 - val_loss: 10.8186 - val_accuracy: 0.9977\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.8404 - accuracy: 0.9836 - val_loss: 10.7778 - val_accuracy: 0.9979\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.7968 - accuracy: 0.9856 - val_loss: 10.7363 - val_accuracy: 0.9979\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.7502 - accuracy: 0.9875 - val_loss: 10.6972 - val_accuracy: 0.9977\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.7113 - accuracy: 0.9862 - val_loss: 10.6557 - val_accuracy: 0.9979\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.6666 - accuracy: 0.9891 - val_loss: 10.6150 - val_accuracy: 0.9980\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.6260 - accuracy: 0.9889 - val_loss: 10.5738 - val_accuracy: 0.9980\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.5842 - accuracy: 0.9890 - val_loss: 10.5336 - val_accuracy: 0.9980\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.5453 - accuracy: 0.9890 - val_loss: 10.4934 - val_accuracy: 0.9979\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 10.4987 - accuracy: 0.9908 - val_loss: 10.4525 - val_accuracy: 0.9981\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.4618 - accuracy: 0.9904 - val_loss: 10.4122 - val_accuracy: 0.9983\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.4200 - accuracy: 0.9903 - val_loss: 10.3721 - val_accuracy: 0.9983\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.3779 - accuracy: 0.9908 - val_loss: 10.3338 - val_accuracy: 0.9981\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 10.3390 - accuracy: 0.9897 - val_loss: 10.2926 - val_accuracy: 0.9985\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.2968 - accuracy: 0.9918 - val_loss: 10.2527 - val_accuracy: 0.9985\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.2548 - accuracy: 0.9929 - val_loss: 10.2129 - val_accuracy: 0.9985\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.2134 - accuracy: 0.9928 - val_loss: 10.1734 - val_accuracy: 0.9988\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.1778 - accuracy: 0.9918 - val_loss: 10.1337 - val_accuracy: 0.9989\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.1363 - accuracy: 0.9925 - val_loss: 10.0956 - val_accuracy: 0.9984\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.0932 - accuracy: 0.9939 - val_loss: 10.0563 - val_accuracy: 0.9984\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.0559 - accuracy: 0.9935 - val_loss: 10.0171 - val_accuracy: 0.9984\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.0177 - accuracy: 0.9924 - val_loss: 9.9781 - val_accuracy: 0.9985\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.9784 - accuracy: 0.9934 - val_loss: 9.9392 - val_accuracy: 0.9984\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.9383 - accuracy: 0.9935 - val_loss: 9.9006 - val_accuracy: 0.9984\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.8991 - accuracy: 0.9943 - val_loss: 9.8614 - val_accuracy: 0.9985\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.8583 - accuracy: 0.9947 - val_loss: 9.8225 - val_accuracy: 0.9985\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.8211 - accuracy: 0.9938 - val_loss: 9.7840 - val_accuracy: 0.9985\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.7827 - accuracy: 0.9933 - val_loss: 9.7453 - val_accuracy: 0.9989\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.7431 - accuracy: 0.9940 - val_loss: 9.7067 - val_accuracy: 0.9989\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 9.7037 - accuracy: 0.9945 - val_loss: 9.6684 - val_accuracy: 0.9992\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.6639 - accuracy: 0.9947 - val_loss: 9.6308 - val_accuracy: 0.9988\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.6258 - accuracy: 0.9954 - val_loss: 9.5925 - val_accuracy: 0.9987\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.5886 - accuracy: 0.9950 - val_loss: 9.5541 - val_accuracy: 0.9991\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 9.5497 - accuracy: 0.9949 - val_loss: 9.5164 - val_accuracy: 0.9991\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.5111 - accuracy: 0.9961 - val_loss: 9.4786 - val_accuracy: 0.9987\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 9.4736 - accuracy: 0.9949 - val_loss: 9.4405 - val_accuracy: 0.9989\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.4356 - accuracy: 0.9952 - val_loss: 9.4036 - val_accuracy: 0.9985\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.3973 - accuracy: 0.9952 - val_loss: 9.3652 - val_accuracy: 0.9991\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 9.3589 - accuracy: 0.9959 - val_loss: 9.3279 - val_accuracy: 0.9989\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.3225 - accuracy: 0.9953 - val_loss: 9.2908 - val_accuracy: 0.9988\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.2833 - accuracy: 0.9965 - val_loss: 9.2535 - val_accuracy: 0.9987\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.2465 - accuracy: 0.9959 - val_loss: 9.2152 - val_accuracy: 0.9993\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.2089 - accuracy: 0.9958 - val_loss: 9.1786 - val_accuracy: 0.9991\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.1715 - accuracy: 0.9959 - val_loss: 9.1427 - val_accuracy: 0.9985\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.1337 - accuracy: 0.9968 - val_loss: 9.1052 - val_accuracy: 0.9988\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.0972 - accuracy: 0.9962 - val_loss: 9.0679 - val_accuracy: 0.9991\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.0595 - accuracy: 0.9966 - val_loss: 9.0304 - val_accuracy: 0.9993\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.0234 - accuracy: 0.9964 - val_loss: 8.9942 - val_accuracy: 0.9992\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 8.9860 - accuracy: 0.9968 - val_loss: 8.9580 - val_accuracy: 0.9991\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.9502 - accuracy: 0.9959 - val_loss: 8.9220 - val_accuracy: 0.9988\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.9130 - accuracy: 0.9966 - val_loss: 8.8845 - val_accuracy: 0.9992\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.8761 - accuracy: 0.9964 - val_loss: 8.8488 - val_accuracy: 0.9987\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.8383 - accuracy: 0.9972 - val_loss: 8.8117 - val_accuracy: 0.9992\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.8028 - accuracy: 0.9972 - val_loss: 8.7762 - val_accuracy: 0.9991\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.7675 - accuracy: 0.9964 - val_loss: 8.7400 - val_accuracy: 0.9991\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.7319 - accuracy: 0.9968 - val_loss: 8.7040 - val_accuracy: 0.9992\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.6956 - accuracy: 0.9968 - val_loss: 8.6677 - val_accuracy: 0.9991\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 8.6586 - accuracy: 0.9972 - val_loss: 8.6315 - val_accuracy: 0.9992\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.6212 - accuracy: 0.9976 - val_loss: 8.5964 - val_accuracy: 0.9993\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.5865 - accuracy: 0.9971 - val_loss: 8.5608 - val_accuracy: 0.9991\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.5509 - accuracy: 0.9974 - val_loss: 8.5246 - val_accuracy: 0.9992\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.5154 - accuracy: 0.9972 - val_loss: 8.4895 - val_accuracy: 0.9991\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.4787 - accuracy: 0.9976 - val_loss: 8.4537 - val_accuracy: 0.9992\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.4435 - accuracy: 0.9972 - val_loss: 8.4185 - val_accuracy: 0.9992\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.4085 - accuracy: 0.9974 - val_loss: 8.3833 - val_accuracy: 0.9993\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.3736 - accuracy: 0.9966 - val_loss: 8.3478 - val_accuracy: 0.9993\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.3392 - accuracy: 0.9968 - val_loss: 8.3131 - val_accuracy: 0.9992\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.3019 - accuracy: 0.9976 - val_loss: 8.2774 - val_accuracy: 0.9997\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.2674 - accuracy: 0.9973 - val_loss: 8.2426 - val_accuracy: 0.9996\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.2320 - accuracy: 0.9977 - val_loss: 8.2077 - val_accuracy: 0.9997\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.1967 - accuracy: 0.9979 - val_loss: 8.1727 - val_accuracy: 0.9996\n",
      "Time: 1072.2761232852936\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_100OU_1KSNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "# Combined 100 OU, 1K SNPs\n",
    "################################################################################################################################################\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test  = train_test_split(y,X,traits_OU,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_OU_subset(ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_100OU_1KSNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xtQ2E4REN6GI",
    "outputId": "4b7f5a1b-0b30-4bcc-a7d0-354788cd57d3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_67_input (InputLayer)  [(None, 3000)]           0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 150)               450000    \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 150)               22500     \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 50)                7550      \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 481,403\n",
      "Trainable params: 480,803\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 13.3521 - accuracy: 0.3694 - val_loss: 13.2223 - val_accuracy: 0.3595\n",
      "Epoch 2/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.2252 - accuracy: 0.4050 - val_loss: 13.1526 - val_accuracy: 0.3937\n",
      "Epoch 3/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.1149 - accuracy: 0.4388 - val_loss: 13.0766 - val_accuracy: 0.4285\n",
      "Epoch 4/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.0186 - accuracy: 0.4669 - val_loss: 13.0007 - val_accuracy: 0.4556\n",
      "Epoch 5/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.9289 - accuracy: 0.4937 - val_loss: 12.9267 - val_accuracy: 0.4749\n",
      "Epoch 6/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.8488 - accuracy: 0.5131 - val_loss: 12.8563 - val_accuracy: 0.4937\n",
      "Epoch 7/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.7717 - accuracy: 0.5349 - val_loss: 12.7893 - val_accuracy: 0.5061\n",
      "Epoch 8/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.6987 - accuracy: 0.5517 - val_loss: 12.7255 - val_accuracy: 0.5145\n",
      "Epoch 9/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.6298 - accuracy: 0.5633 - val_loss: 12.6641 - val_accuracy: 0.5261\n",
      "Epoch 10/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.5637 - accuracy: 0.5792 - val_loss: 12.6049 - val_accuracy: 0.5375\n",
      "Epoch 11/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.5006 - accuracy: 0.5896 - val_loss: 12.5474 - val_accuracy: 0.5445\n",
      "Epoch 12/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.4361 - accuracy: 0.5992 - val_loss: 12.4917 - val_accuracy: 0.5492\n",
      "Epoch 13/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.3777 - accuracy: 0.6092 - val_loss: 12.4371 - val_accuracy: 0.5563\n",
      "Epoch 14/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.3175 - accuracy: 0.6199 - val_loss: 12.3837 - val_accuracy: 0.5612\n",
      "Epoch 15/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.2606 - accuracy: 0.6273 - val_loss: 12.3312 - val_accuracy: 0.5663\n",
      "Epoch 16/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.2042 - accuracy: 0.6372 - val_loss: 12.2797 - val_accuracy: 0.5704\n",
      "Epoch 17/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.1472 - accuracy: 0.6413 - val_loss: 12.2289 - val_accuracy: 0.5728\n",
      "Epoch 18/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.0928 - accuracy: 0.6512 - val_loss: 12.1789 - val_accuracy: 0.5760\n",
      "Epoch 19/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.0379 - accuracy: 0.6587 - val_loss: 12.1293 - val_accuracy: 0.5804\n",
      "Epoch 20/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.9845 - accuracy: 0.6652 - val_loss: 12.0804 - val_accuracy: 0.5836\n",
      "Epoch 21/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.9316 - accuracy: 0.6714 - val_loss: 12.0320 - val_accuracy: 0.5864\n",
      "Epoch 22/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.8806 - accuracy: 0.6760 - val_loss: 11.9840 - val_accuracy: 0.5901\n",
      "Epoch 23/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.8280 - accuracy: 0.6834 - val_loss: 11.9366 - val_accuracy: 0.5921\n",
      "Epoch 24/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.7763 - accuracy: 0.6881 - val_loss: 11.8895 - val_accuracy: 0.5951\n",
      "Epoch 25/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.7250 - accuracy: 0.6940 - val_loss: 11.8428 - val_accuracy: 0.5980\n",
      "Epoch 26/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.6741 - accuracy: 0.7026 - val_loss: 11.7964 - val_accuracy: 0.6007\n",
      "Epoch 27/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.6225 - accuracy: 0.7057 - val_loss: 11.7505 - val_accuracy: 0.6008\n",
      "Epoch 28/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.5740 - accuracy: 0.7104 - val_loss: 11.7049 - val_accuracy: 0.6020\n",
      "Epoch 29/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.5248 - accuracy: 0.7164 - val_loss: 11.6595 - val_accuracy: 0.6037\n",
      "Epoch 30/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.4750 - accuracy: 0.7203 - val_loss: 11.6146 - val_accuracy: 0.6063\n",
      "Epoch 31/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.4249 - accuracy: 0.7273 - val_loss: 11.5698 - val_accuracy: 0.6091\n",
      "Epoch 32/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.3768 - accuracy: 0.7328 - val_loss: 11.5253 - val_accuracy: 0.6113\n",
      "Epoch 33/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.3276 - accuracy: 0.7356 - val_loss: 11.4810 - val_accuracy: 0.6128\n",
      "Epoch 34/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.2804 - accuracy: 0.7390 - val_loss: 11.4369 - val_accuracy: 0.6147\n",
      "Epoch 35/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.2319 - accuracy: 0.7476 - val_loss: 11.3929 - val_accuracy: 0.6160\n",
      "Epoch 36/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.1836 - accuracy: 0.7520 - val_loss: 11.3495 - val_accuracy: 0.6172\n",
      "Epoch 37/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.1362 - accuracy: 0.7562 - val_loss: 11.3060 - val_accuracy: 0.6179\n",
      "Epoch 38/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.0888 - accuracy: 0.7603 - val_loss: 11.2627 - val_accuracy: 0.6199\n",
      "Epoch 39/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.0420 - accuracy: 0.7641 - val_loss: 11.2196 - val_accuracy: 0.6216\n",
      "Epoch 40/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.9952 - accuracy: 0.7670 - val_loss: 11.1768 - val_accuracy: 0.6236\n",
      "Epoch 41/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.9495 - accuracy: 0.7712 - val_loss: 11.1342 - val_accuracy: 0.6239\n",
      "Epoch 42/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.9023 - accuracy: 0.7744 - val_loss: 11.0919 - val_accuracy: 0.6245\n",
      "Epoch 43/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.8555 - accuracy: 0.7809 - val_loss: 11.0496 - val_accuracy: 0.6256\n",
      "Epoch 44/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.8095 - accuracy: 0.7868 - val_loss: 11.0075 - val_accuracy: 0.6285\n",
      "Epoch 45/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.7639 - accuracy: 0.7893 - val_loss: 10.9655 - val_accuracy: 0.6301\n",
      "Epoch 46/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.7183 - accuracy: 0.7927 - val_loss: 10.9238 - val_accuracy: 0.6319\n",
      "Epoch 47/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.6725 - accuracy: 0.7953 - val_loss: 10.8823 - val_accuracy: 0.6333\n",
      "Epoch 48/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.6268 - accuracy: 0.8024 - val_loss: 10.8409 - val_accuracy: 0.6365\n",
      "Epoch 49/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.5816 - accuracy: 0.8061 - val_loss: 10.7995 - val_accuracy: 0.6376\n",
      "Epoch 50/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.5348 - accuracy: 0.8104 - val_loss: 10.7583 - val_accuracy: 0.6392\n",
      "Epoch 51/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.4913 - accuracy: 0.8117 - val_loss: 10.7174 - val_accuracy: 0.6397\n",
      "Epoch 52/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.4471 - accuracy: 0.8161 - val_loss: 10.6765 - val_accuracy: 0.6423\n",
      "Epoch 53/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.4005 - accuracy: 0.8204 - val_loss: 10.6360 - val_accuracy: 0.6432\n",
      "Epoch 54/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.3577 - accuracy: 0.8232 - val_loss: 10.5954 - val_accuracy: 0.6439\n",
      "Epoch 55/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.3110 - accuracy: 0.8276 - val_loss: 10.5551 - val_accuracy: 0.6441\n",
      "Epoch 56/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.2681 - accuracy: 0.8313 - val_loss: 10.5149 - val_accuracy: 0.6447\n",
      "Epoch 57/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.2233 - accuracy: 0.8354 - val_loss: 10.4749 - val_accuracy: 0.6452\n",
      "Epoch 58/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.1799 - accuracy: 0.8384 - val_loss: 10.4348 - val_accuracy: 0.6469\n",
      "Epoch 59/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.1364 - accuracy: 0.8405 - val_loss: 10.3950 - val_accuracy: 0.6475\n",
      "Epoch 60/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.0912 - accuracy: 0.8445 - val_loss: 10.3554 - val_accuracy: 0.6484\n",
      "Epoch 61/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.0478 - accuracy: 0.8491 - val_loss: 10.3158 - val_accuracy: 0.6483\n",
      "Epoch 62/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.0051 - accuracy: 0.8504 - val_loss: 10.2765 - val_accuracy: 0.6492\n",
      "Epoch 63/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.9605 - accuracy: 0.8554 - val_loss: 10.2370 - val_accuracy: 0.6501\n",
      "Epoch 64/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.9181 - accuracy: 0.8587 - val_loss: 10.1979 - val_accuracy: 0.6508\n",
      "Epoch 65/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.8737 - accuracy: 0.8611 - val_loss: 10.1588 - val_accuracy: 0.6519\n",
      "Epoch 66/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.8317 - accuracy: 0.8617 - val_loss: 10.1200 - val_accuracy: 0.6533\n",
      "Epoch 67/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.7882 - accuracy: 0.8683 - val_loss: 10.0811 - val_accuracy: 0.6549\n",
      "Epoch 68/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.7455 - accuracy: 0.8715 - val_loss: 10.0424 - val_accuracy: 0.6556\n",
      "Epoch 69/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.7025 - accuracy: 0.8738 - val_loss: 10.0038 - val_accuracy: 0.6572\n",
      "Epoch 70/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.6619 - accuracy: 0.8760 - val_loss: 9.9652 - val_accuracy: 0.6585\n",
      "Epoch 71/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.6190 - accuracy: 0.8794 - val_loss: 9.9269 - val_accuracy: 0.6595\n",
      "Epoch 72/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.5743 - accuracy: 0.8843 - val_loss: 9.8888 - val_accuracy: 0.6605\n",
      "Epoch 73/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.5348 - accuracy: 0.8840 - val_loss: 9.8505 - val_accuracy: 0.6617\n",
      "Epoch 74/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.4913 - accuracy: 0.8876 - val_loss: 9.8127 - val_accuracy: 0.6619\n",
      "Epoch 75/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.4493 - accuracy: 0.8912 - val_loss: 9.7748 - val_accuracy: 0.6639\n",
      "Epoch 76/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.4081 - accuracy: 0.8940 - val_loss: 9.7369 - val_accuracy: 0.6644\n",
      "Epoch 77/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.3665 - accuracy: 0.8974 - val_loss: 9.6994 - val_accuracy: 0.6647\n",
      "Epoch 78/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.3238 - accuracy: 0.8999 - val_loss: 9.6618 - val_accuracy: 0.6656\n",
      "Epoch 79/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.2826 - accuracy: 0.9032 - val_loss: 9.6243 - val_accuracy: 0.6663\n",
      "Epoch 80/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.2426 - accuracy: 0.9042 - val_loss: 9.5869 - val_accuracy: 0.6676\n",
      "Epoch 81/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.1999 - accuracy: 0.9093 - val_loss: 9.5499 - val_accuracy: 0.6685\n",
      "Epoch 82/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.1593 - accuracy: 0.9113 - val_loss: 9.5126 - val_accuracy: 0.6687\n",
      "Epoch 83/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.1183 - accuracy: 0.9121 - val_loss: 9.4759 - val_accuracy: 0.6696\n",
      "Epoch 84/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.0783 - accuracy: 0.9141 - val_loss: 9.4389 - val_accuracy: 0.6703\n",
      "Epoch 85/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.0374 - accuracy: 0.9162 - val_loss: 9.4020 - val_accuracy: 0.6725\n",
      "Epoch 86/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.9948 - accuracy: 0.9205 - val_loss: 9.3653 - val_accuracy: 0.6736\n",
      "Epoch 87/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.9553 - accuracy: 0.9228 - val_loss: 9.3287 - val_accuracy: 0.6744\n",
      "Epoch 88/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.9154 - accuracy: 0.9248 - val_loss: 9.2921 - val_accuracy: 0.6753\n",
      "Epoch 89/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.8755 - accuracy: 0.9268 - val_loss: 9.2558 - val_accuracy: 0.6767\n",
      "Epoch 90/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.8353 - accuracy: 0.9292 - val_loss: 9.2193 - val_accuracy: 0.6783\n",
      "Epoch 91/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.7951 - accuracy: 0.9311 - val_loss: 9.1831 - val_accuracy: 0.6784\n",
      "Epoch 92/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.7558 - accuracy: 0.9336 - val_loss: 9.1469 - val_accuracy: 0.6791\n",
      "Epoch 93/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.7168 - accuracy: 0.9347 - val_loss: 9.1111 - val_accuracy: 0.6805\n",
      "Epoch 94/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.6750 - accuracy: 0.9386 - val_loss: 9.0752 - val_accuracy: 0.6820\n",
      "Epoch 95/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.6360 - accuracy: 0.9402 - val_loss: 9.0396 - val_accuracy: 0.6827\n",
      "Epoch 96/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.5974 - accuracy: 0.9415 - val_loss: 9.0037 - val_accuracy: 0.6836\n",
      "Epoch 97/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.5574 - accuracy: 0.9461 - val_loss: 8.9680 - val_accuracy: 0.6845\n",
      "Epoch 98/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.5187 - accuracy: 0.9461 - val_loss: 8.9326 - val_accuracy: 0.6855\n",
      "Epoch 99/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.4791 - accuracy: 0.9478 - val_loss: 8.8971 - val_accuracy: 0.6871\n",
      "Epoch 100/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.4396 - accuracy: 0.9506 - val_loss: 8.8618 - val_accuracy: 0.6873\n",
      "Epoch 101/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.4023 - accuracy: 0.9504 - val_loss: 8.8269 - val_accuracy: 0.6879\n",
      "Epoch 102/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.3633 - accuracy: 0.9532 - val_loss: 8.7916 - val_accuracy: 0.6885\n",
      "Epoch 103/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.3248 - accuracy: 0.9547 - val_loss: 8.7565 - val_accuracy: 0.6891\n",
      "Epoch 104/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.2872 - accuracy: 0.9575 - val_loss: 8.7219 - val_accuracy: 0.6905\n",
      "Epoch 105/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.2480 - accuracy: 0.9582 - val_loss: 8.6871 - val_accuracy: 0.6920\n",
      "Epoch 106/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.2106 - accuracy: 0.9585 - val_loss: 8.6524 - val_accuracy: 0.6923\n",
      "Epoch 107/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.1719 - accuracy: 0.9628 - val_loss: 8.6175 - val_accuracy: 0.6935\n",
      "Epoch 108/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.1352 - accuracy: 0.9632 - val_loss: 8.5830 - val_accuracy: 0.6949\n",
      "Epoch 109/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.0965 - accuracy: 0.9648 - val_loss: 8.5485 - val_accuracy: 0.6960\n",
      "Epoch 110/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.0595 - accuracy: 0.9657 - val_loss: 8.5143 - val_accuracy: 0.6972\n",
      "Epoch 111/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.0210 - accuracy: 0.9672 - val_loss: 8.4802 - val_accuracy: 0.6980\n",
      "Epoch 112/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9845 - accuracy: 0.9698 - val_loss: 8.4460 - val_accuracy: 0.6984\n",
      "Epoch 113/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9473 - accuracy: 0.9712 - val_loss: 8.4120 - val_accuracy: 0.6997\n",
      "Epoch 114/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9104 - accuracy: 0.9708 - val_loss: 8.3778 - val_accuracy: 0.6997\n",
      "Epoch 115/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.8724 - accuracy: 0.9744 - val_loss: 8.3440 - val_accuracy: 0.7009\n",
      "Epoch 116/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.8371 - accuracy: 0.9736 - val_loss: 8.3101 - val_accuracy: 0.7017\n",
      "Epoch 117/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.8005 - accuracy: 0.9756 - val_loss: 8.2766 - val_accuracy: 0.7028\n",
      "Epoch 118/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.7634 - accuracy: 0.9757 - val_loss: 8.2429 - val_accuracy: 0.7033\n",
      "Epoch 119/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.7270 - accuracy: 0.9774 - val_loss: 8.2096 - val_accuracy: 0.7043\n",
      "Epoch 120/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.6902 - accuracy: 0.9792 - val_loss: 8.1764 - val_accuracy: 0.7044\n",
      "Epoch 121/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.6548 - accuracy: 0.9785 - val_loss: 8.1429 - val_accuracy: 0.7051\n",
      "Epoch 122/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.6184 - accuracy: 0.9804 - val_loss: 8.1094 - val_accuracy: 0.7065\n",
      "Epoch 123/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.5830 - accuracy: 0.9813 - val_loss: 8.0761 - val_accuracy: 0.7073\n",
      "Epoch 124/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.5480 - accuracy: 0.9819 - val_loss: 8.0431 - val_accuracy: 0.7088\n",
      "Epoch 125/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.5115 - accuracy: 0.9832 - val_loss: 8.0103 - val_accuracy: 0.7100\n",
      "Epoch 126/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4763 - accuracy: 0.9833 - val_loss: 7.9772 - val_accuracy: 0.7105\n",
      "Epoch 127/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4408 - accuracy: 0.9844 - val_loss: 7.9450 - val_accuracy: 0.7107\n",
      "Epoch 128/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4052 - accuracy: 0.9859 - val_loss: 7.9125 - val_accuracy: 0.7112\n",
      "Epoch 129/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.3705 - accuracy: 0.9865 - val_loss: 7.8799 - val_accuracy: 0.7108\n",
      "Epoch 130/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.3357 - accuracy: 0.9865 - val_loss: 7.8475 - val_accuracy: 0.7115\n",
      "Epoch 131/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.3014 - accuracy: 0.9872 - val_loss: 7.8151 - val_accuracy: 0.7125\n",
      "Epoch 132/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.2661 - accuracy: 0.9879 - val_loss: 7.7829 - val_accuracy: 0.7141\n",
      "Epoch 133/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.2311 - accuracy: 0.9894 - val_loss: 7.7506 - val_accuracy: 0.7152\n",
      "Epoch 134/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1980 - accuracy: 0.9897 - val_loss: 7.7185 - val_accuracy: 0.7151\n",
      "Epoch 135/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1633 - accuracy: 0.9904 - val_loss: 7.6866 - val_accuracy: 0.7168\n",
      "Epoch 136/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1298 - accuracy: 0.9900 - val_loss: 7.6549 - val_accuracy: 0.7171\n",
      "Epoch 137/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0959 - accuracy: 0.9912 - val_loss: 7.6225 - val_accuracy: 0.7180\n",
      "Epoch 138/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0603 - accuracy: 0.9924 - val_loss: 7.5911 - val_accuracy: 0.7189\n",
      "Epoch 139/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0283 - accuracy: 0.9924 - val_loss: 7.5598 - val_accuracy: 0.7199\n",
      "Epoch 140/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9940 - accuracy: 0.9925 - val_loss: 7.5282 - val_accuracy: 0.7196\n",
      "Epoch 141/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9607 - accuracy: 0.9929 - val_loss: 7.4966 - val_accuracy: 0.7211\n",
      "Epoch 142/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9267 - accuracy: 0.9939 - val_loss: 7.4652 - val_accuracy: 0.7212\n",
      "Epoch 143/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8941 - accuracy: 0.9942 - val_loss: 7.4338 - val_accuracy: 0.7221\n",
      "Epoch 144/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8606 - accuracy: 0.9948 - val_loss: 7.4029 - val_accuracy: 0.7229\n",
      "Epoch 145/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8285 - accuracy: 0.9941 - val_loss: 7.3718 - val_accuracy: 0.7240\n",
      "Epoch 146/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7949 - accuracy: 0.9952 - val_loss: 7.3412 - val_accuracy: 0.7241\n",
      "Epoch 147/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7623 - accuracy: 0.9951 - val_loss: 7.3101 - val_accuracy: 0.7245\n",
      "Epoch 148/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7292 - accuracy: 0.9958 - val_loss: 7.2790 - val_accuracy: 0.7257\n",
      "Epoch 149/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6973 - accuracy: 0.9957 - val_loss: 7.2488 - val_accuracy: 0.7265\n",
      "Epoch 150/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6644 - accuracy: 0.9964 - val_loss: 7.2177 - val_accuracy: 0.7267\n",
      "Epoch 151/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6329 - accuracy: 0.9965 - val_loss: 7.1868 - val_accuracy: 0.7285\n",
      "Epoch 152/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6011 - accuracy: 0.9968 - val_loss: 7.1564 - val_accuracy: 0.7287\n",
      "Epoch 153/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5695 - accuracy: 0.9970 - val_loss: 7.1258 - val_accuracy: 0.7303\n",
      "Epoch 154/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5363 - accuracy: 0.9970 - val_loss: 7.0955 - val_accuracy: 0.7312\n",
      "Epoch 155/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5057 - accuracy: 0.9972 - val_loss: 7.0653 - val_accuracy: 0.7309\n",
      "Epoch 156/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4738 - accuracy: 0.9969 - val_loss: 7.0350 - val_accuracy: 0.7316\n",
      "Epoch 157/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4421 - accuracy: 0.9974 - val_loss: 7.0047 - val_accuracy: 0.7321\n",
      "Epoch 158/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4107 - accuracy: 0.9979 - val_loss: 6.9746 - val_accuracy: 0.7321\n",
      "Epoch 159/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3797 - accuracy: 0.9982 - val_loss: 6.9444 - val_accuracy: 0.7331\n",
      "Epoch 160/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3485 - accuracy: 0.9982 - val_loss: 6.9150 - val_accuracy: 0.7343\n",
      "Epoch 161/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3176 - accuracy: 0.9985 - val_loss: 6.8854 - val_accuracy: 0.7349\n",
      "Epoch 162/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2868 - accuracy: 0.9986 - val_loss: 6.8553 - val_accuracy: 0.7364\n",
      "Epoch 163/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2555 - accuracy: 0.9986 - val_loss: 6.8256 - val_accuracy: 0.7364\n",
      "Epoch 164/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2254 - accuracy: 0.9990 - val_loss: 6.7966 - val_accuracy: 0.7364\n",
      "Epoch 165/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1946 - accuracy: 0.9988 - val_loss: 6.7672 - val_accuracy: 0.7368\n",
      "Epoch 166/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1648 - accuracy: 0.9991 - val_loss: 6.7370 - val_accuracy: 0.7375\n",
      "Epoch 167/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1340 - accuracy: 0.9990 - val_loss: 6.7077 - val_accuracy: 0.7367\n",
      "Epoch 168/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1043 - accuracy: 0.9990 - val_loss: 6.6789 - val_accuracy: 0.7387\n",
      "Epoch 169/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0742 - accuracy: 0.9994 - val_loss: 6.6501 - val_accuracy: 0.7400\n",
      "Epoch 170/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0445 - accuracy: 0.9993 - val_loss: 6.6208 - val_accuracy: 0.7404\n",
      "Epoch 171/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0140 - accuracy: 0.9994 - val_loss: 6.5918 - val_accuracy: 0.7405\n",
      "Epoch 172/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9843 - accuracy: 0.9994 - val_loss: 6.5624 - val_accuracy: 0.7421\n",
      "Epoch 173/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9551 - accuracy: 0.9995 - val_loss: 6.5342 - val_accuracy: 0.7432\n",
      "Epoch 174/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9251 - accuracy: 0.9992 - val_loss: 6.5051 - val_accuracy: 0.7435\n",
      "Epoch 175/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8957 - accuracy: 0.9997 - val_loss: 6.4762 - val_accuracy: 0.7441\n",
      "Epoch 176/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8658 - accuracy: 0.9996 - val_loss: 6.4480 - val_accuracy: 0.7451\n",
      "Epoch 177/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8369 - accuracy: 0.9996 - val_loss: 6.4197 - val_accuracy: 0.7456\n",
      "Epoch 178/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8079 - accuracy: 0.9995 - val_loss: 6.3913 - val_accuracy: 0.7471\n",
      "Epoch 179/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7789 - accuracy: 0.9997 - val_loss: 6.3630 - val_accuracy: 0.7468\n",
      "Epoch 180/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7506 - accuracy: 0.9996 - val_loss: 6.3345 - val_accuracy: 0.7473\n",
      "Epoch 181/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7213 - accuracy: 0.9997 - val_loss: 6.3062 - val_accuracy: 0.7473\n",
      "Epoch 182/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6928 - accuracy: 0.9996 - val_loss: 6.2777 - val_accuracy: 0.7480\n",
      "Epoch 183/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6643 - accuracy: 0.9998 - val_loss: 6.2499 - val_accuracy: 0.7491\n",
      "Epoch 184/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6351 - accuracy: 0.9997 - val_loss: 6.2221 - val_accuracy: 0.7499\n",
      "Epoch 185/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6071 - accuracy: 0.9998 - val_loss: 6.1945 - val_accuracy: 0.7499\n",
      "Epoch 186/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5791 - accuracy: 0.9997 - val_loss: 6.1669 - val_accuracy: 0.7503\n",
      "Epoch 187/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5508 - accuracy: 0.9998 - val_loss: 6.1393 - val_accuracy: 0.7517\n",
      "Epoch 188/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5225 - accuracy: 0.9998 - val_loss: 6.1118 - val_accuracy: 0.7508\n",
      "Epoch 189/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4951 - accuracy: 0.9998 - val_loss: 6.0847 - val_accuracy: 0.7516\n",
      "Epoch 190/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4664 - accuracy: 0.9998 - val_loss: 6.0573 - val_accuracy: 0.7524\n",
      "Epoch 191/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4395 - accuracy: 0.9998 - val_loss: 6.0298 - val_accuracy: 0.7525\n",
      "Epoch 192/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4112 - accuracy: 0.9998 - val_loss: 6.0028 - val_accuracy: 0.7536\n",
      "Epoch 193/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3835 - accuracy: 0.9998 - val_loss: 5.9758 - val_accuracy: 0.7535\n",
      "Epoch 194/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3564 - accuracy: 0.9999 - val_loss: 5.9484 - val_accuracy: 0.7544\n",
      "Epoch 195/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3291 - accuracy: 1.0000 - val_loss: 5.9221 - val_accuracy: 0.7543\n",
      "Epoch 196/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3019 - accuracy: 0.9999 - val_loss: 5.8948 - val_accuracy: 0.7539\n",
      "Epoch 197/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2749 - accuracy: 0.9999 - val_loss: 5.8682 - val_accuracy: 0.7552\n",
      "Epoch 198/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2477 - accuracy: 0.9999 - val_loss: 5.8415 - val_accuracy: 0.7548\n",
      "Epoch 199/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2200 - accuracy: 0.9999 - val_loss: 5.8150 - val_accuracy: 0.7549\n",
      "Epoch 200/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1939 - accuracy: 0.9999 - val_loss: 5.7885 - val_accuracy: 0.7567\n",
      "Epoch 201/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1668 - accuracy: 1.0000 - val_loss: 5.7619 - val_accuracy: 0.7571\n",
      "Epoch 202/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1405 - accuracy: 1.0000 - val_loss: 5.7351 - val_accuracy: 0.7577\n",
      "Epoch 203/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1138 - accuracy: 1.0000 - val_loss: 5.7091 - val_accuracy: 0.7585\n",
      "Epoch 204/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0871 - accuracy: 0.9999 - val_loss: 5.6828 - val_accuracy: 0.7591\n",
      "Epoch 205/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0611 - accuracy: 1.0000 - val_loss: 5.6569 - val_accuracy: 0.7595\n",
      "Epoch 206/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0350 - accuracy: 1.0000 - val_loss: 5.6310 - val_accuracy: 0.7607\n",
      "Epoch 207/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0083 - accuracy: 0.9999 - val_loss: 5.6051 - val_accuracy: 0.7611\n",
      "Epoch 208/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9823 - accuracy: 1.0000 - val_loss: 5.5793 - val_accuracy: 0.7616\n",
      "Epoch 209/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9564 - accuracy: 1.0000 - val_loss: 5.5537 - val_accuracy: 0.7620\n",
      "Epoch 210/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9303 - accuracy: 1.0000 - val_loss: 5.5278 - val_accuracy: 0.7619\n",
      "Epoch 211/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9046 - accuracy: 1.0000 - val_loss: 5.5024 - val_accuracy: 0.7623\n",
      "Epoch 212/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8790 - accuracy: 1.0000 - val_loss: 5.4769 - val_accuracy: 0.7621\n",
      "Epoch 213/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8532 - accuracy: 1.0000 - val_loss: 5.4518 - val_accuracy: 0.7633\n",
      "Epoch 214/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8282 - accuracy: 1.0000 - val_loss: 5.4264 - val_accuracy: 0.7639\n",
      "Epoch 215/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8027 - accuracy: 1.0000 - val_loss: 5.4007 - val_accuracy: 0.7645\n",
      "Epoch 216/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7775 - accuracy: 1.0000 - val_loss: 5.3755 - val_accuracy: 0.7636\n",
      "Epoch 217/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7523 - accuracy: 1.0000 - val_loss: 5.3508 - val_accuracy: 0.7640\n",
      "Epoch 218/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7268 - accuracy: 1.0000 - val_loss: 5.3261 - val_accuracy: 0.7648\n",
      "Epoch 219/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7017 - accuracy: 1.0000 - val_loss: 5.3007 - val_accuracy: 0.7647\n",
      "Epoch 220/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6770 - accuracy: 1.0000 - val_loss: 5.2759 - val_accuracy: 0.7659\n",
      "Epoch 221/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6522 - accuracy: 1.0000 - val_loss: 5.2507 - val_accuracy: 0.7657\n",
      "Epoch 222/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6278 - accuracy: 1.0000 - val_loss: 5.2264 - val_accuracy: 0.7659\n",
      "Epoch 223/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6027 - accuracy: 1.0000 - val_loss: 5.2014 - val_accuracy: 0.7673\n",
      "Epoch 224/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5780 - accuracy: 1.0000 - val_loss: 5.1763 - val_accuracy: 0.7676\n",
      "Epoch 225/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5537 - accuracy: 1.0000 - val_loss: 5.1525 - val_accuracy: 0.7679\n",
      "Epoch 226/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5293 - accuracy: 1.0000 - val_loss: 5.1281 - val_accuracy: 0.7692\n",
      "Epoch 227/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5047 - accuracy: 1.0000 - val_loss: 5.1036 - val_accuracy: 0.7695\n",
      "Epoch 228/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4805 - accuracy: 1.0000 - val_loss: 5.0795 - val_accuracy: 0.7703\n",
      "Epoch 229/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4564 - accuracy: 1.0000 - val_loss: 5.0559 - val_accuracy: 0.7707\n",
      "Epoch 230/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4327 - accuracy: 1.0000 - val_loss: 5.0319 - val_accuracy: 0.7712\n",
      "Epoch 231/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4086 - accuracy: 1.0000 - val_loss: 5.0075 - val_accuracy: 0.7717\n",
      "Epoch 232/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3848 - accuracy: 1.0000 - val_loss: 4.9837 - val_accuracy: 0.7717\n",
      "Epoch 233/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3615 - accuracy: 1.0000 - val_loss: 4.9598 - val_accuracy: 0.7720\n",
      "Epoch 234/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3372 - accuracy: 1.0000 - val_loss: 4.9358 - val_accuracy: 0.7728\n",
      "Epoch 235/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3139 - accuracy: 1.0000 - val_loss: 4.9127 - val_accuracy: 0.7732\n",
      "Epoch 236/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2907 - accuracy: 1.0000 - val_loss: 4.8890 - val_accuracy: 0.7735\n",
      "Epoch 237/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2670 - accuracy: 1.0000 - val_loss: 4.8654 - val_accuracy: 0.7740\n",
      "Epoch 238/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2439 - accuracy: 1.0000 - val_loss: 4.8421 - val_accuracy: 0.7748\n",
      "Epoch 239/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2202 - accuracy: 1.0000 - val_loss: 4.8185 - val_accuracy: 0.7749\n",
      "Epoch 240/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1973 - accuracy: 1.0000 - val_loss: 4.7956 - val_accuracy: 0.7760\n",
      "Epoch 241/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1749 - accuracy: 1.0000 - val_loss: 4.7726 - val_accuracy: 0.7761\n",
      "Epoch 242/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1517 - accuracy: 1.0000 - val_loss: 4.7498 - val_accuracy: 0.7761\n",
      "Epoch 243/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1291 - accuracy: 1.0000 - val_loss: 4.7271 - val_accuracy: 0.7769\n",
      "Epoch 244/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1060 - accuracy: 1.0000 - val_loss: 4.7037 - val_accuracy: 0.7779\n",
      "Epoch 245/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0832 - accuracy: 1.0000 - val_loss: 4.6807 - val_accuracy: 0.7788\n",
      "Epoch 246/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0609 - accuracy: 1.0000 - val_loss: 4.6584 - val_accuracy: 0.7791\n",
      "Epoch 247/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0383 - accuracy: 1.0000 - val_loss: 4.6359 - val_accuracy: 0.7795\n",
      "Epoch 248/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0160 - accuracy: 1.0000 - val_loss: 4.6133 - val_accuracy: 0.7803\n",
      "Epoch 249/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9939 - accuracy: 1.0000 - val_loss: 4.5906 - val_accuracy: 0.7807\n",
      "Epoch 250/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9711 - accuracy: 1.0000 - val_loss: 4.5684 - val_accuracy: 0.7812\n",
      "Epoch 251/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9495 - accuracy: 1.0000 - val_loss: 4.5463 - val_accuracy: 0.7811\n",
      "Epoch 252/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9276 - accuracy: 1.0000 - val_loss: 4.5243 - val_accuracy: 0.7816\n",
      "Epoch 253/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9054 - accuracy: 1.0000 - val_loss: 4.5025 - val_accuracy: 0.7809\n",
      "Epoch 254/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8840 - accuracy: 1.0000 - val_loss: 4.4810 - val_accuracy: 0.7816\n",
      "Epoch 255/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8621 - accuracy: 1.0000 - val_loss: 4.4586 - val_accuracy: 0.7816\n",
      "Epoch 256/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8402 - accuracy: 1.0000 - val_loss: 4.4366 - val_accuracy: 0.7817\n",
      "Epoch 257/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8189 - accuracy: 1.0000 - val_loss: 4.4149 - val_accuracy: 0.7819\n",
      "Epoch 258/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7973 - accuracy: 1.0000 - val_loss: 4.3934 - val_accuracy: 0.7824\n",
      "Epoch 259/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7762 - accuracy: 1.0000 - val_loss: 4.3710 - val_accuracy: 0.7827\n",
      "Epoch 260/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7551 - accuracy: 1.0000 - val_loss: 4.3499 - val_accuracy: 0.7823\n",
      "Epoch 261/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7335 - accuracy: 1.0000 - val_loss: 4.3281 - val_accuracy: 0.7831\n",
      "Epoch 262/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7124 - accuracy: 1.0000 - val_loss: 4.3070 - val_accuracy: 0.7839\n",
      "Epoch 263/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6919 - accuracy: 1.0000 - val_loss: 4.2854 - val_accuracy: 0.7839\n",
      "Epoch 264/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6704 - accuracy: 1.0000 - val_loss: 4.2638 - val_accuracy: 0.7827\n",
      "Epoch 265/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6499 - accuracy: 1.0000 - val_loss: 4.2426 - val_accuracy: 0.7836\n",
      "Epoch 266/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6291 - accuracy: 1.0000 - val_loss: 4.2223 - val_accuracy: 0.7839\n",
      "Epoch 267/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6087 - accuracy: 1.0000 - val_loss: 4.2018 - val_accuracy: 0.7836\n",
      "Epoch 268/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5883 - accuracy: 1.0000 - val_loss: 4.1806 - val_accuracy: 0.7840\n",
      "Epoch 269/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5673 - accuracy: 1.0000 - val_loss: 4.1600 - val_accuracy: 0.7833\n",
      "Epoch 270/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5472 - accuracy: 1.0000 - val_loss: 4.1392 - val_accuracy: 0.7832\n",
      "Epoch 271/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5271 - accuracy: 1.0000 - val_loss: 4.1191 - val_accuracy: 0.7841\n",
      "Epoch 272/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5063 - accuracy: 1.0000 - val_loss: 4.0989 - val_accuracy: 0.7836\n",
      "Epoch 273/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4866 - accuracy: 1.0000 - val_loss: 4.0784 - val_accuracy: 0.7829\n",
      "Epoch 274/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4665 - accuracy: 1.0000 - val_loss: 4.0576 - val_accuracy: 0.7839\n",
      "Epoch 275/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4467 - accuracy: 1.0000 - val_loss: 4.0373 - val_accuracy: 0.7843\n",
      "Epoch 276/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4272 - accuracy: 1.0000 - val_loss: 4.0165 - val_accuracy: 0.7848\n",
      "Epoch 277/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4071 - accuracy: 1.0000 - val_loss: 3.9972 - val_accuracy: 0.7849\n",
      "Epoch 278/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3877 - accuracy: 1.0000 - val_loss: 3.9776 - val_accuracy: 0.7852\n",
      "Epoch 279/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3680 - accuracy: 1.0000 - val_loss: 3.9582 - val_accuracy: 0.7849\n",
      "Epoch 280/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3488 - accuracy: 1.0000 - val_loss: 3.9383 - val_accuracy: 0.7856\n",
      "Epoch 281/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3293 - accuracy: 1.0000 - val_loss: 3.9184 - val_accuracy: 0.7861\n",
      "Epoch 282/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3098 - accuracy: 1.0000 - val_loss: 3.8988 - val_accuracy: 0.7860\n",
      "Epoch 283/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2910 - accuracy: 1.0000 - val_loss: 3.8790 - val_accuracy: 0.7864\n",
      "Epoch 284/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2716 - accuracy: 1.0000 - val_loss: 3.8595 - val_accuracy: 0.7860\n",
      "Epoch 285/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2529 - accuracy: 1.0000 - val_loss: 3.8401 - val_accuracy: 0.7869\n",
      "Epoch 286/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2339 - accuracy: 1.0000 - val_loss: 3.8214 - val_accuracy: 0.7871\n",
      "Epoch 287/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2152 - accuracy: 1.0000 - val_loss: 3.8028 - val_accuracy: 0.7873\n",
      "Epoch 288/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1963 - accuracy: 1.0000 - val_loss: 3.7836 - val_accuracy: 0.7875\n",
      "Epoch 289/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1778 - accuracy: 1.0000 - val_loss: 3.7649 - val_accuracy: 0.7883\n",
      "Epoch 290/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1593 - accuracy: 1.0000 - val_loss: 3.7462 - val_accuracy: 0.7889\n",
      "Epoch 291/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1406 - accuracy: 1.0000 - val_loss: 3.7272 - val_accuracy: 0.7900\n",
      "Epoch 292/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1222 - accuracy: 1.0000 - val_loss: 3.7087 - val_accuracy: 0.7905\n",
      "Epoch 293/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1042 - accuracy: 1.0000 - val_loss: 3.6899 - val_accuracy: 0.7904\n",
      "Epoch 294/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0862 - accuracy: 1.0000 - val_loss: 3.6717 - val_accuracy: 0.7907\n",
      "Epoch 295/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0679 - accuracy: 1.0000 - val_loss: 3.6533 - val_accuracy: 0.7916\n",
      "Epoch 296/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0497 - accuracy: 1.0000 - val_loss: 3.6343 - val_accuracy: 0.7908\n",
      "Epoch 297/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0317 - accuracy: 1.0000 - val_loss: 3.6166 - val_accuracy: 0.7913\n",
      "Epoch 298/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0140 - accuracy: 1.0000 - val_loss: 3.5976 - val_accuracy: 0.7907\n",
      "Epoch 299/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9964 - accuracy: 1.0000 - val_loss: 3.5802 - val_accuracy: 0.7915\n",
      "Epoch 300/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9789 - accuracy: 1.0000 - val_loss: 3.5616 - val_accuracy: 0.7924\n",
      "Epoch 301/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9614 - accuracy: 1.0000 - val_loss: 3.5438 - val_accuracy: 0.7927\n",
      "Epoch 302/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9441 - accuracy: 1.0000 - val_loss: 3.5257 - val_accuracy: 0.7928\n",
      "Epoch 303/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9265 - accuracy: 1.0000 - val_loss: 3.5079 - val_accuracy: 0.7932\n",
      "Epoch 304/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9090 - accuracy: 1.0000 - val_loss: 3.4906 - val_accuracy: 0.7937\n",
      "Epoch 305/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8920 - accuracy: 1.0000 - val_loss: 3.4728 - val_accuracy: 0.7943\n",
      "Epoch 306/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8747 - accuracy: 1.0000 - val_loss: 3.4560 - val_accuracy: 0.7940\n",
      "Epoch 307/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8579 - accuracy: 1.0000 - val_loss: 3.4383 - val_accuracy: 0.7936\n",
      "Epoch 308/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8408 - accuracy: 1.0000 - val_loss: 3.4200 - val_accuracy: 0.7933\n",
      "Epoch 309/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8243 - accuracy: 1.0000 - val_loss: 3.4023 - val_accuracy: 0.7939\n",
      "Epoch 310/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8077 - accuracy: 1.0000 - val_loss: 3.3850 - val_accuracy: 0.7945\n",
      "Epoch 311/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7907 - accuracy: 1.0000 - val_loss: 3.3682 - val_accuracy: 0.7948\n",
      "Epoch 312/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7743 - accuracy: 1.0000 - val_loss: 3.3522 - val_accuracy: 0.7951\n",
      "Epoch 313/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7577 - accuracy: 1.0000 - val_loss: 3.3356 - val_accuracy: 0.7943\n",
      "Epoch 314/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7413 - accuracy: 1.0000 - val_loss: 3.3184 - val_accuracy: 0.7955\n",
      "Epoch 315/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7250 - accuracy: 1.0000 - val_loss: 3.3023 - val_accuracy: 0.7960\n",
      "Epoch 316/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7085 - accuracy: 1.0000 - val_loss: 3.2849 - val_accuracy: 0.7960\n",
      "Epoch 317/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6926 - accuracy: 1.0000 - val_loss: 3.2684 - val_accuracy: 0.7957\n",
      "Epoch 318/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6767 - accuracy: 1.0000 - val_loss: 3.2508 - val_accuracy: 0.7973\n",
      "Epoch 319/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6608 - accuracy: 1.0000 - val_loss: 3.2349 - val_accuracy: 0.7955\n",
      "Epoch 320/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6449 - accuracy: 1.0000 - val_loss: 3.2181 - val_accuracy: 0.7956\n",
      "Epoch 321/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6287 - accuracy: 1.0000 - val_loss: 3.2015 - val_accuracy: 0.7969\n",
      "Epoch 322/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6135 - accuracy: 1.0000 - val_loss: 3.1861 - val_accuracy: 0.7975\n",
      "Epoch 323/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5978 - accuracy: 1.0000 - val_loss: 3.1696 - val_accuracy: 0.7980\n",
      "Epoch 324/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5821 - accuracy: 1.0000 - val_loss: 3.1538 - val_accuracy: 0.7979\n",
      "Epoch 325/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5665 - accuracy: 1.0000 - val_loss: 3.1390 - val_accuracy: 0.7979\n",
      "Epoch 326/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5519 - accuracy: 1.0000 - val_loss: 3.1219 - val_accuracy: 0.7967\n",
      "Epoch 327/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5360 - accuracy: 1.0000 - val_loss: 3.1066 - val_accuracy: 0.7971\n",
      "Epoch 328/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5210 - accuracy: 1.0000 - val_loss: 3.0910 - val_accuracy: 0.7976\n",
      "Epoch 329/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5061 - accuracy: 1.0000 - val_loss: 3.0752 - val_accuracy: 0.7987\n",
      "Epoch 330/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4913 - accuracy: 1.0000 - val_loss: 3.0605 - val_accuracy: 0.7983\n",
      "Epoch 331/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4765 - accuracy: 1.0000 - val_loss: 3.0449 - val_accuracy: 0.7992\n",
      "Epoch 332/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4616 - accuracy: 1.0000 - val_loss: 3.0298 - val_accuracy: 0.7992\n",
      "Epoch 333/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4471 - accuracy: 1.0000 - val_loss: 3.0146 - val_accuracy: 0.7987\n",
      "Epoch 334/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4322 - accuracy: 1.0000 - val_loss: 2.9987 - val_accuracy: 0.8004\n",
      "Epoch 335/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4180 - accuracy: 1.0000 - val_loss: 2.9836 - val_accuracy: 0.8004\n",
      "Epoch 336/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4036 - accuracy: 1.0000 - val_loss: 2.9701 - val_accuracy: 0.8008\n",
      "Epoch 337/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3891 - accuracy: 1.0000 - val_loss: 2.9548 - val_accuracy: 0.8009\n",
      "Epoch 338/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3749 - accuracy: 1.0000 - val_loss: 2.9402 - val_accuracy: 0.8009\n",
      "Epoch 339/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3606 - accuracy: 1.0000 - val_loss: 2.9262 - val_accuracy: 0.8004\n",
      "Epoch 340/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3465 - accuracy: 1.0000 - val_loss: 2.9115 - val_accuracy: 0.8015\n",
      "Epoch 341/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3325 - accuracy: 1.0000 - val_loss: 2.8958 - val_accuracy: 0.8029\n",
      "Epoch 342/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3190 - accuracy: 1.0000 - val_loss: 2.8821 - val_accuracy: 0.8021\n",
      "Epoch 343/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3050 - accuracy: 1.0000 - val_loss: 2.8691 - val_accuracy: 0.8021\n",
      "Epoch 344/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2915 - accuracy: 1.0000 - val_loss: 2.8550 - val_accuracy: 0.8023\n",
      "Epoch 345/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2775 - accuracy: 1.0000 - val_loss: 2.8399 - val_accuracy: 0.8043\n",
      "Epoch 346/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2640 - accuracy: 1.0000 - val_loss: 2.8265 - val_accuracy: 0.8024\n",
      "Epoch 347/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2508 - accuracy: 1.0000 - val_loss: 2.8118 - val_accuracy: 0.8029\n",
      "Epoch 348/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2374 - accuracy: 1.0000 - val_loss: 2.7986 - val_accuracy: 0.8027\n",
      "Epoch 349/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2242 - accuracy: 1.0000 - val_loss: 2.7849 - val_accuracy: 0.8049\n",
      "Epoch 350/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2115 - accuracy: 1.0000 - val_loss: 2.7703 - val_accuracy: 0.8041\n",
      "Epoch 351/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1980 - accuracy: 1.0000 - val_loss: 2.7579 - val_accuracy: 0.8044\n",
      "Epoch 352/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1850 - accuracy: 1.0000 - val_loss: 2.7444 - val_accuracy: 0.8045\n",
      "Epoch 353/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1722 - accuracy: 1.0000 - val_loss: 2.7314 - val_accuracy: 0.8043\n",
      "Epoch 354/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1599 - accuracy: 1.0000 - val_loss: 2.7185 - val_accuracy: 0.8041\n",
      "Epoch 355/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1470 - accuracy: 1.0000 - val_loss: 2.7056 - val_accuracy: 0.8033\n",
      "Epoch 356/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1343 - accuracy: 1.0000 - val_loss: 2.6923 - val_accuracy: 0.8048\n",
      "Epoch 357/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1216 - accuracy: 1.0000 - val_loss: 2.6796 - val_accuracy: 0.8055\n",
      "Epoch 358/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1095 - accuracy: 1.0000 - val_loss: 2.6667 - val_accuracy: 0.8043\n",
      "Epoch 359/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0970 - accuracy: 1.0000 - val_loss: 2.6544 - val_accuracy: 0.8061\n",
      "Epoch 360/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0846 - accuracy: 1.0000 - val_loss: 2.6432 - val_accuracy: 0.8063\n",
      "Epoch 361/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0730 - accuracy: 1.0000 - val_loss: 2.6308 - val_accuracy: 0.8048\n",
      "Epoch 362/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0612 - accuracy: 1.0000 - val_loss: 2.6187 - val_accuracy: 0.8063\n",
      "Epoch 363/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0485 - accuracy: 1.0000 - val_loss: 2.6067 - val_accuracy: 0.8071\n",
      "Epoch 364/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0367 - accuracy: 1.0000 - val_loss: 2.5953 - val_accuracy: 0.8063\n",
      "Epoch 365/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0248 - accuracy: 1.0000 - val_loss: 2.5831 - val_accuracy: 0.8072\n",
      "Epoch 366/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0135 - accuracy: 1.0000 - val_loss: 2.5717 - val_accuracy: 0.8075\n",
      "Epoch 367/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0018 - accuracy: 1.0000 - val_loss: 2.5609 - val_accuracy: 0.8073\n",
      "Epoch 368/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9908 - accuracy: 1.0000 - val_loss: 2.5481 - val_accuracy: 0.8093\n",
      "Epoch 369/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9787 - accuracy: 1.0000 - val_loss: 2.5367 - val_accuracy: 0.8077\n",
      "Epoch 370/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9673 - accuracy: 1.0000 - val_loss: 2.5242 - val_accuracy: 0.8091\n",
      "Epoch 371/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9564 - accuracy: 1.0000 - val_loss: 2.5131 - val_accuracy: 0.8089\n",
      "Epoch 372/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9452 - accuracy: 1.0000 - val_loss: 2.5025 - val_accuracy: 0.8096\n",
      "Epoch 373/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9348 - accuracy: 1.0000 - val_loss: 2.4915 - val_accuracy: 0.8104\n",
      "Epoch 374/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9231 - accuracy: 1.0000 - val_loss: 2.4811 - val_accuracy: 0.8101\n",
      "Epoch 375/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9122 - accuracy: 1.0000 - val_loss: 2.4692 - val_accuracy: 0.8111\n",
      "Epoch 376/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9017 - accuracy: 1.0000 - val_loss: 2.4579 - val_accuracy: 0.8109\n",
      "Epoch 377/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8909 - accuracy: 1.0000 - val_loss: 2.4486 - val_accuracy: 0.8120\n",
      "Epoch 378/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8805 - accuracy: 1.0000 - val_loss: 2.4374 - val_accuracy: 0.8123\n",
      "Epoch 379/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8696 - accuracy: 1.0000 - val_loss: 2.4291 - val_accuracy: 0.8119\n",
      "Epoch 380/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8596 - accuracy: 1.0000 - val_loss: 2.4190 - val_accuracy: 0.8119\n",
      "Epoch 381/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8492 - accuracy: 1.0000 - val_loss: 2.4044 - val_accuracy: 0.8112\n",
      "Epoch 382/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8389 - accuracy: 1.0000 - val_loss: 2.3958 - val_accuracy: 0.8132\n",
      "Epoch 383/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8285 - accuracy: 1.0000 - val_loss: 2.3837 - val_accuracy: 0.8131\n",
      "Epoch 384/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8186 - accuracy: 1.0000 - val_loss: 2.3747 - val_accuracy: 0.8123\n",
      "Epoch 385/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8087 - accuracy: 1.0000 - val_loss: 2.3666 - val_accuracy: 0.8124\n",
      "Epoch 386/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7986 - accuracy: 1.0000 - val_loss: 2.3533 - val_accuracy: 0.8132\n",
      "Epoch 387/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7890 - accuracy: 1.0000 - val_loss: 2.3433 - val_accuracy: 0.8151\n",
      "Epoch 388/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7793 - accuracy: 1.0000 - val_loss: 2.3337 - val_accuracy: 0.8143\n",
      "Epoch 389/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7698 - accuracy: 1.0000 - val_loss: 2.3242 - val_accuracy: 0.8159\n",
      "Epoch 390/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7603 - accuracy: 1.0000 - val_loss: 2.3153 - val_accuracy: 0.8160\n",
      "Epoch 391/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7505 - accuracy: 1.0000 - val_loss: 2.3041 - val_accuracy: 0.8151\n",
      "Epoch 392/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7414 - accuracy: 1.0000 - val_loss: 2.2972 - val_accuracy: 0.8141\n",
      "Epoch 393/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7319 - accuracy: 1.0000 - val_loss: 2.2862 - val_accuracy: 0.8135\n",
      "Epoch 394/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7231 - accuracy: 1.0000 - val_loss: 2.2790 - val_accuracy: 0.8143\n",
      "Epoch 395/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7138 - accuracy: 1.0000 - val_loss: 2.2693 - val_accuracy: 0.8144\n",
      "Epoch 396/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7049 - accuracy: 1.0000 - val_loss: 2.2633 - val_accuracy: 0.8163\n",
      "Epoch 397/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6961 - accuracy: 1.0000 - val_loss: 2.2508 - val_accuracy: 0.8168\n",
      "Epoch 398/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6877 - accuracy: 1.0000 - val_loss: 2.2423 - val_accuracy: 0.8167\n",
      "Epoch 399/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6788 - accuracy: 1.0000 - val_loss: 2.2347 - val_accuracy: 0.8152\n",
      "Epoch 400/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6693 - accuracy: 1.0000 - val_loss: 2.2266 - val_accuracy: 0.8145\n",
      "Epoch 401/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6609 - accuracy: 1.0000 - val_loss: 2.2171 - val_accuracy: 0.8163\n",
      "Epoch 402/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6527 - accuracy: 1.0000 - val_loss: 2.2066 - val_accuracy: 0.8156\n",
      "Epoch 403/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6445 - accuracy: 1.0000 - val_loss: 2.1982 - val_accuracy: 0.8156\n",
      "Epoch 404/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6360 - accuracy: 1.0000 - val_loss: 2.1911 - val_accuracy: 0.8175\n",
      "Epoch 405/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6274 - accuracy: 1.0000 - val_loss: 2.1818 - val_accuracy: 0.8167\n",
      "Epoch 406/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6198 - accuracy: 1.0000 - val_loss: 2.1753 - val_accuracy: 0.8163\n",
      "Epoch 407/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6118 - accuracy: 1.0000 - val_loss: 2.1700 - val_accuracy: 0.8176\n",
      "Epoch 408/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6034 - accuracy: 1.0000 - val_loss: 2.1577 - val_accuracy: 0.8181\n",
      "Epoch 409/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5960 - accuracy: 1.0000 - val_loss: 2.1532 - val_accuracy: 0.8147\n",
      "Epoch 410/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5882 - accuracy: 1.0000 - val_loss: 2.1396 - val_accuracy: 0.8188\n",
      "Epoch 411/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5805 - accuracy: 1.0000 - val_loss: 2.1348 - val_accuracy: 0.8165\n",
      "Epoch 412/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5734 - accuracy: 1.0000 - val_loss: 2.1297 - val_accuracy: 0.8181\n",
      "Epoch 413/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5653 - accuracy: 1.0000 - val_loss: 2.1197 - val_accuracy: 0.8168\n",
      "Epoch 414/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5579 - accuracy: 1.0000 - val_loss: 2.1211 - val_accuracy: 0.8169\n",
      "Epoch 415/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5510 - accuracy: 1.0000 - val_loss: 2.0987 - val_accuracy: 0.8191\n",
      "Epoch 416/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5431 - accuracy: 1.0000 - val_loss: 2.0995 - val_accuracy: 0.8173\n",
      "Epoch 417/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6832 - accuracy: 0.9669 - val_loss: 3.2505 - val_accuracy: 0.6677\n",
      "Epoch 418/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9795 - accuracy: 0.9003 - val_loss: 2.3577 - val_accuracy: 0.8039\n",
      "Epoch 419/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7596 - accuracy: 0.9803 - val_loss: 2.1469 - val_accuracy: 0.8540\n",
      "Epoch 420/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6867 - accuracy: 0.9978 - val_loss: 2.0919 - val_accuracy: 0.8553\n",
      "Epoch 421/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6438 - accuracy: 0.9997 - val_loss: 2.0798 - val_accuracy: 0.8523\n",
      "Epoch 422/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6098 - accuracy: 1.0000 - val_loss: 2.0616 - val_accuracy: 0.8495\n",
      "Epoch 423/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5825 - accuracy: 1.0000 - val_loss: 2.0391 - val_accuracy: 0.8480\n",
      "Epoch 424/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5593 - accuracy: 1.0000 - val_loss: 2.0161 - val_accuracy: 0.8497\n",
      "Epoch 425/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5395 - accuracy: 1.0000 - val_loss: 1.9960 - val_accuracy: 0.8488\n",
      "Epoch 426/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5225 - accuracy: 1.0000 - val_loss: 1.9773 - val_accuracy: 0.8487\n",
      "Epoch 427/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5081 - accuracy: 1.0000 - val_loss: 1.9643 - val_accuracy: 0.8497\n",
      "Epoch 428/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4956 - accuracy: 1.0000 - val_loss: 1.9572 - val_accuracy: 0.8493\n",
      "Epoch 429/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4844 - accuracy: 1.0000 - val_loss: 1.9427 - val_accuracy: 0.8504\n",
      "Epoch 430/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4739 - accuracy: 1.0000 - val_loss: 1.9374 - val_accuracy: 0.8468\n",
      "Epoch 431/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4660 - accuracy: 1.0000 - val_loss: 1.9357 - val_accuracy: 0.8464\n",
      "Epoch 432/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4578 - accuracy: 1.0000 - val_loss: 1.9293 - val_accuracy: 0.8440\n",
      "Epoch 433/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4499 - accuracy: 1.0000 - val_loss: 1.9192 - val_accuracy: 0.8457\n",
      "Epoch 434/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4428 - accuracy: 1.0000 - val_loss: 1.9172 - val_accuracy: 0.8445\n",
      "Epoch 435/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4356 - accuracy: 1.0000 - val_loss: 1.9135 - val_accuracy: 0.8436\n",
      "Epoch 436/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4313 - accuracy: 1.0000 - val_loss: 1.9286 - val_accuracy: 0.8391\n",
      "Epoch 437/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4266 - accuracy: 1.0000 - val_loss: 1.9103 - val_accuracy: 0.8444\n",
      "Epoch 438/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4197 - accuracy: 1.0000 - val_loss: 1.9214 - val_accuracy: 0.8393\n",
      "Epoch 439/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4293 - accuracy: 0.9967 - val_loss: 3.0677 - val_accuracy: 0.7016\n",
      "Epoch 440/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0791 - accuracy: 0.8507 - val_loss: 2.6193 - val_accuracy: 0.7216\n",
      "Epoch 441/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7110 - accuracy: 0.9688 - val_loss: 2.0112 - val_accuracy: 0.8673\n",
      "Epoch 442/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6136 - accuracy: 0.9968 - val_loss: 1.9780 - val_accuracy: 0.8676\n",
      "Epoch 443/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5651 - accuracy: 1.0000 - val_loss: 1.9799 - val_accuracy: 0.8532\n",
      "Epoch 444/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5293 - accuracy: 1.0000 - val_loss: 1.9729 - val_accuracy: 0.8476\n",
      "Epoch 445/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5000 - accuracy: 1.0000 - val_loss: 1.9525 - val_accuracy: 0.8477\n",
      "Epoch 446/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4743 - accuracy: 1.0000 - val_loss: 1.9231 - val_accuracy: 0.8484\n",
      "Epoch 447/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4521 - accuracy: 1.0000 - val_loss: 1.8979 - val_accuracy: 0.8521\n",
      "Epoch 448/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4331 - accuracy: 1.0000 - val_loss: 1.8731 - val_accuracy: 0.8552\n",
      "Epoch 449/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4165 - accuracy: 1.0000 - val_loss: 1.8503 - val_accuracy: 0.8560\n",
      "Epoch 450/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4018 - accuracy: 1.0000 - val_loss: 1.8319 - val_accuracy: 0.8572\n",
      "Epoch 451/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3891 - accuracy: 1.0000 - val_loss: 1.8144 - val_accuracy: 0.8580\n",
      "Epoch 452/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3781 - accuracy: 1.0000 - val_loss: 1.8032 - val_accuracy: 0.8588\n",
      "Epoch 453/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3690 - accuracy: 1.0000 - val_loss: 1.7926 - val_accuracy: 0.8593\n",
      "Epoch 454/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3634 - accuracy: 0.9999 - val_loss: 1.7854 - val_accuracy: 0.8603\n",
      "Epoch 455/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3595 - accuracy: 1.0000 - val_loss: 1.7848 - val_accuracy: 0.8597\n",
      "Epoch 456/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3708 - accuracy: 0.9952 - val_loss: 2.6064 - val_accuracy: 0.7292\n",
      "Epoch 457/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9328 - accuracy: 0.8657 - val_loss: 2.5707 - val_accuracy: 0.7180\n",
      "Epoch 458/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6398 - accuracy: 0.9693 - val_loss: 1.9011 - val_accuracy: 0.8756\n",
      "Epoch 459/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5434 - accuracy: 0.9972 - val_loss: 1.8537 - val_accuracy: 0.8853\n",
      "Epoch 460/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4962 - accuracy: 1.0000 - val_loss: 1.8557 - val_accuracy: 0.8744\n",
      "Epoch 461/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4610 - accuracy: 1.0000 - val_loss: 1.8483 - val_accuracy: 0.8680\n",
      "Epoch 462/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4320 - accuracy: 1.0000 - val_loss: 1.8294 - val_accuracy: 0.8667\n",
      "Epoch 463/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4072 - accuracy: 1.0000 - val_loss: 1.8036 - val_accuracy: 0.8679\n",
      "Epoch 464/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3857 - accuracy: 1.0000 - val_loss: 1.7790 - val_accuracy: 0.8703\n",
      "Epoch 465/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3673 - accuracy: 1.0000 - val_loss: 1.7580 - val_accuracy: 0.8708\n",
      "Epoch 466/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3520 - accuracy: 1.0000 - val_loss: 1.7401 - val_accuracy: 0.8717\n",
      "Epoch 467/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3391 - accuracy: 1.0000 - val_loss: 1.7199 - val_accuracy: 0.8735\n",
      "Epoch 468/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3267 - accuracy: 1.0000 - val_loss: 1.7025 - val_accuracy: 0.8789\n",
      "Epoch 469/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3181 - accuracy: 1.0000 - val_loss: 1.6929 - val_accuracy: 0.8763\n",
      "Epoch 470/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3092 - accuracy: 1.0000 - val_loss: 1.6791 - val_accuracy: 0.8781\n",
      "Epoch 471/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3026 - accuracy: 1.0000 - val_loss: 1.6738 - val_accuracy: 0.8813\n",
      "Epoch 472/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2961 - accuracy: 1.0000 - val_loss: 1.6573 - val_accuracy: 0.8803\n",
      "Epoch 473/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7452 - accuracy: 0.8944 - val_loss: 3.1889 - val_accuracy: 0.6328\n",
      "Epoch 474/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6405 - accuracy: 0.9477 - val_loss: 1.9139 - val_accuracy: 0.8523\n",
      "Epoch 475/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5067 - accuracy: 0.9940 - val_loss: 1.7864 - val_accuracy: 0.8904\n",
      "Epoch 476/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4544 - accuracy: 0.9996 - val_loss: 1.7843 - val_accuracy: 0.8795\n",
      "Epoch 477/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4160 - accuracy: 1.0000 - val_loss: 1.7822 - val_accuracy: 0.8724\n",
      "Epoch 478/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3856 - accuracy: 1.0000 - val_loss: 1.7617 - val_accuracy: 0.8688\n",
      "Epoch 479/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3602 - accuracy: 1.0000 - val_loss: 1.7359 - val_accuracy: 0.8717\n",
      "Epoch 480/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3385 - accuracy: 1.0000 - val_loss: 1.7084 - val_accuracy: 0.8736\n",
      "Epoch 481/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3196 - accuracy: 1.0000 - val_loss: 1.6840 - val_accuracy: 0.8772\n",
      "Epoch 482/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3037 - accuracy: 1.0000 - val_loss: 1.6624 - val_accuracy: 0.8793\n",
      "Epoch 483/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2903 - accuracy: 1.0000 - val_loss: 1.6439 - val_accuracy: 0.8836\n",
      "Epoch 484/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2786 - accuracy: 1.0000 - val_loss: 1.6199 - val_accuracy: 0.8868\n",
      "Epoch 485/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2692 - accuracy: 1.0000 - val_loss: 1.6066 - val_accuracy: 0.8912\n",
      "Epoch 486/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2618 - accuracy: 1.0000 - val_loss: 1.5954 - val_accuracy: 0.8896\n",
      "Epoch 487/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2698 - accuracy: 0.9967 - val_loss: 2.2523 - val_accuracy: 0.7675\n",
      "Epoch 488/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7795 - accuracy: 0.8776 - val_loss: 2.3894 - val_accuracy: 0.7324\n",
      "Epoch 489/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5237 - accuracy: 0.9738 - val_loss: 1.7445 - val_accuracy: 0.8924\n",
      "Epoch 490/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4390 - accuracy: 0.9973 - val_loss: 1.6953 - val_accuracy: 0.9017\n",
      "Epoch 491/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3935 - accuracy: 1.0000 - val_loss: 1.6982 - val_accuracy: 0.8903\n",
      "Epoch 492/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3593 - accuracy: 1.0000 - val_loss: 1.6883 - val_accuracy: 0.8876\n",
      "Epoch 493/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3311 - accuracy: 1.0000 - val_loss: 1.6701 - val_accuracy: 0.8861\n",
      "Epoch 494/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3076 - accuracy: 1.0000 - val_loss: 1.6459 - val_accuracy: 0.8865\n",
      "Epoch 495/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2876 - accuracy: 1.0000 - val_loss: 1.6224 - val_accuracy: 0.8896\n",
      "Epoch 496/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2708 - accuracy: 1.0000 - val_loss: 1.6012 - val_accuracy: 0.8925\n",
      "Epoch 497/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2567 - accuracy: 1.0000 - val_loss: 1.5798 - val_accuracy: 0.8943\n",
      "Epoch 498/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2447 - accuracy: 1.0000 - val_loss: 1.5617 - val_accuracy: 0.8955\n",
      "Epoch 499/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2349 - accuracy: 1.0000 - val_loss: 1.5469 - val_accuracy: 0.8977\n",
      "Epoch 500/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2266 - accuracy: 1.0000 - val_loss: 1.5323 - val_accuracy: 0.8983\n",
      "Time: 180.49156093597412\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Traits_Model_100OU.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#100 OU\n",
    "################################################################################################################################################\n",
    "# now repeat the analysis only for traits\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test  = train_test_split(y,X,traits_OU,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = OU_subset(ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Traits_Model_100OU.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4qH4j8KaN7Oo",
    "outputId": "85270d63-2aec-4ce6-f9ca-6986834d6771",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 50, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 48, 250)      45000       ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 48, 250)     1000        ['conv1d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 46, 250)      187500      ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 46, 250)     1000        ['conv1d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 44, 250)      187500      ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 44, 250)     1000        ['conv1d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_8 (MaxPooling1D)  (None, 14, 250)     0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 3500)         0           ['max_pooling1d_8[0][0]']        \n",
      "                                                                                                  \n",
      " dense_71_input (InputLayer)    [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_74 (Dense)               (None, 125)          437625      ['flatten_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense_71 (Dense)               (None, 150)          450000      ['dense_71_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 125)          0           ['dense_74[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 150)         600         ['dense_71[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_75 (Dense)               (None, 125)          15750       ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dense_72 (Dense)               (None, 150)          22500       ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 125)          0           ['dense_75[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 150)         600         ['dense_72[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_76 (Dense)               (None, 50)           6300        ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " dense_73 (Dense)               (None, 50)           7550        ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 50)           0           ['dense_76[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_8 (LinearW)           (None, 50)           2           ['dense_73[0][0]',               \n",
      "                                                                  'activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " dense_77 (Dense)               (None, 50)           2550        ['linear_w_8[0][0]']             \n",
      "                                                                                                  \n",
      " dense_78 (Dense)               (None, 3)            153         ['dense_77[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,366,630\n",
      "Trainable params: 1,364,530\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 3s 16ms/step - loss: 13.1849 - accuracy: 0.3903 - val_loss: 13.0798 - val_accuracy: 0.3713\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 13.0757 - accuracy: 0.4215 - val_loss: 13.0025 - val_accuracy: 0.4615\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.9876 - accuracy: 0.4549 - val_loss: 12.9212 - val_accuracy: 0.5155\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.9098 - accuracy: 0.4829 - val_loss: 12.8385 - val_accuracy: 0.5619\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.8366 - accuracy: 0.5037 - val_loss: 12.7573 - val_accuracy: 0.5920\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.7617 - accuracy: 0.5302 - val_loss: 12.6784 - val_accuracy: 0.6100\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.6879 - accuracy: 0.5556 - val_loss: 12.6028 - val_accuracy: 0.6241\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.6145 - accuracy: 0.5754 - val_loss: 12.5282 - val_accuracy: 0.6341\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.5458 - accuracy: 0.5932 - val_loss: 12.4563 - val_accuracy: 0.6428\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.4827 - accuracy: 0.6007 - val_loss: 12.3876 - val_accuracy: 0.6535\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.4084 - accuracy: 0.6228 - val_loss: 12.3199 - val_accuracy: 0.6657\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.3524 - accuracy: 0.6292 - val_loss: 12.2564 - val_accuracy: 0.6745\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.2913 - accuracy: 0.6388 - val_loss: 12.1947 - val_accuracy: 0.6812\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.2294 - accuracy: 0.6480 - val_loss: 12.1347 - val_accuracy: 0.6852\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.1711 - accuracy: 0.6555 - val_loss: 12.0755 - val_accuracy: 0.6917\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.1096 - accuracy: 0.6646 - val_loss: 12.0174 - val_accuracy: 0.6968\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.0553 - accuracy: 0.6724 - val_loss: 11.9596 - val_accuracy: 0.7031\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.9975 - accuracy: 0.6752 - val_loss: 11.9038 - val_accuracy: 0.7084\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.9403 - accuracy: 0.6856 - val_loss: 11.8463 - val_accuracy: 0.7183\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.8869 - accuracy: 0.6914 - val_loss: 11.7895 - val_accuracy: 0.7284\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.8321 - accuracy: 0.6972 - val_loss: 11.7341 - val_accuracy: 0.7376\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.7733 - accuracy: 0.7072 - val_loss: 11.6780 - val_accuracy: 0.7452\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.7212 - accuracy: 0.7111 - val_loss: 11.6205 - val_accuracy: 0.7565\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.6673 - accuracy: 0.7220 - val_loss: 11.5645 - val_accuracy: 0.7648\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.6115 - accuracy: 0.7295 - val_loss: 11.5105 - val_accuracy: 0.7736\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.5547 - accuracy: 0.7385 - val_loss: 11.4552 - val_accuracy: 0.7813\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.4994 - accuracy: 0.7434 - val_loss: 11.4012 - val_accuracy: 0.7887\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.4444 - accuracy: 0.7545 - val_loss: 11.3445 - val_accuracy: 0.8008\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.3880 - accuracy: 0.7580 - val_loss: 11.2900 - val_accuracy: 0.8089\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.3380 - accuracy: 0.7636 - val_loss: 11.2362 - val_accuracy: 0.8148\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.2840 - accuracy: 0.7732 - val_loss: 11.1815 - val_accuracy: 0.8243\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.2291 - accuracy: 0.7804 - val_loss: 11.1260 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.1759 - accuracy: 0.7890 - val_loss: 11.0720 - val_accuracy: 0.8399\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.1237 - accuracy: 0.7930 - val_loss: 11.0191 - val_accuracy: 0.8447\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.0683 - accuracy: 0.8047 - val_loss: 10.9631 - val_accuracy: 0.8529\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.0162 - accuracy: 0.8076 - val_loss: 10.9102 - val_accuracy: 0.8591\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.9561 - accuracy: 0.8240 - val_loss: 10.8554 - val_accuracy: 0.8637\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.9086 - accuracy: 0.8264 - val_loss: 10.8040 - val_accuracy: 0.8689\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.8532 - accuracy: 0.8356 - val_loss: 10.7503 - val_accuracy: 0.8768\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.8016 - accuracy: 0.8400 - val_loss: 10.6980 - val_accuracy: 0.8835\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.7482 - accuracy: 0.8484 - val_loss: 10.6464 - val_accuracy: 0.8900\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.6984 - accuracy: 0.8523 - val_loss: 10.5951 - val_accuracy: 0.8959\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.6464 - accuracy: 0.8584 - val_loss: 10.5446 - val_accuracy: 0.8995\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.5938 - accuracy: 0.8644 - val_loss: 10.4929 - val_accuracy: 0.9065\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.5423 - accuracy: 0.8700 - val_loss: 10.4426 - val_accuracy: 0.9119\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.4929 - accuracy: 0.8758 - val_loss: 10.3931 - val_accuracy: 0.9175\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.4451 - accuracy: 0.8816 - val_loss: 10.3440 - val_accuracy: 0.9213\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.3932 - accuracy: 0.8875 - val_loss: 10.2950 - val_accuracy: 0.9251\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.3441 - accuracy: 0.8904 - val_loss: 10.2478 - val_accuracy: 0.9277\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.2944 - accuracy: 0.8969 - val_loss: 10.1995 - val_accuracy: 0.9317\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.2457 - accuracy: 0.9011 - val_loss: 10.1537 - val_accuracy: 0.9344\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.2079 - accuracy: 0.9020 - val_loss: 10.1064 - val_accuracy: 0.9387\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.1533 - accuracy: 0.9106 - val_loss: 10.0620 - val_accuracy: 0.9399\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.1059 - accuracy: 0.9127 - val_loss: 10.0154 - val_accuracy: 0.9428\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.0635 - accuracy: 0.9144 - val_loss: 9.9704 - val_accuracy: 0.9447\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.0167 - accuracy: 0.9185 - val_loss: 9.9265 - val_accuracy: 0.9461\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.9684 - accuracy: 0.9227 - val_loss: 9.8821 - val_accuracy: 0.9476\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.9236 - accuracy: 0.9252 - val_loss: 9.8391 - val_accuracy: 0.9492\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.8754 - accuracy: 0.9287 - val_loss: 9.7958 - val_accuracy: 0.9516\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.8358 - accuracy: 0.9290 - val_loss: 9.7526 - val_accuracy: 0.9535\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.7979 - accuracy: 0.9305 - val_loss: 9.7106 - val_accuracy: 0.9540\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.7502 - accuracy: 0.9345 - val_loss: 9.6699 - val_accuracy: 0.9543\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.7067 - accuracy: 0.9361 - val_loss: 9.6277 - val_accuracy: 0.9563\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.6668 - accuracy: 0.9376 - val_loss: 9.5862 - val_accuracy: 0.9580\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.6235 - accuracy: 0.9396 - val_loss: 9.5453 - val_accuracy: 0.9583\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.5758 - accuracy: 0.9413 - val_loss: 9.5047 - val_accuracy: 0.9592\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.5362 - accuracy: 0.9432 - val_loss: 9.4643 - val_accuracy: 0.9604\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.5004 - accuracy: 0.9424 - val_loss: 9.4243 - val_accuracy: 0.9616\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.4611 - accuracy: 0.9455 - val_loss: 9.3833 - val_accuracy: 0.9640\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.4169 - accuracy: 0.9468 - val_loss: 9.3458 - val_accuracy: 0.9627\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.3779 - accuracy: 0.9472 - val_loss: 9.3052 - val_accuracy: 0.9644\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.3345 - accuracy: 0.9503 - val_loss: 9.2664 - val_accuracy: 0.9648\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2939 - accuracy: 0.9514 - val_loss: 9.2274 - val_accuracy: 0.9655\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2574 - accuracy: 0.9517 - val_loss: 9.1884 - val_accuracy: 0.9663\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2161 - accuracy: 0.9524 - val_loss: 9.1498 - val_accuracy: 0.9672\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.1805 - accuracy: 0.9523 - val_loss: 9.1098 - val_accuracy: 0.9685\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.1385 - accuracy: 0.9542 - val_loss: 9.0718 - val_accuracy: 0.9691\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0989 - accuracy: 0.9545 - val_loss: 9.0350 - val_accuracy: 0.9689\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0622 - accuracy: 0.9556 - val_loss: 8.9968 - val_accuracy: 0.9707\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0201 - accuracy: 0.9587 - val_loss: 8.9599 - val_accuracy: 0.9695\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.9784 - accuracy: 0.9581 - val_loss: 8.9223 - val_accuracy: 0.9703\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.9426 - accuracy: 0.9584 - val_loss: 8.8845 - val_accuracy: 0.9707\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.9024 - accuracy: 0.9597 - val_loss: 8.8459 - val_accuracy: 0.9717\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.8666 - accuracy: 0.9608 - val_loss: 8.8091 - val_accuracy: 0.9720\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.8272 - accuracy: 0.9614 - val_loss: 8.7737 - val_accuracy: 0.9716\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7874 - accuracy: 0.9632 - val_loss: 8.7367 - val_accuracy: 0.9715\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7543 - accuracy: 0.9617 - val_loss: 8.6987 - val_accuracy: 0.9729\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7156 - accuracy: 0.9628 - val_loss: 8.6615 - val_accuracy: 0.9733\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.6797 - accuracy: 0.9636 - val_loss: 8.6251 - val_accuracy: 0.9736\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.6396 - accuracy: 0.9644 - val_loss: 8.5896 - val_accuracy: 0.9737\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.6025 - accuracy: 0.9656 - val_loss: 8.5522 - val_accuracy: 0.9741\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.5660 - accuracy: 0.9653 - val_loss: 8.5161 - val_accuracy: 0.9745\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.5328 - accuracy: 0.9658 - val_loss: 8.4804 - val_accuracy: 0.9741\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4932 - accuracy: 0.9675 - val_loss: 8.4449 - val_accuracy: 0.9745\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4547 - accuracy: 0.9683 - val_loss: 8.4101 - val_accuracy: 0.9743\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4207 - accuracy: 0.9671 - val_loss: 8.3731 - val_accuracy: 0.9752\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3857 - accuracy: 0.9676 - val_loss: 8.3375 - val_accuracy: 0.9751\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3457 - accuracy: 0.9696 - val_loss: 8.3027 - val_accuracy: 0.9756\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3142 - accuracy: 0.9688 - val_loss: 8.2668 - val_accuracy: 0.9760\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.2744 - accuracy: 0.9703 - val_loss: 8.2316 - val_accuracy: 0.9761\n",
      "Time: 99.2722716331482\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_100OU_50SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#100 OU, 50 SNPs\n",
    "################################################################################################################################################\n",
    "# subset the SNPs\n",
    "X50=X[:,0:50,:]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test  = train_test_split(y,X50,traits_OU,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_OU_subset(ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_100OU_50SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oXWI7orOx8zC",
    "outputId": "aa56ad10-ce27-4d25-fac8-2cc998adc756",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 48, 250)      45000       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 48, 250)     1000        ['conv1d[0][0]']                 \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 46, 250)      187500      ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 46, 250)     1000        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 44, 250)      187500      ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 44, 250)     1000        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 14, 250)      0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 3500)         0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " dense_input (InputLayer)       [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 125)          437625      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 150)          450000      ['dense_input[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 125)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 150)         600         ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 125)          15750       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 150)          22500       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 125)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 150)         600         ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 50)           6300        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 50)           7550        ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 50)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " linear_w (LinearW)             (None, 50)           2           ['dense_2[0][0]',                \n",
      "                                                                  'activation[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 50)           2550        ['linear_w[0][0]']               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 3)            153         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,366,630\n",
      "Trainable params: 1,364,530\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 6s 16ms/step - loss: 13.2234 - accuracy: 0.3284 - val_loss: 13.1227 - val_accuracy: 0.3224\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 13.1285 - accuracy: 0.3556 - val_loss: 13.0637 - val_accuracy: 0.3637\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 13.0524 - accuracy: 0.3841 - val_loss: 12.9932 - val_accuracy: 0.4268\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.9841 - accuracy: 0.4055 - val_loss: 12.9179 - val_accuracy: 0.4856\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.9153 - accuracy: 0.4317 - val_loss: 12.8421 - val_accuracy: 0.5268\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.8486 - accuracy: 0.4564 - val_loss: 12.7667 - val_accuracy: 0.5639\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.7797 - accuracy: 0.4867 - val_loss: 12.6906 - val_accuracy: 0.5912\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.7126 - accuracy: 0.5035 - val_loss: 12.6144 - val_accuracy: 0.6131\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.6411 - accuracy: 0.5264 - val_loss: 12.5380 - val_accuracy: 0.6369\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.5717 - accuracy: 0.5491 - val_loss: 12.4633 - val_accuracy: 0.6557\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.5000 - accuracy: 0.5730 - val_loss: 12.3880 - val_accuracy: 0.6737\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.4330 - accuracy: 0.5874 - val_loss: 12.3137 - val_accuracy: 0.6869\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.3614 - accuracy: 0.6111 - val_loss: 12.2394 - val_accuracy: 0.6989\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.2879 - accuracy: 0.6265 - val_loss: 12.1654 - val_accuracy: 0.7116\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.2213 - accuracy: 0.6404 - val_loss: 12.0914 - val_accuracy: 0.7241\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.1531 - accuracy: 0.6568 - val_loss: 12.0183 - val_accuracy: 0.7377\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.0878 - accuracy: 0.6721 - val_loss: 11.9458 - val_accuracy: 0.7520\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.0127 - accuracy: 0.6908 - val_loss: 11.8716 - val_accuracy: 0.7684\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.9460 - accuracy: 0.7036 - val_loss: 11.7986 - val_accuracy: 0.7813\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.8729 - accuracy: 0.7211 - val_loss: 11.7253 - val_accuracy: 0.7948\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.8024 - accuracy: 0.7291 - val_loss: 11.6515 - val_accuracy: 0.8133\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.7320 - accuracy: 0.7486 - val_loss: 11.5790 - val_accuracy: 0.8267\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.6662 - accuracy: 0.7597 - val_loss: 11.5082 - val_accuracy: 0.8404\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.5990 - accuracy: 0.7752 - val_loss: 11.4392 - val_accuracy: 0.8545\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.5291 - accuracy: 0.7866 - val_loss: 11.3701 - val_accuracy: 0.8696\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.4611 - accuracy: 0.8025 - val_loss: 11.3047 - val_accuracy: 0.8779\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.3920 - accuracy: 0.8160 - val_loss: 11.2395 - val_accuracy: 0.8892\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.3338 - accuracy: 0.8232 - val_loss: 11.1779 - val_accuracy: 0.8969\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.2694 - accuracy: 0.8339 - val_loss: 11.1181 - val_accuracy: 0.9029\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.2077 - accuracy: 0.8423 - val_loss: 11.0606 - val_accuracy: 0.9084\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.1451 - accuracy: 0.8535 - val_loss: 11.0045 - val_accuracy: 0.9128\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.0892 - accuracy: 0.8584 - val_loss: 10.9494 - val_accuracy: 0.9187\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.0336 - accuracy: 0.8692 - val_loss: 10.8952 - val_accuracy: 0.9229\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.9742 - accuracy: 0.8761 - val_loss: 10.8438 - val_accuracy: 0.9248\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.9196 - accuracy: 0.8840 - val_loss: 10.7935 - val_accuracy: 0.9287\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.8699 - accuracy: 0.8892 - val_loss: 10.7431 - val_accuracy: 0.9307\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.8118 - accuracy: 0.8944 - val_loss: 10.6933 - val_accuracy: 0.9356\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.7634 - accuracy: 0.8956 - val_loss: 10.6447 - val_accuracy: 0.9399\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.7107 - accuracy: 0.9034 - val_loss: 10.5971 - val_accuracy: 0.9421\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.6619 - accuracy: 0.9051 - val_loss: 10.5525 - val_accuracy: 0.9428\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.6114 - accuracy: 0.9116 - val_loss: 10.5059 - val_accuracy: 0.9455\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.5668 - accuracy: 0.9125 - val_loss: 10.4601 - val_accuracy: 0.9473\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.5168 - accuracy: 0.9160 - val_loss: 10.4149 - val_accuracy: 0.9488\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.4740 - accuracy: 0.9172 - val_loss: 10.3698 - val_accuracy: 0.9511\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.4257 - accuracy: 0.9235 - val_loss: 10.3255 - val_accuracy: 0.9525\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.3763 - accuracy: 0.9245 - val_loss: 10.2822 - val_accuracy: 0.9533\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.3319 - accuracy: 0.9285 - val_loss: 10.2395 - val_accuracy: 0.9544\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.2946 - accuracy: 0.9281 - val_loss: 10.1986 - val_accuracy: 0.9548\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.2409 - accuracy: 0.9341 - val_loss: 10.1549 - val_accuracy: 0.9565\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.2002 - accuracy: 0.9349 - val_loss: 10.1128 - val_accuracy: 0.9571\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.1538 - accuracy: 0.9367 - val_loss: 10.0711 - val_accuracy: 0.9577\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.1125 - accuracy: 0.9364 - val_loss: 10.0284 - val_accuracy: 0.9587\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.0680 - accuracy: 0.9402 - val_loss: 9.9880 - val_accuracy: 0.9589\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.0236 - accuracy: 0.9420 - val_loss: 9.9462 - val_accuracy: 0.9603\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.9820 - accuracy: 0.9416 - val_loss: 9.9065 - val_accuracy: 0.9609\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.9401 - accuracy: 0.9447 - val_loss: 9.8644 - val_accuracy: 0.9632\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.8968 - accuracy: 0.9443 - val_loss: 9.8243 - val_accuracy: 0.9636\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.8589 - accuracy: 0.9449 - val_loss: 9.7845 - val_accuracy: 0.9641\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.8140 - accuracy: 0.9487 - val_loss: 9.7440 - val_accuracy: 0.9655\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.7735 - accuracy: 0.9482 - val_loss: 9.7034 - val_accuracy: 0.9660\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.7309 - accuracy: 0.9511 - val_loss: 9.6636 - val_accuracy: 0.9665\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.6929 - accuracy: 0.9511 - val_loss: 9.6252 - val_accuracy: 0.9665\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.6488 - accuracy: 0.9529 - val_loss: 9.5862 - val_accuracy: 0.9668\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.6106 - accuracy: 0.9535 - val_loss: 9.5456 - val_accuracy: 0.9673\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.5682 - accuracy: 0.9552 - val_loss: 9.5064 - val_accuracy: 0.9680\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.5268 - accuracy: 0.9560 - val_loss: 9.4667 - val_accuracy: 0.9683\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.4879 - accuracy: 0.9555 - val_loss: 9.4286 - val_accuracy: 0.9687\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.4454 - accuracy: 0.9581 - val_loss: 9.3897 - val_accuracy: 0.9692\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.4080 - accuracy: 0.9577 - val_loss: 9.3530 - val_accuracy: 0.9688\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.3676 - accuracy: 0.9596 - val_loss: 9.3130 - val_accuracy: 0.9705\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.3309 - accuracy: 0.9595 - val_loss: 9.2756 - val_accuracy: 0.9699\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2883 - accuracy: 0.9607 - val_loss: 9.2379 - val_accuracy: 0.9699\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2563 - accuracy: 0.9599 - val_loss: 9.1994 - val_accuracy: 0.9700\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2122 - accuracy: 0.9615 - val_loss: 9.1620 - val_accuracy: 0.9712\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.1709 - accuracy: 0.9628 - val_loss: 9.1241 - val_accuracy: 0.9709\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.1369 - accuracy: 0.9609 - val_loss: 9.0869 - val_accuracy: 0.9712\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0958 - accuracy: 0.9649 - val_loss: 9.0509 - val_accuracy: 0.9711\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0563 - accuracy: 0.9658 - val_loss: 9.0125 - val_accuracy: 0.9716\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0218 - accuracy: 0.9632 - val_loss: 8.9749 - val_accuracy: 0.9719\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.9820 - accuracy: 0.9645 - val_loss: 8.9391 - val_accuracy: 0.9709\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.9459 - accuracy: 0.9647 - val_loss: 8.9019 - val_accuracy: 0.9719\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.9102 - accuracy: 0.9640 - val_loss: 8.8635 - val_accuracy: 0.9727\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.8691 - accuracy: 0.9673 - val_loss: 8.8273 - val_accuracy: 0.9727\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.8311 - accuracy: 0.9674 - val_loss: 8.7891 - val_accuracy: 0.9732\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7935 - accuracy: 0.9684 - val_loss: 8.7540 - val_accuracy: 0.9736\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7530 - accuracy: 0.9684 - val_loss: 8.7174 - val_accuracy: 0.9728\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7196 - accuracy: 0.9692 - val_loss: 8.6822 - val_accuracy: 0.9727\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.6830 - accuracy: 0.9701 - val_loss: 8.6443 - val_accuracy: 0.9747\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.6462 - accuracy: 0.9689 - val_loss: 8.6097 - val_accuracy: 0.9735\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.6085 - accuracy: 0.9710 - val_loss: 8.5736 - val_accuracy: 0.9735\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.5718 - accuracy: 0.9709 - val_loss: 8.5373 - val_accuracy: 0.9745\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.5373 - accuracy: 0.9710 - val_loss: 8.5014 - val_accuracy: 0.9743\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4978 - accuracy: 0.9713 - val_loss: 8.4644 - val_accuracy: 0.9745\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4638 - accuracy: 0.9709 - val_loss: 8.4300 - val_accuracy: 0.9749\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4246 - accuracy: 0.9718 - val_loss: 8.3944 - val_accuracy: 0.9745\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3893 - accuracy: 0.9729 - val_loss: 8.3588 - val_accuracy: 0.9748\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3521 - accuracy: 0.9731 - val_loss: 8.3240 - val_accuracy: 0.9749\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3176 - accuracy: 0.9736 - val_loss: 8.2900 - val_accuracy: 0.9749\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.2875 - accuracy: 0.9727 - val_loss: 8.2554 - val_accuracy: 0.9751\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.2466 - accuracy: 0.9742 - val_loss: 8.2182 - val_accuracy: 0.9760\n",
      "Time: 102.81365871429443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 14:48:24.929390: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_50OU_50SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#50 OU, 50 SNPs\n",
    "################################################################################################################################################\n",
    "# subset the traits\n",
    "traits_OU50=traits_OU[:,0:50,:]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test  = train_test_split(y,X50,traits_OU50,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_OU_subset(ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_50OU_50SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MjNgaOT_0wnm",
    "outputId": "34f570cf-8f13-421a-aa50-b2a6a56a770a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8_input (InputLayer)  [(None, 3000)]            0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 150)               450000    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 150)              600       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 150)               22500     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 150)              600       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 50)                7550      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 481,403\n",
      "Trainable params: 480,803\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 13.4947 - accuracy: 0.3568 - val_loss: 13.2953 - val_accuracy: 0.3357\n",
      "Epoch 2/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.2876 - accuracy: 0.3946 - val_loss: 13.1683 - val_accuracy: 0.3915\n",
      "Epoch 3/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.1374 - accuracy: 0.4290 - val_loss: 13.0707 - val_accuracy: 0.4269\n",
      "Epoch 4/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.0202 - accuracy: 0.4573 - val_loss: 12.9829 - val_accuracy: 0.4581\n",
      "Epoch 5/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.9172 - accuracy: 0.4854 - val_loss: 12.9017 - val_accuracy: 0.4779\n",
      "Epoch 6/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.8291 - accuracy: 0.5064 - val_loss: 12.8263 - val_accuracy: 0.4936\n",
      "Epoch 7/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.7461 - accuracy: 0.5285 - val_loss: 12.7556 - val_accuracy: 0.5097\n",
      "Epoch 8/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.6715 - accuracy: 0.5441 - val_loss: 12.6889 - val_accuracy: 0.5219\n",
      "Epoch 9/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.5981 - accuracy: 0.5594 - val_loss: 12.6252 - val_accuracy: 0.5352\n",
      "Epoch 10/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.5293 - accuracy: 0.5733 - val_loss: 12.5642 - val_accuracy: 0.5433\n",
      "Epoch 11/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.4625 - accuracy: 0.5860 - val_loss: 12.5054 - val_accuracy: 0.5508\n",
      "Epoch 12/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.3977 - accuracy: 0.5993 - val_loss: 12.4481 - val_accuracy: 0.5583\n",
      "Epoch 13/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.3349 - accuracy: 0.6104 - val_loss: 12.3926 - val_accuracy: 0.5640\n",
      "Epoch 14/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.2749 - accuracy: 0.6191 - val_loss: 12.3382 - val_accuracy: 0.5672\n",
      "Epoch 15/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.2142 - accuracy: 0.6294 - val_loss: 12.2851 - val_accuracy: 0.5699\n",
      "Epoch 16/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.1549 - accuracy: 0.6412 - val_loss: 12.2327 - val_accuracy: 0.5736\n",
      "Epoch 17/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.0974 - accuracy: 0.6454 - val_loss: 12.1813 - val_accuracy: 0.5769\n",
      "Epoch 18/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.0409 - accuracy: 0.6549 - val_loss: 12.1306 - val_accuracy: 0.5800\n",
      "Epoch 19/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.9851 - accuracy: 0.6638 - val_loss: 12.0808 - val_accuracy: 0.5843\n",
      "Epoch 20/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.9305 - accuracy: 0.6707 - val_loss: 12.0315 - val_accuracy: 0.5865\n",
      "Epoch 21/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.8765 - accuracy: 0.6755 - val_loss: 11.9827 - val_accuracy: 0.5907\n",
      "Epoch 22/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.8234 - accuracy: 0.6842 - val_loss: 11.9344 - val_accuracy: 0.5925\n",
      "Epoch 23/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.7700 - accuracy: 0.6910 - val_loss: 11.8866 - val_accuracy: 0.5948\n",
      "Epoch 24/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.7176 - accuracy: 0.6959 - val_loss: 11.8393 - val_accuracy: 0.5981\n",
      "Epoch 25/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.6648 - accuracy: 0.7031 - val_loss: 11.7924 - val_accuracy: 0.6016\n",
      "Epoch 26/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.6128 - accuracy: 0.7107 - val_loss: 11.7458 - val_accuracy: 0.6045\n",
      "Epoch 27/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.5622 - accuracy: 0.7168 - val_loss: 11.6998 - val_accuracy: 0.6057\n",
      "Epoch 28/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.5125 - accuracy: 0.7212 - val_loss: 11.6540 - val_accuracy: 0.6079\n",
      "Epoch 29/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.4616 - accuracy: 0.7270 - val_loss: 11.6084 - val_accuracy: 0.6092\n",
      "Epoch 30/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.4117 - accuracy: 0.7315 - val_loss: 11.5633 - val_accuracy: 0.6101\n",
      "Epoch 31/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.3611 - accuracy: 0.7381 - val_loss: 11.5186 - val_accuracy: 0.6136\n",
      "Epoch 32/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.3121 - accuracy: 0.7441 - val_loss: 11.4741 - val_accuracy: 0.6148\n",
      "Epoch 33/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.2627 - accuracy: 0.7485 - val_loss: 11.4299 - val_accuracy: 0.6167\n",
      "Epoch 34/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.2135 - accuracy: 0.7551 - val_loss: 11.3857 - val_accuracy: 0.6185\n",
      "Epoch 35/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.1661 - accuracy: 0.7592 - val_loss: 11.3418 - val_accuracy: 0.6201\n",
      "Epoch 36/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.1169 - accuracy: 0.7643 - val_loss: 11.2984 - val_accuracy: 0.6216\n",
      "Epoch 37/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.0693 - accuracy: 0.7711 - val_loss: 11.2550 - val_accuracy: 0.6233\n",
      "Epoch 38/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.0214 - accuracy: 0.7757 - val_loss: 11.2118 - val_accuracy: 0.6248\n",
      "Epoch 39/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.9741 - accuracy: 0.7799 - val_loss: 11.1689 - val_accuracy: 0.6263\n",
      "Epoch 40/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.9257 - accuracy: 0.7856 - val_loss: 11.1260 - val_accuracy: 0.6289\n",
      "Epoch 41/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.8782 - accuracy: 0.7889 - val_loss: 11.0834 - val_accuracy: 0.6308\n",
      "Epoch 42/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.8315 - accuracy: 0.7947 - val_loss: 11.0410 - val_accuracy: 0.6308\n",
      "Epoch 43/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.7856 - accuracy: 0.8008 - val_loss: 10.9987 - val_accuracy: 0.6329\n",
      "Epoch 44/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.7389 - accuracy: 0.8020 - val_loss: 10.9568 - val_accuracy: 0.6344\n",
      "Epoch 45/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.6933 - accuracy: 0.8060 - val_loss: 10.9149 - val_accuracy: 0.6355\n",
      "Epoch 46/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.6466 - accuracy: 0.8115 - val_loss: 10.8731 - val_accuracy: 0.6360\n",
      "Epoch 47/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.6000 - accuracy: 0.8162 - val_loss: 10.8316 - val_accuracy: 0.6381\n",
      "Epoch 48/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.5547 - accuracy: 0.8206 - val_loss: 10.7902 - val_accuracy: 0.6395\n",
      "Epoch 49/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.5082 - accuracy: 0.8240 - val_loss: 10.7489 - val_accuracy: 0.6412\n",
      "Epoch 50/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.4628 - accuracy: 0.8268 - val_loss: 10.7079 - val_accuracy: 0.6436\n",
      "Epoch 51/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.4187 - accuracy: 0.8317 - val_loss: 10.6671 - val_accuracy: 0.6437\n",
      "Epoch 52/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.3732 - accuracy: 0.8367 - val_loss: 10.6263 - val_accuracy: 0.6453\n",
      "Epoch 53/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.3270 - accuracy: 0.8393 - val_loss: 10.5857 - val_accuracy: 0.6468\n",
      "Epoch 54/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.2826 - accuracy: 0.8426 - val_loss: 10.5452 - val_accuracy: 0.6475\n",
      "Epoch 55/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.2364 - accuracy: 0.8484 - val_loss: 10.5049 - val_accuracy: 0.6483\n",
      "Epoch 56/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.1926 - accuracy: 0.8514 - val_loss: 10.4645 - val_accuracy: 0.6485\n",
      "Epoch 57/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.1486 - accuracy: 0.8552 - val_loss: 10.4246 - val_accuracy: 0.6503\n",
      "Epoch 58/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.1042 - accuracy: 0.8575 - val_loss: 10.3845 - val_accuracy: 0.6504\n",
      "Epoch 59/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.0599 - accuracy: 0.8624 - val_loss: 10.3446 - val_accuracy: 0.6508\n",
      "Epoch 60/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.0176 - accuracy: 0.8646 - val_loss: 10.3048 - val_accuracy: 0.6520\n",
      "Epoch 61/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.9734 - accuracy: 0.8674 - val_loss: 10.2653 - val_accuracy: 0.6535\n",
      "Epoch 62/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.9292 - accuracy: 0.8730 - val_loss: 10.2257 - val_accuracy: 0.6548\n",
      "Epoch 63/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.8846 - accuracy: 0.8766 - val_loss: 10.1863 - val_accuracy: 0.6555\n",
      "Epoch 64/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.8411 - accuracy: 0.8802 - val_loss: 10.1471 - val_accuracy: 0.6565\n",
      "Epoch 65/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.7993 - accuracy: 0.8826 - val_loss: 10.1080 - val_accuracy: 0.6573\n",
      "Epoch 66/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.7553 - accuracy: 0.8870 - val_loss: 10.0689 - val_accuracy: 0.6583\n",
      "Epoch 67/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.7121 - accuracy: 0.8879 - val_loss: 10.0299 - val_accuracy: 0.6596\n",
      "Epoch 68/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.6690 - accuracy: 0.8919 - val_loss: 9.9911 - val_accuracy: 0.6593\n",
      "Epoch 69/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.6263 - accuracy: 0.8968 - val_loss: 9.9525 - val_accuracy: 0.6599\n",
      "Epoch 70/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.5835 - accuracy: 0.8994 - val_loss: 9.9140 - val_accuracy: 0.6604\n",
      "Epoch 71/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.5401 - accuracy: 0.9021 - val_loss: 9.8755 - val_accuracy: 0.6621\n",
      "Epoch 72/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.4989 - accuracy: 0.9056 - val_loss: 9.8373 - val_accuracy: 0.6628\n",
      "Epoch 73/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.4566 - accuracy: 0.9069 - val_loss: 9.7991 - val_accuracy: 0.6641\n",
      "Epoch 74/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.4152 - accuracy: 0.9092 - val_loss: 9.7611 - val_accuracy: 0.6643\n",
      "Epoch 75/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.3729 - accuracy: 0.9132 - val_loss: 9.7230 - val_accuracy: 0.6648\n",
      "Epoch 76/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.3309 - accuracy: 0.9154 - val_loss: 9.6852 - val_accuracy: 0.6660\n",
      "Epoch 77/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.2906 - accuracy: 0.9165 - val_loss: 9.6474 - val_accuracy: 0.6672\n",
      "Epoch 78/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.2480 - accuracy: 0.9203 - val_loss: 9.6099 - val_accuracy: 0.6684\n",
      "Epoch 79/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.2060 - accuracy: 0.9240 - val_loss: 9.5721 - val_accuracy: 0.6691\n",
      "Epoch 80/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.1661 - accuracy: 0.9263 - val_loss: 9.5345 - val_accuracy: 0.6699\n",
      "Epoch 81/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.1239 - accuracy: 0.9292 - val_loss: 9.4972 - val_accuracy: 0.6712\n",
      "Epoch 82/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.0833 - accuracy: 0.9312 - val_loss: 9.4599 - val_accuracy: 0.6731\n",
      "Epoch 83/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.0424 - accuracy: 0.9333 - val_loss: 9.4228 - val_accuracy: 0.6743\n",
      "Epoch 84/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.0017 - accuracy: 0.9344 - val_loss: 9.3857 - val_accuracy: 0.6764\n",
      "Epoch 85/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.9628 - accuracy: 0.9370 - val_loss: 9.3488 - val_accuracy: 0.6771\n",
      "Epoch 86/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.9220 - accuracy: 0.9397 - val_loss: 9.3118 - val_accuracy: 0.6780\n",
      "Epoch 87/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.8808 - accuracy: 0.9414 - val_loss: 9.2753 - val_accuracy: 0.6797\n",
      "Epoch 88/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.8408 - accuracy: 0.9438 - val_loss: 9.2388 - val_accuracy: 0.6800\n",
      "Epoch 89/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.8008 - accuracy: 0.9462 - val_loss: 9.2024 - val_accuracy: 0.6815\n",
      "Epoch 90/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.7605 - accuracy: 0.9486 - val_loss: 9.1660 - val_accuracy: 0.6835\n",
      "Epoch 91/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.7219 - accuracy: 0.9498 - val_loss: 9.1295 - val_accuracy: 0.6841\n",
      "Epoch 92/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.6823 - accuracy: 0.9511 - val_loss: 9.0935 - val_accuracy: 0.6851\n",
      "Epoch 93/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.6426 - accuracy: 0.9526 - val_loss: 9.0574 - val_accuracy: 0.6857\n",
      "Epoch 94/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.6021 - accuracy: 0.9545 - val_loss: 9.0211 - val_accuracy: 0.6860\n",
      "Epoch 95/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.5641 - accuracy: 0.9561 - val_loss: 8.9855 - val_accuracy: 0.6872\n",
      "Epoch 96/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.5243 - accuracy: 0.9593 - val_loss: 8.9497 - val_accuracy: 0.6875\n",
      "Epoch 97/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.4853 - accuracy: 0.9615 - val_loss: 8.9141 - val_accuracy: 0.6892\n",
      "Epoch 98/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.4474 - accuracy: 0.9620 - val_loss: 8.8786 - val_accuracy: 0.6907\n",
      "Epoch 99/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.4079 - accuracy: 0.9642 - val_loss: 8.8429 - val_accuracy: 0.6916\n",
      "Epoch 100/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.3702 - accuracy: 0.9641 - val_loss: 8.8077 - val_accuracy: 0.6920\n",
      "Epoch 101/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.3325 - accuracy: 0.9663 - val_loss: 8.7720 - val_accuracy: 0.6933\n",
      "Epoch 102/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.2922 - accuracy: 0.9684 - val_loss: 8.7368 - val_accuracy: 0.6948\n",
      "Epoch 103/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.2559 - accuracy: 0.9700 - val_loss: 8.7019 - val_accuracy: 0.6955\n",
      "Epoch 104/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.2171 - accuracy: 0.9713 - val_loss: 8.6670 - val_accuracy: 0.6964\n",
      "Epoch 105/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.1793 - accuracy: 0.9726 - val_loss: 8.6320 - val_accuracy: 0.6980\n",
      "Epoch 106/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.1425 - accuracy: 0.9724 - val_loss: 8.5972 - val_accuracy: 0.6988\n",
      "Epoch 107/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.1054 - accuracy: 0.9733 - val_loss: 8.5624 - val_accuracy: 0.6993\n",
      "Epoch 108/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.0671 - accuracy: 0.9761 - val_loss: 8.5279 - val_accuracy: 0.6999\n",
      "Epoch 109/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.0308 - accuracy: 0.9765 - val_loss: 8.4935 - val_accuracy: 0.7003\n",
      "Epoch 110/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9929 - accuracy: 0.9780 - val_loss: 8.4591 - val_accuracy: 0.7016\n",
      "Epoch 111/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9554 - accuracy: 0.9796 - val_loss: 8.4246 - val_accuracy: 0.7028\n",
      "Epoch 112/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9195 - accuracy: 0.9801 - val_loss: 8.3902 - val_accuracy: 0.7048\n",
      "Epoch 113/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.8818 - accuracy: 0.9812 - val_loss: 8.3559 - val_accuracy: 0.7060\n",
      "Epoch 114/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.8450 - accuracy: 0.9827 - val_loss: 8.3217 - val_accuracy: 0.7076\n",
      "Epoch 115/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.8084 - accuracy: 0.9833 - val_loss: 8.2881 - val_accuracy: 0.7080\n",
      "Epoch 116/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.7734 - accuracy: 0.9832 - val_loss: 8.2545 - val_accuracy: 0.7088\n",
      "Epoch 117/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.7364 - accuracy: 0.9840 - val_loss: 8.2207 - val_accuracy: 0.7101\n",
      "Epoch 118/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.7002 - accuracy: 0.9852 - val_loss: 8.1871 - val_accuracy: 0.7116\n",
      "Epoch 119/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.6639 - accuracy: 0.9865 - val_loss: 8.1537 - val_accuracy: 0.7124\n",
      "Epoch 120/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.6285 - accuracy: 0.9872 - val_loss: 8.1202 - val_accuracy: 0.7137\n",
      "Epoch 121/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.5928 - accuracy: 0.9879 - val_loss: 8.0866 - val_accuracy: 0.7140\n",
      "Epoch 122/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.5570 - accuracy: 0.9872 - val_loss: 8.0534 - val_accuracy: 0.7159\n",
      "Epoch 123/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.5220 - accuracy: 0.9888 - val_loss: 8.0201 - val_accuracy: 0.7165\n",
      "Epoch 124/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4873 - accuracy: 0.9887 - val_loss: 7.9870 - val_accuracy: 0.7172\n",
      "Epoch 125/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4520 - accuracy: 0.9893 - val_loss: 7.9543 - val_accuracy: 0.7187\n",
      "Epoch 126/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4171 - accuracy: 0.9910 - val_loss: 7.9212 - val_accuracy: 0.7193\n",
      "Epoch 127/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.3829 - accuracy: 0.9899 - val_loss: 7.8884 - val_accuracy: 0.7205\n",
      "Epoch 128/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.3476 - accuracy: 0.9914 - val_loss: 7.8554 - val_accuracy: 0.7220\n",
      "Epoch 129/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.3133 - accuracy: 0.9913 - val_loss: 7.8231 - val_accuracy: 0.7225\n",
      "Epoch 130/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.2783 - accuracy: 0.9917 - val_loss: 7.7903 - val_accuracy: 0.7224\n",
      "Epoch 131/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.2450 - accuracy: 0.9934 - val_loss: 7.7580 - val_accuracy: 0.7235\n",
      "Epoch 132/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.2102 - accuracy: 0.9932 - val_loss: 7.7260 - val_accuracy: 0.7243\n",
      "Epoch 133/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1761 - accuracy: 0.9937 - val_loss: 7.6938 - val_accuracy: 0.7252\n",
      "Epoch 134/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1413 - accuracy: 0.9941 - val_loss: 7.6614 - val_accuracy: 0.7261\n",
      "Epoch 135/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1078 - accuracy: 0.9946 - val_loss: 7.6291 - val_accuracy: 0.7272\n",
      "Epoch 136/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0753 - accuracy: 0.9942 - val_loss: 7.5971 - val_accuracy: 0.7280\n",
      "Epoch 137/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0407 - accuracy: 0.9946 - val_loss: 7.5652 - val_accuracy: 0.7284\n",
      "Epoch 138/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0079 - accuracy: 0.9944 - val_loss: 7.5335 - val_accuracy: 0.7284\n",
      "Epoch 139/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9740 - accuracy: 0.9954 - val_loss: 7.5015 - val_accuracy: 0.7285\n",
      "Epoch 140/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9410 - accuracy: 0.9961 - val_loss: 7.4699 - val_accuracy: 0.7295\n",
      "Epoch 141/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9084 - accuracy: 0.9956 - val_loss: 7.4386 - val_accuracy: 0.7296\n",
      "Epoch 142/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8746 - accuracy: 0.9965 - val_loss: 7.4069 - val_accuracy: 0.7297\n",
      "Epoch 143/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8426 - accuracy: 0.9965 - val_loss: 7.3754 - val_accuracy: 0.7305\n",
      "Epoch 144/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8101 - accuracy: 0.9966 - val_loss: 7.3439 - val_accuracy: 0.7312\n",
      "Epoch 145/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7761 - accuracy: 0.9977 - val_loss: 7.3129 - val_accuracy: 0.7315\n",
      "Epoch 146/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7451 - accuracy: 0.9968 - val_loss: 7.2813 - val_accuracy: 0.7320\n",
      "Epoch 147/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7128 - accuracy: 0.9973 - val_loss: 7.2503 - val_accuracy: 0.7319\n",
      "Epoch 148/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6809 - accuracy: 0.9974 - val_loss: 7.2196 - val_accuracy: 0.7317\n",
      "Epoch 149/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6481 - accuracy: 0.9976 - val_loss: 7.1889 - val_accuracy: 0.7329\n",
      "Epoch 150/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6165 - accuracy: 0.9978 - val_loss: 7.1577 - val_accuracy: 0.7352\n",
      "Epoch 151/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5850 - accuracy: 0.9978 - val_loss: 7.1276 - val_accuracy: 0.7347\n",
      "Epoch 152/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5529 - accuracy: 0.9979 - val_loss: 7.0964 - val_accuracy: 0.7349\n",
      "Epoch 153/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5213 - accuracy: 0.9978 - val_loss: 7.0659 - val_accuracy: 0.7352\n",
      "Epoch 154/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4887 - accuracy: 0.9982 - val_loss: 7.0355 - val_accuracy: 0.7359\n",
      "Epoch 155/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4575 - accuracy: 0.9984 - val_loss: 7.0052 - val_accuracy: 0.7363\n",
      "Epoch 156/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4269 - accuracy: 0.9985 - val_loss: 6.9747 - val_accuracy: 0.7367\n",
      "Epoch 157/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3954 - accuracy: 0.9985 - val_loss: 6.9445 - val_accuracy: 0.7377\n",
      "Epoch 158/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3654 - accuracy: 0.9988 - val_loss: 6.9143 - val_accuracy: 0.7377\n",
      "Epoch 159/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3342 - accuracy: 0.9987 - val_loss: 6.8845 - val_accuracy: 0.7385\n",
      "Epoch 160/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3033 - accuracy: 0.9987 - val_loss: 6.8548 - val_accuracy: 0.7384\n",
      "Epoch 161/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2724 - accuracy: 0.9990 - val_loss: 6.8250 - val_accuracy: 0.7388\n",
      "Epoch 162/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2415 - accuracy: 0.9991 - val_loss: 6.7954 - val_accuracy: 0.7395\n",
      "Epoch 163/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2117 - accuracy: 0.9991 - val_loss: 6.7652 - val_accuracy: 0.7388\n",
      "Epoch 164/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1805 - accuracy: 0.9994 - val_loss: 6.7361 - val_accuracy: 0.7396\n",
      "Epoch 165/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1509 - accuracy: 0.9991 - val_loss: 6.7070 - val_accuracy: 0.7399\n",
      "Epoch 166/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1209 - accuracy: 0.9993 - val_loss: 6.6772 - val_accuracy: 0.7409\n",
      "Epoch 167/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0904 - accuracy: 0.9995 - val_loss: 6.6478 - val_accuracy: 0.7408\n",
      "Epoch 168/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0605 - accuracy: 0.9992 - val_loss: 6.6187 - val_accuracy: 0.7413\n",
      "Epoch 169/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0316 - accuracy: 0.9992 - val_loss: 6.5893 - val_accuracy: 0.7428\n",
      "Epoch 170/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0010 - accuracy: 0.9992 - val_loss: 6.5600 - val_accuracy: 0.7428\n",
      "Epoch 171/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9713 - accuracy: 0.9996 - val_loss: 6.5310 - val_accuracy: 0.7432\n",
      "Epoch 172/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9419 - accuracy: 0.9996 - val_loss: 6.5018 - val_accuracy: 0.7436\n",
      "Epoch 173/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9125 - accuracy: 0.9996 - val_loss: 6.4731 - val_accuracy: 0.7443\n",
      "Epoch 174/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8835 - accuracy: 0.9998 - val_loss: 6.4451 - val_accuracy: 0.7441\n",
      "Epoch 175/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8544 - accuracy: 0.9998 - val_loss: 6.4159 - val_accuracy: 0.7444\n",
      "Epoch 176/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8254 - accuracy: 0.9996 - val_loss: 6.3870 - val_accuracy: 0.7455\n",
      "Epoch 177/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7955 - accuracy: 0.9998 - val_loss: 6.3585 - val_accuracy: 0.7457\n",
      "Epoch 178/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7672 - accuracy: 0.9997 - val_loss: 6.3302 - val_accuracy: 0.7471\n",
      "Epoch 179/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7395 - accuracy: 0.9999 - val_loss: 6.3019 - val_accuracy: 0.7476\n",
      "Epoch 180/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7094 - accuracy: 0.9997 - val_loss: 6.2734 - val_accuracy: 0.7480\n",
      "Epoch 181/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6816 - accuracy: 0.9997 - val_loss: 6.2455 - val_accuracy: 0.7481\n",
      "Epoch 182/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6536 - accuracy: 0.9998 - val_loss: 6.2171 - val_accuracy: 0.7491\n",
      "Epoch 183/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6240 - accuracy: 1.0000 - val_loss: 6.1895 - val_accuracy: 0.7493\n",
      "Epoch 184/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5961 - accuracy: 0.9999 - val_loss: 6.1616 - val_accuracy: 0.7495\n",
      "Epoch 185/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5679 - accuracy: 0.9999 - val_loss: 6.1337 - val_accuracy: 0.7505\n",
      "Epoch 186/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5399 - accuracy: 0.9999 - val_loss: 6.1061 - val_accuracy: 0.7509\n",
      "Epoch 187/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5122 - accuracy: 0.9999 - val_loss: 6.0789 - val_accuracy: 0.7511\n",
      "Epoch 188/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4839 - accuracy: 1.0000 - val_loss: 6.0511 - val_accuracy: 0.7511\n",
      "Epoch 189/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4567 - accuracy: 0.9999 - val_loss: 6.0239 - val_accuracy: 0.7508\n",
      "Epoch 190/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4287 - accuracy: 1.0000 - val_loss: 5.9957 - val_accuracy: 0.7519\n",
      "Epoch 191/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4014 - accuracy: 1.0000 - val_loss: 5.9680 - val_accuracy: 0.7531\n",
      "Epoch 192/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3739 - accuracy: 1.0000 - val_loss: 5.9415 - val_accuracy: 0.7532\n",
      "Epoch 193/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3457 - accuracy: 1.0000 - val_loss: 5.9143 - val_accuracy: 0.7533\n",
      "Epoch 194/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3195 - accuracy: 1.0000 - val_loss: 5.8872 - val_accuracy: 0.7540\n",
      "Epoch 195/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2919 - accuracy: 1.0000 - val_loss: 5.8607 - val_accuracy: 0.7551\n",
      "Epoch 196/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2647 - accuracy: 1.0000 - val_loss: 5.8338 - val_accuracy: 0.7544\n",
      "Epoch 197/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2380 - accuracy: 1.0000 - val_loss: 5.8072 - val_accuracy: 0.7549\n",
      "Epoch 198/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2108 - accuracy: 1.0000 - val_loss: 5.7804 - val_accuracy: 0.7561\n",
      "Epoch 199/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1845 - accuracy: 1.0000 - val_loss: 5.7539 - val_accuracy: 0.7563\n",
      "Epoch 200/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1577 - accuracy: 0.9999 - val_loss: 5.7272 - val_accuracy: 0.7571\n",
      "Epoch 201/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1309 - accuracy: 1.0000 - val_loss: 5.7008 - val_accuracy: 0.7583\n",
      "Epoch 202/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1041 - accuracy: 1.0000 - val_loss: 5.6745 - val_accuracy: 0.7588\n",
      "Epoch 203/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0780 - accuracy: 1.0000 - val_loss: 5.6480 - val_accuracy: 0.7592\n",
      "Epoch 204/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0517 - accuracy: 1.0000 - val_loss: 5.6224 - val_accuracy: 0.7599\n",
      "Epoch 205/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0259 - accuracy: 1.0000 - val_loss: 5.5953 - val_accuracy: 0.7599\n",
      "Epoch 206/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9998 - accuracy: 1.0000 - val_loss: 5.5688 - val_accuracy: 0.7601\n",
      "Epoch 207/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9737 - accuracy: 1.0000 - val_loss: 5.5430 - val_accuracy: 0.7611\n",
      "Epoch 208/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9474 - accuracy: 1.0000 - val_loss: 5.5175 - val_accuracy: 0.7616\n",
      "Epoch 209/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9222 - accuracy: 1.0000 - val_loss: 5.4918 - val_accuracy: 0.7617\n",
      "Epoch 210/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8957 - accuracy: 1.0000 - val_loss: 5.4663 - val_accuracy: 0.7627\n",
      "Epoch 211/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8706 - accuracy: 1.0000 - val_loss: 5.4404 - val_accuracy: 0.7631\n",
      "Epoch 212/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8448 - accuracy: 1.0000 - val_loss: 5.4153 - val_accuracy: 0.7636\n",
      "Epoch 213/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8195 - accuracy: 1.0000 - val_loss: 5.3892 - val_accuracy: 0.7641\n",
      "Epoch 214/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7940 - accuracy: 1.0000 - val_loss: 5.3635 - val_accuracy: 0.7645\n",
      "Epoch 215/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7688 - accuracy: 1.0000 - val_loss: 5.3386 - val_accuracy: 0.7644\n",
      "Epoch 216/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7438 - accuracy: 1.0000 - val_loss: 5.3136 - val_accuracy: 0.7652\n",
      "Epoch 217/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7189 - accuracy: 1.0000 - val_loss: 5.2884 - val_accuracy: 0.7652\n",
      "Epoch 218/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6934 - accuracy: 1.0000 - val_loss: 5.2636 - val_accuracy: 0.7653\n",
      "Epoch 219/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6687 - accuracy: 1.0000 - val_loss: 5.2385 - val_accuracy: 0.7661\n",
      "Epoch 220/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6443 - accuracy: 1.0000 - val_loss: 5.2137 - val_accuracy: 0.7664\n",
      "Epoch 221/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6190 - accuracy: 1.0000 - val_loss: 5.1890 - val_accuracy: 0.7673\n",
      "Epoch 222/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5951 - accuracy: 1.0000 - val_loss: 5.1645 - val_accuracy: 0.7675\n",
      "Epoch 223/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5699 - accuracy: 1.0000 - val_loss: 5.1395 - val_accuracy: 0.7692\n",
      "Epoch 224/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5459 - accuracy: 1.0000 - val_loss: 5.1150 - val_accuracy: 0.7695\n",
      "Epoch 225/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5217 - accuracy: 1.0000 - val_loss: 5.0907 - val_accuracy: 0.7699\n",
      "Epoch 226/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4977 - accuracy: 1.0000 - val_loss: 5.0661 - val_accuracy: 0.7713\n",
      "Epoch 227/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4733 - accuracy: 1.0000 - val_loss: 5.0418 - val_accuracy: 0.7723\n",
      "Epoch 228/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4486 - accuracy: 1.0000 - val_loss: 5.0180 - val_accuracy: 0.7727\n",
      "Epoch 229/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4250 - accuracy: 1.0000 - val_loss: 4.9939 - val_accuracy: 0.7729\n",
      "Epoch 230/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4005 - accuracy: 1.0000 - val_loss: 4.9696 - val_accuracy: 0.7727\n",
      "Epoch 231/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3770 - accuracy: 1.0000 - val_loss: 4.9457 - val_accuracy: 0.7739\n",
      "Epoch 232/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3536 - accuracy: 1.0000 - val_loss: 4.9220 - val_accuracy: 0.7751\n",
      "Epoch 233/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3298 - accuracy: 1.0000 - val_loss: 4.8978 - val_accuracy: 0.7745\n",
      "Epoch 234/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3064 - accuracy: 1.0000 - val_loss: 4.8743 - val_accuracy: 0.7755\n",
      "Epoch 235/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2827 - accuracy: 1.0000 - val_loss: 4.8506 - val_accuracy: 0.7752\n",
      "Epoch 236/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2596 - accuracy: 1.0000 - val_loss: 4.8269 - val_accuracy: 0.7761\n",
      "Epoch 237/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2361 - accuracy: 1.0000 - val_loss: 4.8033 - val_accuracy: 0.7759\n",
      "Epoch 238/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2133 - accuracy: 1.0000 - val_loss: 4.7798 - val_accuracy: 0.7769\n",
      "Epoch 239/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1902 - accuracy: 1.0000 - val_loss: 4.7564 - val_accuracy: 0.7776\n",
      "Epoch 240/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1673 - accuracy: 1.0000 - val_loss: 4.7328 - val_accuracy: 0.7783\n",
      "Epoch 241/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1447 - accuracy: 1.0000 - val_loss: 4.7102 - val_accuracy: 0.7779\n",
      "Epoch 242/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1217 - accuracy: 1.0000 - val_loss: 4.6879 - val_accuracy: 0.7776\n",
      "Epoch 243/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0989 - accuracy: 1.0000 - val_loss: 4.6648 - val_accuracy: 0.7780\n",
      "Epoch 244/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0760 - accuracy: 1.0000 - val_loss: 4.6420 - val_accuracy: 0.7787\n",
      "Epoch 245/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0535 - accuracy: 1.0000 - val_loss: 4.6187 - val_accuracy: 0.7784\n",
      "Epoch 246/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0310 - accuracy: 1.0000 - val_loss: 4.5961 - val_accuracy: 0.7791\n",
      "Epoch 247/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0090 - accuracy: 1.0000 - val_loss: 4.5734 - val_accuracy: 0.7785\n",
      "Epoch 248/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9865 - accuracy: 1.0000 - val_loss: 4.5509 - val_accuracy: 0.7800\n",
      "Epoch 249/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9645 - accuracy: 1.0000 - val_loss: 4.5285 - val_accuracy: 0.7807\n",
      "Epoch 250/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9424 - accuracy: 1.0000 - val_loss: 4.5064 - val_accuracy: 0.7808\n",
      "Epoch 251/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9205 - accuracy: 1.0000 - val_loss: 4.4845 - val_accuracy: 0.7807\n",
      "Epoch 252/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8987 - accuracy: 1.0000 - val_loss: 4.4619 - val_accuracy: 0.7815\n",
      "Epoch 253/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8770 - accuracy: 1.0000 - val_loss: 4.4398 - val_accuracy: 0.7819\n",
      "Epoch 254/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8547 - accuracy: 1.0000 - val_loss: 4.4175 - val_accuracy: 0.7821\n",
      "Epoch 255/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8335 - accuracy: 1.0000 - val_loss: 4.3963 - val_accuracy: 0.7824\n",
      "Epoch 256/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8121 - accuracy: 1.0000 - val_loss: 4.3745 - val_accuracy: 0.7833\n",
      "Epoch 257/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7905 - accuracy: 1.0000 - val_loss: 4.3530 - val_accuracy: 0.7841\n",
      "Epoch 258/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7696 - accuracy: 1.0000 - val_loss: 4.3316 - val_accuracy: 0.7848\n",
      "Epoch 259/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7481 - accuracy: 1.0000 - val_loss: 4.3096 - val_accuracy: 0.7852\n",
      "Epoch 260/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7268 - accuracy: 1.0000 - val_loss: 4.2875 - val_accuracy: 0.7857\n",
      "Epoch 261/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7056 - accuracy: 1.0000 - val_loss: 4.2656 - val_accuracy: 0.7863\n",
      "Epoch 262/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6847 - accuracy: 1.0000 - val_loss: 4.2447 - val_accuracy: 0.7856\n",
      "Epoch 263/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6642 - accuracy: 1.0000 - val_loss: 4.2244 - val_accuracy: 0.7868\n",
      "Epoch 264/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6435 - accuracy: 1.0000 - val_loss: 4.2031 - val_accuracy: 0.7868\n",
      "Epoch 265/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6228 - accuracy: 1.0000 - val_loss: 4.1810 - val_accuracy: 0.7872\n",
      "Epoch 266/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6019 - accuracy: 1.0000 - val_loss: 4.1607 - val_accuracy: 0.7875\n",
      "Epoch 267/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5813 - accuracy: 1.0000 - val_loss: 4.1400 - val_accuracy: 0.7879\n",
      "Epoch 268/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5608 - accuracy: 1.0000 - val_loss: 4.1195 - val_accuracy: 0.7889\n",
      "Epoch 269/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5404 - accuracy: 1.0000 - val_loss: 4.0990 - val_accuracy: 0.7901\n",
      "Epoch 270/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5203 - accuracy: 1.0000 - val_loss: 4.0785 - val_accuracy: 0.7905\n",
      "Epoch 271/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5002 - accuracy: 1.0000 - val_loss: 4.0583 - val_accuracy: 0.7912\n",
      "Epoch 272/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4800 - accuracy: 1.0000 - val_loss: 4.0378 - val_accuracy: 0.7923\n",
      "Epoch 273/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4599 - accuracy: 1.0000 - val_loss: 4.0169 - val_accuracy: 0.7929\n",
      "Epoch 274/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4406 - accuracy: 1.0000 - val_loss: 3.9969 - val_accuracy: 0.7929\n",
      "Epoch 275/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4204 - accuracy: 1.0000 - val_loss: 3.9768 - val_accuracy: 0.7936\n",
      "Epoch 276/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4010 - accuracy: 1.0000 - val_loss: 3.9561 - val_accuracy: 0.7943\n",
      "Epoch 277/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3813 - accuracy: 1.0000 - val_loss: 3.9368 - val_accuracy: 0.7935\n",
      "Epoch 278/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3621 - accuracy: 1.0000 - val_loss: 3.9168 - val_accuracy: 0.7940\n",
      "Epoch 279/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3419 - accuracy: 1.0000 - val_loss: 3.8963 - val_accuracy: 0.7936\n",
      "Epoch 280/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3228 - accuracy: 1.0000 - val_loss: 3.8768 - val_accuracy: 0.7944\n",
      "Epoch 281/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3033 - accuracy: 1.0000 - val_loss: 3.8565 - val_accuracy: 0.7944\n",
      "Epoch 282/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2841 - accuracy: 1.0000 - val_loss: 3.8375 - val_accuracy: 0.7953\n",
      "Epoch 283/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2653 - accuracy: 1.0000 - val_loss: 3.8192 - val_accuracy: 0.7960\n",
      "Epoch 284/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2463 - accuracy: 1.0000 - val_loss: 3.7989 - val_accuracy: 0.7959\n",
      "Epoch 285/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2274 - accuracy: 1.0000 - val_loss: 3.7800 - val_accuracy: 0.7976\n",
      "Epoch 286/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2084 - accuracy: 1.0000 - val_loss: 3.7605 - val_accuracy: 0.7973\n",
      "Epoch 287/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1897 - accuracy: 1.0000 - val_loss: 3.7422 - val_accuracy: 0.7971\n",
      "Epoch 288/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1710 - accuracy: 1.0000 - val_loss: 3.7220 - val_accuracy: 0.7977\n",
      "Epoch 289/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1522 - accuracy: 1.0000 - val_loss: 3.7041 - val_accuracy: 0.7988\n",
      "Epoch 290/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1340 - accuracy: 1.0000 - val_loss: 3.6845 - val_accuracy: 0.7988\n",
      "Epoch 291/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1156 - accuracy: 1.0000 - val_loss: 3.6662 - val_accuracy: 0.7993\n",
      "Epoch 292/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0972 - accuracy: 1.0000 - val_loss: 3.6481 - val_accuracy: 0.7996\n",
      "Epoch 293/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0793 - accuracy: 1.0000 - val_loss: 3.6295 - val_accuracy: 0.8008\n",
      "Epoch 294/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0611 - accuracy: 1.0000 - val_loss: 3.6103 - val_accuracy: 0.8009\n",
      "Epoch 295/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0432 - accuracy: 1.0000 - val_loss: 3.5925 - val_accuracy: 0.8015\n",
      "Epoch 296/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0251 - accuracy: 1.0000 - val_loss: 3.5737 - val_accuracy: 0.8017\n",
      "Epoch 297/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0073 - accuracy: 1.0000 - val_loss: 3.5554 - val_accuracy: 0.8020\n",
      "Epoch 298/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9896 - accuracy: 1.0000 - val_loss: 3.5370 - val_accuracy: 0.8015\n",
      "Epoch 299/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9721 - accuracy: 1.0000 - val_loss: 3.5191 - val_accuracy: 0.8039\n",
      "Epoch 300/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9544 - accuracy: 1.0000 - val_loss: 3.5005 - val_accuracy: 0.8031\n",
      "Epoch 301/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9371 - accuracy: 1.0000 - val_loss: 3.4827 - val_accuracy: 0.8036\n",
      "Epoch 302/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9195 - accuracy: 1.0000 - val_loss: 3.4655 - val_accuracy: 0.8036\n",
      "Epoch 303/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9026 - accuracy: 1.0000 - val_loss: 3.4484 - val_accuracy: 0.8043\n",
      "Epoch 304/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8850 - accuracy: 1.0000 - val_loss: 3.4305 - val_accuracy: 0.8055\n",
      "Epoch 305/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8677 - accuracy: 1.0000 - val_loss: 3.4131 - val_accuracy: 0.8053\n",
      "Epoch 306/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8510 - accuracy: 1.0000 - val_loss: 3.3951 - val_accuracy: 0.8051\n",
      "Epoch 307/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8340 - accuracy: 1.0000 - val_loss: 3.3783 - val_accuracy: 0.8047\n",
      "Epoch 308/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8173 - accuracy: 1.0000 - val_loss: 3.3615 - val_accuracy: 0.8053\n",
      "Epoch 309/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7999 - accuracy: 1.0000 - val_loss: 3.3435 - val_accuracy: 0.8063\n",
      "Epoch 310/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7836 - accuracy: 1.0000 - val_loss: 3.3267 - val_accuracy: 0.8059\n",
      "Epoch 311/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7671 - accuracy: 1.0000 - val_loss: 3.3094 - val_accuracy: 0.8067\n",
      "Epoch 312/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7510 - accuracy: 1.0000 - val_loss: 3.2927 - val_accuracy: 0.8061\n",
      "Epoch 313/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7344 - accuracy: 1.0000 - val_loss: 3.2765 - val_accuracy: 0.8065\n",
      "Epoch 314/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7178 - accuracy: 1.0000 - val_loss: 3.2600 - val_accuracy: 0.8069\n",
      "Epoch 315/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7018 - accuracy: 1.0000 - val_loss: 3.2432 - val_accuracy: 0.8069\n",
      "Epoch 316/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6857 - accuracy: 1.0000 - val_loss: 3.2273 - val_accuracy: 0.8068\n",
      "Epoch 317/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6696 - accuracy: 1.0000 - val_loss: 3.2113 - val_accuracy: 0.8065\n",
      "Epoch 318/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6536 - accuracy: 1.0000 - val_loss: 3.1954 - val_accuracy: 0.8059\n",
      "Epoch 319/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6376 - accuracy: 1.0000 - val_loss: 3.1782 - val_accuracy: 0.8063\n",
      "Epoch 320/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6226 - accuracy: 1.0000 - val_loss: 3.1622 - val_accuracy: 0.8057\n",
      "Epoch 321/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6062 - accuracy: 1.0000 - val_loss: 3.1456 - val_accuracy: 0.8057\n",
      "Epoch 322/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5905 - accuracy: 1.0000 - val_loss: 3.1295 - val_accuracy: 0.8064\n",
      "Epoch 323/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5752 - accuracy: 1.0000 - val_loss: 3.1146 - val_accuracy: 0.8063\n",
      "Epoch 324/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5599 - accuracy: 1.0000 - val_loss: 3.0990 - val_accuracy: 0.8069\n",
      "Epoch 325/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5445 - accuracy: 1.0000 - val_loss: 3.0834 - val_accuracy: 0.8065\n",
      "Epoch 326/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5293 - accuracy: 1.0000 - val_loss: 3.0674 - val_accuracy: 0.8076\n",
      "Epoch 327/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5141 - accuracy: 1.0000 - val_loss: 3.0518 - val_accuracy: 0.8067\n",
      "Epoch 328/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4992 - accuracy: 1.0000 - val_loss: 3.0370 - val_accuracy: 0.8069\n",
      "Epoch 329/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4843 - accuracy: 1.0000 - val_loss: 3.0212 - val_accuracy: 0.8071\n",
      "Epoch 330/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4694 - accuracy: 1.0000 - val_loss: 3.0062 - val_accuracy: 0.8079\n",
      "Epoch 331/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4546 - accuracy: 1.0000 - val_loss: 2.9908 - val_accuracy: 0.8076\n",
      "Epoch 332/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4397 - accuracy: 1.0000 - val_loss: 2.9769 - val_accuracy: 0.8073\n",
      "Epoch 333/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4254 - accuracy: 1.0000 - val_loss: 2.9618 - val_accuracy: 0.8075\n",
      "Epoch 334/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4107 - accuracy: 1.0000 - val_loss: 2.9479 - val_accuracy: 0.8085\n",
      "Epoch 335/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3968 - accuracy: 1.0000 - val_loss: 2.9313 - val_accuracy: 0.8085\n",
      "Epoch 336/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3825 - accuracy: 1.0000 - val_loss: 2.9173 - val_accuracy: 0.8073\n",
      "Epoch 337/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3678 - accuracy: 1.0000 - val_loss: 2.9028 - val_accuracy: 0.8083\n",
      "Epoch 338/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3536 - accuracy: 1.0000 - val_loss: 2.8891 - val_accuracy: 0.8080\n",
      "Epoch 339/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3402 - accuracy: 1.0000 - val_loss: 2.8750 - val_accuracy: 0.8083\n",
      "Epoch 340/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3257 - accuracy: 1.0000 - val_loss: 2.8605 - val_accuracy: 0.8084\n",
      "Epoch 341/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3120 - accuracy: 1.0000 - val_loss: 2.8460 - val_accuracy: 0.8088\n",
      "Epoch 342/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2981 - accuracy: 1.0000 - val_loss: 2.8337 - val_accuracy: 0.8097\n",
      "Epoch 343/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2848 - accuracy: 1.0000 - val_loss: 2.8184 - val_accuracy: 0.8083\n",
      "Epoch 344/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2709 - accuracy: 1.0000 - val_loss: 2.8047 - val_accuracy: 0.8104\n",
      "Epoch 345/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2578 - accuracy: 1.0000 - val_loss: 2.7916 - val_accuracy: 0.8095\n",
      "Epoch 346/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2442 - accuracy: 1.0000 - val_loss: 2.7780 - val_accuracy: 0.8101\n",
      "Epoch 347/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2309 - accuracy: 1.0000 - val_loss: 2.7640 - val_accuracy: 0.8109\n",
      "Epoch 348/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2177 - accuracy: 1.0000 - val_loss: 2.7509 - val_accuracy: 0.8096\n",
      "Epoch 349/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2047 - accuracy: 1.0000 - val_loss: 2.7365 - val_accuracy: 0.8101\n",
      "Epoch 350/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1915 - accuracy: 1.0000 - val_loss: 2.7246 - val_accuracy: 0.8111\n",
      "Epoch 351/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1784 - accuracy: 1.0000 - val_loss: 2.7106 - val_accuracy: 0.8093\n",
      "Epoch 352/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1656 - accuracy: 1.0000 - val_loss: 2.6979 - val_accuracy: 0.8108\n",
      "Epoch 353/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1527 - accuracy: 1.0000 - val_loss: 2.6850 - val_accuracy: 0.8097\n",
      "Epoch 354/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1405 - accuracy: 1.0000 - val_loss: 2.6711 - val_accuracy: 0.8103\n",
      "Epoch 355/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1278 - accuracy: 1.0000 - val_loss: 2.6588 - val_accuracy: 0.8103\n",
      "Epoch 356/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1150 - accuracy: 1.0000 - val_loss: 2.6462 - val_accuracy: 0.8100\n",
      "Epoch 357/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1028 - accuracy: 1.0000 - val_loss: 2.6330 - val_accuracy: 0.8105\n",
      "Epoch 358/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0903 - accuracy: 1.0000 - val_loss: 2.6209 - val_accuracy: 0.8115\n",
      "Epoch 359/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0786 - accuracy: 1.0000 - val_loss: 2.6072 - val_accuracy: 0.8113\n",
      "Epoch 360/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0663 - accuracy: 1.0000 - val_loss: 2.5952 - val_accuracy: 0.8115\n",
      "Epoch 361/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0540 - accuracy: 1.0000 - val_loss: 2.5826 - val_accuracy: 0.8112\n",
      "Epoch 362/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0422 - accuracy: 1.0000 - val_loss: 2.5712 - val_accuracy: 0.8112\n",
      "Epoch 363/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0301 - accuracy: 1.0000 - val_loss: 2.5590 - val_accuracy: 0.8120\n",
      "Epoch 364/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0184 - accuracy: 1.0000 - val_loss: 2.5465 - val_accuracy: 0.8131\n",
      "Epoch 365/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0069 - accuracy: 1.0000 - val_loss: 2.5353 - val_accuracy: 0.8132\n",
      "Epoch 366/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9951 - accuracy: 1.0000 - val_loss: 2.5230 - val_accuracy: 0.8117\n",
      "Epoch 367/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9837 - accuracy: 1.0000 - val_loss: 2.5102 - val_accuracy: 0.8124\n",
      "Epoch 368/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9724 - accuracy: 1.0000 - val_loss: 2.4999 - val_accuracy: 0.8127\n",
      "Epoch 369/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9608 - accuracy: 1.0000 - val_loss: 2.4868 - val_accuracy: 0.8139\n",
      "Epoch 370/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9496 - accuracy: 1.0000 - val_loss: 2.4768 - val_accuracy: 0.8144\n",
      "Epoch 371/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9382 - accuracy: 1.0000 - val_loss: 2.4651 - val_accuracy: 0.8153\n",
      "Epoch 372/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9274 - accuracy: 1.0000 - val_loss: 2.4551 - val_accuracy: 0.8167\n",
      "Epoch 373/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9162 - accuracy: 1.0000 - val_loss: 2.4441 - val_accuracy: 0.8160\n",
      "Epoch 374/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9053 - accuracy: 1.0000 - val_loss: 2.4337 - val_accuracy: 0.8164\n",
      "Epoch 375/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8951 - accuracy: 1.0000 - val_loss: 2.4219 - val_accuracy: 0.8180\n",
      "Epoch 376/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8847 - accuracy: 1.0000 - val_loss: 2.4109 - val_accuracy: 0.8177\n",
      "Epoch 377/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8739 - accuracy: 1.0000 - val_loss: 2.4021 - val_accuracy: 0.8177\n",
      "Epoch 378/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8632 - accuracy: 1.0000 - val_loss: 2.3906 - val_accuracy: 0.8175\n",
      "Epoch 379/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8528 - accuracy: 1.0000 - val_loss: 2.3792 - val_accuracy: 0.8193\n",
      "Epoch 380/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8421 - accuracy: 1.0000 - val_loss: 2.3708 - val_accuracy: 0.8171\n",
      "Epoch 381/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8318 - accuracy: 1.0000 - val_loss: 2.3598 - val_accuracy: 0.8177\n",
      "Epoch 382/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8214 - accuracy: 1.0000 - val_loss: 2.3489 - val_accuracy: 0.8181\n",
      "Epoch 383/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8122 - accuracy: 1.0000 - val_loss: 2.3394 - val_accuracy: 0.8180\n",
      "Epoch 384/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8021 - accuracy: 1.0000 - val_loss: 2.3302 - val_accuracy: 0.8188\n",
      "Epoch 385/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7921 - accuracy: 1.0000 - val_loss: 2.3208 - val_accuracy: 0.8188\n",
      "Epoch 386/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7820 - accuracy: 1.0000 - val_loss: 2.3107 - val_accuracy: 0.8197\n",
      "Epoch 387/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7727 - accuracy: 1.0000 - val_loss: 2.3010 - val_accuracy: 0.8193\n",
      "Epoch 388/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7627 - accuracy: 1.0000 - val_loss: 2.2883 - val_accuracy: 0.8184\n",
      "Epoch 389/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7532 - accuracy: 1.0000 - val_loss: 2.2816 - val_accuracy: 0.8183\n",
      "Epoch 390/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7438 - accuracy: 1.0000 - val_loss: 2.2705 - val_accuracy: 0.8155\n",
      "Epoch 391/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7344 - accuracy: 1.0000 - val_loss: 2.2635 - val_accuracy: 0.8169\n",
      "Epoch 392/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7251 - accuracy: 1.0000 - val_loss: 2.2512 - val_accuracy: 0.8185\n",
      "Epoch 393/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7158 - accuracy: 1.0000 - val_loss: 2.2450 - val_accuracy: 0.8204\n",
      "Epoch 394/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7070 - accuracy: 1.0000 - val_loss: 2.2352 - val_accuracy: 0.8203\n",
      "Epoch 395/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6983 - accuracy: 1.0000 - val_loss: 2.2231 - val_accuracy: 0.8203\n",
      "Epoch 396/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6887 - accuracy: 1.0000 - val_loss: 2.2173 - val_accuracy: 0.8208\n",
      "Epoch 397/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6799 - accuracy: 1.0000 - val_loss: 2.2060 - val_accuracy: 0.8220\n",
      "Epoch 398/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6710 - accuracy: 1.0000 - val_loss: 2.1990 - val_accuracy: 0.8207\n",
      "Epoch 399/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6628 - accuracy: 1.0000 - val_loss: 2.1888 - val_accuracy: 0.8232\n",
      "Epoch 400/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6544 - accuracy: 1.0000 - val_loss: 2.1820 - val_accuracy: 0.8204\n",
      "Epoch 401/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6453 - accuracy: 1.0000 - val_loss: 2.1727 - val_accuracy: 0.8211\n",
      "Epoch 402/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6371 - accuracy: 1.0000 - val_loss: 2.1643 - val_accuracy: 0.8224\n",
      "Epoch 403/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6290 - accuracy: 1.0000 - val_loss: 2.1590 - val_accuracy: 0.8208\n",
      "Epoch 404/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6210 - accuracy: 1.0000 - val_loss: 2.1448 - val_accuracy: 0.8221\n",
      "Epoch 405/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6128 - accuracy: 1.0000 - val_loss: 2.1373 - val_accuracy: 0.8224\n",
      "Epoch 406/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6046 - accuracy: 1.0000 - val_loss: 2.1306 - val_accuracy: 0.8231\n",
      "Epoch 407/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5966 - accuracy: 1.0000 - val_loss: 2.1245 - val_accuracy: 0.8207\n",
      "Epoch 408/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5892 - accuracy: 1.0000 - val_loss: 2.1166 - val_accuracy: 0.8221\n",
      "Epoch 409/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5810 - accuracy: 1.0000 - val_loss: 2.1081 - val_accuracy: 0.8231\n",
      "Epoch 410/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5729 - accuracy: 1.0000 - val_loss: 2.0988 - val_accuracy: 0.8217\n",
      "Epoch 411/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5657 - accuracy: 1.0000 - val_loss: 2.0934 - val_accuracy: 0.8220\n",
      "Epoch 412/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5582 - accuracy: 1.0000 - val_loss: 2.0800 - val_accuracy: 0.8239\n",
      "Epoch 413/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5504 - accuracy: 1.0000 - val_loss: 2.0781 - val_accuracy: 0.8211\n",
      "Epoch 414/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5427 - accuracy: 1.0000 - val_loss: 2.0684 - val_accuracy: 0.8213\n",
      "Epoch 415/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5357 - accuracy: 1.0000 - val_loss: 2.0626 - val_accuracy: 0.8233\n",
      "Epoch 416/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5288 - accuracy: 1.0000 - val_loss: 2.0546 - val_accuracy: 0.8220\n",
      "Epoch 417/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5220 - accuracy: 1.0000 - val_loss: 2.0517 - val_accuracy: 0.8216\n",
      "Epoch 418/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5151 - accuracy: 1.0000 - val_loss: 2.0375 - val_accuracy: 0.8225\n",
      "Epoch 419/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5080 - accuracy: 1.0000 - val_loss: 2.0399 - val_accuracy: 0.8228\n",
      "Epoch 420/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5022 - accuracy: 1.0000 - val_loss: 2.0212 - val_accuracy: 0.8256\n",
      "Epoch 421/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4944 - accuracy: 1.0000 - val_loss: 2.0143 - val_accuracy: 0.8251\n",
      "Epoch 422/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4868 - accuracy: 1.0000 - val_loss: 2.0098 - val_accuracy: 0.8249\n",
      "Epoch 423/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4807 - accuracy: 1.0000 - val_loss: 2.0001 - val_accuracy: 0.8251\n",
      "Epoch 424/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4746 - accuracy: 1.0000 - val_loss: 1.9965 - val_accuracy: 0.8260\n",
      "Epoch 425/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4698 - accuracy: 1.0000 - val_loss: 1.9952 - val_accuracy: 0.8236\n",
      "Epoch 426/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4624 - accuracy: 1.0000 - val_loss: 1.9786 - val_accuracy: 0.8260\n",
      "Epoch 427/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4544 - accuracy: 1.0000 - val_loss: 1.9786 - val_accuracy: 0.8228\n",
      "Epoch 428/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5445 - accuracy: 0.9802 - val_loss: 4.3156 - val_accuracy: 0.5851\n",
      "Epoch 429/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0740 - accuracy: 0.8596 - val_loss: 2.5691 - val_accuracy: 0.7433\n",
      "Epoch 430/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7269 - accuracy: 0.9717 - val_loss: 2.0604 - val_accuracy: 0.8597\n",
      "Epoch 431/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6366 - accuracy: 0.9981 - val_loss: 2.0190 - val_accuracy: 0.8604\n",
      "Epoch 432/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5913 - accuracy: 0.9999 - val_loss: 2.0195 - val_accuracy: 0.8515\n",
      "Epoch 433/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5561 - accuracy: 1.0000 - val_loss: 2.0053 - val_accuracy: 0.8475\n",
      "Epoch 434/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5272 - accuracy: 1.0000 - val_loss: 1.9793 - val_accuracy: 0.8465\n",
      "Epoch 435/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5024 - accuracy: 1.0000 - val_loss: 1.9516 - val_accuracy: 0.8491\n",
      "Epoch 436/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4809 - accuracy: 1.0000 - val_loss: 1.9271 - val_accuracy: 0.8521\n",
      "Epoch 437/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4618 - accuracy: 1.0000 - val_loss: 1.9022 - val_accuracy: 0.8539\n",
      "Epoch 438/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4456 - accuracy: 1.0000 - val_loss: 1.8840 - val_accuracy: 0.8523\n",
      "Epoch 439/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4311 - accuracy: 1.0000 - val_loss: 1.8653 - val_accuracy: 0.8533\n",
      "Epoch 440/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4188 - accuracy: 1.0000 - val_loss: 1.8487 - val_accuracy: 0.8536\n",
      "Epoch 441/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4078 - accuracy: 1.0000 - val_loss: 1.8364 - val_accuracy: 0.8561\n",
      "Epoch 442/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3980 - accuracy: 1.0000 - val_loss: 1.8254 - val_accuracy: 0.8552\n",
      "Epoch 443/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3900 - accuracy: 1.0000 - val_loss: 1.8172 - val_accuracy: 0.8547\n",
      "Epoch 444/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3841 - accuracy: 0.9999 - val_loss: 1.8163 - val_accuracy: 0.8541\n",
      "Epoch 445/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8511 - accuracy: 0.8904 - val_loss: 2.8585 - val_accuracy: 0.6815\n",
      "Epoch 446/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7111 - accuracy: 0.9496 - val_loss: 2.0128 - val_accuracy: 0.8511\n",
      "Epoch 447/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5856 - accuracy: 0.9936 - val_loss: 1.8906 - val_accuracy: 0.8789\n",
      "Epoch 448/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5295 - accuracy: 0.9999 - val_loss: 1.8921 - val_accuracy: 0.8713\n",
      "Epoch 449/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4921 - accuracy: 1.0000 - val_loss: 1.8821 - val_accuracy: 0.8641\n",
      "Epoch 450/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4621 - accuracy: 1.0000 - val_loss: 1.8617 - val_accuracy: 0.8621\n",
      "Epoch 451/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4362 - accuracy: 1.0000 - val_loss: 1.8366 - val_accuracy: 0.8640\n",
      "Epoch 452/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4144 - accuracy: 1.0000 - val_loss: 1.8122 - val_accuracy: 0.8657\n",
      "Epoch 453/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3959 - accuracy: 1.0000 - val_loss: 1.7892 - val_accuracy: 0.8675\n",
      "Epoch 454/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3800 - accuracy: 1.0000 - val_loss: 1.7698 - val_accuracy: 0.8677\n",
      "Epoch 455/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3663 - accuracy: 1.0000 - val_loss: 1.7459 - val_accuracy: 0.8709\n",
      "Epoch 456/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3536 - accuracy: 1.0000 - val_loss: 1.7307 - val_accuracy: 0.8687\n",
      "Epoch 457/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3431 - accuracy: 1.0000 - val_loss: 1.7141 - val_accuracy: 0.8724\n",
      "Epoch 458/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3361 - accuracy: 1.0000 - val_loss: 1.7044 - val_accuracy: 0.8712\n",
      "Epoch 459/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3288 - accuracy: 1.0000 - val_loss: 1.7037 - val_accuracy: 0.8695\n",
      "Epoch 460/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3221 - accuracy: 1.0000 - val_loss: 1.6902 - val_accuracy: 0.8729\n",
      "Epoch 461/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4239 - accuracy: 0.9755 - val_loss: 3.9838 - val_accuracy: 0.5564\n",
      "Epoch 462/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8572 - accuracy: 0.8781 - val_loss: 2.3582 - val_accuracy: 0.7549\n",
      "Epoch 463/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5822 - accuracy: 0.9780 - val_loss: 1.8240 - val_accuracy: 0.8893\n",
      "Epoch 464/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5002 - accuracy: 0.9988 - val_loss: 1.8081 - val_accuracy: 0.8793\n",
      "Epoch 465/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4563 - accuracy: 1.0000 - val_loss: 1.8170 - val_accuracy: 0.8672\n",
      "Epoch 466/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4228 - accuracy: 1.0000 - val_loss: 1.8053 - val_accuracy: 0.8636\n",
      "Epoch 467/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3947 - accuracy: 1.0000 - val_loss: 1.7832 - val_accuracy: 0.8617\n",
      "Epoch 468/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3709 - accuracy: 1.0000 - val_loss: 1.7570 - val_accuracy: 0.8632\n",
      "Epoch 469/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3507 - accuracy: 1.0000 - val_loss: 1.7277 - val_accuracy: 0.8689\n",
      "Epoch 470/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3328 - accuracy: 1.0000 - val_loss: 1.7033 - val_accuracy: 0.8708\n",
      "Epoch 471/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3173 - accuracy: 1.0000 - val_loss: 1.6844 - val_accuracy: 0.8729\n",
      "Epoch 472/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3051 - accuracy: 1.0000 - val_loss: 1.6617 - val_accuracy: 0.8771\n",
      "Epoch 473/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2943 - accuracy: 1.0000 - val_loss: 1.6430 - val_accuracy: 0.8791\n",
      "Epoch 474/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2851 - accuracy: 1.0000 - val_loss: 1.6232 - val_accuracy: 0.8820\n",
      "Epoch 475/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2778 - accuracy: 1.0000 - val_loss: 1.6209 - val_accuracy: 0.8801\n",
      "Epoch 476/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3455 - accuracy: 0.9812 - val_loss: 3.6074 - val_accuracy: 0.6033\n",
      "Epoch 477/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7805 - accuracy: 0.8846 - val_loss: 2.3357 - val_accuracy: 0.7507\n",
      "Epoch 478/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5297 - accuracy: 0.9780 - val_loss: 1.7749 - val_accuracy: 0.8880\n",
      "Epoch 479/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4527 - accuracy: 0.9982 - val_loss: 1.7311 - val_accuracy: 0.8919\n",
      "Epoch 480/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4091 - accuracy: 0.9999 - val_loss: 1.7263 - val_accuracy: 0.8831\n",
      "Epoch 481/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3750 - accuracy: 1.0000 - val_loss: 1.7158 - val_accuracy: 0.8783\n",
      "Epoch 482/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3472 - accuracy: 1.0000 - val_loss: 1.6938 - val_accuracy: 0.8755\n",
      "Epoch 483/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3237 - accuracy: 1.0000 - val_loss: 1.6695 - val_accuracy: 0.8771\n",
      "Epoch 484/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3037 - accuracy: 1.0000 - val_loss: 1.6416 - val_accuracy: 0.8796\n",
      "Epoch 485/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2867 - accuracy: 1.0000 - val_loss: 1.6189 - val_accuracy: 0.8823\n",
      "Epoch 486/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2720 - accuracy: 1.0000 - val_loss: 1.6000 - val_accuracy: 0.8832\n",
      "Epoch 487/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2608 - accuracy: 1.0000 - val_loss: 1.5825 - val_accuracy: 0.8860\n",
      "Epoch 488/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2506 - accuracy: 1.0000 - val_loss: 1.5675 - val_accuracy: 0.8908\n",
      "Epoch 489/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2436 - accuracy: 1.0000 - val_loss: 1.5494 - val_accuracy: 0.8928\n",
      "Epoch 490/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2467 - accuracy: 0.9976 - val_loss: 2.1274 - val_accuracy: 0.7900\n",
      "Epoch 491/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7263 - accuracy: 0.8868 - val_loss: 2.4320 - val_accuracy: 0.7184\n",
      "Epoch 492/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5004 - accuracy: 0.9736 - val_loss: 1.7342 - val_accuracy: 0.8856\n",
      "Epoch 493/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4171 - accuracy: 0.9974 - val_loss: 1.6687 - val_accuracy: 0.8975\n",
      "Epoch 494/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3709 - accuracy: 0.9999 - val_loss: 1.6676 - val_accuracy: 0.8867\n",
      "Epoch 495/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3366 - accuracy: 1.0000 - val_loss: 1.6553 - val_accuracy: 0.8832\n",
      "Epoch 496/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3085 - accuracy: 1.0000 - val_loss: 1.6351 - val_accuracy: 0.8833\n",
      "Epoch 497/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2851 - accuracy: 1.0000 - val_loss: 1.6102 - val_accuracy: 0.8840\n",
      "Epoch 498/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2653 - accuracy: 1.0000 - val_loss: 1.5855 - val_accuracy: 0.8876\n",
      "Epoch 499/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2489 - accuracy: 1.0000 - val_loss: 1.5637 - val_accuracy: 0.8913\n",
      "Epoch 500/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.2353 - accuracy: 1.0000 - val_loss: 1.5424 - val_accuracy: 0.8936\n",
      "Time: 175.2011215686798\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Traits_Model_50OU.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#50 OU\n",
    "################################################################################################################################################\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test  = train_test_split(y,X50,traits_OU50,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = OU_subset(ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Traits_Model_50OU.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jLWVlN8g82lD",
    "outputId": "1ee86ff8-b433-45a6-c757-d4b8662a7e48",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 20, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 18, 250)      45000       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 18, 250)     1000        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 16, 250)      187500      ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 250)     1000        ['conv1d_4[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 14, 250)      187500      ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 14, 250)     1000        ['conv1d_5[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 4, 250)      0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 1000)         0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense_12_input (InputLayer)    [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 125)          125125      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 150)          450000      ['dense_12_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 125)          0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 150)         600         ['dense_12[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 125)          15750       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 150)          22500       ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 125)          0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 150)         600         ['dense_13[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 50)           6300        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 50)           7550        ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 50)           0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_1 (LinearW)           (None, 50)           2           ['dense_14[0][0]',               \n",
      "                                                                  'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 50)           2550        ['linear_w_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 3)            153         ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,054,130\n",
      "Trainable params: 1,052,030\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 3s 12ms/step - loss: 13.2254 - accuracy: 0.3483 - val_loss: 13.1252 - val_accuracy: 0.3517\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 13.1410 - accuracy: 0.3710 - val_loss: 13.0691 - val_accuracy: 0.3839\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 13.0673 - accuracy: 0.3931 - val_loss: 13.0035 - val_accuracy: 0.4220\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.9952 - accuracy: 0.4188 - val_loss: 12.9327 - val_accuracy: 0.4635\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.9309 - accuracy: 0.4354 - val_loss: 12.8618 - val_accuracy: 0.4993\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.8618 - accuracy: 0.4651 - val_loss: 12.7929 - val_accuracy: 0.5336\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.7991 - accuracy: 0.4765 - val_loss: 12.7259 - val_accuracy: 0.5587\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.7344 - accuracy: 0.4968 - val_loss: 12.6603 - val_accuracy: 0.5761\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.6680 - accuracy: 0.5193 - val_loss: 12.5953 - val_accuracy: 0.5928\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.6144 - accuracy: 0.5255 - val_loss: 12.5332 - val_accuracy: 0.6069\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.5526 - accuracy: 0.5429 - val_loss: 12.4721 - val_accuracy: 0.6185\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.4963 - accuracy: 0.5556 - val_loss: 12.4125 - val_accuracy: 0.6285\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.4377 - accuracy: 0.5636 - val_loss: 12.3547 - val_accuracy: 0.6377\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.3765 - accuracy: 0.5791 - val_loss: 12.2970 - val_accuracy: 0.6465\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.3273 - accuracy: 0.5883 - val_loss: 12.2412 - val_accuracy: 0.6521\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.2653 - accuracy: 0.6003 - val_loss: 12.1857 - val_accuracy: 0.6597\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.2109 - accuracy: 0.6068 - val_loss: 12.1309 - val_accuracy: 0.6661\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.1589 - accuracy: 0.6148 - val_loss: 12.0773 - val_accuracy: 0.6711\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.1009 - accuracy: 0.6238 - val_loss: 12.0239 - val_accuracy: 0.6773\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.0544 - accuracy: 0.6269 - val_loss: 11.9710 - val_accuracy: 0.6840\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.9960 - accuracy: 0.6377 - val_loss: 11.9182 - val_accuracy: 0.6896\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.9474 - accuracy: 0.6400 - val_loss: 11.8662 - val_accuracy: 0.6952\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.8932 - accuracy: 0.6496 - val_loss: 11.8140 - val_accuracy: 0.7013\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.8419 - accuracy: 0.6555 - val_loss: 11.7623 - val_accuracy: 0.7067\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.7887 - accuracy: 0.6625 - val_loss: 11.7104 - val_accuracy: 0.7108\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.7425 - accuracy: 0.6634 - val_loss: 11.6586 - val_accuracy: 0.7169\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.6894 - accuracy: 0.6743 - val_loss: 11.6072 - val_accuracy: 0.7231\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 11.6374 - accuracy: 0.6737 - val_loss: 11.5559 - val_accuracy: 0.7276\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.5867 - accuracy: 0.6835 - val_loss: 11.5039 - val_accuracy: 0.7315\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.5316 - accuracy: 0.6926 - val_loss: 11.4514 - val_accuracy: 0.7380\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.4835 - accuracy: 0.6947 - val_loss: 11.4001 - val_accuracy: 0.7419\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.4328 - accuracy: 0.6999 - val_loss: 11.3485 - val_accuracy: 0.7469\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.3797 - accuracy: 0.7076 - val_loss: 11.2965 - val_accuracy: 0.7517\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.3340 - accuracy: 0.7054 - val_loss: 11.2451 - val_accuracy: 0.7599\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.2750 - accuracy: 0.7223 - val_loss: 11.1934 - val_accuracy: 0.7653\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.2190 - accuracy: 0.7288 - val_loss: 11.1416 - val_accuracy: 0.7708\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.1783 - accuracy: 0.7284 - val_loss: 11.0907 - val_accuracy: 0.7753\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.1310 - accuracy: 0.7323 - val_loss: 11.0392 - val_accuracy: 0.7800\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.0736 - accuracy: 0.7416 - val_loss: 10.9878 - val_accuracy: 0.7865\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.0224 - accuracy: 0.7462 - val_loss: 10.9368 - val_accuracy: 0.7915\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.9734 - accuracy: 0.7520 - val_loss: 10.8866 - val_accuracy: 0.7961\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.9266 - accuracy: 0.7540 - val_loss: 10.8360 - val_accuracy: 0.8024\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.8732 - accuracy: 0.7596 - val_loss: 10.7867 - val_accuracy: 0.8065\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.8258 - accuracy: 0.7689 - val_loss: 10.7369 - val_accuracy: 0.8132\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.7717 - accuracy: 0.7711 - val_loss: 10.6879 - val_accuracy: 0.8164\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.7258 - accuracy: 0.7766 - val_loss: 10.6383 - val_accuracy: 0.8196\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.6785 - accuracy: 0.7786 - val_loss: 10.5900 - val_accuracy: 0.8237\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.6305 - accuracy: 0.7833 - val_loss: 10.5421 - val_accuracy: 0.8263\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.5834 - accuracy: 0.7864 - val_loss: 10.4948 - val_accuracy: 0.8308\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.5317 - accuracy: 0.7908 - val_loss: 10.4478 - val_accuracy: 0.8336\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.4849 - accuracy: 0.7990 - val_loss: 10.4009 - val_accuracy: 0.8369\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.4388 - accuracy: 0.8009 - val_loss: 10.3546 - val_accuracy: 0.8407\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.3923 - accuracy: 0.8058 - val_loss: 10.3084 - val_accuracy: 0.8433\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.3526 - accuracy: 0.8030 - val_loss: 10.2634 - val_accuracy: 0.8475\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.2940 - accuracy: 0.8133 - val_loss: 10.2169 - val_accuracy: 0.8504\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.2520 - accuracy: 0.8168 - val_loss: 10.1707 - val_accuracy: 0.8537\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.2064 - accuracy: 0.8203 - val_loss: 10.1264 - val_accuracy: 0.8561\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.1636 - accuracy: 0.8242 - val_loss: 10.0821 - val_accuracy: 0.8587\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.1158 - accuracy: 0.8270 - val_loss: 10.0380 - val_accuracy: 0.8613\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.0669 - accuracy: 0.8315 - val_loss: 9.9935 - val_accuracy: 0.8637\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.0249 - accuracy: 0.8317 - val_loss: 9.9496 - val_accuracy: 0.8667\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.9821 - accuracy: 0.8348 - val_loss: 9.9062 - val_accuracy: 0.8688\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.9370 - accuracy: 0.8387 - val_loss: 9.8630 - val_accuracy: 0.8715\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.8926 - accuracy: 0.8440 - val_loss: 9.8213 - val_accuracy: 0.8728\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.8517 - accuracy: 0.8438 - val_loss: 9.7787 - val_accuracy: 0.8755\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.8079 - accuracy: 0.8464 - val_loss: 9.7366 - val_accuracy: 0.8787\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.7595 - accuracy: 0.8524 - val_loss: 9.6928 - val_accuracy: 0.8812\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.7206 - accuracy: 0.8530 - val_loss: 9.6513 - val_accuracy: 0.8843\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.6787 - accuracy: 0.8556 - val_loss: 9.6089 - val_accuracy: 0.8859\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.6330 - accuracy: 0.8577 - val_loss: 9.5677 - val_accuracy: 0.8871\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.5965 - accuracy: 0.8592 - val_loss: 9.5280 - val_accuracy: 0.8891\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.5470 - accuracy: 0.8684 - val_loss: 9.4865 - val_accuracy: 0.8893\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.5041 - accuracy: 0.8687 - val_loss: 9.4460 - val_accuracy: 0.8912\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.4648 - accuracy: 0.8661 - val_loss: 9.4054 - val_accuracy: 0.8923\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.4264 - accuracy: 0.8708 - val_loss: 9.3642 - val_accuracy: 0.8940\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.3817 - accuracy: 0.8715 - val_loss: 9.3236 - val_accuracy: 0.8955\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.3456 - accuracy: 0.8739 - val_loss: 9.2841 - val_accuracy: 0.8969\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.3012 - accuracy: 0.8772 - val_loss: 9.2451 - val_accuracy: 0.8967\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.2574 - accuracy: 0.8761 - val_loss: 9.2058 - val_accuracy: 0.8969\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.2198 - accuracy: 0.8800 - val_loss: 9.1658 - val_accuracy: 0.8979\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.1794 - accuracy: 0.8819 - val_loss: 9.1267 - val_accuracy: 0.8987\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.1400 - accuracy: 0.8823 - val_loss: 9.0875 - val_accuracy: 0.8992\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.0952 - accuracy: 0.8872 - val_loss: 9.0495 - val_accuracy: 0.8999\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.0589 - accuracy: 0.8858 - val_loss: 9.0108 - val_accuracy: 0.9003\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.0221 - accuracy: 0.8867 - val_loss: 8.9716 - val_accuracy: 0.9023\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.9796 - accuracy: 0.8897 - val_loss: 8.9337 - val_accuracy: 0.9025\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.9393 - accuracy: 0.8912 - val_loss: 8.8959 - val_accuracy: 0.9033\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.9000 - accuracy: 0.8932 - val_loss: 8.8565 - val_accuracy: 0.9045\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.8620 - accuracy: 0.8955 - val_loss: 8.8199 - val_accuracy: 0.9049\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.8190 - accuracy: 0.8991 - val_loss: 8.7814 - val_accuracy: 0.9053\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.7831 - accuracy: 0.8982 - val_loss: 8.7444 - val_accuracy: 0.9067\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.7474 - accuracy: 0.8972 - val_loss: 8.7071 - val_accuracy: 0.9073\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.7103 - accuracy: 0.8994 - val_loss: 8.6701 - val_accuracy: 0.9077\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.6697 - accuracy: 0.8997 - val_loss: 8.6338 - val_accuracy: 0.9080\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.6310 - accuracy: 0.9012 - val_loss: 8.5961 - val_accuracy: 0.9092\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.5950 - accuracy: 0.9036 - val_loss: 8.5611 - val_accuracy: 0.9088\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.5553 - accuracy: 0.9035 - val_loss: 8.5235 - val_accuracy: 0.9100\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.5173 - accuracy: 0.9053 - val_loss: 8.4874 - val_accuracy: 0.9103\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.4793 - accuracy: 0.9066 - val_loss: 8.4512 - val_accuracy: 0.9105\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.4435 - accuracy: 0.9082 - val_loss: 8.4173 - val_accuracy: 0.9100\n",
      "Time: 70.74308896064758\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_50OU_20SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#50 OU, 20 SNPs\n",
    "################################################################################################################################################\n",
    "# subset the SNPs\n",
    "X20=X[:,0:20,:]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test  = train_test_split(y,X20,traits_OU50,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_OU_subset(ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_50OU_20SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XEmClYK43qOR",
    "outputId": "1ba3ee5d-25cc-4482-8973-6868691a9191",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20_input (InputLayer)  [(None, 1000)]           0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 150)               150000    \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 150)               22500     \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 50)                7550      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 181,403\n",
      "Trainable params: 180,803\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "90/90 [==============================] - 1s 5ms/step - loss: 9.0127 - accuracy: 0.3506 - val_loss: 8.8868 - val_accuracy: 0.3359\n",
      "Epoch 2/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.8867 - accuracy: 0.3711 - val_loss: 8.8267 - val_accuracy: 0.3571\n",
      "Epoch 3/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.7927 - accuracy: 0.3990 - val_loss: 8.7607 - val_accuracy: 0.3992\n",
      "Epoch 4/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.7194 - accuracy: 0.4287 - val_loss: 8.7016 - val_accuracy: 0.4312\n",
      "Epoch 5/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.6600 - accuracy: 0.4532 - val_loss: 8.6515 - val_accuracy: 0.4544\n",
      "Epoch 6/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.6096 - accuracy: 0.4767 - val_loss: 8.6088 - val_accuracy: 0.4729\n",
      "Epoch 7/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.5675 - accuracy: 0.4902 - val_loss: 8.5712 - val_accuracy: 0.4859\n",
      "Epoch 8/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.5274 - accuracy: 0.5065 - val_loss: 8.5369 - val_accuracy: 0.4965\n",
      "Epoch 9/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.4917 - accuracy: 0.5182 - val_loss: 8.5052 - val_accuracy: 0.5067\n",
      "Epoch 10/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.4579 - accuracy: 0.5284 - val_loss: 8.4755 - val_accuracy: 0.5112\n",
      "Epoch 11/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.4256 - accuracy: 0.5387 - val_loss: 8.4473 - val_accuracy: 0.5171\n",
      "Epoch 12/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.3968 - accuracy: 0.5429 - val_loss: 8.4201 - val_accuracy: 0.5217\n",
      "Epoch 13/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.3688 - accuracy: 0.5527 - val_loss: 8.3942 - val_accuracy: 0.5252\n",
      "Epoch 14/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.3408 - accuracy: 0.5558 - val_loss: 8.3693 - val_accuracy: 0.5300\n",
      "Epoch 15/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.3141 - accuracy: 0.5592 - val_loss: 8.3449 - val_accuracy: 0.5340\n",
      "Epoch 16/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.2875 - accuracy: 0.5692 - val_loss: 8.3212 - val_accuracy: 0.5387\n",
      "Epoch 17/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.2615 - accuracy: 0.5765 - val_loss: 8.2981 - val_accuracy: 0.5416\n",
      "Epoch 18/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.2377 - accuracy: 0.5791 - val_loss: 8.2755 - val_accuracy: 0.5433\n",
      "Epoch 19/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.2129 - accuracy: 0.5831 - val_loss: 8.2534 - val_accuracy: 0.5451\n",
      "Epoch 20/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.1887 - accuracy: 0.5868 - val_loss: 8.2318 - val_accuracy: 0.5480\n",
      "Epoch 21/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.1658 - accuracy: 0.5890 - val_loss: 8.2104 - val_accuracy: 0.5511\n",
      "Epoch 22/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.1408 - accuracy: 0.5948 - val_loss: 8.1894 - val_accuracy: 0.5528\n",
      "Epoch 23/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.1206 - accuracy: 0.5963 - val_loss: 8.1687 - val_accuracy: 0.5544\n",
      "Epoch 24/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.0968 - accuracy: 0.5997 - val_loss: 8.1482 - val_accuracy: 0.5551\n",
      "Epoch 25/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.0741 - accuracy: 0.6024 - val_loss: 8.1282 - val_accuracy: 0.5565\n",
      "Epoch 26/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.0535 - accuracy: 0.6053 - val_loss: 8.1083 - val_accuracy: 0.5591\n",
      "Epoch 27/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.0312 - accuracy: 0.6109 - val_loss: 8.0886 - val_accuracy: 0.5607\n",
      "Epoch 28/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.0110 - accuracy: 0.6136 - val_loss: 8.0692 - val_accuracy: 0.5619\n",
      "Epoch 29/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.9892 - accuracy: 0.6134 - val_loss: 8.0499 - val_accuracy: 0.5637\n",
      "Epoch 30/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.9683 - accuracy: 0.6167 - val_loss: 8.0309 - val_accuracy: 0.5651\n",
      "Epoch 31/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.9483 - accuracy: 0.6198 - val_loss: 8.0119 - val_accuracy: 0.5671\n",
      "Epoch 32/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.9271 - accuracy: 0.6188 - val_loss: 7.9932 - val_accuracy: 0.5673\n",
      "Epoch 33/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.9081 - accuracy: 0.6219 - val_loss: 7.9747 - val_accuracy: 0.5683\n",
      "Epoch 34/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.8861 - accuracy: 0.6263 - val_loss: 7.9564 - val_accuracy: 0.5683\n",
      "Epoch 35/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.8673 - accuracy: 0.6276 - val_loss: 7.9381 - val_accuracy: 0.5695\n",
      "Epoch 36/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.8478 - accuracy: 0.6299 - val_loss: 7.9199 - val_accuracy: 0.5697\n",
      "Epoch 37/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.8275 - accuracy: 0.6324 - val_loss: 7.9020 - val_accuracy: 0.5713\n",
      "Epoch 38/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.8084 - accuracy: 0.6354 - val_loss: 7.8840 - val_accuracy: 0.5716\n",
      "Epoch 39/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.7899 - accuracy: 0.6350 - val_loss: 7.8663 - val_accuracy: 0.5729\n",
      "Epoch 40/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.7702 - accuracy: 0.6361 - val_loss: 7.8487 - val_accuracy: 0.5737\n",
      "Epoch 41/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.7507 - accuracy: 0.6380 - val_loss: 7.8311 - val_accuracy: 0.5736\n",
      "Epoch 42/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.7312 - accuracy: 0.6428 - val_loss: 7.8136 - val_accuracy: 0.5751\n",
      "Epoch 43/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.7118 - accuracy: 0.6430 - val_loss: 7.7963 - val_accuracy: 0.5751\n",
      "Epoch 44/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.6935 - accuracy: 0.6452 - val_loss: 7.7791 - val_accuracy: 0.5753\n",
      "Epoch 45/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.6750 - accuracy: 0.6465 - val_loss: 7.7620 - val_accuracy: 0.5763\n",
      "Epoch 46/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.6559 - accuracy: 0.6497 - val_loss: 7.7449 - val_accuracy: 0.5769\n",
      "Epoch 47/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.6376 - accuracy: 0.6499 - val_loss: 7.7280 - val_accuracy: 0.5767\n",
      "Epoch 48/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.6182 - accuracy: 0.6518 - val_loss: 7.7110 - val_accuracy: 0.5776\n",
      "Epoch 49/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5995 - accuracy: 0.6524 - val_loss: 7.6942 - val_accuracy: 0.5779\n",
      "Epoch 50/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5829 - accuracy: 0.6548 - val_loss: 7.6774 - val_accuracy: 0.5792\n",
      "Epoch 51/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5639 - accuracy: 0.6556 - val_loss: 7.6607 - val_accuracy: 0.5788\n",
      "Epoch 52/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5445 - accuracy: 0.6587 - val_loss: 7.6441 - val_accuracy: 0.5795\n",
      "Epoch 53/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5281 - accuracy: 0.6619 - val_loss: 7.6276 - val_accuracy: 0.5797\n",
      "Epoch 54/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5087 - accuracy: 0.6632 - val_loss: 7.6110 - val_accuracy: 0.5796\n",
      "Epoch 55/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.4908 - accuracy: 0.6654 - val_loss: 7.5946 - val_accuracy: 0.5789\n",
      "Epoch 56/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.4731 - accuracy: 0.6662 - val_loss: 7.5782 - val_accuracy: 0.5789\n",
      "Epoch 57/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.4547 - accuracy: 0.6678 - val_loss: 7.5619 - val_accuracy: 0.5796\n",
      "Epoch 58/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.4375 - accuracy: 0.6696 - val_loss: 7.5457 - val_accuracy: 0.5793\n",
      "Epoch 59/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.4202 - accuracy: 0.6688 - val_loss: 7.5295 - val_accuracy: 0.5805\n",
      "Epoch 60/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.4027 - accuracy: 0.6724 - val_loss: 7.5133 - val_accuracy: 0.5800\n",
      "Epoch 61/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.3850 - accuracy: 0.6734 - val_loss: 7.4972 - val_accuracy: 0.5808\n",
      "Epoch 62/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.3671 - accuracy: 0.6747 - val_loss: 7.4811 - val_accuracy: 0.5807\n",
      "Epoch 63/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.3484 - accuracy: 0.6788 - val_loss: 7.4652 - val_accuracy: 0.5807\n",
      "Epoch 64/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.3317 - accuracy: 0.6774 - val_loss: 7.4492 - val_accuracy: 0.5812\n",
      "Epoch 65/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.3133 - accuracy: 0.6811 - val_loss: 7.4332 - val_accuracy: 0.5813\n",
      "Epoch 66/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2975 - accuracy: 0.6800 - val_loss: 7.4174 - val_accuracy: 0.5809\n",
      "Epoch 67/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2801 - accuracy: 0.6820 - val_loss: 7.4016 - val_accuracy: 0.5817\n",
      "Epoch 68/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2626 - accuracy: 0.6854 - val_loss: 7.3858 - val_accuracy: 0.5825\n",
      "Epoch 69/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2448 - accuracy: 0.6843 - val_loss: 7.3700 - val_accuracy: 0.5823\n",
      "Epoch 70/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2270 - accuracy: 0.6872 - val_loss: 7.3543 - val_accuracy: 0.5832\n",
      "Epoch 71/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2095 - accuracy: 0.6876 - val_loss: 7.3386 - val_accuracy: 0.5837\n",
      "Epoch 72/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1928 - accuracy: 0.6899 - val_loss: 7.3231 - val_accuracy: 0.5847\n",
      "Epoch 73/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1762 - accuracy: 0.6899 - val_loss: 7.3075 - val_accuracy: 0.5849\n",
      "Epoch 74/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1591 - accuracy: 0.6935 - val_loss: 7.2921 - val_accuracy: 0.5851\n",
      "Epoch 75/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1412 - accuracy: 0.6941 - val_loss: 7.2766 - val_accuracy: 0.5859\n",
      "Epoch 76/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1239 - accuracy: 0.6956 - val_loss: 7.2611 - val_accuracy: 0.5855\n",
      "Epoch 77/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1083 - accuracy: 0.6957 - val_loss: 7.2456 - val_accuracy: 0.5864\n",
      "Epoch 78/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0905 - accuracy: 0.6979 - val_loss: 7.2302 - val_accuracy: 0.5864\n",
      "Epoch 79/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0725 - accuracy: 0.7005 - val_loss: 7.2149 - val_accuracy: 0.5871\n",
      "Epoch 80/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0576 - accuracy: 0.7020 - val_loss: 7.1997 - val_accuracy: 0.5877\n",
      "Epoch 81/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0403 - accuracy: 0.7013 - val_loss: 7.1843 - val_accuracy: 0.5880\n",
      "Epoch 82/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0228 - accuracy: 0.7043 - val_loss: 7.1691 - val_accuracy: 0.5884\n",
      "Epoch 83/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0070 - accuracy: 0.7029 - val_loss: 7.1539 - val_accuracy: 0.5891\n",
      "Epoch 84/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9888 - accuracy: 0.7100 - val_loss: 7.1388 - val_accuracy: 0.5888\n",
      "Epoch 85/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9719 - accuracy: 0.7081 - val_loss: 7.1237 - val_accuracy: 0.5893\n",
      "Epoch 86/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9558 - accuracy: 0.7089 - val_loss: 7.1085 - val_accuracy: 0.5887\n",
      "Epoch 87/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9380 - accuracy: 0.7126 - val_loss: 7.0935 - val_accuracy: 0.5884\n",
      "Epoch 88/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9217 - accuracy: 0.7142 - val_loss: 7.0786 - val_accuracy: 0.5885\n",
      "Epoch 89/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9047 - accuracy: 0.7141 - val_loss: 7.0636 - val_accuracy: 0.5900\n",
      "Epoch 90/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8896 - accuracy: 0.7178 - val_loss: 7.0486 - val_accuracy: 0.5899\n",
      "Epoch 91/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8734 - accuracy: 0.7155 - val_loss: 7.0338 - val_accuracy: 0.5892\n",
      "Epoch 92/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8566 - accuracy: 0.7194 - val_loss: 7.0189 - val_accuracy: 0.5903\n",
      "Epoch 93/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8399 - accuracy: 0.7198 - val_loss: 7.0042 - val_accuracy: 0.5892\n",
      "Epoch 94/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8241 - accuracy: 0.7188 - val_loss: 6.9894 - val_accuracy: 0.5891\n",
      "Epoch 95/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8071 - accuracy: 0.7206 - val_loss: 6.9746 - val_accuracy: 0.5897\n",
      "Epoch 96/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7909 - accuracy: 0.7222 - val_loss: 6.9599 - val_accuracy: 0.5892\n",
      "Epoch 97/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7740 - accuracy: 0.7245 - val_loss: 6.9452 - val_accuracy: 0.5899\n",
      "Epoch 98/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7583 - accuracy: 0.7266 - val_loss: 6.9305 - val_accuracy: 0.5899\n",
      "Epoch 99/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7432 - accuracy: 0.7264 - val_loss: 6.9159 - val_accuracy: 0.5896\n",
      "Epoch 100/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7255 - accuracy: 0.7286 - val_loss: 6.9012 - val_accuracy: 0.5896\n",
      "Epoch 101/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7095 - accuracy: 0.7296 - val_loss: 6.8867 - val_accuracy: 0.5903\n",
      "Epoch 102/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6928 - accuracy: 0.7325 - val_loss: 6.8721 - val_accuracy: 0.5900\n",
      "Epoch 103/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6769 - accuracy: 0.7323 - val_loss: 6.8577 - val_accuracy: 0.5900\n",
      "Epoch 104/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6597 - accuracy: 0.7337 - val_loss: 6.8433 - val_accuracy: 0.5900\n",
      "Epoch 105/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6448 - accuracy: 0.7342 - val_loss: 6.8287 - val_accuracy: 0.5901\n",
      "Epoch 106/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6278 - accuracy: 0.7331 - val_loss: 6.8142 - val_accuracy: 0.5901\n",
      "Epoch 107/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6123 - accuracy: 0.7368 - val_loss: 6.7998 - val_accuracy: 0.5909\n",
      "Epoch 108/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5955 - accuracy: 0.7397 - val_loss: 6.7854 - val_accuracy: 0.5905\n",
      "Epoch 109/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5808 - accuracy: 0.7389 - val_loss: 6.7711 - val_accuracy: 0.5903\n",
      "Epoch 110/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5642 - accuracy: 0.7413 - val_loss: 6.7569 - val_accuracy: 0.5899\n",
      "Epoch 111/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5492 - accuracy: 0.7434 - val_loss: 6.7426 - val_accuracy: 0.5907\n",
      "Epoch 112/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5323 - accuracy: 0.7422 - val_loss: 6.7283 - val_accuracy: 0.5903\n",
      "Epoch 113/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5167 - accuracy: 0.7480 - val_loss: 6.7141 - val_accuracy: 0.5907\n",
      "Epoch 114/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5022 - accuracy: 0.7433 - val_loss: 6.6999 - val_accuracy: 0.5904\n",
      "Epoch 115/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4841 - accuracy: 0.7444 - val_loss: 6.6856 - val_accuracy: 0.5905\n",
      "Epoch 116/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4689 - accuracy: 0.7513 - val_loss: 6.6714 - val_accuracy: 0.5907\n",
      "Epoch 117/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4523 - accuracy: 0.7488 - val_loss: 6.6574 - val_accuracy: 0.5905\n",
      "Epoch 118/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4373 - accuracy: 0.7507 - val_loss: 6.6432 - val_accuracy: 0.5909\n",
      "Epoch 119/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4200 - accuracy: 0.7512 - val_loss: 6.6292 - val_accuracy: 0.5908\n",
      "Epoch 120/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4038 - accuracy: 0.7549 - val_loss: 6.6151 - val_accuracy: 0.5909\n",
      "Epoch 121/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3900 - accuracy: 0.7535 - val_loss: 6.6011 - val_accuracy: 0.5907\n",
      "Epoch 122/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3746 - accuracy: 0.7563 - val_loss: 6.5872 - val_accuracy: 0.5911\n",
      "Epoch 123/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3590 - accuracy: 0.7546 - val_loss: 6.5732 - val_accuracy: 0.5908\n",
      "Epoch 124/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3437 - accuracy: 0.7565 - val_loss: 6.5592 - val_accuracy: 0.5911\n",
      "Epoch 125/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3271 - accuracy: 0.7593 - val_loss: 6.5454 - val_accuracy: 0.5909\n",
      "Epoch 126/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3125 - accuracy: 0.7588 - val_loss: 6.5316 - val_accuracy: 0.5915\n",
      "Epoch 127/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2965 - accuracy: 0.7634 - val_loss: 6.5177 - val_accuracy: 0.5912\n",
      "Epoch 128/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2811 - accuracy: 0.7624 - val_loss: 6.5038 - val_accuracy: 0.5917\n",
      "Epoch 129/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2649 - accuracy: 0.7640 - val_loss: 6.4901 - val_accuracy: 0.5917\n",
      "Epoch 130/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2484 - accuracy: 0.7654 - val_loss: 6.4763 - val_accuracy: 0.5919\n",
      "Epoch 131/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2339 - accuracy: 0.7664 - val_loss: 6.4625 - val_accuracy: 0.5919\n",
      "Epoch 132/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2186 - accuracy: 0.7676 - val_loss: 6.4489 - val_accuracy: 0.5917\n",
      "Epoch 133/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2028 - accuracy: 0.7699 - val_loss: 6.4353 - val_accuracy: 0.5921\n",
      "Epoch 134/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.1874 - accuracy: 0.7676 - val_loss: 6.4215 - val_accuracy: 0.5925\n",
      "Epoch 135/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.1728 - accuracy: 0.7711 - val_loss: 6.4079 - val_accuracy: 0.5927\n",
      "Epoch 136/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.1561 - accuracy: 0.7724 - val_loss: 6.3943 - val_accuracy: 0.5929\n",
      "Epoch 137/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.1425 - accuracy: 0.7732 - val_loss: 6.3808 - val_accuracy: 0.5924\n",
      "Epoch 138/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.1255 - accuracy: 0.7757 - val_loss: 6.3672 - val_accuracy: 0.5940\n",
      "Epoch 139/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.1111 - accuracy: 0.7747 - val_loss: 6.3538 - val_accuracy: 0.5940\n",
      "Epoch 140/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.0961 - accuracy: 0.7763 - val_loss: 6.3404 - val_accuracy: 0.5939\n",
      "Epoch 141/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.0814 - accuracy: 0.7772 - val_loss: 6.3269 - val_accuracy: 0.5945\n",
      "Epoch 142/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.0652 - accuracy: 0.7805 - val_loss: 6.3135 - val_accuracy: 0.5940\n",
      "Epoch 143/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.0498 - accuracy: 0.7815 - val_loss: 6.3002 - val_accuracy: 0.5935\n",
      "Epoch 144/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.0341 - accuracy: 0.7817 - val_loss: 6.2868 - val_accuracy: 0.5927\n",
      "Epoch 145/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.0198 - accuracy: 0.7812 - val_loss: 6.2735 - val_accuracy: 0.5932\n",
      "Epoch 146/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.0042 - accuracy: 0.7848 - val_loss: 6.2602 - val_accuracy: 0.5941\n",
      "Epoch 147/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.9894 - accuracy: 0.7846 - val_loss: 6.2470 - val_accuracy: 0.5940\n",
      "Epoch 148/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.9753 - accuracy: 0.7861 - val_loss: 6.2337 - val_accuracy: 0.5943\n",
      "Epoch 149/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.9583 - accuracy: 0.7868 - val_loss: 6.2204 - val_accuracy: 0.5949\n",
      "Epoch 150/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.9432 - accuracy: 0.7875 - val_loss: 6.2073 - val_accuracy: 0.5959\n",
      "Epoch 151/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.9285 - accuracy: 0.7904 - val_loss: 6.1941 - val_accuracy: 0.5959\n",
      "Epoch 152/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.9133 - accuracy: 0.7903 - val_loss: 6.1809 - val_accuracy: 0.5955\n",
      "Epoch 153/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.8991 - accuracy: 0.7912 - val_loss: 6.1679 - val_accuracy: 0.5963\n",
      "Epoch 154/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.8838 - accuracy: 0.7933 - val_loss: 6.1549 - val_accuracy: 0.5961\n",
      "Epoch 155/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.8694 - accuracy: 0.7931 - val_loss: 6.1418 - val_accuracy: 0.5964\n",
      "Epoch 156/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.8539 - accuracy: 0.7951 - val_loss: 6.1288 - val_accuracy: 0.5967\n",
      "Epoch 157/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.8376 - accuracy: 0.7982 - val_loss: 6.1157 - val_accuracy: 0.5972\n",
      "Epoch 158/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.8250 - accuracy: 0.7969 - val_loss: 6.1028 - val_accuracy: 0.5968\n",
      "Epoch 159/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.8088 - accuracy: 0.7988 - val_loss: 6.0899 - val_accuracy: 0.5967\n",
      "Epoch 160/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.7930 - accuracy: 0.7992 - val_loss: 6.0770 - val_accuracy: 0.5981\n",
      "Epoch 161/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.7787 - accuracy: 0.8011 - val_loss: 6.0641 - val_accuracy: 0.5981\n",
      "Epoch 162/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.7645 - accuracy: 0.8007 - val_loss: 6.0512 - val_accuracy: 0.5981\n",
      "Epoch 163/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.7493 - accuracy: 0.8020 - val_loss: 6.0383 - val_accuracy: 0.5980\n",
      "Epoch 164/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.7339 - accuracy: 0.8059 - val_loss: 6.0255 - val_accuracy: 0.5975\n",
      "Epoch 165/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.7195 - accuracy: 0.8055 - val_loss: 6.0127 - val_accuracy: 0.5976\n",
      "Epoch 166/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.7058 - accuracy: 0.8069 - val_loss: 5.9999 - val_accuracy: 0.5977\n",
      "Epoch 167/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.6911 - accuracy: 0.8080 - val_loss: 5.9874 - val_accuracy: 0.5977\n",
      "Epoch 168/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.6761 - accuracy: 0.8084 - val_loss: 5.9747 - val_accuracy: 0.5973\n",
      "Epoch 169/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.6609 - accuracy: 0.8091 - val_loss: 5.9621 - val_accuracy: 0.5979\n",
      "Epoch 170/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.6458 - accuracy: 0.8143 - val_loss: 5.9495 - val_accuracy: 0.5975\n",
      "Epoch 171/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.6310 - accuracy: 0.8117 - val_loss: 5.9369 - val_accuracy: 0.5973\n",
      "Epoch 172/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.6166 - accuracy: 0.8132 - val_loss: 5.9243 - val_accuracy: 0.5975\n",
      "Epoch 173/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.6035 - accuracy: 0.8135 - val_loss: 5.9120 - val_accuracy: 0.5984\n",
      "Epoch 174/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.5881 - accuracy: 0.8161 - val_loss: 5.8995 - val_accuracy: 0.5980\n",
      "Epoch 175/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.5725 - accuracy: 0.8176 - val_loss: 5.8869 - val_accuracy: 0.5977\n",
      "Epoch 176/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.5578 - accuracy: 0.8205 - val_loss: 5.8744 - val_accuracy: 0.5981\n",
      "Epoch 177/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.5444 - accuracy: 0.8176 - val_loss: 5.8620 - val_accuracy: 0.5977\n",
      "Epoch 178/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.5288 - accuracy: 0.8215 - val_loss: 5.8496 - val_accuracy: 0.5981\n",
      "Epoch 179/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.5139 - accuracy: 0.8202 - val_loss: 5.8373 - val_accuracy: 0.5980\n",
      "Epoch 180/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.4993 - accuracy: 0.8231 - val_loss: 5.8250 - val_accuracy: 0.5980\n",
      "Epoch 181/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.4860 - accuracy: 0.8252 - val_loss: 5.8127 - val_accuracy: 0.5981\n",
      "Epoch 182/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.4726 - accuracy: 0.8240 - val_loss: 5.8003 - val_accuracy: 0.5976\n",
      "Epoch 183/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.4586 - accuracy: 0.8253 - val_loss: 5.7882 - val_accuracy: 0.5981\n",
      "Epoch 184/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.4441 - accuracy: 0.8261 - val_loss: 5.7758 - val_accuracy: 0.5977\n",
      "Epoch 185/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.4286 - accuracy: 0.8284 - val_loss: 5.7635 - val_accuracy: 0.5984\n",
      "Epoch 186/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.4146 - accuracy: 0.8287 - val_loss: 5.7514 - val_accuracy: 0.5980\n",
      "Epoch 187/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.3998 - accuracy: 0.8311 - val_loss: 5.7392 - val_accuracy: 0.5969\n",
      "Epoch 188/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.3867 - accuracy: 0.8305 - val_loss: 5.7271 - val_accuracy: 0.5973\n",
      "Epoch 189/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.3703 - accuracy: 0.8344 - val_loss: 5.7151 - val_accuracy: 0.5971\n",
      "Epoch 190/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.3553 - accuracy: 0.8340 - val_loss: 5.7030 - val_accuracy: 0.5964\n",
      "Epoch 191/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.3427 - accuracy: 0.8345 - val_loss: 5.6910 - val_accuracy: 0.5959\n",
      "Epoch 192/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.3288 - accuracy: 0.8342 - val_loss: 5.6790 - val_accuracy: 0.5959\n",
      "Epoch 193/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.3154 - accuracy: 0.8354 - val_loss: 5.6671 - val_accuracy: 0.5956\n",
      "Epoch 194/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.2994 - accuracy: 0.8373 - val_loss: 5.6552 - val_accuracy: 0.5948\n",
      "Epoch 195/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.2859 - accuracy: 0.8403 - val_loss: 5.6432 - val_accuracy: 0.5949\n",
      "Epoch 196/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.2700 - accuracy: 0.8410 - val_loss: 5.6312 - val_accuracy: 0.5949\n",
      "Epoch 197/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.2580 - accuracy: 0.8395 - val_loss: 5.6194 - val_accuracy: 0.5952\n",
      "Epoch 198/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.2444 - accuracy: 0.8428 - val_loss: 5.6075 - val_accuracy: 0.5953\n",
      "Epoch 199/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.2299 - accuracy: 0.8434 - val_loss: 5.5958 - val_accuracy: 0.5959\n",
      "Epoch 200/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.2156 - accuracy: 0.8431 - val_loss: 5.5840 - val_accuracy: 0.5949\n",
      "Epoch 201/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.2009 - accuracy: 0.8456 - val_loss: 5.5722 - val_accuracy: 0.5951\n",
      "Epoch 202/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.1872 - accuracy: 0.8468 - val_loss: 5.5606 - val_accuracy: 0.5945\n",
      "Epoch 203/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.1731 - accuracy: 0.8472 - val_loss: 5.5488 - val_accuracy: 0.5947\n",
      "Epoch 204/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.1600 - accuracy: 0.8493 - val_loss: 5.5370 - val_accuracy: 0.5949\n",
      "Epoch 205/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.1445 - accuracy: 0.8498 - val_loss: 5.5255 - val_accuracy: 0.5943\n",
      "Epoch 206/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.1317 - accuracy: 0.8498 - val_loss: 5.5138 - val_accuracy: 0.5941\n",
      "Epoch 207/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.1187 - accuracy: 0.8512 - val_loss: 5.5022 - val_accuracy: 0.5939\n",
      "Epoch 208/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.1042 - accuracy: 0.8530 - val_loss: 5.4906 - val_accuracy: 0.5933\n",
      "Epoch 209/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.0907 - accuracy: 0.8521 - val_loss: 5.4791 - val_accuracy: 0.5944\n",
      "Epoch 210/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.0778 - accuracy: 0.8532 - val_loss: 5.4676 - val_accuracy: 0.5943\n",
      "Epoch 211/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.0616 - accuracy: 0.8560 - val_loss: 5.4559 - val_accuracy: 0.5945\n",
      "Epoch 212/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.0490 - accuracy: 0.8567 - val_loss: 5.4445 - val_accuracy: 0.5952\n",
      "Epoch 213/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.0345 - accuracy: 0.8580 - val_loss: 5.4332 - val_accuracy: 0.5948\n",
      "Epoch 214/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.0205 - accuracy: 0.8606 - val_loss: 5.4218 - val_accuracy: 0.5947\n",
      "Epoch 215/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.0080 - accuracy: 0.8582 - val_loss: 5.4103 - val_accuracy: 0.5945\n",
      "Epoch 216/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.9948 - accuracy: 0.8597 - val_loss: 5.3991 - val_accuracy: 0.5949\n",
      "Epoch 217/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.9796 - accuracy: 0.8624 - val_loss: 5.3877 - val_accuracy: 0.5955\n",
      "Epoch 218/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.9650 - accuracy: 0.8655 - val_loss: 5.3764 - val_accuracy: 0.5951\n",
      "Epoch 219/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.9522 - accuracy: 0.8630 - val_loss: 5.3651 - val_accuracy: 0.5955\n",
      "Epoch 220/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.9408 - accuracy: 0.8650 - val_loss: 5.3538 - val_accuracy: 0.5952\n",
      "Epoch 221/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.9254 - accuracy: 0.8637 - val_loss: 5.3426 - val_accuracy: 0.5949\n",
      "Epoch 222/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.9118 - accuracy: 0.8653 - val_loss: 5.3312 - val_accuracy: 0.5949\n",
      "Epoch 223/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.8977 - accuracy: 0.8663 - val_loss: 5.3200 - val_accuracy: 0.5941\n",
      "Epoch 224/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.8851 - accuracy: 0.8684 - val_loss: 5.3090 - val_accuracy: 0.5947\n",
      "Epoch 225/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.8706 - accuracy: 0.8702 - val_loss: 5.2980 - val_accuracy: 0.5948\n",
      "Epoch 226/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.8576 - accuracy: 0.8697 - val_loss: 5.2869 - val_accuracy: 0.5945\n",
      "Epoch 227/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.8445 - accuracy: 0.8711 - val_loss: 5.2756 - val_accuracy: 0.5955\n",
      "Epoch 228/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.8317 - accuracy: 0.8707 - val_loss: 5.2646 - val_accuracy: 0.5953\n",
      "Epoch 229/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.8169 - accuracy: 0.8734 - val_loss: 5.2535 - val_accuracy: 0.5953\n",
      "Epoch 230/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.8035 - accuracy: 0.8739 - val_loss: 5.2426 - val_accuracy: 0.5947\n",
      "Epoch 231/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.7909 - accuracy: 0.8740 - val_loss: 5.2317 - val_accuracy: 0.5953\n",
      "Epoch 232/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.7770 - accuracy: 0.8750 - val_loss: 5.2210 - val_accuracy: 0.5949\n",
      "Epoch 233/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.7635 - accuracy: 0.8737 - val_loss: 5.2099 - val_accuracy: 0.5955\n",
      "Epoch 234/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.7506 - accuracy: 0.8776 - val_loss: 5.1990 - val_accuracy: 0.5951\n",
      "Epoch 235/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.7358 - accuracy: 0.8806 - val_loss: 5.1882 - val_accuracy: 0.5944\n",
      "Epoch 236/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.7246 - accuracy: 0.8793 - val_loss: 5.1774 - val_accuracy: 0.5945\n",
      "Epoch 237/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.7107 - accuracy: 0.8807 - val_loss: 5.1666 - val_accuracy: 0.5947\n",
      "Epoch 238/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.6970 - accuracy: 0.8809 - val_loss: 5.1559 - val_accuracy: 0.5943\n",
      "Epoch 239/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.6834 - accuracy: 0.8828 - val_loss: 5.1451 - val_accuracy: 0.5944\n",
      "Epoch 240/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.6688 - accuracy: 0.8856 - val_loss: 5.1345 - val_accuracy: 0.5949\n",
      "Epoch 241/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.6567 - accuracy: 0.8831 - val_loss: 5.1237 - val_accuracy: 0.5959\n",
      "Epoch 242/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.6447 - accuracy: 0.8862 - val_loss: 5.1133 - val_accuracy: 0.5960\n",
      "Epoch 243/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.6314 - accuracy: 0.8876 - val_loss: 5.1028 - val_accuracy: 0.5964\n",
      "Epoch 244/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.6166 - accuracy: 0.8893 - val_loss: 5.0921 - val_accuracy: 0.5967\n",
      "Epoch 245/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.6043 - accuracy: 0.8883 - val_loss: 5.0814 - val_accuracy: 0.5980\n",
      "Epoch 246/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.5911 - accuracy: 0.8891 - val_loss: 5.0711 - val_accuracy: 0.5979\n",
      "Epoch 247/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.5778 - accuracy: 0.8869 - val_loss: 5.0604 - val_accuracy: 0.5979\n",
      "Epoch 248/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.5663 - accuracy: 0.8907 - val_loss: 5.0498 - val_accuracy: 0.5979\n",
      "Epoch 249/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.5522 - accuracy: 0.8937 - val_loss: 5.0394 - val_accuracy: 0.5977\n",
      "Epoch 250/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.5383 - accuracy: 0.8961 - val_loss: 5.0289 - val_accuracy: 0.5975\n",
      "Epoch 251/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.5250 - accuracy: 0.8944 - val_loss: 5.0188 - val_accuracy: 0.5972\n",
      "Epoch 252/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.5125 - accuracy: 0.8956 - val_loss: 5.0082 - val_accuracy: 0.5977\n",
      "Epoch 253/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.4999 - accuracy: 0.8953 - val_loss: 4.9976 - val_accuracy: 0.5976\n",
      "Epoch 254/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.4850 - accuracy: 0.8979 - val_loss: 4.9874 - val_accuracy: 0.5976\n",
      "Epoch 255/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.4746 - accuracy: 0.8979 - val_loss: 4.9771 - val_accuracy: 0.5979\n",
      "Epoch 256/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.4600 - accuracy: 0.8978 - val_loss: 4.9666 - val_accuracy: 0.5980\n",
      "Epoch 257/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.4467 - accuracy: 0.9011 - val_loss: 4.9564 - val_accuracy: 0.5983\n",
      "Epoch 258/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.4365 - accuracy: 0.8989 - val_loss: 4.9463 - val_accuracy: 0.5983\n",
      "Epoch 259/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.4219 - accuracy: 0.9011 - val_loss: 4.9355 - val_accuracy: 0.5980\n",
      "Epoch 260/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.4092 - accuracy: 0.9003 - val_loss: 4.9252 - val_accuracy: 0.5979\n",
      "Epoch 261/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.3950 - accuracy: 0.9048 - val_loss: 4.9153 - val_accuracy: 0.5976\n",
      "Epoch 262/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.3828 - accuracy: 0.9050 - val_loss: 4.9051 - val_accuracy: 0.5976\n",
      "Epoch 263/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.3712 - accuracy: 0.9043 - val_loss: 4.8950 - val_accuracy: 0.5975\n",
      "Epoch 264/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.3581 - accuracy: 0.9064 - val_loss: 4.8850 - val_accuracy: 0.5972\n",
      "Epoch 265/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.3451 - accuracy: 0.9088 - val_loss: 4.8749 - val_accuracy: 0.5973\n",
      "Epoch 266/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.3317 - accuracy: 0.9088 - val_loss: 4.8647 - val_accuracy: 0.5972\n",
      "Epoch 267/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.3188 - accuracy: 0.9090 - val_loss: 4.8543 - val_accuracy: 0.5965\n",
      "Epoch 268/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.3067 - accuracy: 0.9105 - val_loss: 4.8442 - val_accuracy: 0.5967\n",
      "Epoch 269/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.2938 - accuracy: 0.9114 - val_loss: 4.8343 - val_accuracy: 0.5967\n",
      "Epoch 270/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.2810 - accuracy: 0.9122 - val_loss: 4.8244 - val_accuracy: 0.5965\n",
      "Epoch 271/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.2693 - accuracy: 0.9110 - val_loss: 4.8145 - val_accuracy: 0.5968\n",
      "Epoch 272/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.2558 - accuracy: 0.9136 - val_loss: 4.8047 - val_accuracy: 0.5967\n",
      "Epoch 273/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.2428 - accuracy: 0.9162 - val_loss: 4.7947 - val_accuracy: 0.5971\n",
      "Epoch 274/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.2313 - accuracy: 0.9130 - val_loss: 4.7850 - val_accuracy: 0.5969\n",
      "Epoch 275/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.2172 - accuracy: 0.9173 - val_loss: 4.7753 - val_accuracy: 0.5960\n",
      "Epoch 276/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.2063 - accuracy: 0.9156 - val_loss: 4.7653 - val_accuracy: 0.5968\n",
      "Epoch 277/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.1932 - accuracy: 0.9156 - val_loss: 4.7555 - val_accuracy: 0.5968\n",
      "Epoch 278/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.1821 - accuracy: 0.9168 - val_loss: 4.7458 - val_accuracy: 0.5965\n",
      "Epoch 279/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.1678 - accuracy: 0.9186 - val_loss: 4.7360 - val_accuracy: 0.5965\n",
      "Epoch 280/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.1553 - accuracy: 0.9210 - val_loss: 4.7262 - val_accuracy: 0.5967\n",
      "Epoch 281/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.1434 - accuracy: 0.9207 - val_loss: 4.7165 - val_accuracy: 0.5967\n",
      "Epoch 282/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.1304 - accuracy: 0.9229 - val_loss: 4.7070 - val_accuracy: 0.5965\n",
      "Epoch 283/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.1184 - accuracy: 0.9223 - val_loss: 4.6974 - val_accuracy: 0.5959\n",
      "Epoch 284/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.1059 - accuracy: 0.9245 - val_loss: 4.6878 - val_accuracy: 0.5948\n",
      "Epoch 285/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.0932 - accuracy: 0.9254 - val_loss: 4.6782 - val_accuracy: 0.5956\n",
      "Epoch 286/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.0817 - accuracy: 0.9255 - val_loss: 4.6686 - val_accuracy: 0.5959\n",
      "Epoch 287/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.0699 - accuracy: 0.9263 - val_loss: 4.6592 - val_accuracy: 0.5963\n",
      "Epoch 288/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.0558 - accuracy: 0.9286 - val_loss: 4.6497 - val_accuracy: 0.5959\n",
      "Epoch 289/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.0431 - accuracy: 0.9291 - val_loss: 4.6404 - val_accuracy: 0.5961\n",
      "Epoch 290/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.0311 - accuracy: 0.9284 - val_loss: 4.6311 - val_accuracy: 0.5952\n",
      "Epoch 291/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.0184 - accuracy: 0.9302 - val_loss: 4.6217 - val_accuracy: 0.5957\n",
      "Epoch 292/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.0067 - accuracy: 0.9317 - val_loss: 4.6124 - val_accuracy: 0.5961\n",
      "Epoch 293/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.9944 - accuracy: 0.9322 - val_loss: 4.6027 - val_accuracy: 0.5959\n",
      "Epoch 294/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.9817 - accuracy: 0.9330 - val_loss: 4.5935 - val_accuracy: 0.5957\n",
      "Epoch 295/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.9706 - accuracy: 0.9341 - val_loss: 4.5842 - val_accuracy: 0.5955\n",
      "Epoch 296/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.9570 - accuracy: 0.9369 - val_loss: 4.5746 - val_accuracy: 0.5959\n",
      "Epoch 297/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.9459 - accuracy: 0.9366 - val_loss: 4.5654 - val_accuracy: 0.5949\n",
      "Epoch 298/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.9352 - accuracy: 0.9347 - val_loss: 4.5561 - val_accuracy: 0.5961\n",
      "Epoch 299/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.9222 - accuracy: 0.9361 - val_loss: 4.5472 - val_accuracy: 0.5963\n",
      "Epoch 300/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.9097 - accuracy: 0.9389 - val_loss: 4.5381 - val_accuracy: 0.5973\n",
      "Epoch 301/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.8964 - accuracy: 0.9378 - val_loss: 4.5289 - val_accuracy: 0.5976\n",
      "Epoch 302/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.8863 - accuracy: 0.9385 - val_loss: 4.5202 - val_accuracy: 0.5972\n",
      "Epoch 303/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.8737 - accuracy: 0.9415 - val_loss: 4.5110 - val_accuracy: 0.5964\n",
      "Epoch 304/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.8620 - accuracy: 0.9406 - val_loss: 4.5017 - val_accuracy: 0.5973\n",
      "Epoch 305/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.8501 - accuracy: 0.9414 - val_loss: 4.4929 - val_accuracy: 0.5969\n",
      "Epoch 306/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.8378 - accuracy: 0.9421 - val_loss: 4.4836 - val_accuracy: 0.5971\n",
      "Epoch 307/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.8252 - accuracy: 0.9453 - val_loss: 4.4744 - val_accuracy: 0.5971\n",
      "Epoch 308/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.8137 - accuracy: 0.9452 - val_loss: 4.4655 - val_accuracy: 0.5976\n",
      "Epoch 309/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.8012 - accuracy: 0.9444 - val_loss: 4.4567 - val_accuracy: 0.5971\n",
      "Epoch 310/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.7909 - accuracy: 0.9456 - val_loss: 4.4477 - val_accuracy: 0.5969\n",
      "Epoch 311/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.7780 - accuracy: 0.9472 - val_loss: 4.4390 - val_accuracy: 0.5971\n",
      "Epoch 312/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.7672 - accuracy: 0.9471 - val_loss: 4.4303 - val_accuracy: 0.5969\n",
      "Epoch 313/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.7561 - accuracy: 0.9460 - val_loss: 4.4215 - val_accuracy: 0.5973\n",
      "Epoch 314/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.7439 - accuracy: 0.9474 - val_loss: 4.4127 - val_accuracy: 0.5961\n",
      "Epoch 315/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.7309 - accuracy: 0.9514 - val_loss: 4.4040 - val_accuracy: 0.5961\n",
      "Epoch 316/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.7197 - accuracy: 0.9496 - val_loss: 4.3951 - val_accuracy: 0.5961\n",
      "Epoch 317/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.7071 - accuracy: 0.9516 - val_loss: 4.3864 - val_accuracy: 0.5959\n",
      "Epoch 318/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.6965 - accuracy: 0.9517 - val_loss: 4.3778 - val_accuracy: 0.5957\n",
      "Epoch 319/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.6844 - accuracy: 0.9532 - val_loss: 4.3691 - val_accuracy: 0.5956\n",
      "Epoch 320/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.6718 - accuracy: 0.9538 - val_loss: 4.3603 - val_accuracy: 0.5961\n",
      "Epoch 321/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.6614 - accuracy: 0.9534 - val_loss: 4.3520 - val_accuracy: 0.5961\n",
      "Epoch 322/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.6496 - accuracy: 0.9540 - val_loss: 4.3436 - val_accuracy: 0.5959\n",
      "Epoch 323/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.6385 - accuracy: 0.9544 - val_loss: 4.3350 - val_accuracy: 0.5953\n",
      "Time: 94.45119452476501\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Traits_Model_10OU.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#10 OU\n",
    "################################################################################################################################################\n",
    "# subset the traits\n",
    "traits_OU10=traits_OU[:,0:10,:]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test  = train_test_split(y,X20,traits_OU10,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = OU_subset(ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Traits_Model_10OU.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bgPi-7r52xv",
    "outputId": "1858277f-eab4-42ab-e8b2-2a00e91d8d68",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 20, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 18, 250)      45000       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 18, 250)     1000        ['conv1d_6[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 16, 250)      187500      ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 16, 250)     1000        ['conv1d_7[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 14, 250)      187500      ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 14, 250)     1000        ['conv1d_8[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 4, 250)      0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 1000)         0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dense_24_input (InputLayer)    [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 125)          125125      ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 150)          150000      ['dense_24_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 125)          0           ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 150)         600         ['dense_24[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 125)          15750       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 150)          22500       ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 125)          0           ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 150)         600         ['dense_25[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 50)           6300        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 50)           7550        ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 50)           0           ['dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_2 (LinearW)           (None, 50)           2           ['dense_26[0][0]',               \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 50)           2550        ['linear_w_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 3)            153         ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 754,130\n",
      "Trainable params: 752,030\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 2s 11ms/step - loss: 8.8965 - accuracy: 0.3404 - val_loss: 8.6955 - val_accuracy: 0.3621\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.7495 - accuracy: 0.3676 - val_loss: 8.6705 - val_accuracy: 0.3999\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.7003 - accuracy: 0.3883 - val_loss: 8.6363 - val_accuracy: 0.4420\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.6665 - accuracy: 0.4062 - val_loss: 8.5974 - val_accuracy: 0.4835\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.6229 - accuracy: 0.4277 - val_loss: 8.5581 - val_accuracy: 0.5145\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.5913 - accuracy: 0.4468 - val_loss: 8.5196 - val_accuracy: 0.5445\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.5534 - accuracy: 0.4707 - val_loss: 8.4810 - val_accuracy: 0.5659\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.5188 - accuracy: 0.4833 - val_loss: 8.4427 - val_accuracy: 0.5851\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.4877 - accuracy: 0.5003 - val_loss: 8.4049 - val_accuracy: 0.6035\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.4537 - accuracy: 0.5128 - val_loss: 8.3673 - val_accuracy: 0.6164\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.4179 - accuracy: 0.5297 - val_loss: 8.3296 - val_accuracy: 0.6316\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.3850 - accuracy: 0.5412 - val_loss: 8.2927 - val_accuracy: 0.6432\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.3483 - accuracy: 0.5584 - val_loss: 8.2556 - val_accuracy: 0.6517\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.3162 - accuracy: 0.5684 - val_loss: 8.2198 - val_accuracy: 0.6607\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.2791 - accuracy: 0.5832 - val_loss: 8.1849 - val_accuracy: 0.6680\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.2533 - accuracy: 0.5883 - val_loss: 8.1511 - val_accuracy: 0.6745\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.2170 - accuracy: 0.6004 - val_loss: 8.1175 - val_accuracy: 0.6824\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.1891 - accuracy: 0.6088 - val_loss: 8.0851 - val_accuracy: 0.6872\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.1652 - accuracy: 0.6117 - val_loss: 8.0539 - val_accuracy: 0.6921\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.1312 - accuracy: 0.6207 - val_loss: 8.0226 - val_accuracy: 0.6984\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.0993 - accuracy: 0.6309 - val_loss: 7.9921 - val_accuracy: 0.7039\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.0736 - accuracy: 0.6397 - val_loss: 7.9619 - val_accuracy: 0.7112\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.0413 - accuracy: 0.6465 - val_loss: 7.9326 - val_accuracy: 0.7172\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.0104 - accuracy: 0.6565 - val_loss: 7.9028 - val_accuracy: 0.7253\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.9876 - accuracy: 0.6595 - val_loss: 7.8723 - val_accuracy: 0.7323\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.9577 - accuracy: 0.6672 - val_loss: 7.8422 - val_accuracy: 0.7381\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.9292 - accuracy: 0.6740 - val_loss: 7.8126 - val_accuracy: 0.7464\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.9074 - accuracy: 0.6784 - val_loss: 7.7830 - val_accuracy: 0.7539\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.8716 - accuracy: 0.6904 - val_loss: 7.7528 - val_accuracy: 0.7609\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.8421 - accuracy: 0.6971 - val_loss: 7.7231 - val_accuracy: 0.7700\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.8177 - accuracy: 0.7029 - val_loss: 7.6930 - val_accuracy: 0.7788\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.7965 - accuracy: 0.7064 - val_loss: 7.6636 - val_accuracy: 0.7860\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.7582 - accuracy: 0.7190 - val_loss: 7.6338 - val_accuracy: 0.7933\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.7321 - accuracy: 0.7213 - val_loss: 7.6053 - val_accuracy: 0.7971\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.7011 - accuracy: 0.7323 - val_loss: 7.5759 - val_accuracy: 0.8039\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.6778 - accuracy: 0.7320 - val_loss: 7.5470 - val_accuracy: 0.8089\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.6492 - accuracy: 0.7419 - val_loss: 7.5194 - val_accuracy: 0.8141\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.6192 - accuracy: 0.7502 - val_loss: 7.4915 - val_accuracy: 0.8199\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.5920 - accuracy: 0.7548 - val_loss: 7.4635 - val_accuracy: 0.8233\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.5657 - accuracy: 0.7618 - val_loss: 7.4374 - val_accuracy: 0.8256\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.5417 - accuracy: 0.7663 - val_loss: 7.4106 - val_accuracy: 0.8319\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.5148 - accuracy: 0.7704 - val_loss: 7.3852 - val_accuracy: 0.8351\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.4867 - accuracy: 0.7730 - val_loss: 7.3600 - val_accuracy: 0.8404\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.4629 - accuracy: 0.7781 - val_loss: 7.3349 - val_accuracy: 0.8444\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.4442 - accuracy: 0.7824 - val_loss: 7.3117 - val_accuracy: 0.8479\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.4113 - accuracy: 0.7913 - val_loss: 7.2872 - val_accuracy: 0.8528\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.3868 - accuracy: 0.7937 - val_loss: 7.2640 - val_accuracy: 0.8563\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.3653 - accuracy: 0.7945 - val_loss: 7.2418 - val_accuracy: 0.8588\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.3475 - accuracy: 0.7980 - val_loss: 7.2207 - val_accuracy: 0.8619\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.3181 - accuracy: 0.8045 - val_loss: 7.1985 - val_accuracy: 0.8637\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.2959 - accuracy: 0.8060 - val_loss: 7.1767 - val_accuracy: 0.8669\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.2749 - accuracy: 0.8120 - val_loss: 7.1553 - val_accuracy: 0.8685\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.2533 - accuracy: 0.8128 - val_loss: 7.1342 - val_accuracy: 0.8719\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.2325 - accuracy: 0.8183 - val_loss: 7.1131 - val_accuracy: 0.8735\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.2098 - accuracy: 0.8216 - val_loss: 7.0924 - val_accuracy: 0.8755\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.1858 - accuracy: 0.8256 - val_loss: 7.0733 - val_accuracy: 0.8768\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.1707 - accuracy: 0.8284 - val_loss: 7.0528 - val_accuracy: 0.8787\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.1449 - accuracy: 0.8304 - val_loss: 7.0333 - val_accuracy: 0.8808\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.1267 - accuracy: 0.8331 - val_loss: 7.0134 - val_accuracy: 0.8825\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.1034 - accuracy: 0.8356 - val_loss: 6.9943 - val_accuracy: 0.8836\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.0852 - accuracy: 0.8386 - val_loss: 6.9748 - val_accuracy: 0.8867\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.0657 - accuracy: 0.8416 - val_loss: 6.9564 - val_accuracy: 0.8875\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.0459 - accuracy: 0.8415 - val_loss: 6.9371 - val_accuracy: 0.8900\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.0262 - accuracy: 0.8444 - val_loss: 6.9189 - val_accuracy: 0.8908\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.0015 - accuracy: 0.8492 - val_loss: 6.9006 - val_accuracy: 0.8927\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.9853 - accuracy: 0.8493 - val_loss: 6.8827 - val_accuracy: 0.8944\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.9688 - accuracy: 0.8505 - val_loss: 6.8654 - val_accuracy: 0.8943\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.9472 - accuracy: 0.8544 - val_loss: 6.8471 - val_accuracy: 0.8957\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.9328 - accuracy: 0.8562 - val_loss: 6.8290 - val_accuracy: 0.8963\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.9104 - accuracy: 0.8572 - val_loss: 6.8104 - val_accuracy: 0.8980\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.8938 - accuracy: 0.8580 - val_loss: 6.7932 - val_accuracy: 0.9001\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.8685 - accuracy: 0.8644 - val_loss: 6.7751 - val_accuracy: 0.9016\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.8499 - accuracy: 0.8649 - val_loss: 6.7581 - val_accuracy: 0.9020\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.8358 - accuracy: 0.8660 - val_loss: 6.7412 - val_accuracy: 0.9019\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.8185 - accuracy: 0.8673 - val_loss: 6.7243 - val_accuracy: 0.9037\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.7928 - accuracy: 0.8706 - val_loss: 6.7060 - val_accuracy: 0.9052\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.7779 - accuracy: 0.8713 - val_loss: 6.6902 - val_accuracy: 0.9052\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.7595 - accuracy: 0.8733 - val_loss: 6.6728 - val_accuracy: 0.9068\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.7433 - accuracy: 0.8729 - val_loss: 6.6559 - val_accuracy: 0.9068\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.7293 - accuracy: 0.8740 - val_loss: 6.6395 - val_accuracy: 0.9077\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.7089 - accuracy: 0.8773 - val_loss: 6.6226 - val_accuracy: 0.9081\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.6882 - accuracy: 0.8762 - val_loss: 6.6062 - val_accuracy: 0.9085\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.6741 - accuracy: 0.8772 - val_loss: 6.5899 - val_accuracy: 0.9081\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.6579 - accuracy: 0.8775 - val_loss: 6.5732 - val_accuracy: 0.9087\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.6313 - accuracy: 0.8836 - val_loss: 6.5572 - val_accuracy: 0.9092\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.6177 - accuracy: 0.8834 - val_loss: 6.5405 - val_accuracy: 0.9099\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.6030 - accuracy: 0.8844 - val_loss: 6.5248 - val_accuracy: 0.9112\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.5881 - accuracy: 0.8851 - val_loss: 6.5094 - val_accuracy: 0.9112\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.5623 - accuracy: 0.8890 - val_loss: 6.4929 - val_accuracy: 0.9123\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.5493 - accuracy: 0.8891 - val_loss: 6.4767 - val_accuracy: 0.9129\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.5377 - accuracy: 0.8885 - val_loss: 6.4610 - val_accuracy: 0.9136\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.5181 - accuracy: 0.8889 - val_loss: 6.4459 - val_accuracy: 0.9136\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4998 - accuracy: 0.8900 - val_loss: 6.4302 - val_accuracy: 0.9137\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4841 - accuracy: 0.8917 - val_loss: 6.4138 - val_accuracy: 0.9144\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4688 - accuracy: 0.8905 - val_loss: 6.3983 - val_accuracy: 0.9151\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4477 - accuracy: 0.8952 - val_loss: 6.3830 - val_accuracy: 0.9153\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4312 - accuracy: 0.8948 - val_loss: 6.3679 - val_accuracy: 0.9151\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4190 - accuracy: 0.8952 - val_loss: 6.3521 - val_accuracy: 0.9167\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.3988 - accuracy: 0.8963 - val_loss: 6.3366 - val_accuracy: 0.9164\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.3850 - accuracy: 0.8960 - val_loss: 6.3212 - val_accuracy: 0.9167\n",
      "Time: 64.441721200943\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_10OU_20SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#20SNPS, 10 OU\n",
    "################################################################################################################################################xtrain, xtest = X[int(len(y)*.25):], X[:int(len(y)*.25)]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test  = train_test_split(y,X20,traits_OU10,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_OU_subset(ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_10OU_20SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vaUOW_lb4205",
    "outputId": "7e4ce685-b2f0-4ef6-9936-68539a49ae8e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 1000, 60)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 998, 250)     45000       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 998, 250)    1000        ['conv1d_9[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 996, 250)     187500      ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 996, 250)    1000        ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 994, 250)     187500      ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 994, 250)    1000        ['conv1d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 331, 250)    0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 82750)        0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " dense_32_input (InputLayer)    [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 125)          10343875    ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 150)          150000      ['dense_32_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 125)          0           ['dense_35[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 150)         600         ['dense_32[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 125)          15750       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 150)          22500       ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 125)          0           ['dense_36[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 150)         600         ['dense_33[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 50)           6300        ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 50)           7550        ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 50)           0           ['dense_37[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_3 (LinearW)           (None, 50)           2           ['dense_34[0][0]',               \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 50)           2550        ['linear_w_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 3)            153         ['dense_38[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,972,880\n",
      "Trainable params: 10,970,780\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 13s 126ms/step - loss: 8.8037 - accuracy: 0.3603 - val_loss: 8.6979 - val_accuracy: 0.3657\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 8.6133 - accuracy: 0.4712 - val_loss: 8.5879 - val_accuracy: 0.5575\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 8.4665 - accuracy: 0.5873 - val_loss: 8.3993 - val_accuracy: 0.7088\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.3307 - accuracy: 0.6701 - val_loss: 8.2003 - val_accuracy: 0.7877\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.2095 - accuracy: 0.7305 - val_loss: 8.0145 - val_accuracy: 0.8725\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.0924 - accuracy: 0.7857 - val_loss: 7.8700 - val_accuracy: 0.9215\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.9809 - accuracy: 0.8317 - val_loss: 7.7624 - val_accuracy: 0.9469\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.8806 - accuracy: 0.8697 - val_loss: 7.6825 - val_accuracy: 0.9611\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.8121 - accuracy: 0.8936 - val_loss: 7.6235 - val_accuracy: 0.9723\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.7421 - accuracy: 0.9133 - val_loss: 7.5711 - val_accuracy: 0.9836\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.6929 - accuracy: 0.9294 - val_loss: 7.5344 - val_accuracy: 0.9869\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.6396 - accuracy: 0.9412 - val_loss: 7.5048 - val_accuracy: 0.9896\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.6026 - accuracy: 0.9481 - val_loss: 7.4793 - val_accuracy: 0.9897\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.5679 - accuracy: 0.9558 - val_loss: 7.4525 - val_accuracy: 0.9932\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.5380 - accuracy: 0.9616 - val_loss: 7.4318 - val_accuracy: 0.9940\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.5075 - accuracy: 0.9647 - val_loss: 7.4113 - val_accuracy: 0.9959\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 7.4817 - accuracy: 0.9692 - val_loss: 7.3921 - val_accuracy: 0.9957\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.4560 - accuracy: 0.9716 - val_loss: 7.3755 - val_accuracy: 0.9957\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.4349 - accuracy: 0.9724 - val_loss: 7.3563 - val_accuracy: 0.9968\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.4041 - accuracy: 0.9779 - val_loss: 7.3373 - val_accuracy: 0.9972\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.3891 - accuracy: 0.9781 - val_loss: 7.3209 - val_accuracy: 0.9971\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.3629 - accuracy: 0.9812 - val_loss: 7.3046 - val_accuracy: 0.9969\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.3480 - accuracy: 0.9808 - val_loss: 7.2862 - val_accuracy: 0.9973\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.3267 - accuracy: 0.9834 - val_loss: 7.2700 - val_accuracy: 0.9979\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 7.3051 - accuracy: 0.9858 - val_loss: 7.2529 - val_accuracy: 0.9979\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.2883 - accuracy: 0.9850 - val_loss: 7.2366 - val_accuracy: 0.9980\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 7.2709 - accuracy: 0.9852 - val_loss: 7.2210 - val_accuracy: 0.9980\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.2512 - accuracy: 0.9871 - val_loss: 7.2039 - val_accuracy: 0.9985\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.2338 - accuracy: 0.9875 - val_loss: 7.1871 - val_accuracy: 0.9989\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 7.2168 - accuracy: 0.9885 - val_loss: 7.1729 - val_accuracy: 0.9980\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 7.2018 - accuracy: 0.9874 - val_loss: 7.1565 - val_accuracy: 0.9987\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 7.1819 - accuracy: 0.9888 - val_loss: 7.1413 - val_accuracy: 0.9981\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.1615 - accuracy: 0.9905 - val_loss: 7.1250 - val_accuracy: 0.9985\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.1457 - accuracy: 0.9903 - val_loss: 7.1080 - val_accuracy: 0.9992\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.1289 - accuracy: 0.9908 - val_loss: 7.0932 - val_accuracy: 0.9987\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 7.1135 - accuracy: 0.9905 - val_loss: 7.0773 - val_accuracy: 0.9987\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 7.0938 - accuracy: 0.9917 - val_loss: 7.0609 - val_accuracy: 0.9991\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 7.0770 - accuracy: 0.9924 - val_loss: 7.0454 - val_accuracy: 0.9992\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 7.0610 - accuracy: 0.9922 - val_loss: 7.0307 - val_accuracy: 0.9987\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 7.0450 - accuracy: 0.9928 - val_loss: 7.0142 - val_accuracy: 0.9991\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 7.0275 - accuracy: 0.9942 - val_loss: 6.9997 - val_accuracy: 0.9987\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 7.0142 - accuracy: 0.9919 - val_loss: 6.9832 - val_accuracy: 0.9992\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.9988 - accuracy: 0.9924 - val_loss: 6.9675 - val_accuracy: 0.9992\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.9807 - accuracy: 0.9936 - val_loss: 6.9520 - val_accuracy: 0.9992\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.9632 - accuracy: 0.9937 - val_loss: 6.9361 - val_accuracy: 0.9995\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.9491 - accuracy: 0.9941 - val_loss: 6.9210 - val_accuracy: 0.9992\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.9322 - accuracy: 0.9941 - val_loss: 6.9064 - val_accuracy: 0.9989\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.9174 - accuracy: 0.9936 - val_loss: 6.8906 - val_accuracy: 0.9993\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.9006 - accuracy: 0.9943 - val_loss: 6.8751 - val_accuracy: 0.9993\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.8843 - accuracy: 0.9949 - val_loss: 6.8600 - val_accuracy: 0.9991\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.8707 - accuracy: 0.9938 - val_loss: 6.8443 - val_accuracy: 0.9993\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.8543 - accuracy: 0.9943 - val_loss: 6.8293 - val_accuracy: 0.9991\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.8369 - accuracy: 0.9951 - val_loss: 6.8143 - val_accuracy: 0.9993\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.8220 - accuracy: 0.9954 - val_loss: 6.7986 - val_accuracy: 0.9995\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.8054 - accuracy: 0.9953 - val_loss: 6.7831 - val_accuracy: 0.9996\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.7903 - accuracy: 0.9957 - val_loss: 6.7680 - val_accuracy: 0.9997\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.7766 - accuracy: 0.9950 - val_loss: 6.7535 - val_accuracy: 0.9993\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.7595 - accuracy: 0.9953 - val_loss: 6.7377 - val_accuracy: 0.9996\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.7456 - accuracy: 0.9951 - val_loss: 6.7226 - val_accuracy: 0.9995\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.7268 - accuracy: 0.9964 - val_loss: 6.7077 - val_accuracy: 0.9995\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.7141 - accuracy: 0.9961 - val_loss: 6.6919 - val_accuracy: 0.9999\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.6990 - accuracy: 0.9955 - val_loss: 6.6772 - val_accuracy: 0.9996\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.6826 - accuracy: 0.9963 - val_loss: 6.6620 - val_accuracy: 0.9997\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.6661 - accuracy: 0.9967 - val_loss: 6.6472 - val_accuracy: 0.9996\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.6523 - accuracy: 0.9961 - val_loss: 6.6320 - val_accuracy: 0.9999\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.6351 - accuracy: 0.9964 - val_loss: 6.6167 - val_accuracy: 0.9999\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.6223 - accuracy: 0.9962 - val_loss: 6.6023 - val_accuracy: 0.9999\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.6058 - accuracy: 0.9965 - val_loss: 6.5869 - val_accuracy: 0.9999\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.5912 - accuracy: 0.9966 - val_loss: 6.5725 - val_accuracy: 0.9996\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.5759 - accuracy: 0.9961 - val_loss: 6.5574 - val_accuracy: 0.9996\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.5597 - accuracy: 0.9970 - val_loss: 6.5419 - val_accuracy: 0.9999\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.5473 - accuracy: 0.9957 - val_loss: 6.5272 - val_accuracy: 0.9999\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.5313 - accuracy: 0.9962 - val_loss: 6.5125 - val_accuracy: 0.9999\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.5150 - accuracy: 0.9972 - val_loss: 6.4977 - val_accuracy: 0.9999\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.5015 - accuracy: 0.9966 - val_loss: 6.4832 - val_accuracy: 0.9995\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.4853 - accuracy: 0.9976 - val_loss: 6.4682 - val_accuracy: 0.9997\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.4703 - accuracy: 0.9968 - val_loss: 6.4534 - val_accuracy: 0.9997\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.4553 - accuracy: 0.9972 - val_loss: 6.4387 - val_accuracy: 0.9997\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.4410 - accuracy: 0.9970 - val_loss: 6.4238 - val_accuracy: 0.9997\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.4263 - accuracy: 0.9966 - val_loss: 6.4088 - val_accuracy: 0.9999\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.4101 - accuracy: 0.9975 - val_loss: 6.3943 - val_accuracy: 0.9999\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.3955 - accuracy: 0.9976 - val_loss: 6.3799 - val_accuracy: 0.9997\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.3805 - accuracy: 0.9976 - val_loss: 6.3652 - val_accuracy: 0.9997\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.3649 - accuracy: 0.9979 - val_loss: 6.3502 - val_accuracy: 0.9999\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.3533 - accuracy: 0.9968 - val_loss: 6.3355 - val_accuracy: 0.9999\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.3363 - accuracy: 0.9976 - val_loss: 6.3210 - val_accuracy: 0.9999\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.3213 - accuracy: 0.9977 - val_loss: 6.3066 - val_accuracy: 0.9999\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.3073 - accuracy: 0.9976 - val_loss: 6.2919 - val_accuracy: 0.9999\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.2924 - accuracy: 0.9976 - val_loss: 6.2772 - val_accuracy: 0.9999\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.2780 - accuracy: 0.9976 - val_loss: 6.2630 - val_accuracy: 0.9997\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.2630 - accuracy: 0.9980 - val_loss: 6.2482 - val_accuracy: 0.9999\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.2479 - accuracy: 0.9981 - val_loss: 6.2337 - val_accuracy: 0.9999\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.2336 - accuracy: 0.9975 - val_loss: 6.2192 - val_accuracy: 0.9999\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.2192 - accuracy: 0.9976 - val_loss: 6.2050 - val_accuracy: 0.9997\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.2055 - accuracy: 0.9976 - val_loss: 6.1904 - val_accuracy: 0.9999\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.1899 - accuracy: 0.9980 - val_loss: 6.1761 - val_accuracy: 0.9999\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 11s 117ms/step - loss: 6.1756 - accuracy: 0.9978 - val_loss: 6.1615 - val_accuracy: 0.9999\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.1611 - accuracy: 0.9980 - val_loss: 6.1474 - val_accuracy: 0.9999\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.1470 - accuracy: 0.9978 - val_loss: 6.1327 - val_accuracy: 0.9999\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 6.1321 - accuracy: 0.9980 - val_loss: 6.1182 - val_accuracy: 0.9999\n",
      "Time: 1061.3073115348816\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_10OU_1KSNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#1KSNPS, 10 OU\n",
    "################################################################################################################################################xtrain, xtest = X[int(len(y)*.25):], X[:int(len(y)*.25)]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test  = train_test_split(y,X,traits_OU10,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_OU_subset(ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_10OU_1KSNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JmdPZdxV699k",
    "outputId": "28a7e81e-1a3c-4845-9ecf-02c5aceb1154",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 1000, 60)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 998, 250)     45000       ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 998, 250)    1000        ['conv1d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 996, 250)     187500      ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 996, 250)    1000        ['conv1d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 994, 250)     187500      ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 994, 250)    1000        ['conv1d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 331, 250)    0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 82750)        0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " dense_40_input (InputLayer)    [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_43 (Dense)               (None, 125)          10343875    ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 150)          450000      ['dense_40_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 125)          0           ['dense_43[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 150)         600         ['dense_40[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 125)          15750       ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 150)          22500       ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 125)          0           ['dense_44[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 150)         600         ['dense_41[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_45 (Dense)               (None, 50)           6300        ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " dense_42 (Dense)               (None, 50)           7550        ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 50)           0           ['dense_45[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_4 (LinearW)           (None, 50)           2           ['dense_42[0][0]',               \n",
      "                                                                  'activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, 50)           2550        ['linear_w_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 3)            153         ['dense_46[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,272,880\n",
      "Trainable params: 11,270,780\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 13s 128ms/step - loss: 13.2098 - accuracy: 0.3895 - val_loss: 13.0897 - val_accuracy: 0.4019\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 12.9602 - accuracy: 0.5375 - val_loss: 12.9197 - val_accuracy: 0.6265\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 12.7370 - accuracy: 0.6488 - val_loss: 12.6165 - val_accuracy: 0.7984\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 12.5336 - accuracy: 0.7400 - val_loss: 12.3220 - val_accuracy: 0.8973\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 12.3595 - accuracy: 0.8097 - val_loss: 12.1107 - val_accuracy: 0.9411\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 12.2068 - accuracy: 0.8586 - val_loss: 11.9707 - val_accuracy: 0.9648\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 12.0887 - accuracy: 0.8915 - val_loss: 11.8769 - val_accuracy: 0.9760\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.9894 - accuracy: 0.9150 - val_loss: 11.7943 - val_accuracy: 0.9843\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.8979 - accuracy: 0.9321 - val_loss: 11.7307 - val_accuracy: 0.9888\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.8262 - accuracy: 0.9426 - val_loss: 11.6749 - val_accuracy: 0.9901\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.7658 - accuracy: 0.9479 - val_loss: 11.6213 - val_accuracy: 0.9923\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.7023 - accuracy: 0.9567 - val_loss: 11.5717 - val_accuracy: 0.9941\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.6404 - accuracy: 0.9640 - val_loss: 11.5227 - val_accuracy: 0.9964\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.5887 - accuracy: 0.9662 - val_loss: 11.4796 - val_accuracy: 0.9955\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.5402 - accuracy: 0.9688 - val_loss: 11.4332 - val_accuracy: 0.9967\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.4859 - accuracy: 0.9731 - val_loss: 11.3885 - val_accuracy: 0.9973\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.4364 - accuracy: 0.9744 - val_loss: 11.3458 - val_accuracy: 0.9971\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.3861 - accuracy: 0.9783 - val_loss: 11.3026 - val_accuracy: 0.9975\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.3387 - accuracy: 0.9796 - val_loss: 11.2587 - val_accuracy: 0.9981\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.2912 - accuracy: 0.9818 - val_loss: 11.2162 - val_accuracy: 0.9984\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.2475 - accuracy: 0.9813 - val_loss: 11.1741 - val_accuracy: 0.9985\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 11.1997 - accuracy: 0.9841 - val_loss: 11.1319 - val_accuracy: 0.9987\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.1574 - accuracy: 0.9832 - val_loss: 11.0906 - val_accuracy: 0.9985\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.1108 - accuracy: 0.9847 - val_loss: 11.0488 - val_accuracy: 0.9987\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.0669 - accuracy: 0.9861 - val_loss: 11.0069 - val_accuracy: 0.9987\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 11.0230 - accuracy: 0.9884 - val_loss: 10.9646 - val_accuracy: 0.9989\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.9803 - accuracy: 0.9879 - val_loss: 10.9236 - val_accuracy: 0.9991\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.9390 - accuracy: 0.9878 - val_loss: 10.8828 - val_accuracy: 0.9989\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.8967 - accuracy: 0.9894 - val_loss: 10.8416 - val_accuracy: 0.9991\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.8533 - accuracy: 0.9886 - val_loss: 10.8003 - val_accuracy: 0.9991\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.8119 - accuracy: 0.9900 - val_loss: 10.7596 - val_accuracy: 0.9992\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.7691 - accuracy: 0.9908 - val_loss: 10.7180 - val_accuracy: 0.9993\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.7244 - accuracy: 0.9919 - val_loss: 10.6776 - val_accuracy: 0.9993\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.6860 - accuracy: 0.9913 - val_loss: 10.6371 - val_accuracy: 0.9993\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.6421 - accuracy: 0.9924 - val_loss: 10.5971 - val_accuracy: 0.9996\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.6012 - accuracy: 0.9928 - val_loss: 10.5564 - val_accuracy: 0.9996\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.5597 - accuracy: 0.9935 - val_loss: 10.5166 - val_accuracy: 0.9993\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.5199 - accuracy: 0.9932 - val_loss: 10.4767 - val_accuracy: 0.9995\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 10.4785 - accuracy: 0.9928 - val_loss: 10.4362 - val_accuracy: 0.9995\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.4372 - accuracy: 0.9936 - val_loss: 10.3964 - val_accuracy: 0.9995\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.3973 - accuracy: 0.9939 - val_loss: 10.3566 - val_accuracy: 0.9995\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.3548 - accuracy: 0.9943 - val_loss: 10.3167 - val_accuracy: 0.9995\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.3153 - accuracy: 0.9946 - val_loss: 10.2773 - val_accuracy: 0.9995\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.2761 - accuracy: 0.9942 - val_loss: 10.2379 - val_accuracy: 0.9995\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.2377 - accuracy: 0.9937 - val_loss: 10.1983 - val_accuracy: 0.9995\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.1963 - accuracy: 0.9948 - val_loss: 10.1585 - val_accuracy: 0.9995\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.1543 - accuracy: 0.9957 - val_loss: 10.1199 - val_accuracy: 0.9996\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.1156 - accuracy: 0.9957 - val_loss: 10.0803 - val_accuracy: 0.9995\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.0800 - accuracy: 0.9942 - val_loss: 10.0410 - val_accuracy: 0.9995\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 10.0389 - accuracy: 0.9945 - val_loss: 10.0022 - val_accuracy: 0.9995\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.9995 - accuracy: 0.9948 - val_loss: 9.9631 - val_accuracy: 0.9996\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.9592 - accuracy: 0.9952 - val_loss: 9.9239 - val_accuracy: 0.9997\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.9197 - accuracy: 0.9960 - val_loss: 9.8856 - val_accuracy: 0.9995\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.8809 - accuracy: 0.9956 - val_loss: 9.8472 - val_accuracy: 0.9995\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.8431 - accuracy: 0.9952 - val_loss: 9.8086 - val_accuracy: 0.9995\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.8035 - accuracy: 0.9955 - val_loss: 9.7702 - val_accuracy: 0.9995\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.7636 - accuracy: 0.9959 - val_loss: 9.7315 - val_accuracy: 0.9995\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.7258 - accuracy: 0.9958 - val_loss: 9.6927 - val_accuracy: 0.9997\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.6884 - accuracy: 0.9956 - val_loss: 9.6550 - val_accuracy: 0.9996\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.6497 - accuracy: 0.9965 - val_loss: 9.6171 - val_accuracy: 0.9995\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.6102 - accuracy: 0.9963 - val_loss: 9.5787 - val_accuracy: 0.9996\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.5729 - accuracy: 0.9966 - val_loss: 9.5408 - val_accuracy: 0.9995\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 9.5331 - accuracy: 0.9968 - val_loss: 9.5027 - val_accuracy: 0.9995\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.4955 - accuracy: 0.9964 - val_loss: 9.4651 - val_accuracy: 0.9995\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.4573 - accuracy: 0.9967 - val_loss: 9.4274 - val_accuracy: 0.9995\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.4208 - accuracy: 0.9964 - val_loss: 9.3897 - val_accuracy: 0.9995\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.3827 - accuracy: 0.9962 - val_loss: 9.3521 - val_accuracy: 0.9995\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.3449 - accuracy: 0.9968 - val_loss: 9.3152 - val_accuracy: 0.9995\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.3060 - accuracy: 0.9971 - val_loss: 9.2775 - val_accuracy: 0.9995\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.2711 - accuracy: 0.9963 - val_loss: 9.2404 - val_accuracy: 0.9995\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.2320 - accuracy: 0.9972 - val_loss: 9.2031 - val_accuracy: 0.9996\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.1933 - accuracy: 0.9975 - val_loss: 9.1664 - val_accuracy: 0.9995\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.1597 - accuracy: 0.9960 - val_loss: 9.1291 - val_accuracy: 0.9995\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.1201 - accuracy: 0.9971 - val_loss: 9.0921 - val_accuracy: 0.9996\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.0846 - accuracy: 0.9969 - val_loss: 9.0550 - val_accuracy: 0.9997\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.0472 - accuracy: 0.9965 - val_loss: 9.0184 - val_accuracy: 0.9996\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 9.0093 - accuracy: 0.9972 - val_loss: 8.9816 - val_accuracy: 0.9997\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.9725 - accuracy: 0.9969 - val_loss: 8.9453 - val_accuracy: 0.9995\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.9350 - accuracy: 0.9979 - val_loss: 8.9089 - val_accuracy: 0.9996\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.8987 - accuracy: 0.9978 - val_loss: 8.8722 - val_accuracy: 0.9997\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.8633 - accuracy: 0.9971 - val_loss: 8.8359 - val_accuracy: 0.9996\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.8273 - accuracy: 0.9975 - val_loss: 8.7998 - val_accuracy: 0.9997\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.7891 - accuracy: 0.9982 - val_loss: 8.7637 - val_accuracy: 0.9996\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.7538 - accuracy: 0.9973 - val_loss: 8.7277 - val_accuracy: 0.9996\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.7180 - accuracy: 0.9974 - val_loss: 8.6918 - val_accuracy: 0.9996\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.6819 - accuracy: 0.9975 - val_loss: 8.6558 - val_accuracy: 0.9996\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.6464 - accuracy: 0.9975 - val_loss: 8.6200 - val_accuracy: 0.9996\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.6102 - accuracy: 0.9977 - val_loss: 8.5843 - val_accuracy: 0.9996\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 11s 119ms/step - loss: 8.5730 - accuracy: 0.9980 - val_loss: 8.5486 - val_accuracy: 0.9996\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.5382 - accuracy: 0.9976 - val_loss: 8.5130 - val_accuracy: 0.9997\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.5034 - accuracy: 0.9976 - val_loss: 8.4775 - val_accuracy: 0.9996\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.4674 - accuracy: 0.9974 - val_loss: 8.4423 - val_accuracy: 0.9996\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.4327 - accuracy: 0.9976 - val_loss: 8.4069 - val_accuracy: 0.9997\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.3959 - accuracy: 0.9982 - val_loss: 8.3717 - val_accuracy: 0.9997\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.3613 - accuracy: 0.9980 - val_loss: 8.3366 - val_accuracy: 0.9996\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.3256 - accuracy: 0.9980 - val_loss: 8.3015 - val_accuracy: 0.9996\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.2914 - accuracy: 0.9980 - val_loss: 8.2667 - val_accuracy: 0.9997\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.2561 - accuracy: 0.9979 - val_loss: 8.2319 - val_accuracy: 0.9997\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.2215 - accuracy: 0.9978 - val_loss: 8.1971 - val_accuracy: 0.9996\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 11s 118ms/step - loss: 8.1854 - accuracy: 0.9985 - val_loss: 8.1625 - val_accuracy: 0.9996\n",
      "Time: 1067.3893823623657\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_50OU_1KSNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#1KSNPS, 50 OU\n",
    "################################################################################################################################################xtrain, xtest = X[int(len(y)*.25):], X[:int(len(y)*.25)]\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test  = train_test_split(y,X,traits_OU50,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_OU_subset(ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_50OU_1KSNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJEoto5M8aSf",
    "outputId": "23d0578d-fd56-4ccb-c35d-06b5887bc51c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 50, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 48, 250)      45000       ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 48, 250)     1000        ['conv1d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 46, 250)      187500      ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 46, 250)     1000        ['conv1d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 44, 250)      187500      ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 44, 250)     1000        ['conv1d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 14, 250)     0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 3500)         0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " dense_48_input (InputLayer)    [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_51 (Dense)               (None, 125)          437625      ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 150)          150000      ['dense_48_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 125)          0           ['dense_51[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 150)         600         ['dense_48[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_52 (Dense)               (None, 125)          15750       ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dense_49 (Dense)               (None, 150)          22500       ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 125)          0           ['dense_52[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 150)         600         ['dense_49[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_53 (Dense)               (None, 50)           6300        ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " dense_50 (Dense)               (None, 50)           7550        ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 50)           0           ['dense_53[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_5 (LinearW)           (None, 50)           2           ['dense_50[0][0]',               \n",
      "                                                                  'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " dense_54 (Dense)               (None, 50)           2550        ['linear_w_5[0][0]']             \n",
      "                                                                                                  \n",
      " dense_55 (Dense)               (None, 3)            153         ['dense_54[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,066,630\n",
      "Trainable params: 1,064,530\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 2s 14ms/step - loss: 8.8824 - accuracy: 0.3384 - val_loss: 8.7504 - val_accuracy: 0.3475\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.7813 - accuracy: 0.3756 - val_loss: 8.7113 - val_accuracy: 0.3948\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.7128 - accuracy: 0.4107 - val_loss: 8.6475 - val_accuracy: 0.4813\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.6477 - accuracy: 0.4513 - val_loss: 8.5697 - val_accuracy: 0.5463\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.5901 - accuracy: 0.4855 - val_loss: 8.4914 - val_accuracy: 0.5956\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.5300 - accuracy: 0.5215 - val_loss: 8.4160 - val_accuracy: 0.6343\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.4821 - accuracy: 0.5420 - val_loss: 8.3528 - val_accuracy: 0.6579\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.4266 - accuracy: 0.5705 - val_loss: 8.2952 - val_accuracy: 0.6773\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.3886 - accuracy: 0.5830 - val_loss: 8.2449 - val_accuracy: 0.6884\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.3346 - accuracy: 0.6052 - val_loss: 8.1982 - val_accuracy: 0.6993\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.3014 - accuracy: 0.6134 - val_loss: 8.1552 - val_accuracy: 0.7091\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.2563 - accuracy: 0.6344 - val_loss: 8.1127 - val_accuracy: 0.7180\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.2157 - accuracy: 0.6480 - val_loss: 8.0717 - val_accuracy: 0.7277\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.1759 - accuracy: 0.6615 - val_loss: 8.0315 - val_accuracy: 0.7407\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.1487 - accuracy: 0.6663 - val_loss: 7.9921 - val_accuracy: 0.7535\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.1109 - accuracy: 0.6782 - val_loss: 7.9543 - val_accuracy: 0.7651\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.0734 - accuracy: 0.6891 - val_loss: 7.9161 - val_accuracy: 0.7793\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.0350 - accuracy: 0.6990 - val_loss: 7.8780 - val_accuracy: 0.7924\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.9952 - accuracy: 0.7151 - val_loss: 7.8403 - val_accuracy: 0.8043\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.9632 - accuracy: 0.7259 - val_loss: 7.8031 - val_accuracy: 0.8151\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.9250 - accuracy: 0.7371 - val_loss: 7.7667 - val_accuracy: 0.8235\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.8882 - accuracy: 0.7451 - val_loss: 7.7307 - val_accuracy: 0.8348\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.8511 - accuracy: 0.7568 - val_loss: 7.6945 - val_accuracy: 0.8467\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.8172 - accuracy: 0.7648 - val_loss: 7.6604 - val_accuracy: 0.8559\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.7823 - accuracy: 0.7751 - val_loss: 7.6275 - val_accuracy: 0.8636\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.7455 - accuracy: 0.7859 - val_loss: 7.5944 - val_accuracy: 0.8717\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.7110 - accuracy: 0.7980 - val_loss: 7.5620 - val_accuracy: 0.8784\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.6765 - accuracy: 0.8066 - val_loss: 7.5307 - val_accuracy: 0.8831\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.6442 - accuracy: 0.8180 - val_loss: 7.5010 - val_accuracy: 0.8900\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.6142 - accuracy: 0.8242 - val_loss: 7.4724 - val_accuracy: 0.8957\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.5795 - accuracy: 0.8346 - val_loss: 7.4440 - val_accuracy: 0.9016\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.5455 - accuracy: 0.8450 - val_loss: 7.4142 - val_accuracy: 0.9065\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.5186 - accuracy: 0.8485 - val_loss: 7.3884 - val_accuracy: 0.9107\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.4915 - accuracy: 0.8550 - val_loss: 7.3612 - val_accuracy: 0.9165\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.4629 - accuracy: 0.8622 - val_loss: 7.3365 - val_accuracy: 0.9192\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.4324 - accuracy: 0.8690 - val_loss: 7.3107 - val_accuracy: 0.9248\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.4016 - accuracy: 0.8776 - val_loss: 7.2852 - val_accuracy: 0.9276\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.3739 - accuracy: 0.8846 - val_loss: 7.2617 - val_accuracy: 0.9297\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.3547 - accuracy: 0.8866 - val_loss: 7.2376 - val_accuracy: 0.9347\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.3211 - accuracy: 0.8912 - val_loss: 7.2124 - val_accuracy: 0.9385\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.2972 - accuracy: 0.8991 - val_loss: 7.1906 - val_accuracy: 0.9405\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.2792 - accuracy: 0.8994 - val_loss: 7.1674 - val_accuracy: 0.9432\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.2482 - accuracy: 0.9045 - val_loss: 7.1467 - val_accuracy: 0.9449\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.2263 - accuracy: 0.9096 - val_loss: 7.1257 - val_accuracy: 0.9468\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.2057 - accuracy: 0.9112 - val_loss: 7.1035 - val_accuracy: 0.9499\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.1800 - accuracy: 0.9133 - val_loss: 7.0832 - val_accuracy: 0.9519\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.1521 - accuracy: 0.9217 - val_loss: 7.0614 - val_accuracy: 0.9536\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.1318 - accuracy: 0.9214 - val_loss: 7.0428 - val_accuracy: 0.9548\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.1124 - accuracy: 0.9238 - val_loss: 7.0211 - val_accuracy: 0.9571\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.0911 - accuracy: 0.9253 - val_loss: 7.0014 - val_accuracy: 0.9595\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.0701 - accuracy: 0.9262 - val_loss: 6.9828 - val_accuracy: 0.9597\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.0483 - accuracy: 0.9303 - val_loss: 6.9633 - val_accuracy: 0.9616\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.0285 - accuracy: 0.9335 - val_loss: 6.9447 - val_accuracy: 0.9621\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.0071 - accuracy: 0.9360 - val_loss: 6.9277 - val_accuracy: 0.9627\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.9854 - accuracy: 0.9394 - val_loss: 6.9098 - val_accuracy: 0.9643\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.9716 - accuracy: 0.9386 - val_loss: 6.8910 - val_accuracy: 0.9644\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.9490 - accuracy: 0.9412 - val_loss: 6.8740 - val_accuracy: 0.9649\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.9284 - accuracy: 0.9422 - val_loss: 6.8559 - val_accuracy: 0.9660\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.9119 - accuracy: 0.9426 - val_loss: 6.8403 - val_accuracy: 0.9655\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.8901 - accuracy: 0.9456 - val_loss: 6.8224 - val_accuracy: 0.9669\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.8721 - accuracy: 0.9472 - val_loss: 6.8047 - val_accuracy: 0.9683\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.8542 - accuracy: 0.9468 - val_loss: 6.7879 - val_accuracy: 0.9683\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.8403 - accuracy: 0.9478 - val_loss: 6.7707 - val_accuracy: 0.9691\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.8153 - accuracy: 0.9515 - val_loss: 6.7549 - val_accuracy: 0.9685\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7997 - accuracy: 0.9501 - val_loss: 6.7368 - val_accuracy: 0.9697\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7773 - accuracy: 0.9542 - val_loss: 6.7205 - val_accuracy: 0.9712\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7647 - accuracy: 0.9524 - val_loss: 6.7049 - val_accuracy: 0.9716\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7470 - accuracy: 0.9559 - val_loss: 6.6882 - val_accuracy: 0.9724\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7333 - accuracy: 0.9540 - val_loss: 6.6742 - val_accuracy: 0.9712\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7089 - accuracy: 0.9563 - val_loss: 6.6570 - val_accuracy: 0.9723\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6909 - accuracy: 0.9572 - val_loss: 6.6421 - val_accuracy: 0.9720\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6757 - accuracy: 0.9583 - val_loss: 6.6258 - val_accuracy: 0.9724\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6583 - accuracy: 0.9596 - val_loss: 6.6090 - val_accuracy: 0.9735\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6421 - accuracy: 0.9600 - val_loss: 6.5934 - val_accuracy: 0.9736\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6231 - accuracy: 0.9609 - val_loss: 6.5777 - val_accuracy: 0.9739\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6089 - accuracy: 0.9614 - val_loss: 6.5617 - val_accuracy: 0.9745\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5923 - accuracy: 0.9616 - val_loss: 6.5460 - val_accuracy: 0.9748\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5734 - accuracy: 0.9621 - val_loss: 6.5314 - val_accuracy: 0.9747\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5624 - accuracy: 0.9619 - val_loss: 6.5165 - val_accuracy: 0.9745\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5394 - accuracy: 0.9641 - val_loss: 6.5000 - val_accuracy: 0.9757\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5292 - accuracy: 0.9631 - val_loss: 6.4853 - val_accuracy: 0.9756\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5083 - accuracy: 0.9644 - val_loss: 6.4697 - val_accuracy: 0.9761\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4917 - accuracy: 0.9657 - val_loss: 6.4548 - val_accuracy: 0.9753\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4771 - accuracy: 0.9653 - val_loss: 6.4404 - val_accuracy: 0.9752\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4604 - accuracy: 0.9664 - val_loss: 6.4248 - val_accuracy: 0.9753\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4465 - accuracy: 0.9668 - val_loss: 6.4099 - val_accuracy: 0.9759\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4258 - accuracy: 0.9674 - val_loss: 6.3946 - val_accuracy: 0.9757\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4121 - accuracy: 0.9676 - val_loss: 6.3785 - val_accuracy: 0.9765\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3974 - accuracy: 0.9668 - val_loss: 6.3645 - val_accuracy: 0.9757\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3820 - accuracy: 0.9674 - val_loss: 6.3497 - val_accuracy: 0.9761\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3638 - accuracy: 0.9695 - val_loss: 6.3348 - val_accuracy: 0.9768\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3518 - accuracy: 0.9680 - val_loss: 6.3193 - val_accuracy: 0.9768\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3361 - accuracy: 0.9693 - val_loss: 6.3048 - val_accuracy: 0.9771\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3163 - accuracy: 0.9722 - val_loss: 6.2895 - val_accuracy: 0.9771\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3036 - accuracy: 0.9699 - val_loss: 6.2748 - val_accuracy: 0.9773\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.2886 - accuracy: 0.9708 - val_loss: 6.2608 - val_accuracy: 0.9768\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.2706 - accuracy: 0.9714 - val_loss: 6.2461 - val_accuracy: 0.9767\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.2585 - accuracy: 0.9707 - val_loss: 6.2314 - val_accuracy: 0.9773\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.2401 - accuracy: 0.9732 - val_loss: 6.2162 - val_accuracy: 0.9777\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.2254 - accuracy: 0.9723 - val_loss: 6.2029 - val_accuracy: 0.9773\n",
      "Time: 93.14271688461304\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_10OU_50SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#50SNPS, 10 OU\n",
    "################################################################################################################################################xtrain, xtest = X[int(len(y)*.25):], X[:int(len(y)*.25)]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test  = train_test_split(y,X50,traits_OU10,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_OU_subset(ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_10OU_50SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "140ckPa_9PWp",
    "outputId": "faf1af63-5383-451e-e964-628ccb33a5d9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 20, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 18, 250)      45000       ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 18, 250)     1000        ['conv1d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 16, 250)      187500      ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 16, 250)     1000        ['conv1d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 14, 250)      187500      ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 14, 250)     1000        ['conv1d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 4, 250)      0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 1000)         0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " dense_56_input (InputLayer)    [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_59 (Dense)               (None, 125)          125125      ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " dense_56 (Dense)               (None, 150)          450000      ['dense_56_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 125)          0           ['dense_59[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 150)         600         ['dense_56[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_60 (Dense)               (None, 125)          15750       ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dense_57 (Dense)               (None, 150)          22500       ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 125)          0           ['dense_60[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 150)         600         ['dense_57[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_61 (Dense)               (None, 50)           6300        ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " dense_58 (Dense)               (None, 50)           7550        ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 50)           0           ['dense_61[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_6 (LinearW)           (None, 50)           2           ['dense_58[0][0]',               \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " dense_62 (Dense)               (None, 50)           2550        ['linear_w_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_63 (Dense)               (None, 3)            153         ['dense_62[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,054,130\n",
      "Trainable params: 1,052,030\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 3s 12ms/step - loss: 13.2680 - accuracy: 0.3332 - val_loss: 13.1230 - val_accuracy: 0.3651\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 13.1643 - accuracy: 0.3622 - val_loss: 13.0644 - val_accuracy: 0.4043\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 13.0824 - accuracy: 0.3926 - val_loss: 12.9971 - val_accuracy: 0.4485\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 13.0089 - accuracy: 0.4125 - val_loss: 12.9262 - val_accuracy: 0.4901\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.9389 - accuracy: 0.4400 - val_loss: 12.8557 - val_accuracy: 0.5207\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.8713 - accuracy: 0.4616 - val_loss: 12.7872 - val_accuracy: 0.5488\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.8092 - accuracy: 0.4791 - val_loss: 12.7195 - val_accuracy: 0.5741\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.7393 - accuracy: 0.5029 - val_loss: 12.6538 - val_accuracy: 0.5915\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.6733 - accuracy: 0.5204 - val_loss: 12.5894 - val_accuracy: 0.6069\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.6121 - accuracy: 0.5350 - val_loss: 12.5252 - val_accuracy: 0.6199\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.5529 - accuracy: 0.5401 - val_loss: 12.4621 - val_accuracy: 0.6291\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.4910 - accuracy: 0.5616 - val_loss: 12.4000 - val_accuracy: 0.6349\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.4308 - accuracy: 0.5769 - val_loss: 12.3390 - val_accuracy: 0.6443\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.3626 - accuracy: 0.5896 - val_loss: 12.2794 - val_accuracy: 0.6519\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.3101 - accuracy: 0.5967 - val_loss: 12.2206 - val_accuracy: 0.6581\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.2536 - accuracy: 0.6070 - val_loss: 12.1630 - val_accuracy: 0.6639\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.1944 - accuracy: 0.6160 - val_loss: 12.1063 - val_accuracy: 0.6704\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.1415 - accuracy: 0.6187 - val_loss: 12.0500 - val_accuracy: 0.6773\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.0840 - accuracy: 0.6348 - val_loss: 11.9941 - val_accuracy: 0.6845\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.0294 - accuracy: 0.6383 - val_loss: 11.9391 - val_accuracy: 0.6911\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.9724 - accuracy: 0.6447 - val_loss: 11.8841 - val_accuracy: 0.6971\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.9205 - accuracy: 0.6543 - val_loss: 11.8295 - val_accuracy: 0.7040\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.8610 - accuracy: 0.6637 - val_loss: 11.7736 - val_accuracy: 0.7111\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.8076 - accuracy: 0.6693 - val_loss: 11.7188 - val_accuracy: 0.7200\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.7544 - accuracy: 0.6787 - val_loss: 11.6637 - val_accuracy: 0.7283\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.7020 - accuracy: 0.6848 - val_loss: 11.6093 - val_accuracy: 0.7327\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.6526 - accuracy: 0.6864 - val_loss: 11.5547 - val_accuracy: 0.7397\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.5926 - accuracy: 0.6996 - val_loss: 11.4998 - val_accuracy: 0.7468\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.5412 - accuracy: 0.7064 - val_loss: 11.4449 - val_accuracy: 0.7532\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.4922 - accuracy: 0.7089 - val_loss: 11.3907 - val_accuracy: 0.7599\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.4327 - accuracy: 0.7199 - val_loss: 11.3357 - val_accuracy: 0.7675\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.3814 - accuracy: 0.7259 - val_loss: 11.2819 - val_accuracy: 0.7741\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.3249 - accuracy: 0.7368 - val_loss: 11.2279 - val_accuracy: 0.7824\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.2732 - accuracy: 0.7356 - val_loss: 11.1750 - val_accuracy: 0.7883\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.2223 - accuracy: 0.7441 - val_loss: 11.1216 - val_accuracy: 0.7948\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.1689 - accuracy: 0.7541 - val_loss: 11.0681 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.1194 - accuracy: 0.7578 - val_loss: 11.0179 - val_accuracy: 0.8041\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.0647 - accuracy: 0.7635 - val_loss: 10.9655 - val_accuracy: 0.8095\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.0120 - accuracy: 0.7694 - val_loss: 10.9146 - val_accuracy: 0.8128\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.9615 - accuracy: 0.7753 - val_loss: 10.8656 - val_accuracy: 0.8175\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.9146 - accuracy: 0.7780 - val_loss: 10.8147 - val_accuracy: 0.8219\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.8599 - accuracy: 0.7867 - val_loss: 10.7658 - val_accuracy: 0.8276\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.8120 - accuracy: 0.7918 - val_loss: 10.7173 - val_accuracy: 0.8312\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.7578 - accuracy: 0.7976 - val_loss: 10.6691 - val_accuracy: 0.8336\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.7173 - accuracy: 0.7960 - val_loss: 10.6205 - val_accuracy: 0.8383\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.6734 - accuracy: 0.8006 - val_loss: 10.5745 - val_accuracy: 0.8408\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.6196 - accuracy: 0.8052 - val_loss: 10.5291 - val_accuracy: 0.8445\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.5752 - accuracy: 0.8099 - val_loss: 10.4821 - val_accuracy: 0.8472\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.5229 - accuracy: 0.8129 - val_loss: 10.4371 - val_accuracy: 0.8499\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.4716 - accuracy: 0.8216 - val_loss: 10.3903 - val_accuracy: 0.8529\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.4286 - accuracy: 0.8227 - val_loss: 10.3451 - val_accuracy: 0.8553\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.3858 - accuracy: 0.8265 - val_loss: 10.3003 - val_accuracy: 0.8584\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.3400 - accuracy: 0.8297 - val_loss: 10.2559 - val_accuracy: 0.8617\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.2910 - accuracy: 0.8356 - val_loss: 10.2126 - val_accuracy: 0.8635\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.2489 - accuracy: 0.8348 - val_loss: 10.1695 - val_accuracy: 0.8657\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.2040 - accuracy: 0.8356 - val_loss: 10.1261 - val_accuracy: 0.8680\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.1567 - accuracy: 0.8426 - val_loss: 10.0829 - val_accuracy: 0.8695\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.1128 - accuracy: 0.8452 - val_loss: 10.0405 - val_accuracy: 0.8719\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.0681 - accuracy: 0.8473 - val_loss: 9.9987 - val_accuracy: 0.8740\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.0279 - accuracy: 0.8508 - val_loss: 9.9555 - val_accuracy: 0.8765\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.9891 - accuracy: 0.8488 - val_loss: 9.9144 - val_accuracy: 0.8787\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.9431 - accuracy: 0.8528 - val_loss: 9.8721 - val_accuracy: 0.8821\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.9004 - accuracy: 0.8563 - val_loss: 9.8305 - val_accuracy: 0.8833\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.8570 - accuracy: 0.8579 - val_loss: 9.7899 - val_accuracy: 0.8836\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.8143 - accuracy: 0.8608 - val_loss: 9.7481 - val_accuracy: 0.8837\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.7688 - accuracy: 0.8629 - val_loss: 9.7087 - val_accuracy: 0.8853\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.7246 - accuracy: 0.8680 - val_loss: 9.6677 - val_accuracy: 0.8860\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.6888 - accuracy: 0.8655 - val_loss: 9.6275 - val_accuracy: 0.8873\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.6460 - accuracy: 0.8696 - val_loss: 9.5874 - val_accuracy: 0.8891\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.6056 - accuracy: 0.8722 - val_loss: 9.5476 - val_accuracy: 0.8893\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.5678 - accuracy: 0.8694 - val_loss: 9.5077 - val_accuracy: 0.8899\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.5265 - accuracy: 0.8716 - val_loss: 9.4676 - val_accuracy: 0.8915\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.4810 - accuracy: 0.8746 - val_loss: 9.4285 - val_accuracy: 0.8915\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.4406 - accuracy: 0.8774 - val_loss: 9.3883 - val_accuracy: 0.8929\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 9.4012 - accuracy: 0.8801 - val_loss: 9.3500 - val_accuracy: 0.8925\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.3588 - accuracy: 0.8815 - val_loss: 9.3098 - val_accuracy: 0.8955\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.3182 - accuracy: 0.8820 - val_loss: 9.2715 - val_accuracy: 0.8960\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 9.2817 - accuracy: 0.8826 - val_loss: 9.2337 - val_accuracy: 0.8952\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.2380 - accuracy: 0.8842 - val_loss: 9.1946 - val_accuracy: 0.8967\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.2020 - accuracy: 0.8861 - val_loss: 9.1568 - val_accuracy: 0.8977\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.1580 - accuracy: 0.8913 - val_loss: 9.1179 - val_accuracy: 0.8985\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.1215 - accuracy: 0.8888 - val_loss: 9.0809 - val_accuracy: 0.8991\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.0821 - accuracy: 0.8911 - val_loss: 9.0414 - val_accuracy: 0.9003\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.0401 - accuracy: 0.8920 - val_loss: 9.0046 - val_accuracy: 0.9012\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.0038 - accuracy: 0.8931 - val_loss: 8.9668 - val_accuracy: 0.9011\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.9628 - accuracy: 0.8936 - val_loss: 8.9283 - val_accuracy: 0.9028\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.9245 - accuracy: 0.8984 - val_loss: 8.8906 - val_accuracy: 0.9023\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.8903 - accuracy: 0.8957 - val_loss: 8.8537 - val_accuracy: 0.9032\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.8484 - accuracy: 0.9004 - val_loss: 8.8174 - val_accuracy: 0.9039\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.8071 - accuracy: 0.9025 - val_loss: 8.7812 - val_accuracy: 0.9037\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.7733 - accuracy: 0.9008 - val_loss: 8.7437 - val_accuracy: 0.9051\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.7332 - accuracy: 0.9018 - val_loss: 8.7059 - val_accuracy: 0.9053\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.6949 - accuracy: 0.9064 - val_loss: 8.6704 - val_accuracy: 0.9060\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.6561 - accuracy: 0.9036 - val_loss: 8.6334 - val_accuracy: 0.9064\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.6204 - accuracy: 0.9059 - val_loss: 8.5970 - val_accuracy: 0.9068\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.5842 - accuracy: 0.9049 - val_loss: 8.5606 - val_accuracy: 0.9077\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.5449 - accuracy: 0.9097 - val_loss: 8.5247 - val_accuracy: 0.9079\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.5097 - accuracy: 0.9085 - val_loss: 8.4892 - val_accuracy: 0.9079\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.4708 - accuracy: 0.9086 - val_loss: 8.4538 - val_accuracy: 0.9081\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.4350 - accuracy: 0.9096 - val_loss: 8.4182 - val_accuracy: 0.9088\n",
      "Time: 71.11040306091309\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_100OU_20SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#20SNPS, 100 OU\n",
    "################################################################################################################################################xtrain, xtest = X[int(len(y)*.25):], X[:int(len(y)*.25)]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test  = train_test_split(y,X20,traits_OU,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_OU_subset(ytrain, ytest, xtrain, xtest, traits_OU_train, traits_OU_test)\n",
    "\n",
    "# save the model\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_100OU_20SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################################################################################################################################\n",
    "# Now repeat with discrete traits.\n",
    "################################################################################################################################################\n",
    "\n",
    "# Since we will run the analysis on several subsets, define a function for training on each data subsets (Combined datasets, SNP only and discrete traits only).\n",
    "\n",
    "# function to train on the combined datasets\n",
    "def combined_disc_subset(ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test):\n",
    "    # convert labels to a categorical matrix of binary values (0 or 1). The number of rows is the length of the input vector (number of simulations) and the number of columns is the number of classes (3 scenarios).\n",
    "    ytest = np_utils.to_categorical(ytest, num_classes)\n",
    "    ytrain = np_utils.to_categorical(ytrain, num_classes)\n",
    "    # reshape the traits matrices to input them into the MLP\n",
    "    traits_disc_train=traits_disc_train.reshape((traits_disc_train.shape[0], (traits_disc_train.shape[1]*traits_disc_train.shape[2])))\n",
    "    traits_disc_test=traits_disc_test.reshape((traits_disc_test.shape[0], (traits_disc_test.shape[1]*traits_disc_test.shape[2])))\n",
    "    # Create the MLP, the CNN and the combined models\n",
    "    mlp = create_mlp(traits_disc_train)\n",
    "    cnn = create_cnn(xtest)\n",
    "    combinedInput = LinearW()([mlp.output, cnn.output])\n",
    "\n",
    "    # The final fully-connected layer head will have two dense layers (one relu and one softmax)\n",
    "    x = Dense(50, activation=\"relu\")(combinedInput)\n",
    "    x = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    # The final model accepts numerical data on the MLP input and images on the CNN input, disctputting a single value\n",
    "    model = Model(inputs=[mlp.input, cnn.input], outputs=x)\n",
    "\n",
    "    # using Stochastic Gradient Descent as optimizer and a categorical cross-entropy loss function\n",
    "    opt = SGD(learning_rate=0.001)\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    # save only the epoch with the highest accuracy in the validation set, by using the model checkpoint\n",
    "    earlyStopping = EarlyStopping(monitor='val_accuracy', patience=150, verbose=0, mode='max', restore_best_weights=True)\n",
    "\n",
    "    # fit the model and record running times\n",
    "    start = time.time()\n",
    "    model.fit([traits_disc_train, xtrain], ytrain, batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=([traits_disc_test, xtest], ytest),callbacks=[earlyStopping])\n",
    "    print (f'Time: {time.time() - start}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# function to train on the discrete trait only datasets\n",
    "def disc_subset(ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test):\n",
    "    # convert labels to a categorical matrix of binary values (0 or 1). The number of rows is the length of the input vector (number of simulations) and the number of columns is the number of classes (3 scenarios).\n",
    "    ytest = np_utils.to_categorical(ytest, num_classes)\n",
    "    ytrain = np_utils.to_categorical(ytrain, num_classes)\n",
    "    # reshape the traits matrices to input them into the MLP\n",
    "    traits_disc_train=traits_disc_train.reshape((traits_disc_train.shape[0], (traits_disc_train.shape[1]*traits_disc_train.shape[2])))\n",
    "    traits_disc_test=traits_disc_test.reshape((traits_disc_test.shape[0], (traits_disc_test.shape[1]*traits_disc_test.shape[2])))\n",
    "    mlp = create_mlp(traits_disc_train)\n",
    "    #Create the last layer for the traits network\n",
    "    xMLP = Dense(num_classes, activation=\"softmax\")(mlp.output)\n",
    "    model = Model(inputs=mlp.input, outputs=xMLP)\n",
    "\n",
    "    # using Stochastic Gradient Descent as optimizer and a categorical cross-entropy loss function\n",
    "    opt = SGD(learning_rate=0.001)\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    # save only the epoch with the highest accuracy in the validation set, by using the model checkpoint\n",
    "    earlyStopping = EarlyStopping(monitor='val_accuracy', patience=150, verbose=0, mode='max', restore_best_weights=True)\n",
    "    # fit the model and record running times\n",
    "    start = time.time()\n",
    "    model.fit(traits_disc_train, ytrain, batch_size=batch_size,\n",
    "          epochs=epochs_traits,\n",
    "          verbose=1,\n",
    "          validation_data=(traits_disc_test, ytest),callbacks=[earlyStopping])\n",
    "    print (f'Time: {time.time() - start}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-JkwcGkqahZ",
    "outputId": "08d18c41-9117-4531-eaa2-216a897a84d4",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000 30000\n"
     ]
    }
   ],
   "source": [
    "# load the discrete traits simulated for the 3 scenarios. \n",
    "traits_disc = []\n",
    "traits_disc = np.loadtxt(\"./traits/traits_disc.txt\").reshape(30000,-1,100)\n",
    "# transform into a NumPy array.\n",
    "traits_disc = np.array(traits_disc)\n",
    "\n",
    "# load the SNPs simulated for the 3 scenarios.\n",
    "u1 = np.load(\"./trainingSims/Model_1sp.npz\",mmap_mode='r')\n",
    "u2 = np.load(\"./trainingSims/Model_2sp.npz\",mmap_mode='r')\n",
    "u3 = np.load(\"./trainingSims/Model_3sp.npz\",mmap_mode='r')\n",
    "\n",
    "# combine the loaded SNPs in a single NumPy array.\n",
    "X=np.concatenate((u1['Model_1sp'],u2['Model_2sp'],u3['Model_3sp']),axis=0)\n",
    "\n",
    "#transform major alleles in -1 and minor in 1\n",
    "for arr,array in enumerate(X):\n",
    "    for idx,row in enumerate(array):\n",
    "        if np.count_nonzero(row) > len(row)/2:\n",
    "            X[arr][idx][X[arr][idx] == 1] = -1\n",
    "            X[arr][idx][X[arr][idx] == 0] = 1\n",
    "        else:\n",
    "            X[arr][idx][X[arr][idx] == 0] = -1\n",
    "            \n",
    "# create a label vector in the same order as the simulations.\n",
    "y=[0 for i in range(len(u1['Model_1sp']))]\n",
    "y.extend([1 for i in range(len(u2['Model_2sp']))])\n",
    "y.extend([2 for i in range(len(u3['Model_3sp']))])\n",
    "y = np.array(y)\n",
    "\n",
    "# make sure labels, SNP and traits matrices all have the same length.\n",
    "print (len(X), len(y), len(traits_disc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLnlQCPD9RED",
    "outputId": "9904b7d4-0cb0-4037-d951-6cd88de5c381",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1000, 60)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 998, 250)     45000       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 998, 250)    1000        ['conv1d[0][0]']                 \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 996, 250)     187500      ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 996, 250)    1000        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 994, 250)     187500      ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 994, 250)    1000        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 331, 250)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 82750)        0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " dense_input (InputLayer)       [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 125)          10343875    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 150)          450000      ['dense_input[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 125)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 150)         600         ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 125)          15750       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 150)          22500       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 125)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 150)         600         ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 50)           6300        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 50)           7550        ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 50)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " linear_w (LinearW)             (None, 50)           2           ['dense_2[0][0]',                \n",
      "                                                                  'activation[0][0]']             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 50)           2550        ['linear_w[0][0]']               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 3)            153         ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,272,880\n",
      "Trainable params: 11,270,780\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 15s 124ms/step - loss: 13.1085 - accuracy: 0.4348 - val_loss: 13.1280 - val_accuracy: 0.3747\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.8974 - accuracy: 0.5632 - val_loss: 12.9302 - val_accuracy: 0.5891\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.7378 - accuracy: 0.6377 - val_loss: 12.6814 - val_accuracy: 0.7675\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.6015 - accuracy: 0.6911 - val_loss: 12.4365 - val_accuracy: 0.8676\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.4553 - accuracy: 0.7532 - val_loss: 12.2264 - val_accuracy: 0.9280\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.3176 - accuracy: 0.8028 - val_loss: 12.0498 - val_accuracy: 0.9561\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.1810 - accuracy: 0.8492 - val_loss: 11.9245 - val_accuracy: 0.9776\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.0626 - accuracy: 0.8837 - val_loss: 11.8263 - val_accuracy: 0.9856\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.9603 - accuracy: 0.9104 - val_loss: 11.7504 - val_accuracy: 0.9927\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 11.8726 - accuracy: 0.9281 - val_loss: 11.6878 - val_accuracy: 0.9920\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.7997 - accuracy: 0.9413 - val_loss: 11.6349 - val_accuracy: 0.9963\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.7318 - accuracy: 0.9502 - val_loss: 11.5830 - val_accuracy: 0.9965\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.6657 - accuracy: 0.9582 - val_loss: 11.5344 - val_accuracy: 0.9971\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.6128 - accuracy: 0.9616 - val_loss: 11.4892 - val_accuracy: 0.9971\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.5542 - accuracy: 0.9672 - val_loss: 11.4433 - val_accuracy: 0.9980\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.5039 - accuracy: 0.9695 - val_loss: 11.3991 - val_accuracy: 0.9981\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 11.4497 - accuracy: 0.9749 - val_loss: 11.3558 - val_accuracy: 0.9980\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.4027 - accuracy: 0.9755 - val_loss: 11.3122 - val_accuracy: 0.9984\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.3553 - accuracy: 0.9788 - val_loss: 11.2686 - val_accuracy: 0.9987\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 11.3083 - accuracy: 0.9799 - val_loss: 11.2274 - val_accuracy: 0.9981\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 11.2618 - accuracy: 0.9798 - val_loss: 11.1844 - val_accuracy: 0.9984\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.2169 - accuracy: 0.9819 - val_loss: 11.1429 - val_accuracy: 0.9985\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.1715 - accuracy: 0.9838 - val_loss: 11.1008 - val_accuracy: 0.9991\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.1278 - accuracy: 0.9846 - val_loss: 11.0583 - val_accuracy: 0.9993\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.0825 - accuracy: 0.9854 - val_loss: 11.0171 - val_accuracy: 0.9988\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 11.0400 - accuracy: 0.9877 - val_loss: 10.9759 - val_accuracy: 0.9989\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 10.9928 - accuracy: 0.9879 - val_loss: 10.9346 - val_accuracy: 0.9989\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 10.9526 - accuracy: 0.9874 - val_loss: 10.8933 - val_accuracy: 0.9989\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 10.9104 - accuracy: 0.9877 - val_loss: 10.8525 - val_accuracy: 0.9987\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.8674 - accuracy: 0.9886 - val_loss: 10.8118 - val_accuracy: 0.9992\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.8256 - accuracy: 0.9894 - val_loss: 10.7705 - val_accuracy: 0.9995\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.7808 - accuracy: 0.9915 - val_loss: 10.7304 - val_accuracy: 0.9992\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 10.7412 - accuracy: 0.9910 - val_loss: 10.6894 - val_accuracy: 0.9993\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.6964 - accuracy: 0.9917 - val_loss: 10.6487 - val_accuracy: 0.9993\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 10.6566 - accuracy: 0.9911 - val_loss: 10.6085 - val_accuracy: 0.9995\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.6153 - accuracy: 0.9911 - val_loss: 10.5678 - val_accuracy: 0.9996\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.5728 - accuracy: 0.9918 - val_loss: 10.5278 - val_accuracy: 0.9995\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 10.5336 - accuracy: 0.9918 - val_loss: 10.4878 - val_accuracy: 0.9995\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 10.4899 - accuracy: 0.9933 - val_loss: 10.4484 - val_accuracy: 0.9989\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 10.4517 - accuracy: 0.9923 - val_loss: 10.4078 - val_accuracy: 0.9995\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.4126 - accuracy: 0.9924 - val_loss: 10.3683 - val_accuracy: 0.9995\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.3697 - accuracy: 0.9934 - val_loss: 10.3288 - val_accuracy: 0.9995\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.3302 - accuracy: 0.9932 - val_loss: 10.2887 - val_accuracy: 0.9995\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.2911 - accuracy: 0.9933 - val_loss: 10.2495 - val_accuracy: 0.9995\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.2481 - accuracy: 0.9944 - val_loss: 10.2099 - val_accuracy: 0.9995\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.2081 - accuracy: 0.9946 - val_loss: 10.1702 - val_accuracy: 0.9995\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 10.1698 - accuracy: 0.9937 - val_loss: 10.1309 - val_accuracy: 0.9995\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.1306 - accuracy: 0.9944 - val_loss: 10.0917 - val_accuracy: 0.9995\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.0895 - accuracy: 0.9948 - val_loss: 10.0526 - val_accuracy: 0.9996\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.0501 - accuracy: 0.9953 - val_loss: 10.0136 - val_accuracy: 0.9995\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.0129 - accuracy: 0.9933 - val_loss: 9.9746 - val_accuracy: 0.9995\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.9710 - accuracy: 0.9954 - val_loss: 9.9356 - val_accuracy: 0.9995\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.9326 - accuracy: 0.9949 - val_loss: 9.8971 - val_accuracy: 0.9995\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.8947 - accuracy: 0.9945 - val_loss: 9.8584 - val_accuracy: 0.9995\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.8540 - accuracy: 0.9957 - val_loss: 9.8197 - val_accuracy: 0.9996\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.8168 - accuracy: 0.9948 - val_loss: 9.7810 - val_accuracy: 0.9996\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.7765 - accuracy: 0.9960 - val_loss: 9.7429 - val_accuracy: 0.9995\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.7376 - accuracy: 0.9957 - val_loss: 9.7046 - val_accuracy: 0.9995\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.6985 - accuracy: 0.9957 - val_loss: 9.6663 - val_accuracy: 0.9996\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.6603 - accuracy: 0.9956 - val_loss: 9.6280 - val_accuracy: 0.9996\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.6220 - accuracy: 0.9958 - val_loss: 9.5899 - val_accuracy: 0.9996\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.5838 - accuracy: 0.9966 - val_loss: 9.5520 - val_accuracy: 0.9996\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.5458 - accuracy: 0.9959 - val_loss: 9.5141 - val_accuracy: 0.9996\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.5070 - accuracy: 0.9964 - val_loss: 9.4761 - val_accuracy: 0.9996\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.4684 - accuracy: 0.9964 - val_loss: 9.4384 - val_accuracy: 0.9996\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.4299 - accuracy: 0.9968 - val_loss: 9.4007 - val_accuracy: 0.9995\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.3929 - accuracy: 0.9970 - val_loss: 9.3632 - val_accuracy: 0.9996\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.3553 - accuracy: 0.9971 - val_loss: 9.3260 - val_accuracy: 0.9995\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.3177 - accuracy: 0.9972 - val_loss: 9.2881 - val_accuracy: 0.9996\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.2822 - accuracy: 0.9961 - val_loss: 9.2509 - val_accuracy: 0.9996\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.2430 - accuracy: 0.9970 - val_loss: 9.2138 - val_accuracy: 0.9996\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.2057 - accuracy: 0.9966 - val_loss: 9.1765 - val_accuracy: 0.9996\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.1694 - accuracy: 0.9963 - val_loss: 9.1394 - val_accuracy: 0.9996\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.1303 - accuracy: 0.9975 - val_loss: 9.1026 - val_accuracy: 0.9996\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.0936 - accuracy: 0.9970 - val_loss: 9.0655 - val_accuracy: 0.9996\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.0576 - accuracy: 0.9966 - val_loss: 9.0288 - val_accuracy: 0.9996\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.0192 - accuracy: 0.9976 - val_loss: 8.9922 - val_accuracy: 0.9996\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 8.9829 - accuracy: 0.9973 - val_loss: 8.9557 - val_accuracy: 0.9996\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 8.9477 - accuracy: 0.9965 - val_loss: 8.9190 - val_accuracy: 0.9996\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 8.9107 - accuracy: 0.9970 - val_loss: 8.8825 - val_accuracy: 0.9996\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 8.8729 - accuracy: 0.9977 - val_loss: 8.8463 - val_accuracy: 0.9996\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.8357 - accuracy: 0.9978 - val_loss: 8.8098 - val_accuracy: 0.9996\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 8.8000 - accuracy: 0.9975 - val_loss: 8.7736 - val_accuracy: 0.9996\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.7657 - accuracy: 0.9966 - val_loss: 8.7375 - val_accuracy: 0.9996\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 8.7282 - accuracy: 0.9974 - val_loss: 8.7014 - val_accuracy: 0.9996\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.6920 - accuracy: 0.9971 - val_loss: 8.6658 - val_accuracy: 0.9995\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.6555 - accuracy: 0.9974 - val_loss: 8.6297 - val_accuracy: 0.9996\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.6212 - accuracy: 0.9972 - val_loss: 8.5938 - val_accuracy: 0.9996\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.5845 - accuracy: 0.9971 - val_loss: 8.5580 - val_accuracy: 0.9996\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 8.5486 - accuracy: 0.9972 - val_loss: 8.5224 - val_accuracy: 0.9996\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 8.5125 - accuracy: 0.9978 - val_loss: 8.4870 - val_accuracy: 0.9996\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 8.4782 - accuracy: 0.9972 - val_loss: 8.4516 - val_accuracy: 0.9996\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.4426 - accuracy: 0.9974 - val_loss: 8.4164 - val_accuracy: 0.9996\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.4066 - accuracy: 0.9976 - val_loss: 8.3812 - val_accuracy: 0.9996\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.3717 - accuracy: 0.9973 - val_loss: 8.3461 - val_accuracy: 0.9996\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.3352 - accuracy: 0.9982 - val_loss: 8.3110 - val_accuracy: 0.9996\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.3005 - accuracy: 0.9978 - val_loss: 8.2759 - val_accuracy: 0.9996\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.2657 - accuracy: 0.9977 - val_loss: 8.2410 - val_accuracy: 0.9996\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.2305 - accuracy: 0.9981 - val_loss: 8.2061 - val_accuracy: 0.9996\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.1949 - accuracy: 0.9981 - val_loss: 8.1713 - val_accuracy: 0.9996\n",
      "Time: 1037.7553007602692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-07 12:36:25.014007: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_100disc_1KSNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "# Combined 100 discrete, 1K SNPs\n",
    "################################################################################################################################################\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test  = train_test_split(y,X,traits_disc,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_disc_subset(ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test)\n",
    "\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_100disc_1KSNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TAaHFwkNC5SF",
    "outputId": "af20f552-c659-4c88-e624-6bff3e623178",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8_input (InputLayer)  [(None, 3000)]            0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 150)               450000    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 150)              600       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 150)               22500     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 150)              600       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 50)                7550      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 481,403\n",
      "Trainable params: 480,803\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 13.8619 - accuracy: 0.3344 - val_loss: 14.1521 - val_accuracy: 0.3325\n",
      "Epoch 2/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.5354 - accuracy: 0.3389 - val_loss: 13.4685 - val_accuracy: 0.3401\n",
      "Epoch 3/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.3460 - accuracy: 0.3438 - val_loss: 13.3007 - val_accuracy: 0.3349\n",
      "Epoch 4/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.2224 - accuracy: 0.3536 - val_loss: 13.2091 - val_accuracy: 0.3384\n",
      "Epoch 5/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.1328 - accuracy: 0.3631 - val_loss: 13.1505 - val_accuracy: 0.3428\n",
      "Epoch 6/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.0584 - accuracy: 0.3662 - val_loss: 13.0803 - val_accuracy: 0.3487\n",
      "Epoch 7/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.9909 - accuracy: 0.3745 - val_loss: 13.0217 - val_accuracy: 0.3492\n",
      "Epoch 8/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.9319 - accuracy: 0.3815 - val_loss: 12.9712 - val_accuracy: 0.3452\n",
      "Epoch 9/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.8711 - accuracy: 0.3883 - val_loss: 12.9281 - val_accuracy: 0.3544\n",
      "Epoch 10/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.8126 - accuracy: 0.3976 - val_loss: 12.8765 - val_accuracy: 0.3488\n",
      "Epoch 11/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.7572 - accuracy: 0.4000 - val_loss: 12.8250 - val_accuracy: 0.3493\n",
      "Epoch 12/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.7027 - accuracy: 0.4042 - val_loss: 12.7775 - val_accuracy: 0.3501\n",
      "Epoch 13/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.6500 - accuracy: 0.4099 - val_loss: 12.7253 - val_accuracy: 0.3535\n",
      "Epoch 14/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.5964 - accuracy: 0.4187 - val_loss: 12.6797 - val_accuracy: 0.3565\n",
      "Epoch 15/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.5441 - accuracy: 0.4266 - val_loss: 12.6324 - val_accuracy: 0.3564\n",
      "Epoch 16/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.4905 - accuracy: 0.4319 - val_loss: 12.5842 - val_accuracy: 0.3553\n",
      "Epoch 17/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.4401 - accuracy: 0.4384 - val_loss: 12.5403 - val_accuracy: 0.3577\n",
      "Epoch 18/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.3872 - accuracy: 0.4460 - val_loss: 12.4996 - val_accuracy: 0.3549\n",
      "Epoch 19/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.3377 - accuracy: 0.4535 - val_loss: 12.4505 - val_accuracy: 0.3608\n",
      "Epoch 20/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.2890 - accuracy: 0.4572 - val_loss: 12.4079 - val_accuracy: 0.3596\n",
      "Epoch 21/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.2391 - accuracy: 0.4665 - val_loss: 12.3612 - val_accuracy: 0.3640\n",
      "Epoch 22/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.1899 - accuracy: 0.4703 - val_loss: 12.3205 - val_accuracy: 0.3633\n",
      "Epoch 23/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.1428 - accuracy: 0.4756 - val_loss: 12.2761 - val_accuracy: 0.3636\n",
      "Epoch 24/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.0930 - accuracy: 0.4835 - val_loss: 12.2332 - val_accuracy: 0.3649\n",
      "Epoch 25/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.0454 - accuracy: 0.4894 - val_loss: 12.1852 - val_accuracy: 0.3655\n",
      "Epoch 26/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.9973 - accuracy: 0.4928 - val_loss: 12.1452 - val_accuracy: 0.3661\n",
      "Epoch 27/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.9484 - accuracy: 0.5032 - val_loss: 12.1024 - val_accuracy: 0.3677\n",
      "Epoch 28/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.9004 - accuracy: 0.5114 - val_loss: 12.0586 - val_accuracy: 0.3691\n",
      "Epoch 29/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.8543 - accuracy: 0.5164 - val_loss: 12.0171 - val_accuracy: 0.3697\n",
      "Epoch 30/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.8052 - accuracy: 0.5231 - val_loss: 11.9776 - val_accuracy: 0.3687\n",
      "Epoch 31/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.7598 - accuracy: 0.5280 - val_loss: 11.9340 - val_accuracy: 0.3689\n",
      "Epoch 32/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.7129 - accuracy: 0.5327 - val_loss: 11.8905 - val_accuracy: 0.3716\n",
      "Epoch 33/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.6650 - accuracy: 0.5408 - val_loss: 11.8484 - val_accuracy: 0.3707\n",
      "Epoch 34/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.6192 - accuracy: 0.5455 - val_loss: 11.8100 - val_accuracy: 0.3728\n",
      "Epoch 35/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.5715 - accuracy: 0.5529 - val_loss: 11.7644 - val_accuracy: 0.3728\n",
      "Epoch 36/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.5264 - accuracy: 0.5559 - val_loss: 11.7249 - val_accuracy: 0.3756\n",
      "Epoch 37/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.4795 - accuracy: 0.5628 - val_loss: 11.6837 - val_accuracy: 0.3749\n",
      "Epoch 38/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.4338 - accuracy: 0.5686 - val_loss: 11.6433 - val_accuracy: 0.3783\n",
      "Epoch 39/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.3879 - accuracy: 0.5756 - val_loss: 11.5996 - val_accuracy: 0.3764\n",
      "Epoch 40/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.3430 - accuracy: 0.5814 - val_loss: 11.5592 - val_accuracy: 0.3809\n",
      "Epoch 41/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.2965 - accuracy: 0.5877 - val_loss: 11.5166 - val_accuracy: 0.3788\n",
      "Epoch 42/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.2516 - accuracy: 0.5901 - val_loss: 11.4787 - val_accuracy: 0.3788\n",
      "Epoch 43/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.2067 - accuracy: 0.5982 - val_loss: 11.4392 - val_accuracy: 0.3824\n",
      "Epoch 44/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.1606 - accuracy: 0.6051 - val_loss: 11.3971 - val_accuracy: 0.3815\n",
      "Epoch 45/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.1152 - accuracy: 0.6110 - val_loss: 11.3581 - val_accuracy: 0.3824\n",
      "Epoch 46/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.0693 - accuracy: 0.6160 - val_loss: 11.3179 - val_accuracy: 0.3855\n",
      "Epoch 47/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.0256 - accuracy: 0.6210 - val_loss: 11.2782 - val_accuracy: 0.3868\n",
      "Epoch 48/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.9796 - accuracy: 0.6262 - val_loss: 11.2404 - val_accuracy: 0.3876\n",
      "Epoch 49/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.9351 - accuracy: 0.6316 - val_loss: 11.1995 - val_accuracy: 0.3883\n",
      "Epoch 50/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.8899 - accuracy: 0.6376 - val_loss: 11.1625 - val_accuracy: 0.3879\n",
      "Epoch 51/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.8451 - accuracy: 0.6457 - val_loss: 11.1216 - val_accuracy: 0.3863\n",
      "Epoch 52/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.8009 - accuracy: 0.6486 - val_loss: 11.0804 - val_accuracy: 0.3912\n",
      "Epoch 53/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.7567 - accuracy: 0.6541 - val_loss: 11.0415 - val_accuracy: 0.3888\n",
      "Epoch 54/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.7117 - accuracy: 0.6582 - val_loss: 11.0008 - val_accuracy: 0.3939\n",
      "Epoch 55/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.6672 - accuracy: 0.6639 - val_loss: 10.9677 - val_accuracy: 0.3925\n",
      "Epoch 56/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.6223 - accuracy: 0.6686 - val_loss: 10.9276 - val_accuracy: 0.3908\n",
      "Epoch 57/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.5792 - accuracy: 0.6758 - val_loss: 10.8868 - val_accuracy: 0.3945\n",
      "Epoch 58/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.5346 - accuracy: 0.6805 - val_loss: 10.8475 - val_accuracy: 0.3932\n",
      "Epoch 59/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.4910 - accuracy: 0.6834 - val_loss: 10.8116 - val_accuracy: 0.3953\n",
      "Epoch 60/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.4464 - accuracy: 0.6899 - val_loss: 10.7721 - val_accuracy: 0.3969\n",
      "Epoch 61/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.4031 - accuracy: 0.6948 - val_loss: 10.7301 - val_accuracy: 0.3964\n",
      "Epoch 62/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.3608 - accuracy: 0.6953 - val_loss: 10.6981 - val_accuracy: 0.3965\n",
      "Epoch 63/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.3157 - accuracy: 0.7036 - val_loss: 10.6570 - val_accuracy: 0.3961\n",
      "Epoch 64/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.2707 - accuracy: 0.7096 - val_loss: 10.6174 - val_accuracy: 0.4027\n",
      "Epoch 65/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.2269 - accuracy: 0.7132 - val_loss: 10.5837 - val_accuracy: 0.4032\n",
      "Epoch 66/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.1835 - accuracy: 0.7175 - val_loss: 10.5456 - val_accuracy: 0.4011\n",
      "Epoch 67/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.1402 - accuracy: 0.7218 - val_loss: 10.5073 - val_accuracy: 0.4015\n",
      "Epoch 68/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.0968 - accuracy: 0.7290 - val_loss: 10.4710 - val_accuracy: 0.4052\n",
      "Epoch 69/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.0537 - accuracy: 0.7314 - val_loss: 10.4334 - val_accuracy: 0.4053\n",
      "Epoch 70/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.0101 - accuracy: 0.7357 - val_loss: 10.3938 - val_accuracy: 0.4061\n",
      "Epoch 71/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.9665 - accuracy: 0.7414 - val_loss: 10.3596 - val_accuracy: 0.4057\n",
      "Epoch 72/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.9230 - accuracy: 0.7488 - val_loss: 10.3196 - val_accuracy: 0.4099\n",
      "Epoch 73/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.8812 - accuracy: 0.7505 - val_loss: 10.2853 - val_accuracy: 0.4009\n",
      "Epoch 74/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.8378 - accuracy: 0.7513 - val_loss: 10.2447 - val_accuracy: 0.4129\n",
      "Epoch 75/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.7941 - accuracy: 0.7565 - val_loss: 10.2105 - val_accuracy: 0.4089\n",
      "Epoch 76/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.7512 - accuracy: 0.7637 - val_loss: 10.1757 - val_accuracy: 0.4049\n",
      "Epoch 77/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.7088 - accuracy: 0.7670 - val_loss: 10.1355 - val_accuracy: 0.4121\n",
      "Epoch 78/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.6657 - accuracy: 0.7705 - val_loss: 10.1025 - val_accuracy: 0.4136\n",
      "Epoch 79/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.6219 - accuracy: 0.7788 - val_loss: 10.0643 - val_accuracy: 0.4181\n",
      "Epoch 80/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.5810 - accuracy: 0.7809 - val_loss: 10.0277 - val_accuracy: 0.4157\n",
      "Epoch 81/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.5383 - accuracy: 0.7846 - val_loss: 9.9921 - val_accuracy: 0.4141\n",
      "Epoch 82/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.4956 - accuracy: 0.7892 - val_loss: 9.9582 - val_accuracy: 0.4195\n",
      "Epoch 83/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.4529 - accuracy: 0.7927 - val_loss: 9.9224 - val_accuracy: 0.4208\n",
      "Epoch 84/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.4115 - accuracy: 0.7965 - val_loss: 9.8887 - val_accuracy: 0.4168\n",
      "Epoch 85/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.3686 - accuracy: 0.8028 - val_loss: 9.8532 - val_accuracy: 0.4223\n",
      "Epoch 86/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.3266 - accuracy: 0.8046 - val_loss: 9.8176 - val_accuracy: 0.4213\n",
      "Epoch 87/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.2831 - accuracy: 0.8103 - val_loss: 9.7796 - val_accuracy: 0.4209\n",
      "Epoch 88/500\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 9.2421 - accuracy: 0.8115 - val_loss: 9.7497 - val_accuracy: 0.4220\n",
      "Epoch 89/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.1999 - accuracy: 0.8183 - val_loss: 9.7139 - val_accuracy: 0.4247\n",
      "Epoch 90/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.1580 - accuracy: 0.8220 - val_loss: 9.6803 - val_accuracy: 0.4224\n",
      "Epoch 91/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.1172 - accuracy: 0.8236 - val_loss: 9.6453 - val_accuracy: 0.4257\n",
      "Epoch 92/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.0738 - accuracy: 0.8299 - val_loss: 9.6076 - val_accuracy: 0.4239\n",
      "Epoch 93/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.0327 - accuracy: 0.8327 - val_loss: 9.5737 - val_accuracy: 0.4271\n",
      "Epoch 94/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.9921 - accuracy: 0.8338 - val_loss: 9.5361 - val_accuracy: 0.4233\n",
      "Epoch 95/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.9494 - accuracy: 0.8421 - val_loss: 9.5068 - val_accuracy: 0.4284\n",
      "Epoch 96/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.9089 - accuracy: 0.8428 - val_loss: 9.4719 - val_accuracy: 0.4265\n",
      "Epoch 97/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.8685 - accuracy: 0.8456 - val_loss: 9.4350 - val_accuracy: 0.4295\n",
      "Epoch 98/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.8269 - accuracy: 0.8499 - val_loss: 9.4007 - val_accuracy: 0.4299\n",
      "Epoch 99/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.7849 - accuracy: 0.8553 - val_loss: 9.3698 - val_accuracy: 0.4285\n",
      "Epoch 100/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.7445 - accuracy: 0.8591 - val_loss: 9.3341 - val_accuracy: 0.4320\n",
      "Epoch 101/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.7043 - accuracy: 0.8608 - val_loss: 9.3048 - val_accuracy: 0.4337\n",
      "Epoch 102/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.6624 - accuracy: 0.8630 - val_loss: 9.2629 - val_accuracy: 0.4339\n",
      "Epoch 103/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.6215 - accuracy: 0.8645 - val_loss: 9.2340 - val_accuracy: 0.4324\n",
      "Epoch 104/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.5827 - accuracy: 0.8676 - val_loss: 9.2005 - val_accuracy: 0.4356\n",
      "Epoch 105/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.5406 - accuracy: 0.8714 - val_loss: 9.1637 - val_accuracy: 0.4347\n",
      "Epoch 106/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.5006 - accuracy: 0.8757 - val_loss: 9.1315 - val_accuracy: 0.4352\n",
      "Epoch 107/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.4594 - accuracy: 0.8794 - val_loss: 9.0986 - val_accuracy: 0.4391\n",
      "Epoch 108/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.4191 - accuracy: 0.8840 - val_loss: 9.0655 - val_accuracy: 0.4385\n",
      "Epoch 109/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.3793 - accuracy: 0.8855 - val_loss: 9.0300 - val_accuracy: 0.4420\n",
      "Epoch 110/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.3387 - accuracy: 0.8886 - val_loss: 9.0034 - val_accuracy: 0.4365\n",
      "Epoch 111/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.2992 - accuracy: 0.8924 - val_loss: 8.9707 - val_accuracy: 0.4387\n",
      "Epoch 112/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.2603 - accuracy: 0.8936 - val_loss: 8.9319 - val_accuracy: 0.4416\n",
      "Epoch 113/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.2214 - accuracy: 0.8957 - val_loss: 8.9023 - val_accuracy: 0.4433\n",
      "Epoch 114/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.1814 - accuracy: 0.8988 - val_loss: 8.8752 - val_accuracy: 0.4413\n",
      "Epoch 115/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.1410 - accuracy: 0.9036 - val_loss: 8.8381 - val_accuracy: 0.4447\n",
      "Epoch 116/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.1016 - accuracy: 0.9073 - val_loss: 8.8103 - val_accuracy: 0.4420\n",
      "Epoch 117/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.0643 - accuracy: 0.9061 - val_loss: 8.7791 - val_accuracy: 0.4420\n",
      "Epoch 118/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.0235 - accuracy: 0.9116 - val_loss: 8.7518 - val_accuracy: 0.4444\n",
      "Epoch 119/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9858 - accuracy: 0.9116 - val_loss: 8.7159 - val_accuracy: 0.4425\n",
      "Epoch 120/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9477 - accuracy: 0.9141 - val_loss: 8.6753 - val_accuracy: 0.4421\n",
      "Epoch 121/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9118 - accuracy: 0.9148 - val_loss: 8.6531 - val_accuracy: 0.4444\n",
      "Epoch 122/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.8699 - accuracy: 0.9192 - val_loss: 8.6198 - val_accuracy: 0.4479\n",
      "Epoch 123/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.8304 - accuracy: 0.9228 - val_loss: 8.5890 - val_accuracy: 0.4467\n",
      "Epoch 124/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.7917 - accuracy: 0.9272 - val_loss: 8.5530 - val_accuracy: 0.4484\n",
      "Epoch 125/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.7545 - accuracy: 0.9278 - val_loss: 8.5278 - val_accuracy: 0.4516\n",
      "Epoch 126/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.7165 - accuracy: 0.9308 - val_loss: 8.4970 - val_accuracy: 0.4556\n",
      "Epoch 127/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.6777 - accuracy: 0.9341 - val_loss: 8.4578 - val_accuracy: 0.4475\n",
      "Epoch 128/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.6407 - accuracy: 0.9340 - val_loss: 8.4272 - val_accuracy: 0.4475\n",
      "Epoch 129/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.6021 - accuracy: 0.9388 - val_loss: 8.4101 - val_accuracy: 0.4539\n",
      "Epoch 130/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.5649 - accuracy: 0.9401 - val_loss: 8.3739 - val_accuracy: 0.4524\n",
      "Epoch 131/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.5270 - accuracy: 0.9411 - val_loss: 8.3394 - val_accuracy: 0.4524\n",
      "Epoch 132/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4907 - accuracy: 0.9418 - val_loss: 8.3091 - val_accuracy: 0.4512\n",
      "Epoch 133/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4537 - accuracy: 0.9453 - val_loss: 8.2829 - val_accuracy: 0.4533\n",
      "Epoch 134/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4165 - accuracy: 0.9459 - val_loss: 8.2541 - val_accuracy: 0.4552\n",
      "Epoch 135/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.3792 - accuracy: 0.9496 - val_loss: 8.2233 - val_accuracy: 0.4541\n",
      "Epoch 136/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.3431 - accuracy: 0.9512 - val_loss: 8.1942 - val_accuracy: 0.4555\n",
      "Epoch 137/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.3085 - accuracy: 0.9499 - val_loss: 8.1589 - val_accuracy: 0.4588\n",
      "Epoch 138/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.2700 - accuracy: 0.9541 - val_loss: 8.1302 - val_accuracy: 0.4552\n",
      "Epoch 139/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.2330 - accuracy: 0.9562 - val_loss: 8.0994 - val_accuracy: 0.4571\n",
      "Epoch 140/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1978 - accuracy: 0.9573 - val_loss: 8.0707 - val_accuracy: 0.4596\n",
      "Epoch 141/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1637 - accuracy: 0.9585 - val_loss: 8.0505 - val_accuracy: 0.4624\n",
      "Epoch 142/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1255 - accuracy: 0.9612 - val_loss: 8.0125 - val_accuracy: 0.4605\n",
      "Epoch 143/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0908 - accuracy: 0.9615 - val_loss: 7.9860 - val_accuracy: 0.4645\n",
      "Epoch 144/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0536 - accuracy: 0.9639 - val_loss: 7.9538 - val_accuracy: 0.4620\n",
      "Epoch 145/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0182 - accuracy: 0.9648 - val_loss: 7.9282 - val_accuracy: 0.4607\n",
      "Epoch 146/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9835 - accuracy: 0.9671 - val_loss: 7.9025 - val_accuracy: 0.4621\n",
      "Epoch 147/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9489 - accuracy: 0.9675 - val_loss: 7.8754 - val_accuracy: 0.4609\n",
      "Epoch 148/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9124 - accuracy: 0.9706 - val_loss: 7.8373 - val_accuracy: 0.4647\n",
      "Epoch 149/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8782 - accuracy: 0.9712 - val_loss: 7.8099 - val_accuracy: 0.4644\n",
      "Epoch 150/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8434 - accuracy: 0.9722 - val_loss: 7.7874 - val_accuracy: 0.4605\n",
      "Epoch 151/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8117 - accuracy: 0.9720 - val_loss: 7.7492 - val_accuracy: 0.4631\n",
      "Epoch 152/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7748 - accuracy: 0.9745 - val_loss: 7.7301 - val_accuracy: 0.4652\n",
      "Epoch 153/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7402 - accuracy: 0.9761 - val_loss: 7.7025 - val_accuracy: 0.4677\n",
      "Epoch 154/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7064 - accuracy: 0.9769 - val_loss: 7.6771 - val_accuracy: 0.4655\n",
      "Epoch 155/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6743 - accuracy: 0.9771 - val_loss: 7.6433 - val_accuracy: 0.4701\n",
      "Epoch 156/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6377 - accuracy: 0.9792 - val_loss: 7.6220 - val_accuracy: 0.4675\n",
      "Epoch 157/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6040 - accuracy: 0.9804 - val_loss: 7.5873 - val_accuracy: 0.4663\n",
      "Epoch 158/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5713 - accuracy: 0.9812 - val_loss: 7.5692 - val_accuracy: 0.4609\n",
      "Epoch 159/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5375 - accuracy: 0.9832 - val_loss: 7.5293 - val_accuracy: 0.4697\n",
      "Epoch 160/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5045 - accuracy: 0.9825 - val_loss: 7.5142 - val_accuracy: 0.4659\n",
      "Epoch 161/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4713 - accuracy: 0.9838 - val_loss: 7.4778 - val_accuracy: 0.4675\n",
      "Epoch 162/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4371 - accuracy: 0.9844 - val_loss: 7.4599 - val_accuracy: 0.4699\n",
      "Epoch 163/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4053 - accuracy: 0.9856 - val_loss: 7.4354 - val_accuracy: 0.4681\n",
      "Epoch 164/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3727 - accuracy: 0.9868 - val_loss: 7.4067 - val_accuracy: 0.4680\n",
      "Epoch 165/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3406 - accuracy: 0.9866 - val_loss: 7.3736 - val_accuracy: 0.4648\n",
      "Epoch 166/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3074 - accuracy: 0.9882 - val_loss: 7.3478 - val_accuracy: 0.4745\n",
      "Epoch 167/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2756 - accuracy: 0.9888 - val_loss: 7.3147 - val_accuracy: 0.4713\n",
      "Epoch 168/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2429 - accuracy: 0.9886 - val_loss: 7.2911 - val_accuracy: 0.4699\n",
      "Epoch 169/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2099 - accuracy: 0.9904 - val_loss: 7.2625 - val_accuracy: 0.4677\n",
      "Epoch 170/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1779 - accuracy: 0.9906 - val_loss: 7.2465 - val_accuracy: 0.4760\n",
      "Epoch 171/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1475 - accuracy: 0.9900 - val_loss: 7.2053 - val_accuracy: 0.4704\n",
      "Epoch 172/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1159 - accuracy: 0.9916 - val_loss: 7.1936 - val_accuracy: 0.4741\n",
      "Epoch 173/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0842 - accuracy: 0.9912 - val_loss: 7.1726 - val_accuracy: 0.4696\n",
      "Epoch 174/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0533 - accuracy: 0.9918 - val_loss: 7.1491 - val_accuracy: 0.4709\n",
      "Epoch 175/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0217 - accuracy: 0.9932 - val_loss: 7.1139 - val_accuracy: 0.4744\n",
      "Epoch 176/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9916 - accuracy: 0.9936 - val_loss: 7.0835 - val_accuracy: 0.4743\n",
      "Epoch 177/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9598 - accuracy: 0.9932 - val_loss: 7.0608 - val_accuracy: 0.4751\n",
      "Epoch 178/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9294 - accuracy: 0.9947 - val_loss: 7.0353 - val_accuracy: 0.4744\n",
      "Epoch 179/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8985 - accuracy: 0.9939 - val_loss: 7.0129 - val_accuracy: 0.4741\n",
      "Epoch 180/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8680 - accuracy: 0.9948 - val_loss: 6.9749 - val_accuracy: 0.4768\n",
      "Epoch 181/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8375 - accuracy: 0.9957 - val_loss: 6.9605 - val_accuracy: 0.4737\n",
      "Epoch 182/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8076 - accuracy: 0.9958 - val_loss: 6.9449 - val_accuracy: 0.4777\n",
      "Epoch 183/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7787 - accuracy: 0.9952 - val_loss: 6.8901 - val_accuracy: 0.4777\n",
      "Epoch 184/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7474 - accuracy: 0.9959 - val_loss: 6.8882 - val_accuracy: 0.4757\n",
      "Epoch 185/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7160 - accuracy: 0.9967 - val_loss: 6.8585 - val_accuracy: 0.4775\n",
      "Epoch 186/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6869 - accuracy: 0.9965 - val_loss: 6.8223 - val_accuracy: 0.4787\n",
      "Epoch 187/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6607 - accuracy: 0.9959 - val_loss: 6.8120 - val_accuracy: 0.4756\n",
      "Epoch 188/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6279 - accuracy: 0.9969 - val_loss: 6.7785 - val_accuracy: 0.4793\n",
      "Epoch 189/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5998 - accuracy: 0.9966 - val_loss: 6.7565 - val_accuracy: 0.4776\n",
      "Epoch 190/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5697 - accuracy: 0.9977 - val_loss: 6.7421 - val_accuracy: 0.4756\n",
      "Epoch 191/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5420 - accuracy: 0.9974 - val_loss: 6.7025 - val_accuracy: 0.4807\n",
      "Epoch 192/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5119 - accuracy: 0.9980 - val_loss: 6.6778 - val_accuracy: 0.4788\n",
      "Epoch 193/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4840 - accuracy: 0.9982 - val_loss: 6.6573 - val_accuracy: 0.4804\n",
      "Epoch 194/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4543 - accuracy: 0.9978 - val_loss: 6.6326 - val_accuracy: 0.4841\n",
      "Epoch 195/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4269 - accuracy: 0.9978 - val_loss: 6.6137 - val_accuracy: 0.4829\n",
      "Epoch 196/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3971 - accuracy: 0.9985 - val_loss: 6.5850 - val_accuracy: 0.4813\n",
      "Epoch 197/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3688 - accuracy: 0.9984 - val_loss: 6.5687 - val_accuracy: 0.4804\n",
      "Epoch 198/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3406 - accuracy: 0.9984 - val_loss: 6.5371 - val_accuracy: 0.4816\n",
      "Epoch 199/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3126 - accuracy: 0.9987 - val_loss: 6.5661 - val_accuracy: 0.4721\n",
      "Epoch 200/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2851 - accuracy: 0.9990 - val_loss: 6.4723 - val_accuracy: 0.4869\n",
      "Epoch 201/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2577 - accuracy: 0.9990 - val_loss: 6.4644 - val_accuracy: 0.4796\n",
      "Epoch 202/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2301 - accuracy: 0.9990 - val_loss: 6.4417 - val_accuracy: 0.4821\n",
      "Epoch 203/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2026 - accuracy: 0.9989 - val_loss: 6.4252 - val_accuracy: 0.4864\n",
      "Epoch 204/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1747 - accuracy: 0.9992 - val_loss: 6.3897 - val_accuracy: 0.4847\n",
      "Epoch 205/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1480 - accuracy: 0.9991 - val_loss: 6.3847 - val_accuracy: 0.4817\n",
      "Epoch 206/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1217 - accuracy: 0.9990 - val_loss: 6.3450 - val_accuracy: 0.4831\n",
      "Epoch 207/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0927 - accuracy: 0.9995 - val_loss: 6.3304 - val_accuracy: 0.4867\n",
      "Epoch 208/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0657 - accuracy: 0.9995 - val_loss: 6.2999 - val_accuracy: 0.4841\n",
      "Epoch 209/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0403 - accuracy: 0.9992 - val_loss: 6.2664 - val_accuracy: 0.4864\n",
      "Epoch 210/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0130 - accuracy: 0.9992 - val_loss: 6.2607 - val_accuracy: 0.4816\n",
      "Epoch 211/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9861 - accuracy: 0.9996 - val_loss: 6.2282 - val_accuracy: 0.4903\n",
      "Epoch 212/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9593 - accuracy: 0.9998 - val_loss: 6.2206 - val_accuracy: 0.4864\n",
      "Epoch 213/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9342 - accuracy: 0.9993 - val_loss: 6.2062 - val_accuracy: 0.4841\n",
      "Epoch 214/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9065 - accuracy: 0.9996 - val_loss: 6.1727 - val_accuracy: 0.4848\n",
      "Epoch 215/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8809 - accuracy: 0.9996 - val_loss: 6.1601 - val_accuracy: 0.4868\n",
      "Epoch 216/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8541 - accuracy: 0.9996 - val_loss: 6.1138 - val_accuracy: 0.4865\n",
      "Epoch 217/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8281 - accuracy: 0.9997 - val_loss: 6.0991 - val_accuracy: 0.4857\n",
      "Epoch 218/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8040 - accuracy: 0.9992 - val_loss: 6.0795 - val_accuracy: 0.4865\n",
      "Epoch 219/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7772 - accuracy: 0.9997 - val_loss: 6.0549 - val_accuracy: 0.4861\n",
      "Epoch 220/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7518 - accuracy: 0.9996 - val_loss: 6.0334 - val_accuracy: 0.4883\n",
      "Epoch 221/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7259 - accuracy: 0.9997 - val_loss: 5.9977 - val_accuracy: 0.4849\n",
      "Epoch 222/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7010 - accuracy: 0.9996 - val_loss: 6.0049 - val_accuracy: 0.4801\n",
      "Epoch 223/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6767 - accuracy: 0.9996 - val_loss: 5.9740 - val_accuracy: 0.4859\n",
      "Epoch 224/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6515 - accuracy: 0.9997 - val_loss: 5.9435 - val_accuracy: 0.4887\n",
      "Epoch 225/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6268 - accuracy: 0.9997 - val_loss: 5.9152 - val_accuracy: 0.4916\n",
      "Epoch 226/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6001 - accuracy: 0.9999 - val_loss: 5.9051 - val_accuracy: 0.4879\n",
      "Epoch 227/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5763 - accuracy: 0.9995 - val_loss: 5.9542 - val_accuracy: 0.4817\n",
      "Epoch 228/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5509 - accuracy: 0.9998 - val_loss: 5.8845 - val_accuracy: 0.4892\n",
      "Epoch 229/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5270 - accuracy: 0.9998 - val_loss: 5.8348 - val_accuracy: 0.4909\n",
      "Epoch 230/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5013 - accuracy: 0.9998 - val_loss: 5.8058 - val_accuracy: 0.4867\n",
      "Epoch 231/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4805 - accuracy: 0.9986 - val_loss: 5.8136 - val_accuracy: 0.4840\n",
      "Epoch 232/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4527 - accuracy: 1.0000 - val_loss: 5.7609 - val_accuracy: 0.4853\n",
      "Epoch 233/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4292 - accuracy: 0.9998 - val_loss: 5.7482 - val_accuracy: 0.4887\n",
      "Epoch 234/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4054 - accuracy: 0.9998 - val_loss: 5.7262 - val_accuracy: 0.4917\n",
      "Epoch 235/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3819 - accuracy: 0.9994 - val_loss: 5.7337 - val_accuracy: 0.4881\n",
      "Epoch 236/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3578 - accuracy: 0.9999 - val_loss: 5.7125 - val_accuracy: 0.4868\n",
      "Epoch 237/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3331 - accuracy: 0.9999 - val_loss: 5.7075 - val_accuracy: 0.4921\n",
      "Epoch 238/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3092 - accuracy: 1.0000 - val_loss: 5.6769 - val_accuracy: 0.4876\n",
      "Epoch 239/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2864 - accuracy: 0.9998 - val_loss: 5.6229 - val_accuracy: 0.4911\n",
      "Epoch 240/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2630 - accuracy: 0.9999 - val_loss: 5.6149 - val_accuracy: 0.4881\n",
      "Epoch 241/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2404 - accuracy: 0.9997 - val_loss: 5.5816 - val_accuracy: 0.4985\n",
      "Epoch 242/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2160 - accuracy: 1.0000 - val_loss: 5.5697 - val_accuracy: 0.4916\n",
      "Epoch 243/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1928 - accuracy: 1.0000 - val_loss: 5.5440 - val_accuracy: 0.4889\n",
      "Epoch 244/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1700 - accuracy: 0.9999 - val_loss: 5.5209 - val_accuracy: 0.4921\n",
      "Epoch 245/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1466 - accuracy: 1.0000 - val_loss: 5.4964 - val_accuracy: 0.4888\n",
      "Epoch 246/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1252 - accuracy: 0.9997 - val_loss: 5.4533 - val_accuracy: 0.4903\n",
      "Epoch 247/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1086 - accuracy: 0.9985 - val_loss: 5.5212 - val_accuracy: 0.4889\n",
      "Epoch 248/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0799 - accuracy: 1.0000 - val_loss: 5.4440 - val_accuracy: 0.4939\n",
      "Epoch 249/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0573 - accuracy: 0.9995 - val_loss: 5.4550 - val_accuracy: 0.4849\n",
      "Epoch 250/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0342 - accuracy: 0.9997 - val_loss: 5.4407 - val_accuracy: 0.4911\n",
      "Epoch 251/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0328 - accuracy: 0.9952 - val_loss: 5.4094 - val_accuracy: 0.4919\n",
      "Epoch 252/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0009 - accuracy: 0.9979 - val_loss: 5.3479 - val_accuracy: 0.4969\n",
      "Epoch 253/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9844 - accuracy: 0.9972 - val_loss: 5.3824 - val_accuracy: 0.4977\n",
      "Epoch 254/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9522 - accuracy: 0.9998 - val_loss: 5.3314 - val_accuracy: 0.4915\n",
      "Epoch 255/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9244 - accuracy: 0.9998 - val_loss: 5.2903 - val_accuracy: 0.4936\n",
      "Epoch 256/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9028 - accuracy: 0.9997 - val_loss: 5.6874 - val_accuracy: 0.4691\n",
      "Epoch 257/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8944 - accuracy: 0.9979 - val_loss: 5.5035 - val_accuracy: 0.4585\n",
      "Epoch 258/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8659 - accuracy: 0.9991 - val_loss: 5.2299 - val_accuracy: 0.4967\n",
      "Epoch 259/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8380 - accuracy: 0.9999 - val_loss: 5.2184 - val_accuracy: 0.4913\n",
      "Epoch 260/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8168 - accuracy: 0.9998 - val_loss: 5.1998 - val_accuracy: 0.4937\n",
      "Epoch 261/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7973 - accuracy: 0.9994 - val_loss: 5.1720 - val_accuracy: 0.4996\n",
      "Epoch 262/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7809 - accuracy: 0.9986 - val_loss: 5.9737 - val_accuracy: 0.4059\n",
      "Epoch 263/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7883 - accuracy: 0.9927 - val_loss: 5.2032 - val_accuracy: 0.4917\n",
      "Epoch 264/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7324 - accuracy: 0.9999 - val_loss: 5.1170 - val_accuracy: 0.5003\n",
      "Epoch 265/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7096 - accuracy: 1.0000 - val_loss: 5.0907 - val_accuracy: 0.4999\n",
      "Epoch 266/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6904 - accuracy: 0.9999 - val_loss: 5.0742 - val_accuracy: 0.4967\n",
      "Epoch 267/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6682 - accuracy: 0.9999 - val_loss: 5.1528 - val_accuracy: 0.4944\n",
      "Epoch 268/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6481 - accuracy: 0.9999 - val_loss: 5.0393 - val_accuracy: 0.5036\n",
      "Epoch 269/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6280 - accuracy: 0.9999 - val_loss: 5.0543 - val_accuracy: 0.4991\n",
      "Epoch 270/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6242 - accuracy: 0.9972 - val_loss: 5.1433 - val_accuracy: 0.4689\n",
      "Epoch 271/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6340 - accuracy: 0.9899 - val_loss: 7.4728 - val_accuracy: 0.3581\n",
      "Epoch 272/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6529 - accuracy: 0.9794 - val_loss: 7.0421 - val_accuracy: 0.4003\n",
      "Epoch 273/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6709 - accuracy: 0.9660 - val_loss: 5.9093 - val_accuracy: 0.3899\n",
      "Epoch 274/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6679 - accuracy: 0.9592 - val_loss: 5.7711 - val_accuracy: 0.4023\n",
      "Epoch 275/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5904 - accuracy: 0.9846 - val_loss: 5.0937 - val_accuracy: 0.4775\n",
      "Epoch 276/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5172 - accuracy: 0.9988 - val_loss: 4.9848 - val_accuracy: 0.5007\n",
      "Epoch 277/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4960 - accuracy: 0.9986 - val_loss: 4.9051 - val_accuracy: 0.4997\n",
      "Epoch 278/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4754 - accuracy: 0.9983 - val_loss: 4.8591 - val_accuracy: 0.5115\n",
      "Epoch 279/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4394 - accuracy: 0.9997 - val_loss: 4.8773 - val_accuracy: 0.5041\n",
      "Epoch 280/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4187 - accuracy: 0.9997 - val_loss: 4.8323 - val_accuracy: 0.5060\n",
      "Epoch 281/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3974 - accuracy: 0.9998 - val_loss: 5.3302 - val_accuracy: 0.4408\n",
      "Epoch 282/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3976 - accuracy: 0.9951 - val_loss: 4.9286 - val_accuracy: 0.4784\n",
      "Epoch 283/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3662 - accuracy: 0.9985 - val_loss: 4.7826 - val_accuracy: 0.4955\n",
      "Epoch 284/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3396 - accuracy: 0.9997 - val_loss: 4.7197 - val_accuracy: 0.5087\n",
      "Epoch 285/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3192 - accuracy: 1.0000 - val_loss: 4.7163 - val_accuracy: 0.5068\n",
      "Epoch 286/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2982 - accuracy: 1.0000 - val_loss: 4.7111 - val_accuracy: 0.5108\n",
      "Epoch 287/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2820 - accuracy: 0.9995 - val_loss: 4.7647 - val_accuracy: 0.5016\n",
      "Epoch 288/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2612 - accuracy: 0.9998 - val_loss: 4.6676 - val_accuracy: 0.5052\n",
      "Epoch 289/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2914 - accuracy: 0.9876 - val_loss: 7.0134 - val_accuracy: 0.3723\n",
      "Epoch 290/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4681 - accuracy: 0.9102 - val_loss: 6.1793 - val_accuracy: 0.3781\n",
      "Epoch 291/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4658 - accuracy: 0.9081 - val_loss: 5.7006 - val_accuracy: 0.3761\n",
      "Epoch 292/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3878 - accuracy: 0.9406 - val_loss: 5.9798 - val_accuracy: 0.4037\n",
      "Epoch 293/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3156 - accuracy: 0.9684 - val_loss: 5.0645 - val_accuracy: 0.4423\n",
      "Epoch 294/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2587 - accuracy: 0.9831 - val_loss: 5.2595 - val_accuracy: 0.4315\n",
      "Epoch 295/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2090 - accuracy: 0.9929 - val_loss: 4.6643 - val_accuracy: 0.4783\n",
      "Epoch 296/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1775 - accuracy: 0.9952 - val_loss: 4.8958 - val_accuracy: 0.4501\n",
      "Epoch 297/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1484 - accuracy: 0.9972 - val_loss: 4.5006 - val_accuracy: 0.5061\n",
      "Epoch 298/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1045 - accuracy: 0.9996 - val_loss: 4.4716 - val_accuracy: 0.5083\n",
      "Epoch 299/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0773 - accuracy: 1.0000 - val_loss: 4.4494 - val_accuracy: 0.5140\n",
      "Epoch 300/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0562 - accuracy: 1.0000 - val_loss: 4.4288 - val_accuracy: 0.5097\n",
      "Epoch 301/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0356 - accuracy: 1.0000 - val_loss: 4.3591 - val_accuracy: 0.5204\n",
      "Epoch 302/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0180 - accuracy: 0.9999 - val_loss: 4.4370 - val_accuracy: 0.5219\n",
      "Epoch 303/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9994 - accuracy: 1.0000 - val_loss: 4.5424 - val_accuracy: 0.5113\n",
      "Epoch 304/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9820 - accuracy: 0.9997 - val_loss: 4.3764 - val_accuracy: 0.5172\n",
      "Epoch 305/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9677 - accuracy: 0.9994 - val_loss: 5.1673 - val_accuracy: 0.4325\n",
      "Epoch 306/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0254 - accuracy: 0.9757 - val_loss: 7.6664 - val_accuracy: 0.3541\n",
      "Epoch 307/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0978 - accuracy: 0.9500 - val_loss: 7.7087 - val_accuracy: 0.3437\n",
      "Epoch 308/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0088 - accuracy: 0.9809 - val_loss: 4.6474 - val_accuracy: 0.4619\n",
      "Epoch 309/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9636 - accuracy: 0.9901 - val_loss: 4.6668 - val_accuracy: 0.4515\n",
      "Epoch 310/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9357 - accuracy: 0.9942 - val_loss: 4.4329 - val_accuracy: 0.4857\n",
      "Epoch 311/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8943 - accuracy: 0.9987 - val_loss: 4.3221 - val_accuracy: 0.5131\n",
      "Epoch 312/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8595 - accuracy: 0.9996 - val_loss: 4.3799 - val_accuracy: 0.5160\n",
      "Epoch 313/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8338 - accuracy: 1.0000 - val_loss: 4.2985 - val_accuracy: 0.5267\n",
      "Epoch 314/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8162 - accuracy: 1.0000 - val_loss: 4.2264 - val_accuracy: 0.5213\n",
      "Epoch 315/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7965 - accuracy: 1.0000 - val_loss: 4.1484 - val_accuracy: 0.5248\n",
      "Epoch 316/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7791 - accuracy: 0.9999 - val_loss: 4.2051 - val_accuracy: 0.5289\n",
      "Epoch 317/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7615 - accuracy: 0.9999 - val_loss: 4.1982 - val_accuracy: 0.5304\n",
      "Epoch 318/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7457 - accuracy: 0.9999 - val_loss: 4.1247 - val_accuracy: 0.5225\n",
      "Epoch 319/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7293 - accuracy: 0.9999 - val_loss: 4.1854 - val_accuracy: 0.5208\n",
      "Epoch 320/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7235 - accuracy: 0.9983 - val_loss: 5.0859 - val_accuracy: 0.4113\n",
      "Epoch 321/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9171 - accuracy: 0.9246 - val_loss: 5.7799 - val_accuracy: 0.3915\n",
      "Epoch 322/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9128 - accuracy: 0.9316 - val_loss: 4.8182 - val_accuracy: 0.4021\n",
      "Epoch 323/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8417 - accuracy: 0.9626 - val_loss: 4.8924 - val_accuracy: 0.4648\n",
      "Epoch 324/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7629 - accuracy: 0.9903 - val_loss: 4.5999 - val_accuracy: 0.4633\n",
      "Epoch 325/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7119 - accuracy: 0.9959 - val_loss: 4.4358 - val_accuracy: 0.4788\n",
      "Epoch 326/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6815 - accuracy: 0.9977 - val_loss: 4.4787 - val_accuracy: 0.4639\n",
      "Epoch 327/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6505 - accuracy: 0.9989 - val_loss: 4.8000 - val_accuracy: 0.4349\n",
      "Epoch 328/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6250 - accuracy: 0.9995 - val_loss: 4.2021 - val_accuracy: 0.4871\n",
      "Epoch 329/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5967 - accuracy: 0.9999 - val_loss: 3.9772 - val_accuracy: 0.5211\n",
      "Epoch 330/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5790 - accuracy: 0.9996 - val_loss: 3.8905 - val_accuracy: 0.5361\n",
      "Epoch 331/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5594 - accuracy: 0.9999 - val_loss: 4.8406 - val_accuracy: 0.4213\n",
      "Epoch 332/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5470 - accuracy: 1.0000 - val_loss: 3.9126 - val_accuracy: 0.5335\n",
      "Epoch 333/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5336 - accuracy: 0.9992 - val_loss: 4.1808 - val_accuracy: 0.4969\n",
      "Epoch 334/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5746 - accuracy: 0.9857 - val_loss: 7.3575 - val_accuracy: 0.3509\n",
      "Epoch 335/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6876 - accuracy: 0.9401 - val_loss: 6.5326 - val_accuracy: 0.3652\n",
      "Epoch 336/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7015 - accuracy: 0.9392 - val_loss: 6.9727 - val_accuracy: 0.3497\n",
      "Epoch 337/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6099 - accuracy: 0.9791 - val_loss: 4.4605 - val_accuracy: 0.4733\n",
      "Epoch 338/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5421 - accuracy: 0.9952 - val_loss: 6.2740 - val_accuracy: 0.3985\n",
      "Epoch 339/500\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.5145 - accuracy: 0.9964 - val_loss: 4.0664 - val_accuracy: 0.4933\n",
      "Epoch 340/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4802 - accuracy: 0.9984 - val_loss: 3.9817 - val_accuracy: 0.4917\n",
      "Epoch 341/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4526 - accuracy: 0.9995 - val_loss: 3.8919 - val_accuracy: 0.5072\n",
      "Epoch 342/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4280 - accuracy: 0.9996 - val_loss: 4.0070 - val_accuracy: 0.5041\n",
      "Epoch 343/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4064 - accuracy: 0.9998 - val_loss: 3.8845 - val_accuracy: 0.5065\n",
      "Epoch 344/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3918 - accuracy: 0.9997 - val_loss: 4.0490 - val_accuracy: 0.4785\n",
      "Epoch 345/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3720 - accuracy: 0.9997 - val_loss: 3.8573 - val_accuracy: 0.5179\n",
      "Epoch 346/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3568 - accuracy: 0.9999 - val_loss: 3.7842 - val_accuracy: 0.5160\n",
      "Epoch 347/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3402 - accuracy: 0.9996 - val_loss: 3.9173 - val_accuracy: 0.5184\n",
      "Epoch 348/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3303 - accuracy: 0.9994 - val_loss: 3.7757 - val_accuracy: 0.5187\n",
      "Epoch 349/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3103 - accuracy: 1.0000 - val_loss: 3.8360 - val_accuracy: 0.5184\n",
      "Epoch 350/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2973 - accuracy: 0.9999 - val_loss: 3.7982 - val_accuracy: 0.5129\n",
      "Epoch 351/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4203 - accuracy: 0.9585 - val_loss: 4.9645 - val_accuracy: 0.4021\n",
      "Epoch 352/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4319 - accuracy: 0.9629 - val_loss: 6.2404 - val_accuracy: 0.3735\n",
      "Epoch 353/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3907 - accuracy: 0.9792 - val_loss: 5.1102 - val_accuracy: 0.3864\n",
      "Epoch 354/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3230 - accuracy: 0.9962 - val_loss: 4.0933 - val_accuracy: 0.4488\n",
      "Epoch 355/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2834 - accuracy: 0.9988 - val_loss: 4.3759 - val_accuracy: 0.4788\n",
      "Epoch 356/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2574 - accuracy: 0.9993 - val_loss: 3.7843 - val_accuracy: 0.5044\n",
      "Epoch 357/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2441 - accuracy: 0.9985 - val_loss: 4.5628 - val_accuracy: 0.4195\n",
      "Epoch 358/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2282 - accuracy: 0.9986 - val_loss: 3.9689 - val_accuracy: 0.4587\n",
      "Epoch 359/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2321 - accuracy: 0.9968 - val_loss: 4.6674 - val_accuracy: 0.4173\n",
      "Epoch 360/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2289 - accuracy: 0.9951 - val_loss: 4.5938 - val_accuracy: 0.4264\n",
      "Epoch 361/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2109 - accuracy: 0.9964 - val_loss: 4.4059 - val_accuracy: 0.4179\n",
      "Epoch 362/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1853 - accuracy: 0.9987 - val_loss: 3.9000 - val_accuracy: 0.4703\n",
      "Epoch 363/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1651 - accuracy: 0.9988 - val_loss: 4.2476 - val_accuracy: 0.4459\n",
      "Epoch 364/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1556 - accuracy: 0.9982 - val_loss: 4.5035 - val_accuracy: 0.4244\n",
      "Epoch 365/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1665 - accuracy: 0.9960 - val_loss: 4.7662 - val_accuracy: 0.4609\n",
      "Epoch 366/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1358 - accuracy: 0.9987 - val_loss: 3.8516 - val_accuracy: 0.4928\n",
      "Epoch 367/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1163 - accuracy: 0.9991 - val_loss: 3.8612 - val_accuracy: 0.4741\n",
      "Epoch 368/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0949 - accuracy: 0.9998 - val_loss: 3.5341 - val_accuracy: 0.5049\n",
      "Epoch 369/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0759 - accuracy: 1.0000 - val_loss: 3.6392 - val_accuracy: 0.5031\n",
      "Epoch 370/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0652 - accuracy: 0.9998 - val_loss: 3.5398 - val_accuracy: 0.5139\n",
      "Epoch 371/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0514 - accuracy: 0.9998 - val_loss: 3.4399 - val_accuracy: 0.5388\n",
      "Epoch 372/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0406 - accuracy: 0.9998 - val_loss: 3.5472 - val_accuracy: 0.5045\n",
      "Epoch 373/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1398 - accuracy: 0.9702 - val_loss: 5.4717 - val_accuracy: 0.3896\n",
      "Epoch 374/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1539 - accuracy: 0.9734 - val_loss: 7.0943 - val_accuracy: 0.3461\n",
      "Epoch 375/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0889 - accuracy: 0.9944 - val_loss: 5.8138 - val_accuracy: 0.3692\n",
      "Epoch 376/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0440 - accuracy: 0.9992 - val_loss: 4.9165 - val_accuracy: 0.3784\n",
      "Epoch 377/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0169 - accuracy: 0.9997 - val_loss: 3.5014 - val_accuracy: 0.4956\n",
      "Epoch 378/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9989 - accuracy: 0.9999 - val_loss: 3.4819 - val_accuracy: 0.5112\n",
      "Epoch 379/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9800 - accuracy: 0.9996 - val_loss: 3.8838 - val_accuracy: 0.4463\n",
      "Epoch 380/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9695 - accuracy: 0.9997 - val_loss: 4.2515 - val_accuracy: 0.4425\n",
      "Epoch 381/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9513 - accuracy: 1.0000 - val_loss: 4.2172 - val_accuracy: 0.4443\n",
      "Epoch 382/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9503 - accuracy: 0.9985 - val_loss: 4.6020 - val_accuracy: 0.4053\n",
      "Epoch 383/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9781 - accuracy: 0.9965 - val_loss: 4.1008 - val_accuracy: 0.4419\n",
      "Epoch 384/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9558 - accuracy: 0.9983 - val_loss: 5.0704 - val_accuracy: 0.4153\n",
      "Epoch 385/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9302 - accuracy: 0.9996 - val_loss: 3.2661 - val_accuracy: 0.5209\n",
      "Epoch 386/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9078 - accuracy: 0.9998 - val_loss: 4.2962 - val_accuracy: 0.4308\n",
      "Epoch 387/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9005 - accuracy: 0.9996 - val_loss: 3.7471 - val_accuracy: 0.4649\n",
      "Epoch 388/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8914 - accuracy: 0.9998 - val_loss: 3.9534 - val_accuracy: 0.4683\n",
      "Epoch 389/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8976 - accuracy: 0.9970 - val_loss: 9.6178 - val_accuracy: 0.3435\n",
      "Epoch 390/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9363 - accuracy: 0.9905 - val_loss: 5.8963 - val_accuracy: 0.3712\n",
      "Epoch 391/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9079 - accuracy: 0.9972 - val_loss: 4.1491 - val_accuracy: 0.4116\n",
      "Epoch 392/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8733 - accuracy: 0.9998 - val_loss: 4.2698 - val_accuracy: 0.4333\n",
      "Epoch 393/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8486 - accuracy: 0.9999 - val_loss: 4.3712 - val_accuracy: 0.4029\n",
      "Epoch 394/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8366 - accuracy: 0.9998 - val_loss: 3.4051 - val_accuracy: 0.4973\n",
      "Epoch 395/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8263 - accuracy: 0.9995 - val_loss: 3.4791 - val_accuracy: 0.4653\n",
      "Epoch 396/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8246 - accuracy: 0.9991 - val_loss: 3.8313 - val_accuracy: 0.4384\n",
      "Epoch 397/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8185 - accuracy: 0.9992 - val_loss: 3.8462 - val_accuracy: 0.4525\n",
      "Epoch 398/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8011 - accuracy: 0.9998 - val_loss: 3.5400 - val_accuracy: 0.4696\n",
      "Epoch 399/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7918 - accuracy: 0.9997 - val_loss: 4.3030 - val_accuracy: 0.4192\n",
      "Epoch 400/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7828 - accuracy: 0.9998 - val_loss: 5.5304 - val_accuracy: 0.3741\n",
      "Epoch 401/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7704 - accuracy: 0.9997 - val_loss: 3.8509 - val_accuracy: 0.4620\n",
      "Epoch 402/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7572 - accuracy: 0.9999 - val_loss: 3.6242 - val_accuracy: 0.4511\n",
      "Epoch 403/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7553 - accuracy: 0.9996 - val_loss: 9.7878 - val_accuracy: 0.3367\n",
      "Epoch 404/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7663 - accuracy: 0.9983 - val_loss: 3.6553 - val_accuracy: 0.4392\n",
      "Epoch 405/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7572 - accuracy: 0.9988 - val_loss: 3.9340 - val_accuracy: 0.4491\n",
      "Epoch 406/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7463 - accuracy: 0.9995 - val_loss: 4.0847 - val_accuracy: 0.4292\n",
      "Epoch 407/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7205 - accuracy: 1.0000 - val_loss: 3.2473 - val_accuracy: 0.5075\n",
      "Epoch 408/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7061 - accuracy: 0.9999 - val_loss: 4.3088 - val_accuracy: 0.4337\n",
      "Epoch 409/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6968 - accuracy: 1.0000 - val_loss: 3.9077 - val_accuracy: 0.4443\n",
      "Epoch 410/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6920 - accuracy: 0.9998 - val_loss: 3.4957 - val_accuracy: 0.4637\n",
      "Epoch 411/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6827 - accuracy: 1.0000 - val_loss: 3.4988 - val_accuracy: 0.4543\n",
      "Epoch 412/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6734 - accuracy: 0.9999 - val_loss: 4.0800 - val_accuracy: 0.4451\n",
      "Epoch 413/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7241 - accuracy: 0.9843 - val_loss: 7.3537 - val_accuracy: 0.3431\n",
      "Epoch 414/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0095 - accuracy: 0.8882 - val_loss: 7.3232 - val_accuracy: 0.3425\n",
      "Epoch 415/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9785 - accuracy: 0.9204 - val_loss: 7.0272 - val_accuracy: 0.3464\n",
      "Epoch 416/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8220 - accuracy: 0.9861 - val_loss: 3.3844 - val_accuracy: 0.4932\n",
      "Epoch 417/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7514 - accuracy: 0.9997 - val_loss: 3.1339 - val_accuracy: 0.5372\n",
      "Epoch 418/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7173 - accuracy: 1.0000 - val_loss: 3.0191 - val_accuracy: 0.5567\n",
      "Epoch 419/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6935 - accuracy: 1.0000 - val_loss: 2.9037 - val_accuracy: 0.5635\n",
      "Epoch 420/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6736 - accuracy: 1.0000 - val_loss: 3.0364 - val_accuracy: 0.5307\n",
      "Epoch 421/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6573 - accuracy: 1.0000 - val_loss: 2.9946 - val_accuracy: 0.5565\n",
      "Epoch 422/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6428 - accuracy: 1.0000 - val_loss: 3.0932 - val_accuracy: 0.5359\n",
      "Epoch 423/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6314 - accuracy: 0.9999 - val_loss: 7.1229 - val_accuracy: 0.3475\n",
      "Epoch 424/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6202 - accuracy: 0.9999 - val_loss: 3.3567 - val_accuracy: 0.4825\n",
      "Epoch 425/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6076 - accuracy: 0.9999 - val_loss: 2.9636 - val_accuracy: 0.5369\n",
      "Epoch 426/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5952 - accuracy: 1.0000 - val_loss: 3.3808 - val_accuracy: 0.4948\n",
      "Epoch 427/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5854 - accuracy: 1.0000 - val_loss: 3.0799 - val_accuracy: 0.5196\n",
      "Epoch 428/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5805 - accuracy: 0.9999 - val_loss: 3.3099 - val_accuracy: 0.4925\n",
      "Epoch 429/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5826 - accuracy: 0.9995 - val_loss: 3.8080 - val_accuracy: 0.4491\n",
      "Epoch 430/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5740 - accuracy: 0.9998 - val_loss: 4.8247 - val_accuracy: 0.4056\n",
      "Epoch 431/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5648 - accuracy: 0.9999 - val_loss: 3.1046 - val_accuracy: 0.5133\n",
      "Epoch 432/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5478 - accuracy: 1.0000 - val_loss: 3.1576 - val_accuracy: 0.5063\n",
      "Epoch 433/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5362 - accuracy: 1.0000 - val_loss: 3.3160 - val_accuracy: 0.4895\n",
      "Epoch 434/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5239 - accuracy: 1.0000 - val_loss: 2.9739 - val_accuracy: 0.5392\n",
      "Epoch 435/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5148 - accuracy: 1.0000 - val_loss: 3.3020 - val_accuracy: 0.4681\n",
      "Epoch 436/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5097 - accuracy: 0.9999 - val_loss: 6.9160 - val_accuracy: 0.3449\n",
      "Epoch 437/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5128 - accuracy: 0.9999 - val_loss: 3.5678 - val_accuracy: 0.4344\n",
      "Epoch 438/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5145 - accuracy: 0.9992 - val_loss: 3.6294 - val_accuracy: 0.4516\n",
      "Epoch 439/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5469 - accuracy: 0.9913 - val_loss: 14.0434 - val_accuracy: 0.3356\n",
      "Epoch 440/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0421 - accuracy: 0.8240 - val_loss: 12.2431 - val_accuracy: 0.3337\n",
      "Epoch 441/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8350 - accuracy: 0.9290 - val_loss: 3.7324 - val_accuracy: 0.4527\n",
      "Epoch 442/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6802 - accuracy: 0.9911 - val_loss: 3.0321 - val_accuracy: 0.5591\n",
      "Epoch 443/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6196 - accuracy: 0.9998 - val_loss: 2.7166 - val_accuracy: 0.6015\n",
      "Epoch 444/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5845 - accuracy: 1.0000 - val_loss: 2.6731 - val_accuracy: 0.6029\n",
      "Epoch 445/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5583 - accuracy: 1.0000 - val_loss: 2.6867 - val_accuracy: 0.6044\n",
      "Epoch 446/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5353 - accuracy: 1.0000 - val_loss: 2.6887 - val_accuracy: 0.5987\n",
      "Epoch 447/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5155 - accuracy: 1.0000 - val_loss: 2.6354 - val_accuracy: 0.5971\n",
      "Epoch 448/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4977 - accuracy: 1.0000 - val_loss: 2.6912 - val_accuracy: 0.5945\n",
      "Epoch 449/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4825 - accuracy: 1.0000 - val_loss: 2.8166 - val_accuracy: 0.5533\n",
      "Epoch 450/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4688 - accuracy: 1.0000 - val_loss: 2.8047 - val_accuracy: 0.5625\n",
      "Epoch 451/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4564 - accuracy: 1.0000 - val_loss: 2.7171 - val_accuracy: 0.5768\n",
      "Epoch 452/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4466 - accuracy: 1.0000 - val_loss: 3.0842 - val_accuracy: 0.4980\n",
      "Epoch 453/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4382 - accuracy: 1.0000 - val_loss: 2.8179 - val_accuracy: 0.5495\n",
      "Epoch 454/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4287 - accuracy: 1.0000 - val_loss: 2.9472 - val_accuracy: 0.5232\n",
      "Epoch 455/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4218 - accuracy: 0.9999 - val_loss: 3.4763 - val_accuracy: 0.4484\n",
      "Epoch 456/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4164 - accuracy: 1.0000 - val_loss: 2.8686 - val_accuracy: 0.5325\n",
      "Epoch 457/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4065 - accuracy: 1.0000 - val_loss: 3.1694 - val_accuracy: 0.4861\n",
      "Epoch 458/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4029 - accuracy: 1.0000 - val_loss: 3.8561 - val_accuracy: 0.4317\n",
      "Epoch 459/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3984 - accuracy: 0.9999 - val_loss: 3.7160 - val_accuracy: 0.4432\n",
      "Epoch 460/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3906 - accuracy: 1.0000 - val_loss: 3.1413 - val_accuracy: 0.5101\n",
      "Epoch 461/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3803 - accuracy: 1.0000 - val_loss: 2.9805 - val_accuracy: 0.5273\n",
      "Epoch 462/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3724 - accuracy: 1.0000 - val_loss: 5.6050 - val_accuracy: 0.3857\n",
      "Epoch 463/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1646 - accuracy: 0.7515 - val_loss: 9.1161 - val_accuracy: 0.3481\n",
      "Epoch 464/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8697 - accuracy: 0.8845 - val_loss: 5.4859 - val_accuracy: 0.3751\n",
      "Epoch 465/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6403 - accuracy: 0.9830 - val_loss: 2.7584 - val_accuracy: 0.5899\n",
      "Epoch 466/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5624 - accuracy: 0.9997 - val_loss: 2.6445 - val_accuracy: 0.5951\n",
      "Epoch 467/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5268 - accuracy: 1.0000 - val_loss: 2.5260 - val_accuracy: 0.6228\n",
      "Epoch 468/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4979 - accuracy: 1.0000 - val_loss: 2.5587 - val_accuracy: 0.6156\n",
      "Epoch 469/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4740 - accuracy: 1.0000 - val_loss: 2.5000 - val_accuracy: 0.6143\n",
      "Epoch 470/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4531 - accuracy: 1.0000 - val_loss: 2.5297 - val_accuracy: 0.6123\n",
      "Epoch 471/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4344 - accuracy: 1.0000 - val_loss: 2.5856 - val_accuracy: 0.5925\n",
      "Epoch 472/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4176 - accuracy: 1.0000 - val_loss: 2.5205 - val_accuracy: 0.6105\n",
      "Epoch 473/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4025 - accuracy: 1.0000 - val_loss: 2.4102 - val_accuracy: 0.6184\n",
      "Epoch 474/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3891 - accuracy: 1.0000 - val_loss: 2.5010 - val_accuracy: 0.6015\n",
      "Epoch 475/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3764 - accuracy: 1.0000 - val_loss: 2.4396 - val_accuracy: 0.6147\n",
      "Epoch 476/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3657 - accuracy: 1.0000 - val_loss: 2.4486 - val_accuracy: 0.6087\n",
      "Epoch 477/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3550 - accuracy: 1.0000 - val_loss: 2.5174 - val_accuracy: 0.5880\n",
      "Epoch 478/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3466 - accuracy: 1.0000 - val_loss: 2.8357 - val_accuracy: 0.5303\n",
      "Epoch 479/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3422 - accuracy: 1.0000 - val_loss: 3.0561 - val_accuracy: 0.5105\n",
      "Epoch 480/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3375 - accuracy: 0.9996 - val_loss: 3.5481 - val_accuracy: 0.4432\n",
      "Epoch 481/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7211 - accuracy: 0.8714 - val_loss: 20.7651 - val_accuracy: 0.3380\n",
      "Epoch 482/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8529 - accuracy: 0.8531 - val_loss: 4.1785 - val_accuracy: 0.4171\n",
      "Epoch 483/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5678 - accuracy: 0.9798 - val_loss: 3.1898 - val_accuracy: 0.5223\n",
      "Epoch 484/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4897 - accuracy: 0.9993 - val_loss: 2.5526 - val_accuracy: 0.6092\n",
      "Epoch 485/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4528 - accuracy: 1.0000 - val_loss: 2.4528 - val_accuracy: 0.6280\n",
      "Epoch 486/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4276 - accuracy: 1.0000 - val_loss: 2.5446 - val_accuracy: 0.6173\n",
      "Epoch 487/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4058 - accuracy: 1.0000 - val_loss: 2.5396 - val_accuracy: 0.6125\n",
      "Epoch 488/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3863 - accuracy: 1.0000 - val_loss: 2.7858 - val_accuracy: 0.5781\n",
      "Epoch 489/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3697 - accuracy: 1.0000 - val_loss: 2.6333 - val_accuracy: 0.5693\n",
      "Epoch 490/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3545 - accuracy: 1.0000 - val_loss: 2.4976 - val_accuracy: 0.6039\n",
      "Epoch 491/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3402 - accuracy: 1.0000 - val_loss: 2.7934 - val_accuracy: 0.5633\n",
      "Epoch 492/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3282 - accuracy: 1.0000 - val_loss: 2.5470 - val_accuracy: 0.5839\n",
      "Epoch 493/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3179 - accuracy: 1.0000 - val_loss: 2.8211 - val_accuracy: 0.5511\n",
      "Epoch 494/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3119 - accuracy: 0.9998 - val_loss: 4.8321 - val_accuracy: 0.4295\n",
      "Epoch 495/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3310 - accuracy: 0.9977 - val_loss: 13.4866 - val_accuracy: 0.3332\n",
      "Epoch 496/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7911 - accuracy: 0.8447 - val_loss: 9.5035 - val_accuracy: 0.3584\n",
      "Epoch 497/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7073 - accuracy: 0.9070 - val_loss: 4.3413 - val_accuracy: 0.3907\n",
      "Epoch 498/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5270 - accuracy: 0.9869 - val_loss: 3.8877 - val_accuracy: 0.4369\n",
      "Epoch 499/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4616 - accuracy: 0.9995 - val_loss: 2.5271 - val_accuracy: 0.6017\n",
      "Epoch 500/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4236 - accuracy: 1.0000 - val_loss: 2.5794 - val_accuracy: 0.5816\n",
      "Time: 180.5962450504303\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Traits_Model_100disc.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#100 Discrete\n",
    "################################################################################################################################################\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test  = train_test_split(y,X,traits_disc,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = disc_subset(ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test)\n",
    "\n",
    "model.save(filepath='./Trained_Models/Trained_Traits_Model_100disc.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZfvCxXABC5SX",
    "outputId": "5508eb70-1fbe-4a27-e25f-3b19d3b3333b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 50, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 48, 250)      45000       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 48, 250)     1000        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 46, 250)      187500      ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 46, 250)     1000        ['conv1d_4[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 44, 250)      187500      ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 44, 250)     1000        ['conv1d_5[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 14, 250)     0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 3500)         0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense_12_input (InputLayer)    [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 125)          437625      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 150)          450000      ['dense_12_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 125)          0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 150)         600         ['dense_12[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 125)          15750       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 150)          22500       ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 125)          0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 150)         600         ['dense_13[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 50)           6300        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 50)           7550        ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 50)           0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_1 (LinearW)           (None, 50)           2           ['dense_14[0][0]',               \n",
      "                                                                  'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 50)           2550        ['linear_w_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 3)            153         ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,366,630\n",
      "Trainable params: 1,364,530\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 3s 15ms/step - loss: 13.2188 - accuracy: 0.3432 - val_loss: 13.1279 - val_accuracy: 0.3363\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 13.1188 - accuracy: 0.3672 - val_loss: 13.0577 - val_accuracy: 0.3713\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 13.0519 - accuracy: 0.3824 - val_loss: 12.9980 - val_accuracy: 0.4052\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.9857 - accuracy: 0.4065 - val_loss: 12.9326 - val_accuracy: 0.4452\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.9277 - accuracy: 0.4173 - val_loss: 12.8607 - val_accuracy: 0.4901\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.8573 - accuracy: 0.4491 - val_loss: 12.7870 - val_accuracy: 0.5231\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.7936 - accuracy: 0.4661 - val_loss: 12.7077 - val_accuracy: 0.5555\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.7226 - accuracy: 0.4880 - val_loss: 12.6254 - val_accuracy: 0.5829\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.6515 - accuracy: 0.5146 - val_loss: 12.5425 - val_accuracy: 0.6120\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.5805 - accuracy: 0.5340 - val_loss: 12.4601 - val_accuracy: 0.6285\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.5120 - accuracy: 0.5508 - val_loss: 12.3806 - val_accuracy: 0.6395\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.4418 - accuracy: 0.5723 - val_loss: 12.3082 - val_accuracy: 0.6444\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.3730 - accuracy: 0.5892 - val_loss: 12.2366 - val_accuracy: 0.6583\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.2990 - accuracy: 0.6012 - val_loss: 12.1686 - val_accuracy: 0.6679\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.2430 - accuracy: 0.6114 - val_loss: 12.1026 - val_accuracy: 0.6780\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.1793 - accuracy: 0.6263 - val_loss: 12.0382 - val_accuracy: 0.6872\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.1119 - accuracy: 0.6429 - val_loss: 11.9737 - val_accuracy: 0.7017\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.0495 - accuracy: 0.6521 - val_loss: 11.9088 - val_accuracy: 0.7187\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.9943 - accuracy: 0.6587 - val_loss: 11.8454 - val_accuracy: 0.7335\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.9256 - accuracy: 0.6737 - val_loss: 11.7836 - val_accuracy: 0.7429\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.8664 - accuracy: 0.6821 - val_loss: 11.7182 - val_accuracy: 0.7576\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.8068 - accuracy: 0.6899 - val_loss: 11.6545 - val_accuracy: 0.7696\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.7430 - accuracy: 0.7075 - val_loss: 11.5903 - val_accuracy: 0.7811\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.6827 - accuracy: 0.7174 - val_loss: 11.5257 - val_accuracy: 0.7955\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.6128 - accuracy: 0.7295 - val_loss: 11.4635 - val_accuracy: 0.8055\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.5589 - accuracy: 0.7380 - val_loss: 11.4015 - val_accuracy: 0.8177\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.4984 - accuracy: 0.7487 - val_loss: 11.3409 - val_accuracy: 0.8287\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.4277 - accuracy: 0.7652 - val_loss: 11.2791 - val_accuracy: 0.8392\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.3699 - accuracy: 0.7708 - val_loss: 11.2216 - val_accuracy: 0.8464\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.3161 - accuracy: 0.7813 - val_loss: 11.1630 - val_accuracy: 0.8540\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.2566 - accuracy: 0.7892 - val_loss: 11.1055 - val_accuracy: 0.8607\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.1941 - accuracy: 0.8011 - val_loss: 11.0503 - val_accuracy: 0.8641\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.1386 - accuracy: 0.8108 - val_loss: 10.9965 - val_accuracy: 0.8697\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.0859 - accuracy: 0.8184 - val_loss: 10.9402 - val_accuracy: 0.8779\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.0266 - accuracy: 0.8267 - val_loss: 10.8877 - val_accuracy: 0.8852\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.9722 - accuracy: 0.8344 - val_loss: 10.8356 - val_accuracy: 0.8903\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.9166 - accuracy: 0.8444 - val_loss: 10.7837 - val_accuracy: 0.8961\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.8594 - accuracy: 0.8514 - val_loss: 10.7327 - val_accuracy: 0.9011\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.8097 - accuracy: 0.8554 - val_loss: 10.6824 - val_accuracy: 0.9077\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.7609 - accuracy: 0.8630 - val_loss: 10.6328 - val_accuracy: 0.9116\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.7067 - accuracy: 0.8692 - val_loss: 10.5834 - val_accuracy: 0.9144\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.6540 - accuracy: 0.8737 - val_loss: 10.5354 - val_accuracy: 0.9189\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.6074 - accuracy: 0.8780 - val_loss: 10.4879 - val_accuracy: 0.9213\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 10.5578 - accuracy: 0.8850 - val_loss: 10.4416 - val_accuracy: 0.9236\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.5023 - accuracy: 0.8918 - val_loss: 10.3931 - val_accuracy: 0.9255\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 10.4558 - accuracy: 0.8926 - val_loss: 10.3459 - val_accuracy: 0.9304\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.4076 - accuracy: 0.8991 - val_loss: 10.3000 - val_accuracy: 0.9336\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.3671 - accuracy: 0.9009 - val_loss: 10.2521 - val_accuracy: 0.9369\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.3133 - accuracy: 0.9062 - val_loss: 10.2062 - val_accuracy: 0.9401\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.2662 - accuracy: 0.9107 - val_loss: 10.1617 - val_accuracy: 0.9439\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.2215 - accuracy: 0.9151 - val_loss: 10.1164 - val_accuracy: 0.9465\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.1696 - accuracy: 0.9163 - val_loss: 10.0714 - val_accuracy: 0.9483\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.1264 - accuracy: 0.9195 - val_loss: 10.0293 - val_accuracy: 0.9496\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.0840 - accuracy: 0.9222 - val_loss: 9.9840 - val_accuracy: 0.9517\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.0365 - accuracy: 0.9270 - val_loss: 9.9412 - val_accuracy: 0.9527\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.9916 - accuracy: 0.9284 - val_loss: 9.8992 - val_accuracy: 0.9544\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.9530 - accuracy: 0.9289 - val_loss: 9.8557 - val_accuracy: 0.9561\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.9082 - accuracy: 0.9312 - val_loss: 9.8137 - val_accuracy: 0.9583\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.8617 - accuracy: 0.9340 - val_loss: 9.7723 - val_accuracy: 0.9591\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.8219 - accuracy: 0.9350 - val_loss: 9.7312 - val_accuracy: 0.9603\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.7774 - accuracy: 0.9383 - val_loss: 9.6894 - val_accuracy: 0.9617\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.7350 - accuracy: 0.9393 - val_loss: 9.6491 - val_accuracy: 0.9621\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.6932 - accuracy: 0.9387 - val_loss: 9.6085 - val_accuracy: 0.9629\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.6535 - accuracy: 0.9422 - val_loss: 9.5679 - val_accuracy: 0.9637\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.6113 - accuracy: 0.9437 - val_loss: 9.5273 - val_accuracy: 0.9648\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.5679 - accuracy: 0.9434 - val_loss: 9.4866 - val_accuracy: 0.9653\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.5306 - accuracy: 0.9450 - val_loss: 9.4479 - val_accuracy: 0.9659\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.4892 - accuracy: 0.9463 - val_loss: 9.4067 - val_accuracy: 0.9677\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 12ms/step - loss: 9.4483 - accuracy: 0.9464 - val_loss: 9.3683 - val_accuracy: 0.9679\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.4034 - accuracy: 0.9507 - val_loss: 9.3287 - val_accuracy: 0.9683\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.3663 - accuracy: 0.9518 - val_loss: 9.2896 - val_accuracy: 0.9689\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.3247 - accuracy: 0.9538 - val_loss: 9.2507 - val_accuracy: 0.9691\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2839 - accuracy: 0.9519 - val_loss: 9.2127 - val_accuracy: 0.9692\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2493 - accuracy: 0.9514 - val_loss: 9.1729 - val_accuracy: 0.9707\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2049 - accuracy: 0.9546 - val_loss: 9.1353 - val_accuracy: 0.9708\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.1645 - accuracy: 0.9563 - val_loss: 9.0968 - val_accuracy: 0.9712\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.1274 - accuracy: 0.9561 - val_loss: 9.0595 - val_accuracy: 0.9721\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0885 - accuracy: 0.9564 - val_loss: 9.0214 - val_accuracy: 0.9724\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 9.0502 - accuracy: 0.9591 - val_loss: 8.9841 - val_accuracy: 0.9721\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0114 - accuracy: 0.9594 - val_loss: 8.9460 - val_accuracy: 0.9729\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.9727 - accuracy: 0.9601 - val_loss: 8.9084 - val_accuracy: 0.9735\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.9356 - accuracy: 0.9607 - val_loss: 8.8715 - val_accuracy: 0.9741\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.8957 - accuracy: 0.9620 - val_loss: 8.8330 - val_accuracy: 0.9747\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.8587 - accuracy: 0.9614 - val_loss: 8.7966 - val_accuracy: 0.9751\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.8187 - accuracy: 0.9623 - val_loss: 8.7596 - val_accuracy: 0.9757\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7836 - accuracy: 0.9630 - val_loss: 8.7235 - val_accuracy: 0.9755\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7428 - accuracy: 0.9638 - val_loss: 8.6862 - val_accuracy: 0.9759\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7091 - accuracy: 0.9626 - val_loss: 8.6493 - val_accuracy: 0.9763\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.6685 - accuracy: 0.9652 - val_loss: 8.6128 - val_accuracy: 0.9767\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.6323 - accuracy: 0.9657 - val_loss: 8.5768 - val_accuracy: 0.9765\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.5963 - accuracy: 0.9660 - val_loss: 8.5411 - val_accuracy: 0.9775\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 12ms/step - loss: 8.5604 - accuracy: 0.9661 - val_loss: 8.5040 - val_accuracy: 0.9773\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.5244 - accuracy: 0.9656 - val_loss: 8.4672 - val_accuracy: 0.9775\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4897 - accuracy: 0.9656 - val_loss: 8.4325 - val_accuracy: 0.9773\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4463 - accuracy: 0.9694 - val_loss: 8.3972 - val_accuracy: 0.9772\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4104 - accuracy: 0.9683 - val_loss: 8.3616 - val_accuracy: 0.9779\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3745 - accuracy: 0.9700 - val_loss: 8.3253 - val_accuracy: 0.9783\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3386 - accuracy: 0.9700 - val_loss: 8.2894 - val_accuracy: 0.9787\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3033 - accuracy: 0.9702 - val_loss: 8.2541 - val_accuracy: 0.9795\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.2669 - accuracy: 0.9703 - val_loss: 8.2195 - val_accuracy: 0.9789\n",
      "Time: 98.6472020149231\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_100disc_50SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#100 discrete, 50 SNPs\n",
    "################################################################################################################################################\n",
    "\n",
    "# subset the SNPs\n",
    "X50=X[:,0:50,:]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test  = train_test_split(y,X50,traits_disc,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_disc_subset(ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test)\n",
    "\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_100disc_50SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMz5CqgKC5SY",
    "outputId": "accb9171-f15b-4ab6-9ee8-d2d2ccab8108",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 50, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 48, 250)      45000       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 48, 250)     1000        ['conv1d_6[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 46, 250)      187500      ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 46, 250)     1000        ['conv1d_7[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 44, 250)      187500      ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 44, 250)     1000        ['conv1d_8[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 14, 250)     0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 3500)         0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dense_20_input (InputLayer)    [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 125)          437625      ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 150)          450000      ['dense_20_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 125)          0           ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 150)         600         ['dense_20[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 125)          15750       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 150)          22500       ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 125)          0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 150)         600         ['dense_21[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 50)           6300        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 50)           7550        ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 50)           0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_2 (LinearW)           (None, 50)           2           ['dense_22[0][0]',               \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 50)           2550        ['linear_w_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 3)            153         ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,366,630\n",
      "Trainable params: 1,364,530\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 3s 15ms/step - loss: 13.2318 - accuracy: 0.3516 - val_loss: 13.1281 - val_accuracy: 0.3537\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 13.1160 - accuracy: 0.3873 - val_loss: 13.0516 - val_accuracy: 0.4039\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 13.0326 - accuracy: 0.4183 - val_loss: 12.9670 - val_accuracy: 0.4812\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.9528 - accuracy: 0.4549 - val_loss: 12.8783 - val_accuracy: 0.5324\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.8748 - accuracy: 0.4796 - val_loss: 12.7906 - val_accuracy: 0.5620\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.7961 - accuracy: 0.5096 - val_loss: 12.7061 - val_accuracy: 0.5871\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.7241 - accuracy: 0.5311 - val_loss: 12.6255 - val_accuracy: 0.6049\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.6450 - accuracy: 0.5566 - val_loss: 12.5484 - val_accuracy: 0.6212\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.5754 - accuracy: 0.5729 - val_loss: 12.4725 - val_accuracy: 0.6365\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.5104 - accuracy: 0.5864 - val_loss: 12.4043 - val_accuracy: 0.6453\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.4392 - accuracy: 0.6038 - val_loss: 12.3327 - val_accuracy: 0.6628\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.3708 - accuracy: 0.6188 - val_loss: 12.2627 - val_accuracy: 0.6769\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.3041 - accuracy: 0.6279 - val_loss: 12.1959 - val_accuracy: 0.6943\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.2424 - accuracy: 0.6460 - val_loss: 12.1265 - val_accuracy: 0.7096\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.1750 - accuracy: 0.6562 - val_loss: 12.0575 - val_accuracy: 0.7233\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.1121 - accuracy: 0.6703 - val_loss: 11.9884 - val_accuracy: 0.7381\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 12.0440 - accuracy: 0.6842 - val_loss: 11.9199 - val_accuracy: 0.7536\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.9810 - accuracy: 0.6948 - val_loss: 11.8522 - val_accuracy: 0.7671\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.9234 - accuracy: 0.7068 - val_loss: 11.7866 - val_accuracy: 0.7781\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.8538 - accuracy: 0.7206 - val_loss: 11.7156 - val_accuracy: 0.7961\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.7909 - accuracy: 0.7278 - val_loss: 11.6489 - val_accuracy: 0.8092\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.7208 - accuracy: 0.7498 - val_loss: 11.5831 - val_accuracy: 0.8197\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.6640 - accuracy: 0.7551 - val_loss: 11.5184 - val_accuracy: 0.8304\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.5907 - accuracy: 0.7731 - val_loss: 11.4560 - val_accuracy: 0.8371\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.5320 - accuracy: 0.7807 - val_loss: 11.3933 - val_accuracy: 0.8488\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.4707 - accuracy: 0.7924 - val_loss: 11.3353 - val_accuracy: 0.8551\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.4141 - accuracy: 0.8033 - val_loss: 11.2756 - val_accuracy: 0.8637\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.3542 - accuracy: 0.8115 - val_loss: 11.2170 - val_accuracy: 0.8704\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.2979 - accuracy: 0.8193 - val_loss: 11.1600 - val_accuracy: 0.8777\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.2347 - accuracy: 0.8338 - val_loss: 11.1057 - val_accuracy: 0.8839\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.1813 - accuracy: 0.8356 - val_loss: 11.0526 - val_accuracy: 0.8893\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.1234 - accuracy: 0.8464 - val_loss: 10.9990 - val_accuracy: 0.8953\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.0690 - accuracy: 0.8530 - val_loss: 10.9459 - val_accuracy: 0.9019\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 11.0072 - accuracy: 0.8611 - val_loss: 10.8950 - val_accuracy: 0.9068\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.9646 - accuracy: 0.8644 - val_loss: 10.8449 - val_accuracy: 0.9120\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.9048 - accuracy: 0.8752 - val_loss: 10.7922 - val_accuracy: 0.9185\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.8516 - accuracy: 0.8797 - val_loss: 10.7442 - val_accuracy: 0.9228\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.8050 - accuracy: 0.8812 - val_loss: 10.6940 - val_accuracy: 0.9268\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.7551 - accuracy: 0.8884 - val_loss: 10.6450 - val_accuracy: 0.9315\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.7067 - accuracy: 0.8928 - val_loss: 10.5983 - val_accuracy: 0.9340\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.6533 - accuracy: 0.8985 - val_loss: 10.5505 - val_accuracy: 0.9365\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.6028 - accuracy: 0.9033 - val_loss: 10.5031 - val_accuracy: 0.9403\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.5565 - accuracy: 0.9067 - val_loss: 10.4569 - val_accuracy: 0.9440\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.5105 - accuracy: 0.9114 - val_loss: 10.4110 - val_accuracy: 0.9461\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.4620 - accuracy: 0.9144 - val_loss: 10.3655 - val_accuracy: 0.9481\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.4144 - accuracy: 0.9164 - val_loss: 10.3207 - val_accuracy: 0.9503\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.3699 - accuracy: 0.9190 - val_loss: 10.2761 - val_accuracy: 0.9509\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.3210 - accuracy: 0.9241 - val_loss: 10.2319 - val_accuracy: 0.9535\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.2784 - accuracy: 0.9241 - val_loss: 10.1887 - val_accuracy: 0.9552\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.2342 - accuracy: 0.9255 - val_loss: 10.1456 - val_accuracy: 0.9564\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.1960 - accuracy: 0.9272 - val_loss: 10.1020 - val_accuracy: 0.9575\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.1407 - accuracy: 0.9327 - val_loss: 10.0607 - val_accuracy: 0.9587\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.1036 - accuracy: 0.9312 - val_loss: 10.0163 - val_accuracy: 0.9600\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.0594 - accuracy: 0.9356 - val_loss: 9.9754 - val_accuracy: 0.9607\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 10.0138 - accuracy: 0.9371 - val_loss: 9.9333 - val_accuracy: 0.9613\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.9719 - accuracy: 0.9402 - val_loss: 9.8929 - val_accuracy: 0.9620\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.9278 - accuracy: 0.9416 - val_loss: 9.8508 - val_accuracy: 0.9629\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.8835 - accuracy: 0.9435 - val_loss: 9.8103 - val_accuracy: 0.9633\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.8418 - accuracy: 0.9437 - val_loss: 9.7685 - val_accuracy: 0.9647\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.8003 - accuracy: 0.9452 - val_loss: 9.7290 - val_accuracy: 0.9651\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 9.7584 - accuracy: 0.9468 - val_loss: 9.6905 - val_accuracy: 0.9643\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.7196 - accuracy: 0.9469 - val_loss: 9.6483 - val_accuracy: 0.9655\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.6793 - accuracy: 0.9475 - val_loss: 9.6087 - val_accuracy: 0.9661\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.6394 - accuracy: 0.9492 - val_loss: 9.5703 - val_accuracy: 0.9665\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.5985 - accuracy: 0.9503 - val_loss: 9.5306 - val_accuracy: 0.9669\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.5580 - accuracy: 0.9518 - val_loss: 9.4901 - val_accuracy: 0.9673\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.5132 - accuracy: 0.9528 - val_loss: 9.4511 - val_accuracy: 0.9680\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.4723 - accuracy: 0.9538 - val_loss: 9.4115 - val_accuracy: 0.9684\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.4322 - accuracy: 0.9548 - val_loss: 9.3741 - val_accuracy: 0.9685\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.3957 - accuracy: 0.9549 - val_loss: 9.3347 - val_accuracy: 0.9693\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.3563 - accuracy: 0.9552 - val_loss: 9.2975 - val_accuracy: 0.9700\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.3143 - accuracy: 0.9577 - val_loss: 9.2579 - val_accuracy: 0.9703\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2732 - accuracy: 0.9587 - val_loss: 9.2189 - val_accuracy: 0.9709\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.2370 - accuracy: 0.9584 - val_loss: 9.1817 - val_accuracy: 0.9709\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.1974 - accuracy: 0.9588 - val_loss: 9.1419 - val_accuracy: 0.9713\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 9.1557 - accuracy: 0.9597 - val_loss: 9.1051 - val_accuracy: 0.9712\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.1210 - accuracy: 0.9612 - val_loss: 9.0684 - val_accuracy: 0.9712\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0811 - accuracy: 0.9616 - val_loss: 9.0304 - val_accuracy: 0.9719\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0429 - accuracy: 0.9626 - val_loss: 8.9927 - val_accuracy: 0.9723\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 9.0092 - accuracy: 0.9605 - val_loss: 8.9544 - val_accuracy: 0.9728\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.9660 - accuracy: 0.9640 - val_loss: 8.9183 - val_accuracy: 0.9731\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.9300 - accuracy: 0.9633 - val_loss: 8.8815 - val_accuracy: 0.9740\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.8883 - accuracy: 0.9658 - val_loss: 8.8431 - val_accuracy: 0.9733\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.8521 - accuracy: 0.9649 - val_loss: 8.8065 - val_accuracy: 0.9737\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.8129 - accuracy: 0.9680 - val_loss: 8.7704 - val_accuracy: 0.9739\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7761 - accuracy: 0.9672 - val_loss: 8.7342 - val_accuracy: 0.9739\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7418 - accuracy: 0.9642 - val_loss: 8.6973 - val_accuracy: 0.9745\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.7060 - accuracy: 0.9666 - val_loss: 8.6605 - val_accuracy: 0.9744\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.6677 - accuracy: 0.9669 - val_loss: 8.6241 - val_accuracy: 0.9757\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.6285 - accuracy: 0.9680 - val_loss: 8.5899 - val_accuracy: 0.9748\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.5909 - accuracy: 0.9677 - val_loss: 8.5527 - val_accuracy: 0.9756\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.5523 - accuracy: 0.9697 - val_loss: 8.5178 - val_accuracy: 0.9759\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.5205 - accuracy: 0.9687 - val_loss: 8.4818 - val_accuracy: 0.9755\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4848 - accuracy: 0.9679 - val_loss: 8.4454 - val_accuracy: 0.9763\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4482 - accuracy: 0.9698 - val_loss: 8.4112 - val_accuracy: 0.9760\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.4076 - accuracy: 0.9717 - val_loss: 8.3758 - val_accuracy: 0.9760\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3745 - accuracy: 0.9703 - val_loss: 8.3389 - val_accuracy: 0.9765\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3374 - accuracy: 0.9714 - val_loss: 8.3034 - val_accuracy: 0.9765\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.3025 - accuracy: 0.9716 - val_loss: 8.2692 - val_accuracy: 0.9765\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 8.2625 - accuracy: 0.9731 - val_loss: 8.2334 - val_accuracy: 0.9769\n",
      "Time: 98.31952905654907\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_50disc_50SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#50 disc, 50 SNPs\n",
    "################################################################################################################################################\n",
    "traits_disc50=traits_disc[:,0:50,:]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test  = train_test_split(y,X50,traits_disc50,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_disc_subset(ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test)\n",
    "\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_50disc_50SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LVM4GrIVE0ol",
    "outputId": "8676d351-b7c6-4d31-cf38-eb0429ae41a3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28_input (InputLayer)  [(None, 3000)]           0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 150)               450000    \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 150)               22500     \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 50)                7550      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 481,403\n",
      "Trainable params: 480,803\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 13.4283 - accuracy: 0.3357 - val_loss: 13.2743 - val_accuracy: 0.3344\n",
      "Epoch 2/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.3111 - accuracy: 0.3469 - val_loss: 13.2040 - val_accuracy: 0.3412\n",
      "Epoch 3/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.2220 - accuracy: 0.3548 - val_loss: 13.1598 - val_accuracy: 0.3444\n",
      "Epoch 4/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.1452 - accuracy: 0.3605 - val_loss: 13.1204 - val_accuracy: 0.3423\n",
      "Epoch 5/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.0766 - accuracy: 0.3673 - val_loss: 13.0790 - val_accuracy: 0.3417\n",
      "Epoch 6/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 13.0132 - accuracy: 0.3710 - val_loss: 13.0280 - val_accuracy: 0.3460\n",
      "Epoch 7/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.9544 - accuracy: 0.3788 - val_loss: 12.9846 - val_accuracy: 0.3445\n",
      "Epoch 8/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.8940 - accuracy: 0.3847 - val_loss: 12.9319 - val_accuracy: 0.3528\n",
      "Epoch 9/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.8398 - accuracy: 0.3916 - val_loss: 12.8863 - val_accuracy: 0.3476\n",
      "Epoch 10/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.7824 - accuracy: 0.3955 - val_loss: 12.8324 - val_accuracy: 0.3564\n",
      "Epoch 11/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.7304 - accuracy: 0.4033 - val_loss: 12.7902 - val_accuracy: 0.3511\n",
      "Epoch 12/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.6750 - accuracy: 0.4090 - val_loss: 12.7345 - val_accuracy: 0.3557\n",
      "Epoch 13/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.6236 - accuracy: 0.4140 - val_loss: 12.6994 - val_accuracy: 0.3544\n",
      "Epoch 14/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.5707 - accuracy: 0.4231 - val_loss: 12.6544 - val_accuracy: 0.3548\n",
      "Epoch 15/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.5211 - accuracy: 0.4266 - val_loss: 12.6096 - val_accuracy: 0.3605\n",
      "Epoch 16/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.4676 - accuracy: 0.4332 - val_loss: 12.5583 - val_accuracy: 0.3584\n",
      "Epoch 17/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.4175 - accuracy: 0.4419 - val_loss: 12.5082 - val_accuracy: 0.3637\n",
      "Epoch 18/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.3672 - accuracy: 0.4482 - val_loss: 12.4681 - val_accuracy: 0.3644\n",
      "Epoch 19/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.3166 - accuracy: 0.4546 - val_loss: 12.4231 - val_accuracy: 0.3651\n",
      "Epoch 20/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.2669 - accuracy: 0.4617 - val_loss: 12.3761 - val_accuracy: 0.3663\n",
      "Epoch 21/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.2184 - accuracy: 0.4668 - val_loss: 12.3327 - val_accuracy: 0.3651\n",
      "Epoch 22/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.1679 - accuracy: 0.4769 - val_loss: 12.2898 - val_accuracy: 0.3659\n",
      "Epoch 23/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.1210 - accuracy: 0.4791 - val_loss: 12.2462 - val_accuracy: 0.3699\n",
      "Epoch 24/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.0721 - accuracy: 0.4865 - val_loss: 12.2061 - val_accuracy: 0.3671\n",
      "Epoch 25/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 12.0241 - accuracy: 0.4957 - val_loss: 12.1569 - val_accuracy: 0.3729\n",
      "Epoch 26/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.9757 - accuracy: 0.4982 - val_loss: 12.1245 - val_accuracy: 0.3688\n",
      "Epoch 27/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.9268 - accuracy: 0.5061 - val_loss: 12.0672 - val_accuracy: 0.3727\n",
      "Epoch 28/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.8800 - accuracy: 0.5139 - val_loss: 12.0293 - val_accuracy: 0.3780\n",
      "Epoch 29/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.8330 - accuracy: 0.5191 - val_loss: 11.9892 - val_accuracy: 0.3696\n",
      "Epoch 30/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.7858 - accuracy: 0.5233 - val_loss: 11.9441 - val_accuracy: 0.3735\n",
      "Epoch 31/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.7390 - accuracy: 0.5308 - val_loss: 11.9026 - val_accuracy: 0.3739\n",
      "Epoch 32/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.6914 - accuracy: 0.5359 - val_loss: 11.8633 - val_accuracy: 0.3767\n",
      "Epoch 33/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.6448 - accuracy: 0.5431 - val_loss: 11.8199 - val_accuracy: 0.3747\n",
      "Epoch 34/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.5999 - accuracy: 0.5500 - val_loss: 11.7771 - val_accuracy: 0.3816\n",
      "Epoch 35/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.5521 - accuracy: 0.5563 - val_loss: 11.7373 - val_accuracy: 0.3825\n",
      "Epoch 36/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.5047 - accuracy: 0.5630 - val_loss: 11.6986 - val_accuracy: 0.3795\n",
      "Epoch 37/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.4593 - accuracy: 0.5653 - val_loss: 11.6560 - val_accuracy: 0.3784\n",
      "Epoch 38/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.4137 - accuracy: 0.5703 - val_loss: 11.6141 - val_accuracy: 0.3828\n",
      "Epoch 39/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.3677 - accuracy: 0.5780 - val_loss: 11.5723 - val_accuracy: 0.3821\n",
      "Epoch 40/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.3220 - accuracy: 0.5840 - val_loss: 11.5306 - val_accuracy: 0.3875\n",
      "Epoch 41/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.2759 - accuracy: 0.5883 - val_loss: 11.4929 - val_accuracy: 0.3852\n",
      "Epoch 42/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.2309 - accuracy: 0.5952 - val_loss: 11.4536 - val_accuracy: 0.3843\n",
      "Epoch 43/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.1854 - accuracy: 0.6021 - val_loss: 11.4121 - val_accuracy: 0.3859\n",
      "Epoch 44/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.1402 - accuracy: 0.6040 - val_loss: 11.3746 - val_accuracy: 0.3873\n",
      "Epoch 45/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.0943 - accuracy: 0.6138 - val_loss: 11.3274 - val_accuracy: 0.3936\n",
      "Epoch 46/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.0498 - accuracy: 0.6164 - val_loss: 11.2923 - val_accuracy: 0.3939\n",
      "Epoch 47/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 11.0041 - accuracy: 0.6230 - val_loss: 11.2540 - val_accuracy: 0.3925\n",
      "Epoch 48/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.9601 - accuracy: 0.6256 - val_loss: 11.2089 - val_accuracy: 0.3931\n",
      "Epoch 49/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.9150 - accuracy: 0.6318 - val_loss: 11.1710 - val_accuracy: 0.3948\n",
      "Epoch 50/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.8699 - accuracy: 0.6364 - val_loss: 11.1301 - val_accuracy: 0.3953\n",
      "Epoch 51/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.8246 - accuracy: 0.6451 - val_loss: 11.0938 - val_accuracy: 0.3960\n",
      "Epoch 52/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.7810 - accuracy: 0.6470 - val_loss: 11.0546 - val_accuracy: 0.4007\n",
      "Epoch 53/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.7366 - accuracy: 0.6552 - val_loss: 11.0162 - val_accuracy: 0.3976\n",
      "Epoch 54/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.6917 - accuracy: 0.6571 - val_loss: 10.9736 - val_accuracy: 0.3993\n",
      "Epoch 55/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.6467 - accuracy: 0.6647 - val_loss: 10.9383 - val_accuracy: 0.4033\n",
      "Epoch 56/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.6037 - accuracy: 0.6643 - val_loss: 10.8972 - val_accuracy: 0.4027\n",
      "Epoch 57/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.5591 - accuracy: 0.6733 - val_loss: 10.8604 - val_accuracy: 0.4072\n",
      "Epoch 58/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.5161 - accuracy: 0.6755 - val_loss: 10.8159 - val_accuracy: 0.4036\n",
      "Epoch 59/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.4713 - accuracy: 0.6808 - val_loss: 10.7824 - val_accuracy: 0.4012\n",
      "Epoch 60/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.4262 - accuracy: 0.6883 - val_loss: 10.7418 - val_accuracy: 0.4047\n",
      "Epoch 61/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.3831 - accuracy: 0.6925 - val_loss: 10.7058 - val_accuracy: 0.4087\n",
      "Epoch 62/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.3395 - accuracy: 0.6960 - val_loss: 10.6691 - val_accuracy: 0.4087\n",
      "Epoch 63/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.2948 - accuracy: 0.7011 - val_loss: 10.6275 - val_accuracy: 0.4101\n",
      "Epoch 64/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.2521 - accuracy: 0.7048 - val_loss: 10.5931 - val_accuracy: 0.4077\n",
      "Epoch 65/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.2091 - accuracy: 0.7100 - val_loss: 10.5573 - val_accuracy: 0.4057\n",
      "Epoch 66/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.1635 - accuracy: 0.7148 - val_loss: 10.5163 - val_accuracy: 0.4088\n",
      "Epoch 67/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.1219 - accuracy: 0.7192 - val_loss: 10.4815 - val_accuracy: 0.4127\n",
      "Epoch 68/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.0777 - accuracy: 0.7233 - val_loss: 10.4393 - val_accuracy: 0.4143\n",
      "Epoch 69/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 10.0347 - accuracy: 0.7259 - val_loss: 10.4017 - val_accuracy: 0.4172\n",
      "Epoch 70/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.9923 - accuracy: 0.7339 - val_loss: 10.3627 - val_accuracy: 0.4148\n",
      "Epoch 71/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.9501 - accuracy: 0.7332 - val_loss: 10.3287 - val_accuracy: 0.4179\n",
      "Epoch 72/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.9050 - accuracy: 0.7388 - val_loss: 10.2992 - val_accuracy: 0.4151\n",
      "Epoch 73/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.8633 - accuracy: 0.7435 - val_loss: 10.2525 - val_accuracy: 0.4191\n",
      "Epoch 74/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.8188 - accuracy: 0.7501 - val_loss: 10.2163 - val_accuracy: 0.4203\n",
      "Epoch 75/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.7763 - accuracy: 0.7528 - val_loss: 10.1864 - val_accuracy: 0.4211\n",
      "Epoch 76/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.7349 - accuracy: 0.7547 - val_loss: 10.1469 - val_accuracy: 0.4217\n",
      "Epoch 77/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.6918 - accuracy: 0.7615 - val_loss: 10.1129 - val_accuracy: 0.4208\n",
      "Epoch 78/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.6469 - accuracy: 0.7655 - val_loss: 10.0710 - val_accuracy: 0.4215\n",
      "Epoch 79/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.6067 - accuracy: 0.7677 - val_loss: 10.0394 - val_accuracy: 0.4239\n",
      "Epoch 80/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.5629 - accuracy: 0.7748 - val_loss: 10.0006 - val_accuracy: 0.4224\n",
      "Epoch 81/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.5208 - accuracy: 0.7757 - val_loss: 9.9754 - val_accuracy: 0.4240\n",
      "Epoch 82/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.4789 - accuracy: 0.7832 - val_loss: 9.9328 - val_accuracy: 0.4237\n",
      "Epoch 83/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.4369 - accuracy: 0.7840 - val_loss: 9.8922 - val_accuracy: 0.4268\n",
      "Epoch 84/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.3950 - accuracy: 0.7879 - val_loss: 9.8599 - val_accuracy: 0.4261\n",
      "Epoch 85/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.3531 - accuracy: 0.7924 - val_loss: 9.8186 - val_accuracy: 0.4267\n",
      "Epoch 86/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.3115 - accuracy: 0.7942 - val_loss: 9.7839 - val_accuracy: 0.4292\n",
      "Epoch 87/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.2684 - accuracy: 0.8033 - val_loss: 9.7482 - val_accuracy: 0.4287\n",
      "Epoch 88/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.2264 - accuracy: 0.8060 - val_loss: 9.7153 - val_accuracy: 0.4341\n",
      "Epoch 89/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.1864 - accuracy: 0.8064 - val_loss: 9.6791 - val_accuracy: 0.4288\n",
      "Epoch 90/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.1431 - accuracy: 0.8124 - val_loss: 9.6465 - val_accuracy: 0.4311\n",
      "Epoch 91/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.1028 - accuracy: 0.8154 - val_loss: 9.6088 - val_accuracy: 0.4303\n",
      "Epoch 92/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.0604 - accuracy: 0.8177 - val_loss: 9.5765 - val_accuracy: 0.4381\n",
      "Epoch 93/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 9.0205 - accuracy: 0.8217 - val_loss: 9.5368 - val_accuracy: 0.4325\n",
      "Epoch 94/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.9777 - accuracy: 0.8271 - val_loss: 9.5095 - val_accuracy: 0.4332\n",
      "Epoch 95/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.9374 - accuracy: 0.8282 - val_loss: 9.4807 - val_accuracy: 0.4375\n",
      "Epoch 96/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.8951 - accuracy: 0.8338 - val_loss: 9.4458 - val_accuracy: 0.4343\n",
      "Epoch 97/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.8551 - accuracy: 0.8353 - val_loss: 9.4020 - val_accuracy: 0.4357\n",
      "Epoch 98/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.8164 - accuracy: 0.8365 - val_loss: 9.3769 - val_accuracy: 0.4343\n",
      "Epoch 99/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.7749 - accuracy: 0.8404 - val_loss: 9.3379 - val_accuracy: 0.4367\n",
      "Epoch 100/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.7328 - accuracy: 0.8479 - val_loss: 9.3040 - val_accuracy: 0.4387\n",
      "Epoch 101/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.6930 - accuracy: 0.8491 - val_loss: 9.2748 - val_accuracy: 0.4415\n",
      "Epoch 102/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.6520 - accuracy: 0.8525 - val_loss: 9.2332 - val_accuracy: 0.4427\n",
      "Epoch 103/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.6112 - accuracy: 0.8577 - val_loss: 9.1997 - val_accuracy: 0.4413\n",
      "Epoch 104/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.5703 - accuracy: 0.8603 - val_loss: 9.1716 - val_accuracy: 0.4413\n",
      "Epoch 105/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.5312 - accuracy: 0.8595 - val_loss: 9.1398 - val_accuracy: 0.4457\n",
      "Epoch 106/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.4905 - accuracy: 0.8655 - val_loss: 9.1062 - val_accuracy: 0.4459\n",
      "Epoch 107/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.4513 - accuracy: 0.8668 - val_loss: 9.0670 - val_accuracy: 0.4451\n",
      "Epoch 108/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.4108 - accuracy: 0.8722 - val_loss: 9.0352 - val_accuracy: 0.4496\n",
      "Epoch 109/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.3717 - accuracy: 0.8754 - val_loss: 8.9989 - val_accuracy: 0.4461\n",
      "Epoch 110/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.3331 - accuracy: 0.8772 - val_loss: 8.9710 - val_accuracy: 0.4488\n",
      "Epoch 111/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.2916 - accuracy: 0.8818 - val_loss: 8.9409 - val_accuracy: 0.4499\n",
      "Epoch 112/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.2538 - accuracy: 0.8830 - val_loss: 8.9102 - val_accuracy: 0.4469\n",
      "Epoch 113/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.2138 - accuracy: 0.8856 - val_loss: 8.8773 - val_accuracy: 0.4505\n",
      "Epoch 114/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.1740 - accuracy: 0.8894 - val_loss: 8.8442 - val_accuracy: 0.4472\n",
      "Epoch 115/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.1347 - accuracy: 0.8909 - val_loss: 8.8109 - val_accuracy: 0.4476\n",
      "Epoch 116/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.0967 - accuracy: 0.8940 - val_loss: 8.7799 - val_accuracy: 0.4515\n",
      "Epoch 117/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.0589 - accuracy: 0.8955 - val_loss: 8.7465 - val_accuracy: 0.4512\n",
      "Epoch 118/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 8.0198 - accuracy: 0.8983 - val_loss: 8.7072 - val_accuracy: 0.4521\n",
      "Epoch 119/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9813 - accuracy: 0.9007 - val_loss: 8.6837 - val_accuracy: 0.4537\n",
      "Epoch 120/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9415 - accuracy: 0.9029 - val_loss: 8.6553 - val_accuracy: 0.4529\n",
      "Epoch 121/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9038 - accuracy: 0.9060 - val_loss: 8.6163 - val_accuracy: 0.4525\n",
      "Epoch 122/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.8665 - accuracy: 0.9091 - val_loss: 8.5851 - val_accuracy: 0.4556\n",
      "Epoch 123/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.8257 - accuracy: 0.9122 - val_loss: 8.5547 - val_accuracy: 0.4533\n",
      "Epoch 124/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.7893 - accuracy: 0.9127 - val_loss: 8.5269 - val_accuracy: 0.4521\n",
      "Epoch 125/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.7506 - accuracy: 0.9166 - val_loss: 8.4939 - val_accuracy: 0.4539\n",
      "Epoch 126/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.7138 - accuracy: 0.9201 - val_loss: 8.4634 - val_accuracy: 0.4568\n",
      "Epoch 127/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.6745 - accuracy: 0.9216 - val_loss: 8.4398 - val_accuracy: 0.4572\n",
      "Epoch 128/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.6378 - accuracy: 0.9248 - val_loss: 8.4014 - val_accuracy: 0.4627\n",
      "Epoch 129/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.6003 - accuracy: 0.9255 - val_loss: 8.3720 - val_accuracy: 0.4600\n",
      "Epoch 130/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.5627 - accuracy: 0.9296 - val_loss: 8.3491 - val_accuracy: 0.4564\n",
      "Epoch 131/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.5285 - accuracy: 0.9294 - val_loss: 8.3126 - val_accuracy: 0.4595\n",
      "Epoch 132/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4930 - accuracy: 0.9288 - val_loss: 8.2925 - val_accuracy: 0.4573\n",
      "Epoch 133/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4540 - accuracy: 0.9326 - val_loss: 8.2485 - val_accuracy: 0.4603\n",
      "Epoch 134/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.4181 - accuracy: 0.9350 - val_loss: 8.2261 - val_accuracy: 0.4633\n",
      "Epoch 135/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.3785 - accuracy: 0.9392 - val_loss: 8.1903 - val_accuracy: 0.4597\n",
      "Epoch 136/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.3421 - accuracy: 0.9405 - val_loss: 8.1607 - val_accuracy: 0.4624\n",
      "Epoch 137/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.3061 - accuracy: 0.9419 - val_loss: 8.1260 - val_accuracy: 0.4624\n",
      "Epoch 138/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.2700 - accuracy: 0.9448 - val_loss: 8.1136 - val_accuracy: 0.4637\n",
      "Epoch 139/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.2343 - accuracy: 0.9469 - val_loss: 8.0865 - val_accuracy: 0.4589\n",
      "Epoch 140/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1956 - accuracy: 0.9491 - val_loss: 8.0342 - val_accuracy: 0.4608\n",
      "Epoch 141/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1616 - accuracy: 0.9488 - val_loss: 8.0186 - val_accuracy: 0.4643\n",
      "Epoch 142/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.1252 - accuracy: 0.9516 - val_loss: 8.0051 - val_accuracy: 0.4615\n",
      "Epoch 143/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0912 - accuracy: 0.9523 - val_loss: 7.9892 - val_accuracy: 0.4639\n",
      "Epoch 144/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0538 - accuracy: 0.9557 - val_loss: 7.9412 - val_accuracy: 0.4611\n",
      "Epoch 145/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.0188 - accuracy: 0.9566 - val_loss: 7.9027 - val_accuracy: 0.4643\n",
      "Epoch 146/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9839 - accuracy: 0.9568 - val_loss: 7.8618 - val_accuracy: 0.4641\n",
      "Epoch 147/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9495 - accuracy: 0.9595 - val_loss: 7.9253 - val_accuracy: 0.4513\n",
      "Epoch 148/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.9144 - accuracy: 0.9614 - val_loss: 7.8214 - val_accuracy: 0.4675\n",
      "Epoch 149/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8789 - accuracy: 0.9616 - val_loss: 7.7900 - val_accuracy: 0.4664\n",
      "Epoch 150/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8446 - accuracy: 0.9640 - val_loss: 7.7616 - val_accuracy: 0.4651\n",
      "Epoch 151/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.8109 - accuracy: 0.9646 - val_loss: 7.8219 - val_accuracy: 0.4563\n",
      "Epoch 152/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7759 - accuracy: 0.9661 - val_loss: 7.7130 - val_accuracy: 0.4663\n",
      "Epoch 153/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7399 - accuracy: 0.9691 - val_loss: 7.6785 - val_accuracy: 0.4693\n",
      "Epoch 154/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.7071 - accuracy: 0.9685 - val_loss: 7.6521 - val_accuracy: 0.4688\n",
      "Epoch 155/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6772 - accuracy: 0.9679 - val_loss: 7.6296 - val_accuracy: 0.4665\n",
      "Epoch 156/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6400 - accuracy: 0.9705 - val_loss: 7.6004 - val_accuracy: 0.4668\n",
      "Epoch 157/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.6071 - accuracy: 0.9720 - val_loss: 7.5627 - val_accuracy: 0.4705\n",
      "Epoch 158/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5733 - accuracy: 0.9729 - val_loss: 7.5405 - val_accuracy: 0.4704\n",
      "Epoch 159/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5375 - accuracy: 0.9747 - val_loss: 7.5140 - val_accuracy: 0.4703\n",
      "Epoch 160/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.5039 - accuracy: 0.9766 - val_loss: 7.4775 - val_accuracy: 0.4701\n",
      "Epoch 161/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4721 - accuracy: 0.9775 - val_loss: 7.4503 - val_accuracy: 0.4704\n",
      "Epoch 162/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4391 - accuracy: 0.9790 - val_loss: 7.4278 - val_accuracy: 0.4755\n",
      "Epoch 163/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4081 - accuracy: 0.9780 - val_loss: 7.4337 - val_accuracy: 0.4700\n",
      "Epoch 164/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3735 - accuracy: 0.9800 - val_loss: 7.3826 - val_accuracy: 0.4731\n",
      "Epoch 165/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3457 - accuracy: 0.9784 - val_loss: 7.3520 - val_accuracy: 0.4739\n",
      "Epoch 166/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.3100 - accuracy: 0.9810 - val_loss: 7.3283 - val_accuracy: 0.4736\n",
      "Epoch 167/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2763 - accuracy: 0.9827 - val_loss: 7.2906 - val_accuracy: 0.4707\n",
      "Epoch 168/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2463 - accuracy: 0.9812 - val_loss: 7.2682 - val_accuracy: 0.4756\n",
      "Epoch 169/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.2126 - accuracy: 0.9840 - val_loss: 7.2557 - val_accuracy: 0.4731\n",
      "Epoch 170/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1814 - accuracy: 0.9842 - val_loss: 7.2128 - val_accuracy: 0.4731\n",
      "Epoch 171/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1478 - accuracy: 0.9857 - val_loss: 7.2010 - val_accuracy: 0.4749\n",
      "Epoch 172/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.1167 - accuracy: 0.9866 - val_loss: 7.1618 - val_accuracy: 0.4777\n",
      "Epoch 173/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0853 - accuracy: 0.9875 - val_loss: 7.1516 - val_accuracy: 0.4725\n",
      "Epoch 174/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0541 - accuracy: 0.9883 - val_loss: 7.0840 - val_accuracy: 0.4811\n",
      "Epoch 175/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.0226 - accuracy: 0.9872 - val_loss: 7.1012 - val_accuracy: 0.4799\n",
      "Epoch 176/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9919 - accuracy: 0.9883 - val_loss: 7.0619 - val_accuracy: 0.4811\n",
      "Epoch 177/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9639 - accuracy: 0.9874 - val_loss: 7.0469 - val_accuracy: 0.4771\n",
      "Epoch 178/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.9297 - accuracy: 0.9900 - val_loss: 7.0315 - val_accuracy: 0.4761\n",
      "Epoch 179/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8991 - accuracy: 0.9908 - val_loss: 7.0059 - val_accuracy: 0.4773\n",
      "Epoch 180/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8693 - accuracy: 0.9903 - val_loss: 6.9722 - val_accuracy: 0.4759\n",
      "Epoch 181/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8381 - accuracy: 0.9913 - val_loss: 6.9520 - val_accuracy: 0.4813\n",
      "Epoch 182/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.8075 - accuracy: 0.9915 - val_loss: 6.9117 - val_accuracy: 0.4779\n",
      "Epoch 183/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7768 - accuracy: 0.9924 - val_loss: 6.8811 - val_accuracy: 0.4812\n",
      "Epoch 184/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7477 - accuracy: 0.9924 - val_loss: 6.8756 - val_accuracy: 0.4867\n",
      "Epoch 185/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.7167 - accuracy: 0.9924 - val_loss: 6.8571 - val_accuracy: 0.4824\n",
      "Epoch 186/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6875 - accuracy: 0.9938 - val_loss: 6.8099 - val_accuracy: 0.4776\n",
      "Epoch 187/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6567 - accuracy: 0.9945 - val_loss: 6.8127 - val_accuracy: 0.4788\n",
      "Epoch 188/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6278 - accuracy: 0.9946 - val_loss: 6.7425 - val_accuracy: 0.4832\n",
      "Epoch 189/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.6027 - accuracy: 0.9922 - val_loss: 6.7336 - val_accuracy: 0.4789\n",
      "Epoch 190/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5780 - accuracy: 0.9908 - val_loss: 6.7477 - val_accuracy: 0.4812\n",
      "Epoch 191/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5407 - accuracy: 0.9956 - val_loss: 6.6947 - val_accuracy: 0.4855\n",
      "Epoch 192/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.5108 - accuracy: 0.9956 - val_loss: 6.6731 - val_accuracy: 0.4845\n",
      "Epoch 193/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4822 - accuracy: 0.9956 - val_loss: 6.6509 - val_accuracy: 0.4829\n",
      "Epoch 194/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4538 - accuracy: 0.9956 - val_loss: 6.6142 - val_accuracy: 0.4828\n",
      "Epoch 195/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.4253 - accuracy: 0.9961 - val_loss: 6.7223 - val_accuracy: 0.4772\n",
      "Epoch 196/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3965 - accuracy: 0.9967 - val_loss: 6.5842 - val_accuracy: 0.4836\n",
      "Epoch 197/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3694 - accuracy: 0.9961 - val_loss: 6.5422 - val_accuracy: 0.4872\n",
      "Epoch 198/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3394 - accuracy: 0.9969 - val_loss: 6.5165 - val_accuracy: 0.4836\n",
      "Epoch 199/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.3202 - accuracy: 0.9935 - val_loss: 6.5241 - val_accuracy: 0.4845\n",
      "Epoch 200/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2896 - accuracy: 0.9945 - val_loss: 6.4801 - val_accuracy: 0.4907\n",
      "Epoch 201/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2594 - accuracy: 0.9957 - val_loss: 6.4379 - val_accuracy: 0.4867\n",
      "Epoch 202/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2347 - accuracy: 0.9956 - val_loss: 6.4045 - val_accuracy: 0.4857\n",
      "Epoch 203/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.2113 - accuracy: 0.9936 - val_loss: 6.4683 - val_accuracy: 0.4800\n",
      "Epoch 204/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1739 - accuracy: 0.9972 - val_loss: 6.4205 - val_accuracy: 0.4857\n",
      "Epoch 205/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1450 - accuracy: 0.9984 - val_loss: 6.3578 - val_accuracy: 0.4857\n",
      "Epoch 206/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.1231 - accuracy: 0.9960 - val_loss: 6.3322 - val_accuracy: 0.4856\n",
      "Epoch 207/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0911 - accuracy: 0.9980 - val_loss: 6.3280 - val_accuracy: 0.4861\n",
      "Epoch 208/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0649 - accuracy: 0.9980 - val_loss: 6.2704 - val_accuracy: 0.4892\n",
      "Epoch 209/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0370 - accuracy: 0.9983 - val_loss: 6.2530 - val_accuracy: 0.4888\n",
      "Epoch 210/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 5.0097 - accuracy: 0.9988 - val_loss: 6.2302 - val_accuracy: 0.4919\n",
      "Epoch 211/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9826 - accuracy: 0.9986 - val_loss: 6.2271 - val_accuracy: 0.4876\n",
      "Epoch 212/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9703 - accuracy: 0.9932 - val_loss: 6.1763 - val_accuracy: 0.4863\n",
      "Epoch 213/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9578 - accuracy: 0.9888 - val_loss: 6.2134 - val_accuracy: 0.4783\n",
      "Epoch 214/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.9241 - accuracy: 0.9921 - val_loss: 6.1131 - val_accuracy: 0.4885\n",
      "Epoch 215/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8890 - accuracy: 0.9955 - val_loss: 6.1148 - val_accuracy: 0.4861\n",
      "Epoch 216/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8549 - accuracy: 0.9977 - val_loss: 6.0962 - val_accuracy: 0.4949\n",
      "Epoch 217/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8271 - accuracy: 0.9987 - val_loss: 6.0916 - val_accuracy: 0.4896\n",
      "Epoch 218/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.8008 - accuracy: 0.9990 - val_loss: 6.0391 - val_accuracy: 0.4920\n",
      "Epoch 219/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7750 - accuracy: 0.9992 - val_loss: 6.0269 - val_accuracy: 0.4880\n",
      "Epoch 220/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7481 - accuracy: 0.9992 - val_loss: 6.0236 - val_accuracy: 0.4883\n",
      "Epoch 221/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7244 - accuracy: 0.9988 - val_loss: 5.9511 - val_accuracy: 0.4884\n",
      "Epoch 222/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.7043 - accuracy: 0.9977 - val_loss: 5.9596 - val_accuracy: 0.4913\n",
      "Epoch 223/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6752 - accuracy: 0.9984 - val_loss: 5.9770 - val_accuracy: 0.4907\n",
      "Epoch 224/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6509 - accuracy: 0.9986 - val_loss: 5.9320 - val_accuracy: 0.4861\n",
      "Epoch 225/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6224 - accuracy: 0.9992 - val_loss: 5.9240 - val_accuracy: 0.4964\n",
      "Epoch 226/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5983 - accuracy: 0.9992 - val_loss: 5.9060 - val_accuracy: 0.4855\n",
      "Epoch 227/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.6267 - accuracy: 0.9792 - val_loss: 5.9091 - val_accuracy: 0.4893\n",
      "Epoch 228/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5833 - accuracy: 0.9884 - val_loss: 6.1215 - val_accuracy: 0.4579\n",
      "Epoch 229/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5333 - accuracy: 0.9978 - val_loss: 5.7884 - val_accuracy: 0.4989\n",
      "Epoch 230/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.5045 - accuracy: 0.9981 - val_loss: 5.7584 - val_accuracy: 0.4951\n",
      "Epoch 231/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4758 - accuracy: 0.9990 - val_loss: 5.9348 - val_accuracy: 0.4747\n",
      "Epoch 232/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4527 - accuracy: 0.9992 - val_loss: 5.7236 - val_accuracy: 0.4952\n",
      "Epoch 233/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4300 - accuracy: 0.9987 - val_loss: 5.7188 - val_accuracy: 0.4932\n",
      "Epoch 234/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.4087 - accuracy: 0.9982 - val_loss: 5.6937 - val_accuracy: 0.4947\n",
      "Epoch 235/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3798 - accuracy: 0.9993 - val_loss: 5.6610 - val_accuracy: 0.5007\n",
      "Epoch 236/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3537 - accuracy: 0.9993 - val_loss: 5.6560 - val_accuracy: 0.4928\n",
      "Epoch 237/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3381 - accuracy: 0.9972 - val_loss: 7.4833 - val_accuracy: 0.3684\n",
      "Epoch 238/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3412 - accuracy: 0.9912 - val_loss: 6.5961 - val_accuracy: 0.4132\n",
      "Epoch 239/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.3012 - accuracy: 0.9967 - val_loss: 5.6494 - val_accuracy: 0.4979\n",
      "Epoch 240/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2652 - accuracy: 0.9982 - val_loss: 5.6237 - val_accuracy: 0.4897\n",
      "Epoch 241/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2378 - accuracy: 0.9996 - val_loss: 5.5495 - val_accuracy: 0.5011\n",
      "Epoch 242/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2128 - accuracy: 0.9998 - val_loss: 5.5347 - val_accuracy: 0.4952\n",
      "Epoch 243/500\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 4.2020 - accuracy: 0.9966 - val_loss: 5.8404 - val_accuracy: 0.4652\n",
      "Epoch 244/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.2091 - accuracy: 0.9864 - val_loss: 5.5669 - val_accuracy: 0.4888\n",
      "Epoch 245/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1896 - accuracy: 0.9873 - val_loss: 5.9515 - val_accuracy: 0.4207\n",
      "Epoch 246/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1714 - accuracy: 0.9896 - val_loss: 6.7514 - val_accuracy: 0.4069\n",
      "Epoch 247/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1496 - accuracy: 0.9896 - val_loss: 5.4158 - val_accuracy: 0.4847\n",
      "Epoch 248/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.1330 - accuracy: 0.9839 - val_loss: 5.4378 - val_accuracy: 0.4924\n",
      "Epoch 249/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0762 - accuracy: 0.9943 - val_loss: 6.3821 - val_accuracy: 0.4276\n",
      "Epoch 250/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0469 - accuracy: 0.9961 - val_loss: 5.3034 - val_accuracy: 0.5043\n",
      "Epoch 251/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 4.0324 - accuracy: 0.9938 - val_loss: 5.2901 - val_accuracy: 0.5068\n",
      "Epoch 252/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9981 - accuracy: 0.9985 - val_loss: 5.3584 - val_accuracy: 0.5029\n",
      "Epoch 253/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9643 - accuracy: 1.0000 - val_loss: 5.2710 - val_accuracy: 0.5016\n",
      "Epoch 254/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9417 - accuracy: 0.9999 - val_loss: 5.2766 - val_accuracy: 0.5019\n",
      "Epoch 255/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.9197 - accuracy: 0.9999 - val_loss: 5.2944 - val_accuracy: 0.4995\n",
      "Epoch 256/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8974 - accuracy: 1.0000 - val_loss: 5.2433 - val_accuracy: 0.5000\n",
      "Epoch 257/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8790 - accuracy: 0.9993 - val_loss: 5.2134 - val_accuracy: 0.5041\n",
      "Epoch 258/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8576 - accuracy: 0.9996 - val_loss: 5.2242 - val_accuracy: 0.4989\n",
      "Epoch 259/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8380 - accuracy: 0.9985 - val_loss: 5.1670 - val_accuracy: 0.5052\n",
      "Epoch 260/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8128 - accuracy: 0.9997 - val_loss: 5.2660 - val_accuracy: 0.4933\n",
      "Epoch 261/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7899 - accuracy: 0.9997 - val_loss: 5.1349 - val_accuracy: 0.5048\n",
      "Epoch 262/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7728 - accuracy: 0.9992 - val_loss: 5.1286 - val_accuracy: 0.5027\n",
      "Epoch 263/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7490 - accuracy: 0.9998 - val_loss: 5.8964 - val_accuracy: 0.4539\n",
      "Epoch 264/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8171 - accuracy: 0.9729 - val_loss: 6.8488 - val_accuracy: 0.3771\n",
      "Epoch 265/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8613 - accuracy: 0.9470 - val_loss: 5.1210 - val_accuracy: 0.4836\n",
      "Epoch 266/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.8005 - accuracy: 0.9675 - val_loss: 5.1734 - val_accuracy: 0.4813\n",
      "Epoch 267/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7000 - accuracy: 0.9938 - val_loss: 4.9968 - val_accuracy: 0.5081\n",
      "Epoch 268/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6622 - accuracy: 0.9975 - val_loss: 4.9954 - val_accuracy: 0.5033\n",
      "Epoch 269/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6354 - accuracy: 0.9986 - val_loss: 10.5886 - val_accuracy: 0.3428\n",
      "Epoch 270/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6828 - accuracy: 0.9801 - val_loss: 5.4169 - val_accuracy: 0.4483\n",
      "Epoch 271/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.7292 - accuracy: 0.9553 - val_loss: 6.0830 - val_accuracy: 0.4019\n",
      "Epoch 272/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6741 - accuracy: 0.9720 - val_loss: 6.1384 - val_accuracy: 0.3929\n",
      "Epoch 273/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.6733 - accuracy: 0.9635 - val_loss: 6.0935 - val_accuracy: 0.4027\n",
      "Epoch 274/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5892 - accuracy: 0.9895 - val_loss: 4.9361 - val_accuracy: 0.4991\n",
      "Epoch 275/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5403 - accuracy: 0.9963 - val_loss: 4.8693 - val_accuracy: 0.5059\n",
      "Epoch 276/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.5047 - accuracy: 0.9990 - val_loss: 5.1886 - val_accuracy: 0.4685\n",
      "Epoch 277/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4925 - accuracy: 0.9970 - val_loss: 5.1072 - val_accuracy: 0.4711\n",
      "Epoch 278/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4926 - accuracy: 0.9913 - val_loss: 5.4599 - val_accuracy: 0.4432\n",
      "Epoch 279/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4389 - accuracy: 0.9987 - val_loss: 4.8353 - val_accuracy: 0.4980\n",
      "Epoch 280/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4107 - accuracy: 0.9997 - val_loss: 4.7967 - val_accuracy: 0.5035\n",
      "Epoch 281/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3989 - accuracy: 0.9982 - val_loss: 6.4783 - val_accuracy: 0.3784\n",
      "Epoch 282/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4127 - accuracy: 0.9916 - val_loss: 4.7762 - val_accuracy: 0.5076\n",
      "Epoch 283/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3595 - accuracy: 0.9989 - val_loss: 4.6883 - val_accuracy: 0.5052\n",
      "Epoch 284/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3324 - accuracy: 0.9998 - val_loss: 4.6832 - val_accuracy: 0.5077\n",
      "Epoch 285/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3107 - accuracy: 1.0000 - val_loss: 4.6540 - val_accuracy: 0.5139\n",
      "Epoch 286/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2908 - accuracy: 0.9999 - val_loss: 4.6451 - val_accuracy: 0.5135\n",
      "Epoch 287/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2732 - accuracy: 0.9999 - val_loss: 4.6518 - val_accuracy: 0.5045\n",
      "Epoch 288/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2551 - accuracy: 0.9997 - val_loss: 4.6170 - val_accuracy: 0.5119\n",
      "Epoch 289/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2367 - accuracy: 0.9999 - val_loss: 5.6221 - val_accuracy: 0.4352\n",
      "Epoch 290/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2228 - accuracy: 0.9993 - val_loss: 4.6417 - val_accuracy: 0.5129\n",
      "Epoch 291/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2064 - accuracy: 0.9991 - val_loss: 4.6751 - val_accuracy: 0.4988\n",
      "Epoch 292/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3097 - accuracy: 0.9532 - val_loss: 5.5416 - val_accuracy: 0.4092\n",
      "Epoch 293/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4442 - accuracy: 0.8940 - val_loss: 5.5737 - val_accuracy: 0.4184\n",
      "Epoch 294/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.4027 - accuracy: 0.9128 - val_loss: 5.2422 - val_accuracy: 0.4155\n",
      "Epoch 295/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.3023 - accuracy: 0.9530 - val_loss: 5.8280 - val_accuracy: 0.3871\n",
      "Epoch 296/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.2856 - accuracy: 0.9551 - val_loss: 5.6332 - val_accuracy: 0.4305\n",
      "Epoch 297/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1838 - accuracy: 0.9901 - val_loss: 4.6182 - val_accuracy: 0.4948\n",
      "Epoch 298/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1285 - accuracy: 0.9980 - val_loss: 4.6324 - val_accuracy: 0.4932\n",
      "Epoch 299/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0924 - accuracy: 0.9993 - val_loss: 4.4822 - val_accuracy: 0.4948\n",
      "Epoch 300/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0655 - accuracy: 0.9997 - val_loss: 4.4074 - val_accuracy: 0.5164\n",
      "Epoch 301/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0434 - accuracy: 0.9998 - val_loss: 4.4458 - val_accuracy: 0.5061\n",
      "Epoch 302/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0208 - accuracy: 0.9998 - val_loss: 4.3651 - val_accuracy: 0.5119\n",
      "Epoch 303/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0032 - accuracy: 0.9998 - val_loss: 4.3305 - val_accuracy: 0.5235\n",
      "Epoch 304/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9835 - accuracy: 0.9997 - val_loss: 4.3642 - val_accuracy: 0.5152\n",
      "Epoch 305/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9673 - accuracy: 0.9995 - val_loss: 5.2139 - val_accuracy: 0.4509\n",
      "Epoch 306/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9659 - accuracy: 0.9967 - val_loss: 4.9264 - val_accuracy: 0.4325\n",
      "Epoch 307/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9814 - accuracy: 0.9859 - val_loss: 7.0567 - val_accuracy: 0.3591\n",
      "Epoch 308/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1319 - accuracy: 0.9195 - val_loss: 5.8597 - val_accuracy: 0.3824\n",
      "Epoch 309/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.1384 - accuracy: 0.9180 - val_loss: 8.0479 - val_accuracy: 0.3749\n",
      "Epoch 310/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0812 - accuracy: 0.9417 - val_loss: 5.1097 - val_accuracy: 0.4516\n",
      "Epoch 311/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 3.0204 - accuracy: 0.9656 - val_loss: 4.3843 - val_accuracy: 0.4759\n",
      "Epoch 312/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9649 - accuracy: 0.9806 - val_loss: 4.7132 - val_accuracy: 0.4407\n",
      "Epoch 313/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.9217 - accuracy: 0.9904 - val_loss: 4.3268 - val_accuracy: 0.4888\n",
      "Epoch 314/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8692 - accuracy: 0.9963 - val_loss: 4.2278 - val_accuracy: 0.5172\n",
      "Epoch 315/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8269 - accuracy: 0.9996 - val_loss: 4.1612 - val_accuracy: 0.5271\n",
      "Epoch 316/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8025 - accuracy: 0.9994 - val_loss: 4.1493 - val_accuracy: 0.5180\n",
      "Epoch 317/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7783 - accuracy: 0.9998 - val_loss: 4.1077 - val_accuracy: 0.5252\n",
      "Epoch 318/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7564 - accuracy: 0.9999 - val_loss: 4.1624 - val_accuracy: 0.5169\n",
      "Epoch 319/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7424 - accuracy: 0.9994 - val_loss: 4.2393 - val_accuracy: 0.4911\n",
      "Epoch 320/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7211 - accuracy: 0.9998 - val_loss: 4.0644 - val_accuracy: 0.5217\n",
      "Epoch 321/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7010 - accuracy: 1.0000 - val_loss: 4.6031 - val_accuracy: 0.4639\n",
      "Epoch 322/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6878 - accuracy: 0.9998 - val_loss: 4.7402 - val_accuracy: 0.4503\n",
      "Epoch 323/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6709 - accuracy: 0.9997 - val_loss: 4.1452 - val_accuracy: 0.5103\n",
      "Epoch 324/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6591 - accuracy: 0.9997 - val_loss: 4.0031 - val_accuracy: 0.5260\n",
      "Epoch 325/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6470 - accuracy: 0.9989 - val_loss: 4.7823 - val_accuracy: 0.4749\n",
      "Epoch 326/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6544 - accuracy: 0.9955 - val_loss: 6.7208 - val_accuracy: 0.3912\n",
      "Epoch 327/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7479 - accuracy: 0.9573 - val_loss: 4.8113 - val_accuracy: 0.3969\n",
      "Epoch 328/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.8266 - accuracy: 0.9232 - val_loss: 4.8568 - val_accuracy: 0.4133\n",
      "Epoch 329/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.7667 - accuracy: 0.9535 - val_loss: 4.8745 - val_accuracy: 0.4377\n",
      "Epoch 330/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6818 - accuracy: 0.9846 - val_loss: 4.3533 - val_accuracy: 0.4764\n",
      "Epoch 331/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6236 - accuracy: 0.9956 - val_loss: 4.5016 - val_accuracy: 0.4592\n",
      "Epoch 332/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5798 - accuracy: 0.9996 - val_loss: 4.0134 - val_accuracy: 0.5089\n",
      "Epoch 333/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5532 - accuracy: 0.9993 - val_loss: 4.0204 - val_accuracy: 0.5200\n",
      "Epoch 334/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5386 - accuracy: 0.9979 - val_loss: 4.5630 - val_accuracy: 0.4520\n",
      "Epoch 335/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5288 - accuracy: 0.9976 - val_loss: 5.3667 - val_accuracy: 0.4069\n",
      "Epoch 336/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5590 - accuracy: 0.9874 - val_loss: 4.8046 - val_accuracy: 0.4400\n",
      "Epoch 337/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5352 - accuracy: 0.9904 - val_loss: 6.2789 - val_accuracy: 0.3928\n",
      "Epoch 338/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5821 - accuracy: 0.9707 - val_loss: 6.1230 - val_accuracy: 0.3727\n",
      "Epoch 339/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.6149 - accuracy: 0.9559 - val_loss: 5.3764 - val_accuracy: 0.3765\n",
      "Epoch 340/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5520 - accuracy: 0.9804 - val_loss: 3.9065 - val_accuracy: 0.4933\n",
      "Epoch 341/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.5049 - accuracy: 0.9922 - val_loss: 4.2416 - val_accuracy: 0.4936\n",
      "Epoch 342/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4571 - accuracy: 0.9981 - val_loss: 3.9123 - val_accuracy: 0.5063\n",
      "Epoch 343/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4318 - accuracy: 0.9983 - val_loss: 4.1350 - val_accuracy: 0.4869\n",
      "Epoch 344/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4072 - accuracy: 0.9991 - val_loss: 3.8792 - val_accuracy: 0.5144\n",
      "Epoch 345/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3878 - accuracy: 0.9991 - val_loss: 3.7718 - val_accuracy: 0.5243\n",
      "Epoch 346/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3650 - accuracy: 0.9996 - val_loss: 3.7014 - val_accuracy: 0.5395\n",
      "Epoch 347/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3477 - accuracy: 0.9995 - val_loss: 3.6754 - val_accuracy: 0.5391\n",
      "Epoch 348/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3286 - accuracy: 0.9998 - val_loss: 3.7070 - val_accuracy: 0.5343\n",
      "Epoch 349/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3126 - accuracy: 1.0000 - val_loss: 3.6524 - val_accuracy: 0.5328\n",
      "Epoch 350/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2970 - accuracy: 1.0000 - val_loss: 3.6515 - val_accuracy: 0.5401\n",
      "Epoch 351/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2890 - accuracy: 0.9996 - val_loss: 4.3305 - val_accuracy: 0.4563\n",
      "Epoch 352/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2777 - accuracy: 0.9997 - val_loss: 3.7360 - val_accuracy: 0.5201\n",
      "Epoch 353/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3846 - accuracy: 0.9615 - val_loss: 8.1022 - val_accuracy: 0.3621\n",
      "Epoch 354/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3962 - accuracy: 0.9659 - val_loss: 5.1676 - val_accuracy: 0.4340\n",
      "Epoch 355/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3374 - accuracy: 0.9881 - val_loss: 4.1897 - val_accuracy: 0.4541\n",
      "Epoch 356/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2844 - accuracy: 0.9979 - val_loss: 3.9471 - val_accuracy: 0.4784\n",
      "Epoch 357/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2718 - accuracy: 0.9954 - val_loss: 6.9820 - val_accuracy: 0.3589\n",
      "Epoch 358/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2430 - accuracy: 0.9988 - val_loss: 4.2335 - val_accuracy: 0.4525\n",
      "Epoch 359/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2154 - accuracy: 0.9993 - val_loss: 3.7462 - val_accuracy: 0.5133\n",
      "Epoch 360/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1953 - accuracy: 0.9996 - val_loss: 3.8255 - val_accuracy: 0.4960\n",
      "Epoch 361/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1825 - accuracy: 0.9996 - val_loss: 4.1110 - val_accuracy: 0.4793\n",
      "Epoch 362/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1643 - accuracy: 0.9997 - val_loss: 3.6290 - val_accuracy: 0.5233\n",
      "Epoch 363/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1553 - accuracy: 0.9989 - val_loss: 7.6444 - val_accuracy: 0.3485\n",
      "Epoch 364/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2032 - accuracy: 0.9866 - val_loss: 9.9129 - val_accuracy: 0.3336\n",
      "Epoch 365/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2211 - accuracy: 0.9824 - val_loss: 3.9746 - val_accuracy: 0.4515\n",
      "Epoch 366/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1929 - accuracy: 0.9908 - val_loss: 4.4679 - val_accuracy: 0.4115\n",
      "Epoch 367/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1399 - accuracy: 0.9991 - val_loss: 3.7995 - val_accuracy: 0.4872\n",
      "Epoch 368/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1132 - accuracy: 0.9994 - val_loss: 3.7950 - val_accuracy: 0.5013\n",
      "Epoch 369/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0888 - accuracy: 0.9998 - val_loss: 3.6993 - val_accuracy: 0.4856\n",
      "Epoch 370/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0763 - accuracy: 0.9997 - val_loss: 3.6462 - val_accuracy: 0.5005\n",
      "Epoch 371/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0654 - accuracy: 0.9997 - val_loss: 3.7311 - val_accuracy: 0.5163\n",
      "Epoch 372/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0470 - accuracy: 0.9999 - val_loss: 3.4623 - val_accuracy: 0.5216\n",
      "Epoch 373/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0336 - accuracy: 0.9996 - val_loss: 3.9767 - val_accuracy: 0.4775\n",
      "Epoch 374/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0524 - accuracy: 0.9927 - val_loss: 9.1674 - val_accuracy: 0.3459\n",
      "Epoch 375/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0975 - accuracy: 0.9857 - val_loss: 4.3266 - val_accuracy: 0.4151\n",
      "Epoch 376/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0506 - accuracy: 0.9975 - val_loss: 3.9264 - val_accuracy: 0.4535\n",
      "Epoch 377/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0191 - accuracy: 0.9994 - val_loss: 3.6761 - val_accuracy: 0.4959\n",
      "Epoch 378/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9931 - accuracy: 0.9997 - val_loss: 3.4119 - val_accuracy: 0.5137\n",
      "Epoch 379/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9756 - accuracy: 1.0000 - val_loss: 3.5074 - val_accuracy: 0.5171\n",
      "Epoch 380/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9691 - accuracy: 0.9997 - val_loss: 3.5002 - val_accuracy: 0.5132\n",
      "Epoch 381/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9654 - accuracy: 0.9962 - val_loss: 5.6934 - val_accuracy: 0.3549\n",
      "Epoch 382/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0290 - accuracy: 0.9841 - val_loss: 4.6430 - val_accuracy: 0.3983\n",
      "Epoch 383/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9900 - accuracy: 0.9964 - val_loss: 4.2214 - val_accuracy: 0.4313\n",
      "Epoch 384/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9582 - accuracy: 0.9988 - val_loss: 3.8607 - val_accuracy: 0.4597\n",
      "Epoch 385/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9291 - accuracy: 0.9999 - val_loss: 4.1010 - val_accuracy: 0.4519\n",
      "Epoch 386/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9053 - accuracy: 1.0000 - val_loss: 4.2876 - val_accuracy: 0.4423\n",
      "Epoch 387/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8898 - accuracy: 1.0000 - val_loss: 3.6534 - val_accuracy: 0.5072\n",
      "Epoch 388/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8776 - accuracy: 1.0000 - val_loss: 3.5929 - val_accuracy: 0.4876\n",
      "Epoch 389/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8972 - accuracy: 0.9963 - val_loss: 4.3819 - val_accuracy: 0.4005\n",
      "Epoch 390/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9223 - accuracy: 0.9928 - val_loss: 5.1262 - val_accuracy: 0.3879\n",
      "Epoch 391/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8779 - accuracy: 0.9993 - val_loss: 3.4273 - val_accuracy: 0.5183\n",
      "Epoch 392/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8513 - accuracy: 0.9999 - val_loss: 3.3771 - val_accuracy: 0.5061\n",
      "Epoch 393/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8353 - accuracy: 1.0000 - val_loss: 3.3405 - val_accuracy: 0.5136\n",
      "Epoch 394/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8206 - accuracy: 1.0000 - val_loss: 3.2686 - val_accuracy: 0.5317\n",
      "Epoch 395/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8123 - accuracy: 0.9997 - val_loss: 4.2528 - val_accuracy: 0.4157\n",
      "Epoch 396/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8438 - accuracy: 0.9921 - val_loss: 9.5362 - val_accuracy: 0.3347\n",
      "Epoch 397/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8961 - accuracy: 0.9818 - val_loss: 4.1466 - val_accuracy: 0.4336\n",
      "Epoch 398/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8472 - accuracy: 0.9974 - val_loss: 4.5157 - val_accuracy: 0.3949\n",
      "Epoch 399/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8256 - accuracy: 0.9985 - val_loss: 3.8008 - val_accuracy: 0.4655\n",
      "Epoch 400/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7951 - accuracy: 0.9999 - val_loss: 3.2810 - val_accuracy: 0.5273\n",
      "Epoch 401/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7748 - accuracy: 0.9998 - val_loss: 3.4301 - val_accuracy: 0.5033\n",
      "Epoch 402/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7590 - accuracy: 1.0000 - val_loss: 3.2865 - val_accuracy: 0.5260\n",
      "Epoch 403/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7455 - accuracy: 0.9999 - val_loss: 3.4565 - val_accuracy: 0.5032\n",
      "Epoch 404/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7358 - accuracy: 1.0000 - val_loss: 3.6646 - val_accuracy: 0.4747\n",
      "Epoch 405/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7341 - accuracy: 0.9998 - val_loss: 3.7205 - val_accuracy: 0.4772\n",
      "Epoch 406/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7232 - accuracy: 0.9999 - val_loss: 4.6761 - val_accuracy: 0.4433\n",
      "Epoch 407/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7199 - accuracy: 0.9994 - val_loss: 7.3126 - val_accuracy: 0.3467\n",
      "Epoch 408/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7150 - accuracy: 0.9996 - val_loss: 4.3807 - val_accuracy: 0.4141\n",
      "Epoch 409/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7087 - accuracy: 0.9997 - val_loss: 3.4684 - val_accuracy: 0.4735\n",
      "Epoch 410/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6955 - accuracy: 1.0000 - val_loss: 3.2254 - val_accuracy: 0.5015\n",
      "Epoch 411/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6858 - accuracy: 0.9996 - val_loss: 3.7360 - val_accuracy: 0.4403\n",
      "Epoch 412/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6729 - accuracy: 1.0000 - val_loss: 3.1804 - val_accuracy: 0.5219\n",
      "Epoch 413/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6619 - accuracy: 0.9999 - val_loss: 3.6818 - val_accuracy: 0.4617\n",
      "Epoch 414/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6726 - accuracy: 0.9977 - val_loss: 5.8715 - val_accuracy: 0.3641\n",
      "Epoch 415/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6885 - accuracy: 0.9972 - val_loss: 5.7910 - val_accuracy: 0.3620\n",
      "Epoch 416/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6887 - accuracy: 0.9964 - val_loss: 7.8344 - val_accuracy: 0.3524\n",
      "Epoch 417/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6698 - accuracy: 0.9988 - val_loss: 3.3729 - val_accuracy: 0.4861\n",
      "Epoch 418/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6387 - accuracy: 1.0000 - val_loss: 3.3285 - val_accuracy: 0.5043\n",
      "Epoch 419/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6189 - accuracy: 1.0000 - val_loss: 3.8347 - val_accuracy: 0.4512\n",
      "Epoch 420/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6071 - accuracy: 1.0000 - val_loss: 3.1697 - val_accuracy: 0.5115\n",
      "Epoch 421/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5969 - accuracy: 1.0000 - val_loss: 3.6947 - val_accuracy: 0.4713\n",
      "Epoch 422/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5949 - accuracy: 1.0000 - val_loss: 3.6600 - val_accuracy: 0.4775\n",
      "Epoch 423/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5945 - accuracy: 1.0000 - val_loss: 6.5080 - val_accuracy: 0.3480\n",
      "Epoch 424/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5883 - accuracy: 0.9999 - val_loss: 3.4213 - val_accuracy: 0.4704\n",
      "Epoch 425/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5744 - accuracy: 0.9999 - val_loss: 3.2513 - val_accuracy: 0.5012\n",
      "Epoch 426/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5724 - accuracy: 0.9993 - val_loss: 4.0498 - val_accuracy: 0.3736\n",
      "Epoch 427/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5786 - accuracy: 0.9996 - val_loss: 6.9342 - val_accuracy: 0.3573\n",
      "Epoch 428/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5689 - accuracy: 0.9996 - val_loss: 3.2257 - val_accuracy: 0.4888\n",
      "Epoch 429/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5562 - accuracy: 0.9997 - val_loss: 3.5140 - val_accuracy: 0.4733\n",
      "Epoch 430/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5408 - accuracy: 1.0000 - val_loss: 3.0132 - val_accuracy: 0.5325\n",
      "Epoch 431/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5280 - accuracy: 1.0000 - val_loss: 3.2528 - val_accuracy: 0.4899\n",
      "Epoch 432/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5208 - accuracy: 1.0000 - val_loss: 3.5190 - val_accuracy: 0.4601\n",
      "Epoch 433/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5172 - accuracy: 1.0000 - val_loss: 3.3154 - val_accuracy: 0.4703\n",
      "Epoch 434/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5435 - accuracy: 0.9940 - val_loss: 7.8333 - val_accuracy: 0.3373\n",
      "Epoch 435/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0946 - accuracy: 0.8085 - val_loss: 8.6057 - val_accuracy: 0.3453\n",
      "Epoch 436/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.8951 - accuracy: 0.9081 - val_loss: 5.9474 - val_accuracy: 0.3657\n",
      "Epoch 437/500\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 1.7150 - accuracy: 0.9878 - val_loss: 3.1508 - val_accuracy: 0.5397\n",
      "Epoch 438/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6466 - accuracy: 0.9997 - val_loss: 2.9330 - val_accuracy: 0.5740\n",
      "Epoch 439/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6107 - accuracy: 1.0000 - val_loss: 2.8486 - val_accuracy: 0.5828\n",
      "Epoch 440/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5848 - accuracy: 1.0000 - val_loss: 2.7843 - val_accuracy: 0.5859\n",
      "Epoch 441/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5629 - accuracy: 1.0000 - val_loss: 2.8319 - val_accuracy: 0.5696\n",
      "Epoch 442/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5439 - accuracy: 1.0000 - val_loss: 2.8326 - val_accuracy: 0.5720\n",
      "Epoch 443/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5266 - accuracy: 1.0000 - val_loss: 2.7537 - val_accuracy: 0.5799\n",
      "Epoch 444/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5110 - accuracy: 1.0000 - val_loss: 2.7065 - val_accuracy: 0.5804\n",
      "Epoch 445/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4986 - accuracy: 1.0000 - val_loss: 2.7268 - val_accuracy: 0.5791\n",
      "Epoch 446/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4862 - accuracy: 1.0000 - val_loss: 2.7615 - val_accuracy: 0.5652\n",
      "Epoch 447/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4768 - accuracy: 1.0000 - val_loss: 2.7689 - val_accuracy: 0.5596\n",
      "Epoch 448/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4682 - accuracy: 1.0000 - val_loss: 2.8376 - val_accuracy: 0.5564\n",
      "Epoch 449/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4583 - accuracy: 1.0000 - val_loss: 2.9561 - val_accuracy: 0.5449\n",
      "Epoch 450/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4472 - accuracy: 1.0000 - val_loss: 3.0741 - val_accuracy: 0.5499\n",
      "Epoch 451/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4370 - accuracy: 1.0000 - val_loss: 3.1839 - val_accuracy: 0.5076\n",
      "Epoch 452/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4334 - accuracy: 1.0000 - val_loss: 3.1149 - val_accuracy: 0.5115\n",
      "Epoch 453/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4272 - accuracy: 0.9999 - val_loss: 3.5670 - val_accuracy: 0.4427\n",
      "Epoch 454/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7518 - accuracy: 0.8934 - val_loss: 15.5816 - val_accuracy: 0.3344\n",
      "Epoch 455/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9746 - accuracy: 0.8390 - val_loss: 5.9120 - val_accuracy: 0.3785\n",
      "Epoch 456/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6834 - accuracy: 0.9710 - val_loss: 5.1135 - val_accuracy: 0.3841\n",
      "Epoch 457/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5883 - accuracy: 0.9984 - val_loss: 2.8300 - val_accuracy: 0.5685\n",
      "Epoch 458/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5454 - accuracy: 1.0000 - val_loss: 2.6074 - val_accuracy: 0.6095\n",
      "Epoch 459/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5163 - accuracy: 1.0000 - val_loss: 2.6265 - val_accuracy: 0.6088\n",
      "Epoch 460/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4920 - accuracy: 1.0000 - val_loss: 2.6590 - val_accuracy: 0.5996\n",
      "Epoch 461/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4712 - accuracy: 1.0000 - val_loss: 2.6297 - val_accuracy: 0.5993\n",
      "Epoch 462/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4524 - accuracy: 1.0000 - val_loss: 2.5556 - val_accuracy: 0.6084\n",
      "Epoch 463/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4359 - accuracy: 1.0000 - val_loss: 2.7626 - val_accuracy: 0.5793\n",
      "Epoch 464/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4210 - accuracy: 1.0000 - val_loss: 2.5895 - val_accuracy: 0.5961\n",
      "Epoch 465/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4076 - accuracy: 1.0000 - val_loss: 2.5393 - val_accuracy: 0.6045\n",
      "Epoch 466/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3960 - accuracy: 1.0000 - val_loss: 2.5993 - val_accuracy: 0.5937\n",
      "Epoch 467/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3854 - accuracy: 1.0000 - val_loss: 2.9059 - val_accuracy: 0.5291\n",
      "Epoch 468/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3763 - accuracy: 1.0000 - val_loss: 2.5978 - val_accuracy: 0.5856\n",
      "Epoch 469/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3654 - accuracy: 1.0000 - val_loss: 2.5743 - val_accuracy: 0.5803\n",
      "Epoch 470/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3573 - accuracy: 1.0000 - val_loss: 2.6904 - val_accuracy: 0.5688\n",
      "Epoch 471/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3534 - accuracy: 1.0000 - val_loss: 2.9971 - val_accuracy: 0.5016\n",
      "Epoch 472/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3489 - accuracy: 1.0000 - val_loss: 2.6268 - val_accuracy: 0.5592\n",
      "Epoch 473/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3503 - accuracy: 0.9997 - val_loss: 4.9294 - val_accuracy: 0.3676\n",
      "Epoch 474/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.0579 - accuracy: 0.7642 - val_loss: 21.2974 - val_accuracy: 0.3339\n",
      "Epoch 475/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.7428 - accuracy: 0.9156 - val_loss: 3.6493 - val_accuracy: 0.4681\n",
      "Epoch 476/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5561 - accuracy: 0.9920 - val_loss: 2.8429 - val_accuracy: 0.5687\n",
      "Epoch 477/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4974 - accuracy: 0.9999 - val_loss: 2.5211 - val_accuracy: 0.6245\n",
      "Epoch 478/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4657 - accuracy: 1.0000 - val_loss: 2.4724 - val_accuracy: 0.6293\n",
      "Epoch 479/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4412 - accuracy: 1.0000 - val_loss: 2.5050 - val_accuracy: 0.6203\n",
      "Epoch 480/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4201 - accuracy: 1.0000 - val_loss: 2.5832 - val_accuracy: 0.5979\n",
      "Epoch 481/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4007 - accuracy: 1.0000 - val_loss: 2.5602 - val_accuracy: 0.6003\n",
      "Epoch 482/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3836 - accuracy: 1.0000 - val_loss: 2.4935 - val_accuracy: 0.6011\n",
      "Epoch 483/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3687 - accuracy: 1.0000 - val_loss: 2.8162 - val_accuracy: 0.5545\n",
      "Epoch 484/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3550 - accuracy: 1.0000 - val_loss: 2.5822 - val_accuracy: 0.5769\n",
      "Epoch 485/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3424 - accuracy: 1.0000 - val_loss: 2.6215 - val_accuracy: 0.5767\n",
      "Epoch 486/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3310 - accuracy: 1.0000 - val_loss: 2.7716 - val_accuracy: 0.5645\n",
      "Epoch 487/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3209 - accuracy: 1.0000 - val_loss: 2.5194 - val_accuracy: 0.5912\n",
      "Epoch 488/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3120 - accuracy: 1.0000 - val_loss: 2.5372 - val_accuracy: 0.5840\n",
      "Epoch 489/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3066 - accuracy: 1.0000 - val_loss: 3.4673 - val_accuracy: 0.4667\n",
      "Epoch 490/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4645 - accuracy: 0.9458 - val_loss: 44.0695 - val_accuracy: 0.3333\n",
      "Epoch 491/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.9834 - accuracy: 0.7841 - val_loss: 12.2480 - val_accuracy: 0.3332\n",
      "Epoch 492/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.6124 - accuracy: 0.9547 - val_loss: 4.0764 - val_accuracy: 0.4215\n",
      "Epoch 493/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.5101 - accuracy: 0.9937 - val_loss: 3.0446 - val_accuracy: 0.5368\n",
      "Epoch 494/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4551 - accuracy: 1.0000 - val_loss: 2.8594 - val_accuracy: 0.5636\n",
      "Epoch 495/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.4233 - accuracy: 1.0000 - val_loss: 2.6843 - val_accuracy: 0.5856\n",
      "Epoch 496/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3980 - accuracy: 1.0000 - val_loss: 2.5327 - val_accuracy: 0.5961\n",
      "Epoch 497/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3761 - accuracy: 1.0000 - val_loss: 2.5579 - val_accuracy: 0.5924\n",
      "Epoch 498/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3568 - accuracy: 1.0000 - val_loss: 2.9554 - val_accuracy: 0.5343\n",
      "Epoch 499/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3397 - accuracy: 1.0000 - val_loss: 2.5879 - val_accuracy: 0.5855\n",
      "Epoch 500/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 1.3246 - accuracy: 1.0000 - val_loss: 2.6974 - val_accuracy: 0.5607\n",
      "Time: 180.22986435890198\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Traits_Model_50disc.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#50 discrete\n",
    "################################################################################################################################################\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test  = train_test_split(y,X50,traits_disc50,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = disc_subset(ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test)\n",
    "\n",
    "model.save(filepath='./Trained_Models/Trained_Traits_Model_50disc.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ugE2A-JE0oz",
    "outputId": "e87f74a4-4ed1-4a84-d202-9398f05e9cf1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 20, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 18, 250)      45000       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 18, 250)     1000        ['conv1d_9[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 16, 250)      187500      ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 16, 250)     1000        ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 14, 250)      187500      ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 14, 250)     1000        ['conv1d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 4, 250)      0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 1000)         0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " dense_32_input (InputLayer)    [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 125)          125125      ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 150)          450000      ['dense_32_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 125)          0           ['dense_35[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 150)         600         ['dense_32[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 125)          15750       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 150)          22500       ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 125)          0           ['dense_36[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 150)         600         ['dense_33[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 50)           6300        ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 50)           7550        ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 50)           0           ['dense_37[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_3 (LinearW)           (None, 50)           2           ['dense_34[0][0]',               \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 50)           2550        ['linear_w_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 3)            153         ['dense_38[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,054,130\n",
      "Trainable params: 1,052,030\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 2s 12ms/step - loss: 13.3363 - accuracy: 0.3359 - val_loss: 13.1357 - val_accuracy: 0.3460\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 13.1658 - accuracy: 0.3510 - val_loss: 13.0790 - val_accuracy: 0.3633\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 13.0792 - accuracy: 0.3690 - val_loss: 13.0187 - val_accuracy: 0.3971\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 13.0141 - accuracy: 0.3920 - val_loss: 12.9587 - val_accuracy: 0.4296\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.9529 - accuracy: 0.4057 - val_loss: 12.8986 - val_accuracy: 0.4512\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.8960 - accuracy: 0.4196 - val_loss: 12.8402 - val_accuracy: 0.4705\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.8369 - accuracy: 0.4392 - val_loss: 12.7829 - val_accuracy: 0.4841\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.7824 - accuracy: 0.4485 - val_loss: 12.7247 - val_accuracy: 0.5013\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.7248 - accuracy: 0.4611 - val_loss: 12.6666 - val_accuracy: 0.5147\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.6659 - accuracy: 0.4783 - val_loss: 12.6077 - val_accuracy: 0.5312\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.6080 - accuracy: 0.4946 - val_loss: 12.5485 - val_accuracy: 0.5440\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.5523 - accuracy: 0.5054 - val_loss: 12.4909 - val_accuracy: 0.5563\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.4932 - accuracy: 0.5182 - val_loss: 12.4336 - val_accuracy: 0.5655\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.4390 - accuracy: 0.5256 - val_loss: 12.3791 - val_accuracy: 0.5749\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.3804 - accuracy: 0.5413 - val_loss: 12.3224 - val_accuracy: 0.5824\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.3301 - accuracy: 0.5452 - val_loss: 12.2667 - val_accuracy: 0.5929\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.2729 - accuracy: 0.5587 - val_loss: 12.2106 - val_accuracy: 0.6032\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.2194 - accuracy: 0.5627 - val_loss: 12.1562 - val_accuracy: 0.6112\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.1680 - accuracy: 0.5689 - val_loss: 12.1031 - val_accuracy: 0.6184\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.1131 - accuracy: 0.5789 - val_loss: 12.0507 - val_accuracy: 0.6219\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.0625 - accuracy: 0.5825 - val_loss: 11.9980 - val_accuracy: 0.6275\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.0122 - accuracy: 0.5908 - val_loss: 11.9447 - val_accuracy: 0.6320\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.9640 - accuracy: 0.5934 - val_loss: 11.8930 - val_accuracy: 0.6399\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.9124 - accuracy: 0.6004 - val_loss: 11.8410 - val_accuracy: 0.6445\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.8638 - accuracy: 0.6069 - val_loss: 11.7910 - val_accuracy: 0.6489\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.8096 - accuracy: 0.6154 - val_loss: 11.7388 - val_accuracy: 0.6565\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.7597 - accuracy: 0.6212 - val_loss: 11.6892 - val_accuracy: 0.6580\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.7070 - accuracy: 0.6287 - val_loss: 11.6383 - val_accuracy: 0.6628\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.6605 - accuracy: 0.6304 - val_loss: 11.5875 - val_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.6046 - accuracy: 0.6411 - val_loss: 11.5363 - val_accuracy: 0.6711\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.5628 - accuracy: 0.6395 - val_loss: 11.4845 - val_accuracy: 0.6759\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.5094 - accuracy: 0.6467 - val_loss: 11.4338 - val_accuracy: 0.6807\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.4612 - accuracy: 0.6543 - val_loss: 11.3821 - val_accuracy: 0.6844\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.4028 - accuracy: 0.6615 - val_loss: 11.3310 - val_accuracy: 0.6931\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.3564 - accuracy: 0.6662 - val_loss: 11.2792 - val_accuracy: 0.6984\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.3065 - accuracy: 0.6716 - val_loss: 11.2282 - val_accuracy: 0.7021\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.2582 - accuracy: 0.6732 - val_loss: 11.1756 - val_accuracy: 0.7096\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.2036 - accuracy: 0.6824 - val_loss: 11.1231 - val_accuracy: 0.7176\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.1511 - accuracy: 0.6884 - val_loss: 11.0705 - val_accuracy: 0.7235\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.1043 - accuracy: 0.6984 - val_loss: 11.0184 - val_accuracy: 0.7295\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.0511 - accuracy: 0.7017 - val_loss: 10.9665 - val_accuracy: 0.7359\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.9964 - accuracy: 0.7075 - val_loss: 10.9124 - val_accuracy: 0.7467\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.9472 - accuracy: 0.7135 - val_loss: 10.8606 - val_accuracy: 0.7529\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.8924 - accuracy: 0.7213 - val_loss: 10.8092 - val_accuracy: 0.7596\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.8425 - accuracy: 0.7254 - val_loss: 10.7562 - val_accuracy: 0.7651\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.7940 - accuracy: 0.7280 - val_loss: 10.7056 - val_accuracy: 0.7709\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.7438 - accuracy: 0.7346 - val_loss: 10.6551 - val_accuracy: 0.7748\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.6930 - accuracy: 0.7379 - val_loss: 10.6053 - val_accuracy: 0.7793\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.6433 - accuracy: 0.7442 - val_loss: 10.5553 - val_accuracy: 0.7860\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.5964 - accuracy: 0.7472 - val_loss: 10.5062 - val_accuracy: 0.7905\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.5483 - accuracy: 0.7546 - val_loss: 10.4578 - val_accuracy: 0.7969\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.4963 - accuracy: 0.7594 - val_loss: 10.4099 - val_accuracy: 0.8012\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.4494 - accuracy: 0.7626 - val_loss: 10.3627 - val_accuracy: 0.8069\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.4051 - accuracy: 0.7694 - val_loss: 10.3163 - val_accuracy: 0.8093\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.3562 - accuracy: 0.7718 - val_loss: 10.2693 - val_accuracy: 0.8124\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.3100 - accuracy: 0.7750 - val_loss: 10.2234 - val_accuracy: 0.8144\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.2597 - accuracy: 0.7810 - val_loss: 10.1792 - val_accuracy: 0.8167\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.2195 - accuracy: 0.7848 - val_loss: 10.1346 - val_accuracy: 0.8212\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.1725 - accuracy: 0.7876 - val_loss: 10.0892 - val_accuracy: 0.8247\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.1301 - accuracy: 0.7900 - val_loss: 10.0459 - val_accuracy: 0.8275\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.0798 - accuracy: 0.7978 - val_loss: 10.0017 - val_accuracy: 0.8300\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.0388 - accuracy: 0.7994 - val_loss: 9.9572 - val_accuracy: 0.8347\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.9948 - accuracy: 0.8001 - val_loss: 9.9139 - val_accuracy: 0.8360\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.9509 - accuracy: 0.8044 - val_loss: 9.8712 - val_accuracy: 0.8389\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.9081 - accuracy: 0.8064 - val_loss: 9.8294 - val_accuracy: 0.8416\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.8604 - accuracy: 0.8143 - val_loss: 9.7859 - val_accuracy: 0.8440\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.8132 - accuracy: 0.8182 - val_loss: 9.7446 - val_accuracy: 0.8459\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.7756 - accuracy: 0.8194 - val_loss: 9.7039 - val_accuracy: 0.8477\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.7308 - accuracy: 0.8254 - val_loss: 9.6594 - val_accuracy: 0.8503\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.6886 - accuracy: 0.8235 - val_loss: 9.6195 - val_accuracy: 0.8513\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.6428 - accuracy: 0.8316 - val_loss: 9.5761 - val_accuracy: 0.8536\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.6098 - accuracy: 0.8305 - val_loss: 9.5349 - val_accuracy: 0.8549\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.5640 - accuracy: 0.8318 - val_loss: 9.4942 - val_accuracy: 0.8581\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.5215 - accuracy: 0.8352 - val_loss: 9.4540 - val_accuracy: 0.8591\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.4832 - accuracy: 0.8367 - val_loss: 9.4122 - val_accuracy: 0.8607\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.4403 - accuracy: 0.8434 - val_loss: 9.3728 - val_accuracy: 0.8645\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.3970 - accuracy: 0.8414 - val_loss: 9.3318 - val_accuracy: 0.8657\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.3576 - accuracy: 0.8444 - val_loss: 9.2914 - val_accuracy: 0.8680\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.3185 - accuracy: 0.8452 - val_loss: 9.2519 - val_accuracy: 0.8700\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.2790 - accuracy: 0.8458 - val_loss: 9.2114 - val_accuracy: 0.8720\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.2351 - accuracy: 0.8496 - val_loss: 9.1705 - val_accuracy: 0.8747\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.1936 - accuracy: 0.8559 - val_loss: 9.1319 - val_accuracy: 0.8751\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.1545 - accuracy: 0.8560 - val_loss: 9.0908 - val_accuracy: 0.8781\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.1119 - accuracy: 0.8597 - val_loss: 9.0512 - val_accuracy: 0.8779\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.0734 - accuracy: 0.8596 - val_loss: 9.0130 - val_accuracy: 0.8804\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.0345 - accuracy: 0.8606 - val_loss: 8.9744 - val_accuracy: 0.8803\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.9939 - accuracy: 0.8656 - val_loss: 8.9356 - val_accuracy: 0.8835\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.9573 - accuracy: 0.8650 - val_loss: 8.8979 - val_accuracy: 0.8840\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.9148 - accuracy: 0.8669 - val_loss: 8.8581 - val_accuracy: 0.8855\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.8797 - accuracy: 0.8657 - val_loss: 8.8196 - val_accuracy: 0.8869\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.8349 - accuracy: 0.8715 - val_loss: 8.7815 - val_accuracy: 0.8879\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.8027 - accuracy: 0.8702 - val_loss: 8.7438 - val_accuracy: 0.8881\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.7631 - accuracy: 0.8727 - val_loss: 8.7052 - val_accuracy: 0.8896\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.7251 - accuracy: 0.8722 - val_loss: 8.6678 - val_accuracy: 0.8901\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.6822 - accuracy: 0.8766 - val_loss: 8.6298 - val_accuracy: 0.8917\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.6432 - accuracy: 0.8791 - val_loss: 8.5922 - val_accuracy: 0.8921\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.6044 - accuracy: 0.8810 - val_loss: 8.5551 - val_accuracy: 0.8933\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.5701 - accuracy: 0.8801 - val_loss: 8.5178 - val_accuracy: 0.8941\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.5327 - accuracy: 0.8826 - val_loss: 8.4812 - val_accuracy: 0.8948\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.4933 - accuracy: 0.8840 - val_loss: 8.4442 - val_accuracy: 0.8960\n",
      "Time: 72.28256916999817\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_50disc_20SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#50 discrete, 20 SNPs\n",
    "################################################################################################################################################\n",
    "\n",
    "# subset the SNPs\n",
    "X20=X[:,0:20,:]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test  = train_test_split(y,X20,traits_disc50,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_disc_subset(ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test)\n",
    "\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_50disc_20SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "liXDwXzOE0o0",
    "outputId": "3551ebd9-eb0b-4411-8831-dc32ee284157",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40_input (InputLayer)  [(None, 1000)]           0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 150)               150000    \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 150)               22500     \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 150)              600       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 50)                7550      \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 181,403\n",
      "Trainable params: 180,803\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 9.2222 - accuracy: 0.3365 - val_loss: 8.9038 - val_accuracy: 0.3333\n",
      "Epoch 2/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 9.0551 - accuracy: 0.3388 - val_loss: 8.8894 - val_accuracy: 0.3304\n",
      "Epoch 3/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.9560 - accuracy: 0.3431 - val_loss: 8.8856 - val_accuracy: 0.3336\n",
      "Epoch 4/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.8938 - accuracy: 0.3458 - val_loss: 8.8694 - val_accuracy: 0.3313\n",
      "Epoch 5/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.8460 - accuracy: 0.3486 - val_loss: 8.8403 - val_accuracy: 0.3389\n",
      "Epoch 6/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.8084 - accuracy: 0.3520 - val_loss: 8.8205 - val_accuracy: 0.3392\n",
      "Epoch 7/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.7758 - accuracy: 0.3544 - val_loss: 8.7957 - val_accuracy: 0.3377\n",
      "Epoch 8/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.7463 - accuracy: 0.3561 - val_loss: 8.7709 - val_accuracy: 0.3428\n",
      "Epoch 9/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.7166 - accuracy: 0.3596 - val_loss: 8.7498 - val_accuracy: 0.3352\n",
      "Epoch 10/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.6906 - accuracy: 0.3605 - val_loss: 8.7275 - val_accuracy: 0.3385\n",
      "Epoch 11/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.6656 - accuracy: 0.3627 - val_loss: 8.7086 - val_accuracy: 0.3355\n",
      "Epoch 12/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.6412 - accuracy: 0.3643 - val_loss: 8.6852 - val_accuracy: 0.3372\n",
      "Epoch 13/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.6185 - accuracy: 0.3652 - val_loss: 8.6630 - val_accuracy: 0.3371\n",
      "Epoch 14/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.5967 - accuracy: 0.3673 - val_loss: 8.6439 - val_accuracy: 0.3369\n",
      "Epoch 15/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.5730 - accuracy: 0.3685 - val_loss: 8.6225 - val_accuracy: 0.3369\n",
      "Epoch 16/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.5497 - accuracy: 0.3740 - val_loss: 8.6021 - val_accuracy: 0.3384\n",
      "Epoch 17/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.5305 - accuracy: 0.3736 - val_loss: 8.5857 - val_accuracy: 0.3355\n",
      "Epoch 18/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.5058 - accuracy: 0.3816 - val_loss: 8.5666 - val_accuracy: 0.3353\n",
      "Epoch 19/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.4867 - accuracy: 0.3824 - val_loss: 8.5478 - val_accuracy: 0.3364\n",
      "Epoch 20/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.4657 - accuracy: 0.3834 - val_loss: 8.5305 - val_accuracy: 0.3351\n",
      "Epoch 21/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.4460 - accuracy: 0.3836 - val_loss: 8.5109 - val_accuracy: 0.3356\n",
      "Epoch 22/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.4248 - accuracy: 0.3892 - val_loss: 8.4937 - val_accuracy: 0.3317\n",
      "Epoch 23/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.4040 - accuracy: 0.3898 - val_loss: 8.4738 - val_accuracy: 0.3337\n",
      "Epoch 24/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.3849 - accuracy: 0.3929 - val_loss: 8.4576 - val_accuracy: 0.3333\n",
      "Epoch 25/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.3654 - accuracy: 0.3949 - val_loss: 8.4391 - val_accuracy: 0.3363\n",
      "Epoch 26/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.3472 - accuracy: 0.3984 - val_loss: 8.4211 - val_accuracy: 0.3356\n",
      "Epoch 27/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.3274 - accuracy: 0.3997 - val_loss: 8.4036 - val_accuracy: 0.3359\n",
      "Epoch 28/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.3075 - accuracy: 0.4017 - val_loss: 8.3878 - val_accuracy: 0.3325\n",
      "Epoch 29/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.2898 - accuracy: 0.4037 - val_loss: 8.3682 - val_accuracy: 0.3343\n",
      "Epoch 30/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.2697 - accuracy: 0.4070 - val_loss: 8.3534 - val_accuracy: 0.3348\n",
      "Epoch 31/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.2521 - accuracy: 0.4091 - val_loss: 8.3352 - val_accuracy: 0.3316\n",
      "Epoch 32/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.2328 - accuracy: 0.4122 - val_loss: 8.3183 - val_accuracy: 0.3347\n",
      "Epoch 33/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.2148 - accuracy: 0.4148 - val_loss: 8.3023 - val_accuracy: 0.3351\n",
      "Epoch 34/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.1960 - accuracy: 0.4135 - val_loss: 8.2866 - val_accuracy: 0.3360\n",
      "Epoch 35/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.1774 - accuracy: 0.4177 - val_loss: 8.2680 - val_accuracy: 0.3349\n",
      "Epoch 36/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.1594 - accuracy: 0.4168 - val_loss: 8.2521 - val_accuracy: 0.3333\n",
      "Epoch 37/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.1410 - accuracy: 0.4213 - val_loss: 8.2355 - val_accuracy: 0.3349\n",
      "Epoch 38/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.1223 - accuracy: 0.4251 - val_loss: 8.2194 - val_accuracy: 0.3360\n",
      "Epoch 39/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.1060 - accuracy: 0.4269 - val_loss: 8.2034 - val_accuracy: 0.3359\n",
      "Epoch 40/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.0871 - accuracy: 0.4294 - val_loss: 8.1873 - val_accuracy: 0.3367\n",
      "Epoch 41/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.0701 - accuracy: 0.4305 - val_loss: 8.1700 - val_accuracy: 0.3344\n",
      "Epoch 42/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.0515 - accuracy: 0.4312 - val_loss: 8.1547 - val_accuracy: 0.3336\n",
      "Epoch 43/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.0336 - accuracy: 0.4340 - val_loss: 8.1394 - val_accuracy: 0.3353\n",
      "Epoch 44/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 8.0156 - accuracy: 0.4380 - val_loss: 8.1223 - val_accuracy: 0.3329\n",
      "Epoch 45/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.9981 - accuracy: 0.4395 - val_loss: 8.1066 - val_accuracy: 0.3361\n",
      "Epoch 46/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.9818 - accuracy: 0.4400 - val_loss: 8.0913 - val_accuracy: 0.3356\n",
      "Epoch 47/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.9634 - accuracy: 0.4411 - val_loss: 8.0744 - val_accuracy: 0.3351\n",
      "Epoch 48/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.9458 - accuracy: 0.4424 - val_loss: 8.0593 - val_accuracy: 0.3333\n",
      "Epoch 49/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 7.9299 - accuracy: 0.4470 - val_loss: 8.0423 - val_accuracy: 0.3345\n",
      "Epoch 50/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.9130 - accuracy: 0.4464 - val_loss: 8.0269 - val_accuracy: 0.3353\n",
      "Epoch 51/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.8947 - accuracy: 0.4522 - val_loss: 8.0112 - val_accuracy: 0.3361\n",
      "Epoch 52/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.8775 - accuracy: 0.4528 - val_loss: 7.9963 - val_accuracy: 0.3355\n",
      "Epoch 53/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.8601 - accuracy: 0.4548 - val_loss: 7.9802 - val_accuracy: 0.3344\n",
      "Epoch 54/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.8432 - accuracy: 0.4567 - val_loss: 7.9651 - val_accuracy: 0.3327\n",
      "Epoch 55/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.8265 - accuracy: 0.4574 - val_loss: 7.9498 - val_accuracy: 0.3348\n",
      "Epoch 56/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.8096 - accuracy: 0.4579 - val_loss: 7.9348 - val_accuracy: 0.3336\n",
      "Epoch 57/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.7926 - accuracy: 0.4602 - val_loss: 7.9176 - val_accuracy: 0.3319\n",
      "Epoch 58/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.7757 - accuracy: 0.4630 - val_loss: 7.9022 - val_accuracy: 0.3328\n",
      "Epoch 59/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.7587 - accuracy: 0.4636 - val_loss: 7.8882 - val_accuracy: 0.3336\n",
      "Epoch 60/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.7415 - accuracy: 0.4675 - val_loss: 7.8731 - val_accuracy: 0.3340\n",
      "Epoch 61/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.7245 - accuracy: 0.4700 - val_loss: 7.8574 - val_accuracy: 0.3351\n",
      "Epoch 62/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.7080 - accuracy: 0.4725 - val_loss: 7.8424 - val_accuracy: 0.3340\n",
      "Epoch 63/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.6920 - accuracy: 0.4716 - val_loss: 7.8263 - val_accuracy: 0.3324\n",
      "Epoch 64/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.6745 - accuracy: 0.4776 - val_loss: 7.8112 - val_accuracy: 0.3328\n",
      "Epoch 65/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.6575 - accuracy: 0.4787 - val_loss: 7.7966 - val_accuracy: 0.3325\n",
      "Epoch 66/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.6406 - accuracy: 0.4800 - val_loss: 7.7820 - val_accuracy: 0.3341\n",
      "Epoch 67/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.6248 - accuracy: 0.4787 - val_loss: 7.7676 - val_accuracy: 0.3328\n",
      "Epoch 68/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.6090 - accuracy: 0.4823 - val_loss: 7.7516 - val_accuracy: 0.3327\n",
      "Epoch 69/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5922 - accuracy: 0.4852 - val_loss: 7.7368 - val_accuracy: 0.3313\n",
      "Epoch 70/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5746 - accuracy: 0.4854 - val_loss: 7.7214 - val_accuracy: 0.3329\n",
      "Epoch 71/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5600 - accuracy: 0.4863 - val_loss: 7.7072 - val_accuracy: 0.3313\n",
      "Epoch 72/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5413 - accuracy: 0.4948 - val_loss: 7.6921 - val_accuracy: 0.3327\n",
      "Epoch 73/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5266 - accuracy: 0.4911 - val_loss: 7.6768 - val_accuracy: 0.3359\n",
      "Epoch 74/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5094 - accuracy: 0.4956 - val_loss: 7.6627 - val_accuracy: 0.3329\n",
      "Epoch 75/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.4919 - accuracy: 0.4958 - val_loss: 7.6473 - val_accuracy: 0.3303\n",
      "Epoch 76/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.4764 - accuracy: 0.5002 - val_loss: 7.6336 - val_accuracy: 0.3329\n",
      "Epoch 77/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.4598 - accuracy: 0.5024 - val_loss: 7.6188 - val_accuracy: 0.3299\n",
      "Epoch 78/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.4445 - accuracy: 0.5015 - val_loss: 7.6044 - val_accuracy: 0.3351\n",
      "Epoch 79/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.4285 - accuracy: 0.5027 - val_loss: 7.5895 - val_accuracy: 0.3313\n",
      "Epoch 80/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.4114 - accuracy: 0.5052 - val_loss: 7.5763 - val_accuracy: 0.3313\n",
      "Epoch 81/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.3958 - accuracy: 0.5062 - val_loss: 7.5602 - val_accuracy: 0.3320\n",
      "Epoch 82/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.3788 - accuracy: 0.5111 - val_loss: 7.5464 - val_accuracy: 0.3297\n",
      "Epoch 83/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.3626 - accuracy: 0.5111 - val_loss: 7.5311 - val_accuracy: 0.3316\n",
      "Epoch 84/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.3464 - accuracy: 0.5144 - val_loss: 7.5176 - val_accuracy: 0.3316\n",
      "Epoch 85/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.3306 - accuracy: 0.5155 - val_loss: 7.5034 - val_accuracy: 0.3344\n",
      "Epoch 86/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.3147 - accuracy: 0.5166 - val_loss: 7.4878 - val_accuracy: 0.3333\n",
      "Epoch 87/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2979 - accuracy: 0.5198 - val_loss: 7.4737 - val_accuracy: 0.3307\n",
      "Epoch 88/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2834 - accuracy: 0.5175 - val_loss: 7.4603 - val_accuracy: 0.3339\n",
      "Epoch 89/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2665 - accuracy: 0.5203 - val_loss: 7.4443 - val_accuracy: 0.3335\n",
      "Epoch 90/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2504 - accuracy: 0.5242 - val_loss: 7.4299 - val_accuracy: 0.3341\n",
      "Epoch 91/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2337 - accuracy: 0.5276 - val_loss: 7.4164 - val_accuracy: 0.3321\n",
      "Epoch 92/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2182 - accuracy: 0.5264 - val_loss: 7.4022 - val_accuracy: 0.3353\n",
      "Epoch 93/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.2015 - accuracy: 0.5264 - val_loss: 7.3875 - val_accuracy: 0.3329\n",
      "Epoch 94/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1853 - accuracy: 0.5320 - val_loss: 7.3740 - val_accuracy: 0.3315\n",
      "Epoch 95/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1705 - accuracy: 0.5311 - val_loss: 7.3599 - val_accuracy: 0.3317\n",
      "Epoch 96/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1545 - accuracy: 0.5352 - val_loss: 7.3444 - val_accuracy: 0.3339\n",
      "Epoch 97/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1394 - accuracy: 0.5365 - val_loss: 7.3303 - val_accuracy: 0.3335\n",
      "Epoch 98/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1225 - accuracy: 0.5378 - val_loss: 7.3171 - val_accuracy: 0.3328\n",
      "Epoch 99/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.1060 - accuracy: 0.5391 - val_loss: 7.3037 - val_accuracy: 0.3340\n",
      "Epoch 100/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0907 - accuracy: 0.5385 - val_loss: 7.2889 - val_accuracy: 0.3337\n",
      "Epoch 101/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0748 - accuracy: 0.5436 - val_loss: 7.2742 - val_accuracy: 0.3327\n",
      "Epoch 102/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0606 - accuracy: 0.5417 - val_loss: 7.2611 - val_accuracy: 0.3353\n",
      "Epoch 103/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0425 - accuracy: 0.5494 - val_loss: 7.2471 - val_accuracy: 0.3335\n",
      "Epoch 104/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0286 - accuracy: 0.5460 - val_loss: 7.2343 - val_accuracy: 0.3329\n",
      "Epoch 105/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.0114 - accuracy: 0.5496 - val_loss: 7.2196 - val_accuracy: 0.3341\n",
      "Epoch 106/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9959 - accuracy: 0.5493 - val_loss: 7.2066 - val_accuracy: 0.3340\n",
      "Epoch 107/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9800 - accuracy: 0.5525 - val_loss: 7.1921 - val_accuracy: 0.3337\n",
      "Epoch 108/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9642 - accuracy: 0.5540 - val_loss: 7.1780 - val_accuracy: 0.3336\n",
      "Epoch 109/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9487 - accuracy: 0.5567 - val_loss: 7.1647 - val_accuracy: 0.3323\n",
      "Epoch 110/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9332 - accuracy: 0.5583 - val_loss: 7.1508 - val_accuracy: 0.3361\n",
      "Epoch 111/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9176 - accuracy: 0.5617 - val_loss: 7.1365 - val_accuracy: 0.3359\n",
      "Epoch 112/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.9015 - accuracy: 0.5615 - val_loss: 7.1221 - val_accuracy: 0.3359\n",
      "Epoch 113/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8866 - accuracy: 0.5638 - val_loss: 7.1099 - val_accuracy: 0.3336\n",
      "Epoch 114/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8701 - accuracy: 0.5640 - val_loss: 7.0959 - val_accuracy: 0.3328\n",
      "Epoch 115/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8549 - accuracy: 0.5664 - val_loss: 7.0831 - val_accuracy: 0.3357\n",
      "Epoch 116/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8386 - accuracy: 0.5693 - val_loss: 7.0689 - val_accuracy: 0.3353\n",
      "Epoch 117/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8236 - accuracy: 0.5721 - val_loss: 7.0551 - val_accuracy: 0.3345\n",
      "Epoch 118/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.8076 - accuracy: 0.5732 - val_loss: 7.0421 - val_accuracy: 0.3352\n",
      "Epoch 119/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7924 - accuracy: 0.5744 - val_loss: 7.0292 - val_accuracy: 0.3320\n",
      "Epoch 120/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7773 - accuracy: 0.5744 - val_loss: 7.0157 - val_accuracy: 0.3355\n",
      "Epoch 121/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7606 - accuracy: 0.5792 - val_loss: 7.0012 - val_accuracy: 0.3336\n",
      "Epoch 122/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7452 - accuracy: 0.5807 - val_loss: 6.9886 - val_accuracy: 0.3339\n",
      "Epoch 123/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7293 - accuracy: 0.5826 - val_loss: 6.9751 - val_accuracy: 0.3345\n",
      "Epoch 124/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7145 - accuracy: 0.5848 - val_loss: 6.9618 - val_accuracy: 0.3347\n",
      "Epoch 125/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6992 - accuracy: 0.5852 - val_loss: 6.9477 - val_accuracy: 0.3361\n",
      "Epoch 126/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6838 - accuracy: 0.5853 - val_loss: 6.9355 - val_accuracy: 0.3296\n",
      "Epoch 127/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6676 - accuracy: 0.5900 - val_loss: 6.9210 - val_accuracy: 0.3347\n",
      "Epoch 128/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6527 - accuracy: 0.5907 - val_loss: 6.9098 - val_accuracy: 0.3333\n",
      "Epoch 129/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6377 - accuracy: 0.5905 - val_loss: 6.8951 - val_accuracy: 0.3324\n",
      "Epoch 130/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6226 - accuracy: 0.5912 - val_loss: 6.8829 - val_accuracy: 0.3320\n",
      "Epoch 131/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6065 - accuracy: 0.5977 - val_loss: 6.8693 - val_accuracy: 0.3333\n",
      "Epoch 132/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5912 - accuracy: 0.5953 - val_loss: 6.8562 - val_accuracy: 0.3351\n",
      "Epoch 133/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5763 - accuracy: 0.5991 - val_loss: 6.8434 - val_accuracy: 0.3348\n",
      "Epoch 134/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5606 - accuracy: 0.5998 - val_loss: 6.8303 - val_accuracy: 0.3332\n",
      "Epoch 135/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5451 - accuracy: 0.5993 - val_loss: 6.8174 - val_accuracy: 0.3325\n",
      "Epoch 136/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5286 - accuracy: 0.6038 - val_loss: 6.8048 - val_accuracy: 0.3324\n",
      "Epoch 137/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.5141 - accuracy: 0.6040 - val_loss: 6.7906 - val_accuracy: 0.3351\n",
      "Epoch 138/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4991 - accuracy: 0.6069 - val_loss: 6.7773 - val_accuracy: 0.3341\n",
      "Epoch 139/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4844 - accuracy: 0.6082 - val_loss: 6.7658 - val_accuracy: 0.3321\n",
      "Epoch 140/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4697 - accuracy: 0.6079 - val_loss: 6.7523 - val_accuracy: 0.3349\n",
      "Epoch 141/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4536 - accuracy: 0.6123 - val_loss: 6.7400 - val_accuracy: 0.3337\n",
      "Epoch 142/500\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 6.4381 - accuracy: 0.6116 - val_loss: 6.7275 - val_accuracy: 0.3331\n",
      "Epoch 143/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4228 - accuracy: 0.6162 - val_loss: 6.7137 - val_accuracy: 0.3337\n",
      "Epoch 144/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.4081 - accuracy: 0.6149 - val_loss: 6.7009 - val_accuracy: 0.3339\n",
      "Epoch 145/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3923 - accuracy: 0.6189 - val_loss: 6.6881 - val_accuracy: 0.3339\n",
      "Epoch 146/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3763 - accuracy: 0.6217 - val_loss: 6.6757 - val_accuracy: 0.3313\n",
      "Epoch 147/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3613 - accuracy: 0.6229 - val_loss: 6.6633 - val_accuracy: 0.3340\n",
      "Epoch 148/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3460 - accuracy: 0.6220 - val_loss: 6.6501 - val_accuracy: 0.3353\n",
      "Epoch 149/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3329 - accuracy: 0.6200 - val_loss: 6.6362 - val_accuracy: 0.3375\n",
      "Epoch 150/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3167 - accuracy: 0.6264 - val_loss: 6.6232 - val_accuracy: 0.3361\n",
      "Epoch 151/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3012 - accuracy: 0.6285 - val_loss: 6.6111 - val_accuracy: 0.3353\n",
      "Epoch 152/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2851 - accuracy: 0.6310 - val_loss: 6.6005 - val_accuracy: 0.3359\n",
      "Epoch 153/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2726 - accuracy: 0.6315 - val_loss: 6.5884 - val_accuracy: 0.3355\n",
      "Epoch 154/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2547 - accuracy: 0.6365 - val_loss: 6.5754 - val_accuracy: 0.3325\n",
      "Epoch 155/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2408 - accuracy: 0.6357 - val_loss: 6.5636 - val_accuracy: 0.3325\n",
      "Epoch 156/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2261 - accuracy: 0.6361 - val_loss: 6.5519 - val_accuracy: 0.3355\n",
      "Epoch 157/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2094 - accuracy: 0.6373 - val_loss: 6.5387 - val_accuracy: 0.3340\n",
      "Epoch 158/500\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.1951 - accuracy: 0.6405 - val_loss: 6.5248 - val_accuracy: 0.3337\n",
      "Time: 48.00619959831238\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Traits_Model_10disc.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#10 discrete\n",
    "################################################################################################################################################\n",
    "traits_disc10=traits_disc[:,0:10,:]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test  = train_test_split(y,X20,traits_disc10,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = disc_subset(ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test)\n",
    "\n",
    "model.save(filepath='./Trained_Models/Trained_Traits_Model_10disc.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0B1h_TqkE0o0",
    "outputId": "e56a2c1e-e86f-470b-9634-e4d3d51918e0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 20, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 18, 250)      45000       ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 18, 250)     1000        ['conv1d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 16, 250)      187500      ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 16, 250)     1000        ['conv1d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 14, 250)      187500      ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 14, 250)     1000        ['conv1d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 4, 250)      0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 1000)         0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " dense_44_input (InputLayer)    [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 125)          125125      ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 150)          150000      ['dense_44_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 125)          0           ['dense_47[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 150)         600         ['dense_44[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 125)          15750       ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense_45 (Dense)               (None, 150)          22500       ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 125)          0           ['dense_48[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 150)         600         ['dense_45[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_49 (Dense)               (None, 50)           6300        ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, 50)           7550        ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 50)           0           ['dense_49[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_4 (LinearW)           (None, 50)           2           ['dense_46[0][0]',               \n",
      "                                                                  'activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_50 (Dense)               (None, 50)           2550        ['linear_w_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_51 (Dense)               (None, 3)            153         ['dense_50[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 754,130\n",
      "Trainable params: 752,030\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 2s 11ms/step - loss: 8.8170 - accuracy: 0.3486 - val_loss: 8.7573 - val_accuracy: 0.3391\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.7804 - accuracy: 0.3549 - val_loss: 8.7197 - val_accuracy: 0.3564\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.7379 - accuracy: 0.3747 - val_loss: 8.6832 - val_accuracy: 0.3892\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.7046 - accuracy: 0.3929 - val_loss: 8.6426 - val_accuracy: 0.4293\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.6666 - accuracy: 0.4085 - val_loss: 8.6035 - val_accuracy: 0.4616\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.6349 - accuracy: 0.4208 - val_loss: 8.5659 - val_accuracy: 0.4855\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.5996 - accuracy: 0.4383 - val_loss: 8.5286 - val_accuracy: 0.5100\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.5723 - accuracy: 0.4516 - val_loss: 8.4938 - val_accuracy: 0.5303\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.5357 - accuracy: 0.4673 - val_loss: 8.4572 - val_accuracy: 0.5480\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.5061 - accuracy: 0.4801 - val_loss: 8.4214 - val_accuracy: 0.5656\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.4698 - accuracy: 0.4966 - val_loss: 8.3848 - val_accuracy: 0.5796\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.4377 - accuracy: 0.5071 - val_loss: 8.3483 - val_accuracy: 0.5935\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.4053 - accuracy: 0.5209 - val_loss: 8.3127 - val_accuracy: 0.6055\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.3713 - accuracy: 0.5366 - val_loss: 8.2777 - val_accuracy: 0.6177\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.3458 - accuracy: 0.5428 - val_loss: 8.2430 - val_accuracy: 0.6307\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.3149 - accuracy: 0.5544 - val_loss: 8.2092 - val_accuracy: 0.6412\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.2831 - accuracy: 0.5639 - val_loss: 8.1753 - val_accuracy: 0.6516\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.2480 - accuracy: 0.5765 - val_loss: 8.1412 - val_accuracy: 0.6608\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.2142 - accuracy: 0.5909 - val_loss: 8.1079 - val_accuracy: 0.6715\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.1863 - accuracy: 0.5982 - val_loss: 8.0751 - val_accuracy: 0.6764\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.1564 - accuracy: 0.6048 - val_loss: 8.0423 - val_accuracy: 0.6844\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.1226 - accuracy: 0.6162 - val_loss: 8.0084 - val_accuracy: 0.6919\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.0902 - accuracy: 0.6257 - val_loss: 7.9747 - val_accuracy: 0.7029\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.0620 - accuracy: 0.6328 - val_loss: 7.9411 - val_accuracy: 0.7103\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 8.0243 - accuracy: 0.6466 - val_loss: 7.9076 - val_accuracy: 0.7153\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.9918 - accuracy: 0.6571 - val_loss: 7.8747 - val_accuracy: 0.7251\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.9634 - accuracy: 0.6632 - val_loss: 7.8396 - val_accuracy: 0.7361\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.9288 - accuracy: 0.6717 - val_loss: 7.8062 - val_accuracy: 0.7435\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.8986 - accuracy: 0.6802 - val_loss: 7.7717 - val_accuracy: 0.7531\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.8611 - accuracy: 0.6931 - val_loss: 7.7393 - val_accuracy: 0.7605\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.8308 - accuracy: 0.7024 - val_loss: 7.7063 - val_accuracy: 0.7675\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.8016 - accuracy: 0.7068 - val_loss: 7.6753 - val_accuracy: 0.7747\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.7742 - accuracy: 0.7104 - val_loss: 7.6456 - val_accuracy: 0.7809\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.7358 - accuracy: 0.7248 - val_loss: 7.6150 - val_accuracy: 0.7880\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.7112 - accuracy: 0.7319 - val_loss: 7.5871 - val_accuracy: 0.7939\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.6763 - accuracy: 0.7395 - val_loss: 7.5594 - val_accuracy: 0.7992\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 7.6549 - accuracy: 0.7415 - val_loss: 7.5316 - val_accuracy: 0.8048\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.6242 - accuracy: 0.7493 - val_loss: 7.5060 - val_accuracy: 0.8097\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 7.5975 - accuracy: 0.7554 - val_loss: 7.4795 - val_accuracy: 0.8137\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 7.5720 - accuracy: 0.7594 - val_loss: 7.4548 - val_accuracy: 0.8176\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.5489 - accuracy: 0.7644 - val_loss: 7.4306 - val_accuracy: 0.8212\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.5187 - accuracy: 0.7689 - val_loss: 7.4048 - val_accuracy: 0.8264\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.4908 - accuracy: 0.7788 - val_loss: 7.3818 - val_accuracy: 0.8288\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.4695 - accuracy: 0.7785 - val_loss: 7.3605 - val_accuracy: 0.8316\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.4430 - accuracy: 0.7869 - val_loss: 7.3385 - val_accuracy: 0.8355\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.4204 - accuracy: 0.7871 - val_loss: 7.3157 - val_accuracy: 0.8371\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.4001 - accuracy: 0.7910 - val_loss: 7.2941 - val_accuracy: 0.8417\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.3740 - accuracy: 0.7969 - val_loss: 7.2716 - val_accuracy: 0.8448\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.3548 - accuracy: 0.8016 - val_loss: 7.2494 - val_accuracy: 0.8476\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.3257 - accuracy: 0.8068 - val_loss: 7.2274 - val_accuracy: 0.8487\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.3072 - accuracy: 0.8093 - val_loss: 7.2075 - val_accuracy: 0.8521\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.2885 - accuracy: 0.8102 - val_loss: 7.1865 - val_accuracy: 0.8548\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.2658 - accuracy: 0.8113 - val_loss: 7.1681 - val_accuracy: 0.8576\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.2422 - accuracy: 0.8213 - val_loss: 7.1484 - val_accuracy: 0.8600\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.2235 - accuracy: 0.8176 - val_loss: 7.1292 - val_accuracy: 0.8620\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.2024 - accuracy: 0.8227 - val_loss: 7.1084 - val_accuracy: 0.8659\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.1775 - accuracy: 0.8264 - val_loss: 7.0894 - val_accuracy: 0.8675\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.1586 - accuracy: 0.8275 - val_loss: 7.0691 - val_accuracy: 0.8695\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.1420 - accuracy: 0.8320 - val_loss: 7.0503 - val_accuracy: 0.8713\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.1204 - accuracy: 0.8314 - val_loss: 7.0342 - val_accuracy: 0.8711\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.0984 - accuracy: 0.8356 - val_loss: 7.0149 - val_accuracy: 0.8743\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 7.0776 - accuracy: 0.8404 - val_loss: 6.9954 - val_accuracy: 0.8759\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.0582 - accuracy: 0.8446 - val_loss: 6.9778 - val_accuracy: 0.8771\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.0363 - accuracy: 0.8467 - val_loss: 6.9582 - val_accuracy: 0.8801\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.0184 - accuracy: 0.8480 - val_loss: 6.9382 - val_accuracy: 0.8817\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.0025 - accuracy: 0.8494 - val_loss: 6.9233 - val_accuracy: 0.8811\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.9795 - accuracy: 0.8509 - val_loss: 6.9053 - val_accuracy: 0.8824\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.9637 - accuracy: 0.8518 - val_loss: 6.8857 - val_accuracy: 0.8832\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.9452 - accuracy: 0.8534 - val_loss: 6.8691 - val_accuracy: 0.8837\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.9319 - accuracy: 0.8547 - val_loss: 6.8524 - val_accuracy: 0.8847\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.9133 - accuracy: 0.8568 - val_loss: 6.8348 - val_accuracy: 0.8856\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.8928 - accuracy: 0.8575 - val_loss: 6.8162 - val_accuracy: 0.8863\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.8734 - accuracy: 0.8611 - val_loss: 6.8010 - val_accuracy: 0.8860\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.8537 - accuracy: 0.8624 - val_loss: 6.7806 - val_accuracy: 0.8892\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.8312 - accuracy: 0.8683 - val_loss: 6.7657 - val_accuracy: 0.8887\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.8129 - accuracy: 0.8666 - val_loss: 6.7500 - val_accuracy: 0.8895\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.7972 - accuracy: 0.8668 - val_loss: 6.7309 - val_accuracy: 0.8909\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.7762 - accuracy: 0.8718 - val_loss: 6.7130 - val_accuracy: 0.8920\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.7641 - accuracy: 0.8669 - val_loss: 6.6967 - val_accuracy: 0.8929\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.7484 - accuracy: 0.8730 - val_loss: 6.6808 - val_accuracy: 0.8932\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.7264 - accuracy: 0.8720 - val_loss: 6.6625 - val_accuracy: 0.8948\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.7102 - accuracy: 0.8762 - val_loss: 6.6471 - val_accuracy: 0.8945\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.6874 - accuracy: 0.8769 - val_loss: 6.6308 - val_accuracy: 0.8953\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.6695 - accuracy: 0.8800 - val_loss: 6.6171 - val_accuracy: 0.8951\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.6543 - accuracy: 0.8794 - val_loss: 6.5978 - val_accuracy: 0.8967\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.6368 - accuracy: 0.8788 - val_loss: 6.5814 - val_accuracy: 0.8971\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 6.6209 - accuracy: 0.8839 - val_loss: 6.5648 - val_accuracy: 0.8976\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.6046 - accuracy: 0.8820 - val_loss: 6.5476 - val_accuracy: 0.8987\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.5826 - accuracy: 0.8848 - val_loss: 6.5314 - val_accuracy: 0.8991\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.5706 - accuracy: 0.8849 - val_loss: 6.5153 - val_accuracy: 0.8999\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.5515 - accuracy: 0.8838 - val_loss: 6.5013 - val_accuracy: 0.8995\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.5365 - accuracy: 0.8856 - val_loss: 6.4856 - val_accuracy: 0.8999\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.5118 - accuracy: 0.8910 - val_loss: 6.4695 - val_accuracy: 0.9005\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.5044 - accuracy: 0.8868 - val_loss: 6.4517 - val_accuracy: 0.9020\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4861 - accuracy: 0.8905 - val_loss: 6.4377 - val_accuracy: 0.9015\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4750 - accuracy: 0.8872 - val_loss: 6.4205 - val_accuracy: 0.9021\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4539 - accuracy: 0.8896 - val_loss: 6.4066 - val_accuracy: 0.9032\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4352 - accuracy: 0.8925 - val_loss: 6.3916 - val_accuracy: 0.9033\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4185 - accuracy: 0.8940 - val_loss: 6.3750 - val_accuracy: 0.9037\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.4044 - accuracy: 0.8940 - val_loss: 6.3600 - val_accuracy: 0.9045\n",
      "Time: 66.29165625572205\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_10disc_20SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#20SNPS, 10 discrete\n",
    "################################################################################################################################################xtrain, xtest = X[int(len(y)*.25):], X[:int(len(y)*.25)]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test  = train_test_split(y,X20,traits_disc10,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_disc_subset(ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test)\n",
    "\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_10disc_20SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXtY3u-cE0o0",
    "outputId": "0a66d429-c6e2-41a7-e076-4d59a6dc6bd9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 1000, 60)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 998, 250)     45000       ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 998, 250)    1000        ['conv1d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 996, 250)     187500      ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 996, 250)    1000        ['conv1d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 994, 250)     187500      ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 994, 250)    1000        ['conv1d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 331, 250)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 82750)        0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " dense_52_input (InputLayer)    [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_55 (Dense)               (None, 125)          10343875    ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_52 (Dense)               (None, 150)          150000      ['dense_52_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 125)          0           ['dense_55[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 150)         600         ['dense_52[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_56 (Dense)               (None, 125)          15750       ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dense_53 (Dense)               (None, 150)          22500       ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 125)          0           ['dense_56[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 150)         600         ['dense_53[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_57 (Dense)               (None, 50)           6300        ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " dense_54 (Dense)               (None, 50)           7550        ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 50)           0           ['dense_57[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_5 (LinearW)           (None, 50)           2           ['dense_54[0][0]',               \n",
      "                                                                  'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " dense_58 (Dense)               (None, 50)           2550        ['linear_w_5[0][0]']             \n",
      "                                                                                                  \n",
      " dense_59 (Dense)               (None, 3)            153         ['dense_58[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,972,880\n",
      "Trainable params: 10,970,780\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 12s 122ms/step - loss: 8.7257 - accuracy: 0.4233 - val_loss: 8.6911 - val_accuracy: 0.4164\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 8.5047 - accuracy: 0.5718 - val_loss: 8.5125 - val_accuracy: 0.6627\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 8.3719 - accuracy: 0.6453 - val_loss: 8.3082 - val_accuracy: 0.7189\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 8.2624 - accuracy: 0.7041 - val_loss: 8.1269 - val_accuracy: 0.7988\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 8.1584 - accuracy: 0.7557 - val_loss: 7.9645 - val_accuracy: 0.8711\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 8.0489 - accuracy: 0.8046 - val_loss: 7.8339 - val_accuracy: 0.9167\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.9431 - accuracy: 0.8484 - val_loss: 7.7353 - val_accuracy: 0.9500\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 7.8618 - accuracy: 0.8795 - val_loss: 7.6626 - val_accuracy: 0.9688\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.7840 - accuracy: 0.9068 - val_loss: 7.6092 - val_accuracy: 0.9780\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.7194 - accuracy: 0.9289 - val_loss: 7.5706 - val_accuracy: 0.9839\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.6762 - accuracy: 0.9374 - val_loss: 7.5388 - val_accuracy: 0.9857\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.6290 - accuracy: 0.9487 - val_loss: 7.5097 - val_accuracy: 0.9891\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.5941 - accuracy: 0.9567 - val_loss: 7.4864 - val_accuracy: 0.9913\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.5576 - accuracy: 0.9625 - val_loss: 7.4631 - val_accuracy: 0.9916\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.5281 - accuracy: 0.9679 - val_loss: 7.4405 - val_accuracy: 0.9927\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.5030 - accuracy: 0.9704 - val_loss: 7.4197 - val_accuracy: 0.9957\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 7.4772 - accuracy: 0.9741 - val_loss: 7.3996 - val_accuracy: 0.9957\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.4541 - accuracy: 0.9767 - val_loss: 7.3815 - val_accuracy: 0.9968\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.4316 - accuracy: 0.9767 - val_loss: 7.3646 - val_accuracy: 0.9949\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.4088 - accuracy: 0.9809 - val_loss: 7.3471 - val_accuracy: 0.9971\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 7.3895 - accuracy: 0.9801 - val_loss: 7.3300 - val_accuracy: 0.9971\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.3686 - accuracy: 0.9828 - val_loss: 7.3112 - val_accuracy: 0.9975\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.3473 - accuracy: 0.9842 - val_loss: 7.2941 - val_accuracy: 0.9980\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.3285 - accuracy: 0.9850 - val_loss: 7.2783 - val_accuracy: 0.9976\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.3095 - accuracy: 0.9860 - val_loss: 7.2619 - val_accuracy: 0.9975\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.2934 - accuracy: 0.9860 - val_loss: 7.2451 - val_accuracy: 0.9981\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.2712 - accuracy: 0.9883 - val_loss: 7.2283 - val_accuracy: 0.9983\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.2543 - accuracy: 0.9887 - val_loss: 7.2122 - val_accuracy: 0.9981\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.2383 - accuracy: 0.9882 - val_loss: 7.1962 - val_accuracy: 0.9985\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.2196 - accuracy: 0.9899 - val_loss: 7.1803 - val_accuracy: 0.9980\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.2017 - accuracy: 0.9899 - val_loss: 7.1639 - val_accuracy: 0.9984\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.1855 - accuracy: 0.9896 - val_loss: 7.1481 - val_accuracy: 0.9984\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.1695 - accuracy: 0.9899 - val_loss: 7.1312 - val_accuracy: 0.9988\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.1481 - accuracy: 0.9925 - val_loss: 7.1162 - val_accuracy: 0.9985\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.1358 - accuracy: 0.9906 - val_loss: 7.1004 - val_accuracy: 0.9985\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.1166 - accuracy: 0.9925 - val_loss: 7.0846 - val_accuracy: 0.9985\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.1004 - accuracy: 0.9927 - val_loss: 7.0688 - val_accuracy: 0.9985\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 7.0851 - accuracy: 0.9921 - val_loss: 7.0529 - val_accuracy: 0.9989\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.0668 - accuracy: 0.9926 - val_loss: 7.0371 - val_accuracy: 0.9988\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.0508 - accuracy: 0.9931 - val_loss: 7.0218 - val_accuracy: 0.9988\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.0329 - accuracy: 0.9936 - val_loss: 7.0058 - val_accuracy: 0.9988\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 7.0181 - accuracy: 0.9939 - val_loss: 6.9903 - val_accuracy: 0.9991\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 7.0022 - accuracy: 0.9940 - val_loss: 6.9747 - val_accuracy: 0.9989\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.9861 - accuracy: 0.9937 - val_loss: 6.9600 - val_accuracy: 0.9988\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.9702 - accuracy: 0.9946 - val_loss: 6.9440 - val_accuracy: 0.9992\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.9538 - accuracy: 0.9937 - val_loss: 6.9287 - val_accuracy: 0.9989\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.9372 - accuracy: 0.9948 - val_loss: 6.9129 - val_accuracy: 0.9992\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.9234 - accuracy: 0.9938 - val_loss: 6.8972 - val_accuracy: 0.9993\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.9049 - accuracy: 0.9950 - val_loss: 6.8820 - val_accuracy: 0.9989\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.8895 - accuracy: 0.9954 - val_loss: 6.8666 - val_accuracy: 0.9993\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.8738 - accuracy: 0.9952 - val_loss: 6.8516 - val_accuracy: 0.9991\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.8587 - accuracy: 0.9955 - val_loss: 6.8364 - val_accuracy: 0.9991\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.8429 - accuracy: 0.9959 - val_loss: 6.8207 - val_accuracy: 0.9992\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.8248 - accuracy: 0.9963 - val_loss: 6.8057 - val_accuracy: 0.9989\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.8116 - accuracy: 0.9959 - val_loss: 6.7904 - val_accuracy: 0.9992\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.7957 - accuracy: 0.9954 - val_loss: 6.7753 - val_accuracy: 0.9992\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.7807 - accuracy: 0.9959 - val_loss: 6.7602 - val_accuracy: 0.9992\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.7645 - accuracy: 0.9963 - val_loss: 6.7445 - val_accuracy: 0.9995\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.7492 - accuracy: 0.9961 - val_loss: 6.7299 - val_accuracy: 0.9992\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.7336 - accuracy: 0.9966 - val_loss: 6.7146 - val_accuracy: 0.9992\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.7203 - accuracy: 0.9954 - val_loss: 6.6991 - val_accuracy: 0.9995\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.7049 - accuracy: 0.9960 - val_loss: 6.6842 - val_accuracy: 0.9996\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.6880 - accuracy: 0.9958 - val_loss: 6.6692 - val_accuracy: 0.9993\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.6728 - accuracy: 0.9966 - val_loss: 6.6542 - val_accuracy: 0.9993\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.6578 - accuracy: 0.9961 - val_loss: 6.6391 - val_accuracy: 0.9995\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.6412 - accuracy: 0.9970 - val_loss: 6.6238 - val_accuracy: 0.9996\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.6276 - accuracy: 0.9967 - val_loss: 6.6089 - val_accuracy: 0.9995\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.6112 - accuracy: 0.9970 - val_loss: 6.5942 - val_accuracy: 0.9993\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.5961 - accuracy: 0.9965 - val_loss: 6.5789 - val_accuracy: 0.9996\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.5826 - accuracy: 0.9966 - val_loss: 6.5642 - val_accuracy: 0.9995\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.5661 - accuracy: 0.9969 - val_loss: 6.5492 - val_accuracy: 0.9995\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.5500 - accuracy: 0.9974 - val_loss: 6.5339 - val_accuracy: 0.9996\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.5359 - accuracy: 0.9972 - val_loss: 6.5194 - val_accuracy: 0.9995\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.5202 - accuracy: 0.9974 - val_loss: 6.5045 - val_accuracy: 0.9996\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.5058 - accuracy: 0.9975 - val_loss: 6.4899 - val_accuracy: 0.9995\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.4914 - accuracy: 0.9971 - val_loss: 6.4747 - val_accuracy: 0.9996\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.4764 - accuracy: 0.9969 - val_loss: 6.4599 - val_accuracy: 0.9996\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.4612 - accuracy: 0.9973 - val_loss: 6.4450 - val_accuracy: 0.9996\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.4484 - accuracy: 0.9963 - val_loss: 6.4302 - val_accuracy: 0.9997\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.4306 - accuracy: 0.9974 - val_loss: 6.4155 - val_accuracy: 0.9996\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.4178 - accuracy: 0.9969 - val_loss: 6.4007 - val_accuracy: 0.9997\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.4012 - accuracy: 0.9975 - val_loss: 6.3858 - val_accuracy: 0.9997\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.3878 - accuracy: 0.9972 - val_loss: 6.3714 - val_accuracy: 0.9997\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.3719 - accuracy: 0.9976 - val_loss: 6.3567 - val_accuracy: 0.9997\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.3575 - accuracy: 0.9976 - val_loss: 6.3421 - val_accuracy: 0.9997\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.3431 - accuracy: 0.9978 - val_loss: 6.3273 - val_accuracy: 0.9997\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.3278 - accuracy: 0.9975 - val_loss: 6.3128 - val_accuracy: 0.9997\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 10s 113ms/step - loss: 6.3141 - accuracy: 0.9972 - val_loss: 6.2981 - val_accuracy: 0.9997\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.2977 - accuracy: 0.9979 - val_loss: 6.2839 - val_accuracy: 0.9997\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.2832 - accuracy: 0.9979 - val_loss: 6.2692 - val_accuracy: 0.9997\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.2692 - accuracy: 0.9979 - val_loss: 6.2548 - val_accuracy: 0.9996\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.2542 - accuracy: 0.9982 - val_loss: 6.2401 - val_accuracy: 0.9996\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.2395 - accuracy: 0.9982 - val_loss: 6.2256 - val_accuracy: 0.9997\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.2243 - accuracy: 0.9984 - val_loss: 6.2111 - val_accuracy: 0.9997\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.2109 - accuracy: 0.9974 - val_loss: 6.1967 - val_accuracy: 0.9997\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.1957 - accuracy: 0.9980 - val_loss: 6.1822 - val_accuracy: 0.9997\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.1806 - accuracy: 0.9985 - val_loss: 6.1676 - val_accuracy: 0.9997\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.1672 - accuracy: 0.9981 - val_loss: 6.1536 - val_accuracy: 0.9996\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.1528 - accuracy: 0.9976 - val_loss: 6.1391 - val_accuracy: 0.9996\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 6.1394 - accuracy: 0.9976 - val_loss: 6.1247 - val_accuracy: 0.9996\n",
      "Time: 1027.511019229889\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_10disc_1KSNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#1KSNPS, 10 discrete\n",
    "################################################################################################################################################xtrain, xtest = X[int(len(y)*.25):], X[:int(len(y)*.25)]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test  = train_test_split(y,X,traits_disc10,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_disc_subset(ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test)\n",
    "\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_10disc_1KSNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cBiwcebIE0o1",
    "outputId": "1667ae85-9e11-4e6b-8816-b09147857126",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 1000, 60)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 998, 250)     45000       ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 998, 250)    1000        ['conv1d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 996, 250)     187500      ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 996, 250)    1000        ['conv1d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 994, 250)     187500      ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 994, 250)    1000        ['conv1d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 331, 250)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 82750)        0           ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " dense_60_input (InputLayer)    [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_63 (Dense)               (None, 125)          10343875    ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " dense_60 (Dense)               (None, 150)          450000      ['dense_60_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 125)          0           ['dense_63[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 150)         600         ['dense_60[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_64 (Dense)               (None, 125)          15750       ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dense_61 (Dense)               (None, 150)          22500       ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 125)          0           ['dense_64[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 150)         600         ['dense_61[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_65 (Dense)               (None, 50)           6300        ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " dense_62 (Dense)               (None, 50)           7550        ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 50)           0           ['dense_65[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_6 (LinearW)           (None, 50)           2           ['dense_62[0][0]',               \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " dense_66 (Dense)               (None, 50)           2550        ['linear_w_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_67 (Dense)               (None, 3)            153         ['dense_66[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,272,880\n",
      "Trainable params: 11,270,780\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 12s 125ms/step - loss: 13.0991 - accuracy: 0.4426 - val_loss: 13.0956 - val_accuracy: 0.4285\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.8719 - accuracy: 0.5834 - val_loss: 12.8777 - val_accuracy: 0.6183\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.6998 - accuracy: 0.6646 - val_loss: 12.6061 - val_accuracy: 0.7436\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.5406 - accuracy: 0.7301 - val_loss: 12.3501 - val_accuracy: 0.8539\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.3870 - accuracy: 0.7887 - val_loss: 12.1348 - val_accuracy: 0.9347\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.2421 - accuracy: 0.8416 - val_loss: 11.9896 - val_accuracy: 0.9645\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.1283 - accuracy: 0.8737 - val_loss: 11.8912 - val_accuracy: 0.9780\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 12.0251 - accuracy: 0.8991 - val_loss: 11.8096 - val_accuracy: 0.9847\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.9318 - accuracy: 0.9225 - val_loss: 11.7403 - val_accuracy: 0.9895\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.8516 - accuracy: 0.9343 - val_loss: 11.6833 - val_accuracy: 0.9912\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.7818 - accuracy: 0.9454 - val_loss: 11.6287 - val_accuracy: 0.9939\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.7202 - accuracy: 0.9519 - val_loss: 11.5795 - val_accuracy: 0.9941\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.6632 - accuracy: 0.9558 - val_loss: 11.5305 - val_accuracy: 0.9956\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 11.6067 - accuracy: 0.9617 - val_loss: 11.4872 - val_accuracy: 0.9955\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.5469 - accuracy: 0.9676 - val_loss: 11.4400 - val_accuracy: 0.9961\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.5033 - accuracy: 0.9682 - val_loss: 11.3960 - val_accuracy: 0.9967\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.4480 - accuracy: 0.9726 - val_loss: 11.3515 - val_accuracy: 0.9972\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.4010 - accuracy: 0.9750 - val_loss: 11.3096 - val_accuracy: 0.9968\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 11.3536 - accuracy: 0.9760 - val_loss: 11.2667 - val_accuracy: 0.9971\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.3090 - accuracy: 0.9786 - val_loss: 11.2238 - val_accuracy: 0.9980\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.2640 - accuracy: 0.9779 - val_loss: 11.1809 - val_accuracy: 0.9979\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.2178 - accuracy: 0.9796 - val_loss: 11.1388 - val_accuracy: 0.9979\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 11.1710 - accuracy: 0.9822 - val_loss: 11.0976 - val_accuracy: 0.9980\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.1240 - accuracy: 0.9836 - val_loss: 11.0555 - val_accuracy: 0.9981\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 11.0824 - accuracy: 0.9843 - val_loss: 11.0146 - val_accuracy: 0.9976\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 11.0383 - accuracy: 0.9849 - val_loss: 10.9728 - val_accuracy: 0.9981\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.9920 - accuracy: 0.9867 - val_loss: 10.9313 - val_accuracy: 0.9983\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.9539 - accuracy: 0.9859 - val_loss: 10.8898 - val_accuracy: 0.9985\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 10.9078 - accuracy: 0.9865 - val_loss: 10.8491 - val_accuracy: 0.9985\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.8654 - accuracy: 0.9879 - val_loss: 10.8082 - val_accuracy: 0.9987\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.8238 - accuracy: 0.9876 - val_loss: 10.7674 - val_accuracy: 0.9985\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.7811 - accuracy: 0.9894 - val_loss: 10.7264 - val_accuracy: 0.9989\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.7398 - accuracy: 0.9891 - val_loss: 10.6856 - val_accuracy: 0.9989\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 10.6967 - accuracy: 0.9901 - val_loss: 10.6453 - val_accuracy: 0.9989\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 10.6578 - accuracy: 0.9892 - val_loss: 10.6053 - val_accuracy: 0.9988\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.6137 - accuracy: 0.9906 - val_loss: 10.5651 - val_accuracy: 0.9988\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.5741 - accuracy: 0.9903 - val_loss: 10.5251 - val_accuracy: 0.9988\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.5332 - accuracy: 0.9900 - val_loss: 10.4846 - val_accuracy: 0.9989\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 10.4912 - accuracy: 0.9909 - val_loss: 10.4444 - val_accuracy: 0.9991\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.4509 - accuracy: 0.9915 - val_loss: 10.4050 - val_accuracy: 0.9989\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.4077 - accuracy: 0.9926 - val_loss: 10.3647 - val_accuracy: 0.9989\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 10.3680 - accuracy: 0.9929 - val_loss: 10.3257 - val_accuracy: 0.9989\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 10.3296 - accuracy: 0.9918 - val_loss: 10.2856 - val_accuracy: 0.9989\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 10.2889 - accuracy: 0.9924 - val_loss: 10.2464 - val_accuracy: 0.9988\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 10.2477 - accuracy: 0.9930 - val_loss: 10.2069 - val_accuracy: 0.9988\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.2065 - accuracy: 0.9942 - val_loss: 10.1673 - val_accuracy: 0.9991\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.1673 - accuracy: 0.9933 - val_loss: 10.1281 - val_accuracy: 0.9989\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.1270 - accuracy: 0.9935 - val_loss: 10.0895 - val_accuracy: 0.9989\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.0886 - accuracy: 0.9937 - val_loss: 10.0502 - val_accuracy: 0.9989\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 10.0502 - accuracy: 0.9939 - val_loss: 10.0108 - val_accuracy: 0.9991\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 10.0109 - accuracy: 0.9936 - val_loss: 9.9724 - val_accuracy: 0.9989\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.9688 - accuracy: 0.9945 - val_loss: 9.9328 - val_accuracy: 0.9993\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.9336 - accuracy: 0.9931 - val_loss: 9.8944 - val_accuracy: 0.9991\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.8918 - accuracy: 0.9943 - val_loss: 9.8558 - val_accuracy: 0.9992\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.8539 - accuracy: 0.9946 - val_loss: 9.8172 - val_accuracy: 0.9992\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.8134 - accuracy: 0.9953 - val_loss: 9.7790 - val_accuracy: 0.9992\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.7766 - accuracy: 0.9949 - val_loss: 9.7408 - val_accuracy: 0.9992\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.7361 - accuracy: 0.9959 - val_loss: 9.7027 - val_accuracy: 0.9988\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.6976 - accuracy: 0.9951 - val_loss: 9.6639 - val_accuracy: 0.9992\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.6592 - accuracy: 0.9952 - val_loss: 9.6258 - val_accuracy: 0.9992\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.6215 - accuracy: 0.9949 - val_loss: 9.5877 - val_accuracy: 0.9993\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.5834 - accuracy: 0.9951 - val_loss: 9.5494 - val_accuracy: 0.9992\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.5445 - accuracy: 0.9950 - val_loss: 9.5118 - val_accuracy: 0.9993\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.5053 - accuracy: 0.9960 - val_loss: 9.4742 - val_accuracy: 0.9992\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.4699 - accuracy: 0.9952 - val_loss: 9.4364 - val_accuracy: 0.9993\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.4295 - accuracy: 0.9964 - val_loss: 9.3992 - val_accuracy: 0.9992\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.3939 - accuracy: 0.9956 - val_loss: 9.3617 - val_accuracy: 0.9992\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.3551 - accuracy: 0.9956 - val_loss: 9.3239 - val_accuracy: 0.9993\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.3156 - accuracy: 0.9964 - val_loss: 9.2867 - val_accuracy: 0.9992\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.2791 - accuracy: 0.9961 - val_loss: 9.2493 - val_accuracy: 0.9993\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.2447 - accuracy: 0.9958 - val_loss: 9.2121 - val_accuracy: 0.9993\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.2058 - accuracy: 0.9954 - val_loss: 9.1748 - val_accuracy: 0.9995\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.1672 - accuracy: 0.9969 - val_loss: 9.1382 - val_accuracy: 0.9992\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.1306 - accuracy: 0.9961 - val_loss: 9.1013 - val_accuracy: 0.9992\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.0932 - accuracy: 0.9966 - val_loss: 9.0642 - val_accuracy: 0.9993\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 9.0569 - accuracy: 0.9966 - val_loss: 9.0276 - val_accuracy: 0.9993\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 9.0194 - accuracy: 0.9963 - val_loss: 8.9911 - val_accuracy: 0.9992\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.9827 - accuracy: 0.9967 - val_loss: 8.9542 - val_accuracy: 0.9993\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 8.9470 - accuracy: 0.9963 - val_loss: 8.9179 - val_accuracy: 0.9993\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.9103 - accuracy: 0.9966 - val_loss: 8.8815 - val_accuracy: 0.9993\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.8724 - accuracy: 0.9967 - val_loss: 8.8453 - val_accuracy: 0.9992\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.8382 - accuracy: 0.9965 - val_loss: 8.8087 - val_accuracy: 0.9993\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 8.7998 - accuracy: 0.9969 - val_loss: 8.7727 - val_accuracy: 0.9993\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.7645 - accuracy: 0.9965 - val_loss: 8.7364 - val_accuracy: 0.9993\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.7273 - accuracy: 0.9976 - val_loss: 8.7004 - val_accuracy: 0.9993\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.6919 - accuracy: 0.9973 - val_loss: 8.6645 - val_accuracy: 0.9995\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.6554 - accuracy: 0.9971 - val_loss: 8.6291 - val_accuracy: 0.9993\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 8.6199 - accuracy: 0.9966 - val_loss: 8.5930 - val_accuracy: 0.9995\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.5846 - accuracy: 0.9967 - val_loss: 8.5577 - val_accuracy: 0.9993\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.5493 - accuracy: 0.9972 - val_loss: 8.5219 - val_accuracy: 0.9993\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 10s 114ms/step - loss: 8.5132 - accuracy: 0.9967 - val_loss: 8.4865 - val_accuracy: 0.9993\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.4751 - accuracy: 0.9983 - val_loss: 8.4511 - val_accuracy: 0.9993\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.4410 - accuracy: 0.9972 - val_loss: 8.4160 - val_accuracy: 0.9992\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.4057 - accuracy: 0.9972 - val_loss: 8.3805 - val_accuracy: 0.9993\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.3702 - accuracy: 0.9976 - val_loss: 8.3451 - val_accuracy: 0.9995\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.3364 - accuracy: 0.9976 - val_loss: 8.3101 - val_accuracy: 0.9993\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 10s 116ms/step - loss: 8.3004 - accuracy: 0.9974 - val_loss: 8.2753 - val_accuracy: 0.9993\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.2664 - accuracy: 0.9973 - val_loss: 8.2400 - val_accuracy: 0.9995\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.2310 - accuracy: 0.9974 - val_loss: 8.2054 - val_accuracy: 0.9995\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 10s 115ms/step - loss: 8.1947 - accuracy: 0.9980 - val_loss: 8.1704 - val_accuracy: 0.9996\n",
      "Time: 1035.2422256469727\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_50disc_1KSNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#1KSNPS, 50 discrete\n",
    "################################################################################################################################################xtrain, xtest = X[int(len(y)*.25):], X[:int(len(y)*.25)]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test  = train_test_split(y,X,traits_disc50,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_disc_subset(ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test)\n",
    "\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_50disc_1KSNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IacZgKopE0o1",
    "outputId": "78612e46-1906-4e5e-eb7a-2f7a62ee3569",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 50, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 48, 250)      45000       ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 48, 250)     1000        ['conv1d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 46, 250)      187500      ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 46, 250)     1000        ['conv1d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 44, 250)      187500      ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 44, 250)     1000        ['conv1d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPooling1D)  (None, 14, 250)     0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 3500)         0           ['max_pooling1d_7[0][0]']        \n",
      "                                                                                                  \n",
      " dense_68_input (InputLayer)    [(None, 1000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_71 (Dense)               (None, 125)          437625      ['flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_68 (Dense)               (None, 150)          150000      ['dense_68_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 125)          0           ['dense_71[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 150)         600         ['dense_68[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_72 (Dense)               (None, 125)          15750       ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dense_69 (Dense)               (None, 150)          22500       ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 125)          0           ['dense_72[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 150)         600         ['dense_69[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_73 (Dense)               (None, 50)           6300        ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " dense_70 (Dense)               (None, 50)           7550        ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 50)           0           ['dense_73[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_7 (LinearW)           (None, 50)           2           ['dense_70[0][0]',               \n",
      "                                                                  'activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " dense_74 (Dense)               (None, 50)           2550        ['linear_w_7[0][0]']             \n",
      "                                                                                                  \n",
      " dense_75 (Dense)               (None, 3)            153         ['dense_74[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,066,630\n",
      "Trainable params: 1,064,530\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 2s 14ms/step - loss: 8.8925 - accuracy: 0.3406 - val_loss: 8.7840 - val_accuracy: 0.3396\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.8127 - accuracy: 0.3585 - val_loss: 8.7459 - val_accuracy: 0.3779\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.7631 - accuracy: 0.3861 - val_loss: 8.7129 - val_accuracy: 0.4175\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.7307 - accuracy: 0.3938 - val_loss: 8.6756 - val_accuracy: 0.4468\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.6893 - accuracy: 0.4179 - val_loss: 8.6336 - val_accuracy: 0.4847\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.6540 - accuracy: 0.4316 - val_loss: 8.5886 - val_accuracy: 0.5235\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.6163 - accuracy: 0.4580 - val_loss: 8.5381 - val_accuracy: 0.5579\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.5711 - accuracy: 0.4826 - val_loss: 8.4840 - val_accuracy: 0.5921\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.5237 - accuracy: 0.5084 - val_loss: 8.4242 - val_accuracy: 0.6265\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.4781 - accuracy: 0.5330 - val_loss: 8.3630 - val_accuracy: 0.6565\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.4252 - accuracy: 0.5617 - val_loss: 8.3017 - val_accuracy: 0.6825\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.3719 - accuracy: 0.5852 - val_loss: 8.2405 - val_accuracy: 0.7020\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.3260 - accuracy: 0.6052 - val_loss: 8.1808 - val_accuracy: 0.7184\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.2803 - accuracy: 0.6250 - val_loss: 8.1206 - val_accuracy: 0.7403\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.2267 - accuracy: 0.6446 - val_loss: 8.0642 - val_accuracy: 0.7580\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.1751 - accuracy: 0.6673 - val_loss: 8.0101 - val_accuracy: 0.7736\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.1331 - accuracy: 0.6806 - val_loss: 7.9554 - val_accuracy: 0.7888\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.0811 - accuracy: 0.6990 - val_loss: 7.8983 - val_accuracy: 0.8085\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 8.0369 - accuracy: 0.7160 - val_loss: 7.8445 - val_accuracy: 0.8255\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.9829 - accuracy: 0.7358 - val_loss: 7.7932 - val_accuracy: 0.8376\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.9351 - accuracy: 0.7519 - val_loss: 7.7446 - val_accuracy: 0.8513\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.8879 - accuracy: 0.7676 - val_loss: 7.6986 - val_accuracy: 0.8661\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.8485 - accuracy: 0.7815 - val_loss: 7.6557 - val_accuracy: 0.8776\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.8008 - accuracy: 0.7964 - val_loss: 7.6157 - val_accuracy: 0.8863\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.7605 - accuracy: 0.8097 - val_loss: 7.5778 - val_accuracy: 0.8945\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.7152 - accuracy: 0.8218 - val_loss: 7.5403 - val_accuracy: 0.9031\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.6831 - accuracy: 0.8340 - val_loss: 7.5088 - val_accuracy: 0.9092\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.6401 - accuracy: 0.8437 - val_loss: 7.4763 - val_accuracy: 0.9168\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.6096 - accuracy: 0.8489 - val_loss: 7.4457 - val_accuracy: 0.9220\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.5811 - accuracy: 0.8548 - val_loss: 7.4195 - val_accuracy: 0.9268\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.5428 - accuracy: 0.8671 - val_loss: 7.3918 - val_accuracy: 0.9311\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.5139 - accuracy: 0.8707 - val_loss: 7.3652 - val_accuracy: 0.9357\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.4874 - accuracy: 0.8775 - val_loss: 7.3405 - val_accuracy: 0.9383\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.4533 - accuracy: 0.8854 - val_loss: 7.3169 - val_accuracy: 0.9412\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.4313 - accuracy: 0.8904 - val_loss: 7.2935 - val_accuracy: 0.9428\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.4020 - accuracy: 0.8951 - val_loss: 7.2720 - val_accuracy: 0.9451\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.3801 - accuracy: 0.8948 - val_loss: 7.2512 - val_accuracy: 0.9472\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.3517 - accuracy: 0.9029 - val_loss: 7.2293 - val_accuracy: 0.9489\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.3290 - accuracy: 0.9073 - val_loss: 7.2084 - val_accuracy: 0.9516\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.3039 - accuracy: 0.9092 - val_loss: 7.1875 - val_accuracy: 0.9533\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.2828 - accuracy: 0.9111 - val_loss: 7.1675 - val_accuracy: 0.9548\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.2538 - accuracy: 0.9183 - val_loss: 7.1471 - val_accuracy: 0.9567\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.2396 - accuracy: 0.9169 - val_loss: 7.1308 - val_accuracy: 0.9561\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.2203 - accuracy: 0.9180 - val_loss: 7.1111 - val_accuracy: 0.9573\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.1924 - accuracy: 0.9240 - val_loss: 7.0917 - val_accuracy: 0.9587\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.1704 - accuracy: 0.9240 - val_loss: 7.0719 - val_accuracy: 0.9605\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.1500 - accuracy: 0.9273 - val_loss: 7.0535 - val_accuracy: 0.9615\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.1264 - accuracy: 0.9316 - val_loss: 7.0359 - val_accuracy: 0.9619\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.1081 - accuracy: 0.9322 - val_loss: 7.0173 - val_accuracy: 0.9633\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.0903 - accuracy: 0.9349 - val_loss: 6.9998 - val_accuracy: 0.9643\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.0653 - accuracy: 0.9381 - val_loss: 6.9818 - val_accuracy: 0.9649\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.0524 - accuracy: 0.9374 - val_loss: 6.9655 - val_accuracy: 0.9649\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.0292 - accuracy: 0.9383 - val_loss: 6.9473 - val_accuracy: 0.9669\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 7.0078 - accuracy: 0.9412 - val_loss: 6.9308 - val_accuracy: 0.9667\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.9948 - accuracy: 0.9396 - val_loss: 6.9135 - val_accuracy: 0.9676\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.9713 - accuracy: 0.9436 - val_loss: 6.8972 - val_accuracy: 0.9673\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.9602 - accuracy: 0.9423 - val_loss: 6.8799 - val_accuracy: 0.9681\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.9366 - accuracy: 0.9442 - val_loss: 6.8630 - val_accuracy: 0.9684\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.9169 - accuracy: 0.9482 - val_loss: 6.8461 - val_accuracy: 0.9693\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 6.9026 - accuracy: 0.9450 - val_loss: 6.8286 - val_accuracy: 0.9697\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.8802 - accuracy: 0.9497 - val_loss: 6.8127 - val_accuracy: 0.9701\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.8632 - accuracy: 0.9509 - val_loss: 6.7957 - val_accuracy: 0.9713\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.8429 - accuracy: 0.9514 - val_loss: 6.7801 - val_accuracy: 0.9721\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.8272 - accuracy: 0.9515 - val_loss: 6.7643 - val_accuracy: 0.9720\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.8104 - accuracy: 0.9540 - val_loss: 6.7487 - val_accuracy: 0.9729\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7963 - accuracy: 0.9544 - val_loss: 6.7330 - val_accuracy: 0.9719\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7771 - accuracy: 0.9556 - val_loss: 6.7161 - val_accuracy: 0.9729\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7633 - accuracy: 0.9542 - val_loss: 6.7017 - val_accuracy: 0.9740\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7418 - accuracy: 0.9560 - val_loss: 6.6847 - val_accuracy: 0.9747\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7240 - accuracy: 0.9575 - val_loss: 6.6682 - val_accuracy: 0.9748\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.7050 - accuracy: 0.9593 - val_loss: 6.6533 - val_accuracy: 0.9751\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6901 - accuracy: 0.9592 - val_loss: 6.6366 - val_accuracy: 0.9752\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6750 - accuracy: 0.9588 - val_loss: 6.6217 - val_accuracy: 0.9757\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6582 - accuracy: 0.9589 - val_loss: 6.6060 - val_accuracy: 0.9765\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6407 - accuracy: 0.9613 - val_loss: 6.5906 - val_accuracy: 0.9765\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6254 - accuracy: 0.9603 - val_loss: 6.5757 - val_accuracy: 0.9763\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.6069 - accuracy: 0.9626 - val_loss: 6.5602 - val_accuracy: 0.9760\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5905 - accuracy: 0.9638 - val_loss: 6.5442 - val_accuracy: 0.9765\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5759 - accuracy: 0.9629 - val_loss: 6.5289 - val_accuracy: 0.9768\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5584 - accuracy: 0.9640 - val_loss: 6.5145 - val_accuracy: 0.9765\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5457 - accuracy: 0.9632 - val_loss: 6.4974 - val_accuracy: 0.9773\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5228 - accuracy: 0.9675 - val_loss: 6.4827 - val_accuracy: 0.9771\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.5065 - accuracy: 0.9646 - val_loss: 6.4676 - val_accuracy: 0.9775\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4926 - accuracy: 0.9651 - val_loss: 6.4525 - val_accuracy: 0.9777\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4759 - accuracy: 0.9668 - val_loss: 6.4377 - val_accuracy: 0.9777\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4602 - accuracy: 0.9664 - val_loss: 6.4238 - val_accuracy: 0.9787\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4512 - accuracy: 0.9651 - val_loss: 6.4080 - val_accuracy: 0.9777\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4291 - accuracy: 0.9673 - val_loss: 6.3930 - val_accuracy: 0.9777\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.4147 - accuracy: 0.9677 - val_loss: 6.3787 - val_accuracy: 0.9781\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3983 - accuracy: 0.9680 - val_loss: 6.3628 - val_accuracy: 0.9781\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3896 - accuracy: 0.9667 - val_loss: 6.3471 - val_accuracy: 0.9785\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3679 - accuracy: 0.9685 - val_loss: 6.3325 - val_accuracy: 0.9789\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3508 - accuracy: 0.9705 - val_loss: 6.3184 - val_accuracy: 0.9788\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3339 - accuracy: 0.9706 - val_loss: 6.3049 - val_accuracy: 0.9783\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3207 - accuracy: 0.9691 - val_loss: 6.2892 - val_accuracy: 0.9784\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.3073 - accuracy: 0.9689 - val_loss: 6.2740 - val_accuracy: 0.9789\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.2906 - accuracy: 0.9699 - val_loss: 6.2591 - val_accuracy: 0.9788\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.2738 - accuracy: 0.9701 - val_loss: 6.2445 - val_accuracy: 0.9784\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 6.2577 - accuracy: 0.9720 - val_loss: 6.2295 - val_accuracy: 0.9787\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 6.2422 - accuracy: 0.9720 - val_loss: 6.2153 - val_accuracy: 0.9788\n",
      "Time: 92.50887441635132\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_10disc_50SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#50SNPS, 10 discrete\n",
    "################################################################################################################################################xtrain, xtest = X[int(len(y)*.25):], X[:int(len(y)*.25)]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test  = train_test_split(y,X50,traits_disc10,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_disc_subset(ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test)\n",
    "\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_10disc_50SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-7WAzgnxE0o1",
    "outputId": "9f1ae619-bde9-49d0-c9ef-622e789c9a8f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 20, 60)]     0           []                               \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 18, 250)      45000       ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 18, 250)     1000        ['conv1d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 16, 250)      187500      ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 16, 250)     1000        ['conv1d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 14, 250)      187500      ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 14, 250)     1000        ['conv1d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling1d_8 (MaxPooling1D)  (None, 4, 250)      0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 1000)         0           ['max_pooling1d_8[0][0]']        \n",
      "                                                                                                  \n",
      " dense_76_input (InputLayer)    [(None, 3000)]       0           []                               \n",
      "                                                                                                  \n",
      " dense_79 (Dense)               (None, 125)          125125      ['flatten_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense_76 (Dense)               (None, 150)          450000      ['dense_76_input[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 125)          0           ['dense_79[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 150)         600         ['dense_76[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_80 (Dense)               (None, 125)          15750       ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dense_77 (Dense)               (None, 150)          22500       ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 125)          0           ['dense_80[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 150)         600         ['dense_77[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_81 (Dense)               (None, 50)           6300        ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " dense_78 (Dense)               (None, 50)           7550        ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 50)           0           ['dense_81[0][0]']               \n",
      "                                                                                                  \n",
      " linear_w_8 (LinearW)           (None, 50)           2           ['dense_78[0][0]',               \n",
      "                                                                  'activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " dense_82 (Dense)               (None, 50)           2550        ['linear_w_8[0][0]']             \n",
      "                                                                                                  \n",
      " dense_83 (Dense)               (None, 3)            153         ['dense_82[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,054,130\n",
      "Trainable params: 1,052,030\n",
      "Non-trainable params: 2,100\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "90/90 [==============================] - 2s 13ms/step - loss: 13.3218 - accuracy: 0.3359 - val_loss: 13.1367 - val_accuracy: 0.3400\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 13.1560 - accuracy: 0.3680 - val_loss: 13.0590 - val_accuracy: 0.3827\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 13.0728 - accuracy: 0.3986 - val_loss: 12.9795 - val_accuracy: 0.4515\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.9994 - accuracy: 0.4186 - val_loss: 12.8970 - val_accuracy: 0.4956\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.9215 - accuracy: 0.4454 - val_loss: 12.8189 - val_accuracy: 0.5209\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.8567 - accuracy: 0.4620 - val_loss: 12.7459 - val_accuracy: 0.5447\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.7854 - accuracy: 0.4848 - val_loss: 12.6756 - val_accuracy: 0.5628\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.7243 - accuracy: 0.4991 - val_loss: 12.6121 - val_accuracy: 0.5784\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.6615 - accuracy: 0.5150 - val_loss: 12.5492 - val_accuracy: 0.5915\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.6046 - accuracy: 0.5285 - val_loss: 12.4892 - val_accuracy: 0.6004\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.5376 - accuracy: 0.5447 - val_loss: 12.4299 - val_accuracy: 0.6093\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.4867 - accuracy: 0.5468 - val_loss: 12.3719 - val_accuracy: 0.6181\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.4216 - accuracy: 0.5675 - val_loss: 12.3156 - val_accuracy: 0.6260\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.3743 - accuracy: 0.5693 - val_loss: 12.2609 - val_accuracy: 0.6315\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.3206 - accuracy: 0.5748 - val_loss: 12.2059 - val_accuracy: 0.6369\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.2671 - accuracy: 0.5790 - val_loss: 12.1516 - val_accuracy: 0.6395\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.2109 - accuracy: 0.5890 - val_loss: 12.0981 - val_accuracy: 0.6444\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.1565 - accuracy: 0.5982 - val_loss: 12.0456 - val_accuracy: 0.6493\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.1034 - accuracy: 0.6132 - val_loss: 11.9910 - val_accuracy: 0.6587\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 12.0506 - accuracy: 0.6117 - val_loss: 11.9381 - val_accuracy: 0.6647\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.9964 - accuracy: 0.6174 - val_loss: 11.8828 - val_accuracy: 0.6711\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.9414 - accuracy: 0.6293 - val_loss: 11.8284 - val_accuracy: 0.6805\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.8888 - accuracy: 0.6358 - val_loss: 11.7753 - val_accuracy: 0.6863\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.8350 - accuracy: 0.6448 - val_loss: 11.7200 - val_accuracy: 0.6984\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.7845 - accuracy: 0.6513 - val_loss: 11.6656 - val_accuracy: 0.7084\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.7240 - accuracy: 0.6585 - val_loss: 11.6106 - val_accuracy: 0.7163\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.6727 - accuracy: 0.6666 - val_loss: 11.5553 - val_accuracy: 0.7268\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.6171 - accuracy: 0.6723 - val_loss: 11.4994 - val_accuracy: 0.7385\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.5633 - accuracy: 0.6775 - val_loss: 11.4425 - val_accuracy: 0.7487\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.5091 - accuracy: 0.6892 - val_loss: 11.3866 - val_accuracy: 0.7564\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.4526 - accuracy: 0.6971 - val_loss: 11.3288 - val_accuracy: 0.7665\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.3932 - accuracy: 0.7058 - val_loss: 11.2726 - val_accuracy: 0.7757\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.3451 - accuracy: 0.7116 - val_loss: 11.2159 - val_accuracy: 0.7844\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.2880 - accuracy: 0.7229 - val_loss: 11.1602 - val_accuracy: 0.7909\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.2338 - accuracy: 0.7247 - val_loss: 11.1048 - val_accuracy: 0.7977\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.1785 - accuracy: 0.7348 - val_loss: 11.0502 - val_accuracy: 0.8048\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.1256 - accuracy: 0.7414 - val_loss: 10.9962 - val_accuracy: 0.8105\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.0779 - accuracy: 0.7488 - val_loss: 10.9429 - val_accuracy: 0.8173\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 11.0250 - accuracy: 0.7545 - val_loss: 10.8911 - val_accuracy: 0.8225\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.9637 - accuracy: 0.7642 - val_loss: 10.8389 - val_accuracy: 0.8249\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.9213 - accuracy: 0.7658 - val_loss: 10.7902 - val_accuracy: 0.8304\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.8686 - accuracy: 0.7684 - val_loss: 10.7389 - val_accuracy: 0.8364\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.8155 - accuracy: 0.7781 - val_loss: 10.6905 - val_accuracy: 0.8383\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.7656 - accuracy: 0.7831 - val_loss: 10.6428 - val_accuracy: 0.8395\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.7162 - accuracy: 0.7876 - val_loss: 10.5943 - val_accuracy: 0.8440\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.6700 - accuracy: 0.7936 - val_loss: 10.5471 - val_accuracy: 0.8463\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.6253 - accuracy: 0.7943 - val_loss: 10.5008 - val_accuracy: 0.8493\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.5722 - accuracy: 0.8046 - val_loss: 10.4556 - val_accuracy: 0.8524\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.5246 - accuracy: 0.8064 - val_loss: 10.4102 - val_accuracy: 0.8557\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.4831 - accuracy: 0.8098 - val_loss: 10.3647 - val_accuracy: 0.8583\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.4337 - accuracy: 0.8086 - val_loss: 10.3207 - val_accuracy: 0.8588\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.3841 - accuracy: 0.8191 - val_loss: 10.2759 - val_accuracy: 0.8632\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.3429 - accuracy: 0.8211 - val_loss: 10.2318 - val_accuracy: 0.8651\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.2968 - accuracy: 0.8237 - val_loss: 10.1886 - val_accuracy: 0.8668\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.2520 - accuracy: 0.8287 - val_loss: 10.1452 - val_accuracy: 0.8673\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.2092 - accuracy: 0.8283 - val_loss: 10.1026 - val_accuracy: 0.8704\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.1605 - accuracy: 0.8330 - val_loss: 10.0599 - val_accuracy: 0.8732\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.1182 - accuracy: 0.8368 - val_loss: 10.0170 - val_accuracy: 0.8769\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.0767 - accuracy: 0.8394 - val_loss: 9.9747 - val_accuracy: 0.8753\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 10.0239 - accuracy: 0.8465 - val_loss: 9.9329 - val_accuracy: 0.8800\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.9817 - accuracy: 0.8463 - val_loss: 9.8901 - val_accuracy: 0.8804\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.9444 - accuracy: 0.8467 - val_loss: 9.8482 - val_accuracy: 0.8821\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.8968 - accuracy: 0.8513 - val_loss: 9.8059 - val_accuracy: 0.8835\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.8536 - accuracy: 0.8509 - val_loss: 9.7663 - val_accuracy: 0.8849\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.8157 - accuracy: 0.8563 - val_loss: 9.7238 - val_accuracy: 0.8871\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.7698 - accuracy: 0.8577 - val_loss: 9.6832 - val_accuracy: 0.8884\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.7269 - accuracy: 0.8629 - val_loss: 9.6430 - val_accuracy: 0.8895\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.6847 - accuracy: 0.8652 - val_loss: 9.6021 - val_accuracy: 0.8904\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.6473 - accuracy: 0.8663 - val_loss: 9.5618 - val_accuracy: 0.8913\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.6029 - accuracy: 0.8660 - val_loss: 9.5215 - val_accuracy: 0.8928\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.5621 - accuracy: 0.8690 - val_loss: 9.4814 - val_accuracy: 0.8932\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.5264 - accuracy: 0.8700 - val_loss: 9.4422 - val_accuracy: 0.8932\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.4795 - accuracy: 0.8755 - val_loss: 9.4022 - val_accuracy: 0.8940\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.4452 - accuracy: 0.8723 - val_loss: 9.3636 - val_accuracy: 0.8940\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.3995 - accuracy: 0.8744 - val_loss: 9.3237 - val_accuracy: 0.8964\n",
      "Epoch 76/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.3553 - accuracy: 0.8772 - val_loss: 9.2846 - val_accuracy: 0.8972\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.3258 - accuracy: 0.8768 - val_loss: 9.2449 - val_accuracy: 0.8976\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.2789 - accuracy: 0.8809 - val_loss: 9.2077 - val_accuracy: 0.8993\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.2436 - accuracy: 0.8816 - val_loss: 9.1683 - val_accuracy: 0.9001\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.1987 - accuracy: 0.8841 - val_loss: 9.1307 - val_accuracy: 0.9015\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.1575 - accuracy: 0.8873 - val_loss: 9.0931 - val_accuracy: 0.9021\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.1240 - accuracy: 0.8851 - val_loss: 9.0548 - val_accuracy: 0.9019\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.0762 - accuracy: 0.8903 - val_loss: 9.0163 - val_accuracy: 0.9031\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.0414 - accuracy: 0.8885 - val_loss: 8.9794 - val_accuracy: 0.9037\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.0015 - accuracy: 0.8893 - val_loss: 8.9406 - val_accuracy: 0.9049\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.9662 - accuracy: 0.8894 - val_loss: 8.9035 - val_accuracy: 0.9049\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.9251 - accuracy: 0.8910 - val_loss: 8.8673 - val_accuracy: 0.9045\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.8830 - accuracy: 0.8953 - val_loss: 8.8298 - val_accuracy: 0.9049\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.8510 - accuracy: 0.8950 - val_loss: 8.7924 - val_accuracy: 0.9073\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.8108 - accuracy: 0.8965 - val_loss: 8.7560 - val_accuracy: 0.9080\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.7734 - accuracy: 0.8987 - val_loss: 8.7191 - val_accuracy: 0.9084\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.7351 - accuracy: 0.8978 - val_loss: 8.6826 - val_accuracy: 0.9080\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.6942 - accuracy: 0.8987 - val_loss: 8.6464 - val_accuracy: 0.9081\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.6591 - accuracy: 0.9016 - val_loss: 8.6096 - val_accuracy: 0.9093\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.6222 - accuracy: 0.9022 - val_loss: 8.5744 - val_accuracy: 0.9091\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.5835 - accuracy: 0.9005 - val_loss: 8.5386 - val_accuracy: 0.9084\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.5493 - accuracy: 0.9003 - val_loss: 8.5023 - val_accuracy: 0.9085\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.5142 - accuracy: 0.9012 - val_loss: 8.4663 - val_accuracy: 0.9103\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.4706 - accuracy: 0.9040 - val_loss: 8.4304 - val_accuracy: 0.9097\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 8.4364 - accuracy: 0.9058 - val_loss: 8.3951 - val_accuracy: 0.9103\n",
      "Time: 73.23046231269836\n",
      "INFO:tensorflow:Assets written to: ./Trained_Models/Trained_Comb_Model_100disc_20SNPs.acc.mod/assets\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################\n",
    "#20SNPS, 100 disc\n",
    "################################################################################################################################################xtrain, xtest = X[int(len(y)*.25):], X[:int(len(y)*.25)]\n",
    "\n",
    "# separate 75% of labels, SNP and traits matrices as training set. The other 25% are assigned to the test set. The two sets are shuffled.\n",
    "ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test  = train_test_split(y,X20,traits_disc,test_size=0.25, shuffle=True,stratify=y)\n",
    "\n",
    "# train the network\n",
    "model = combined_disc_subset(ytrain, ytest, xtrain, xtest, traits_disc_train, traits_disc_test)\n",
    "\n",
    "model.save(filepath='./Trained_Models/Trained_Comb_Model_100disc_20SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CJn4Q4eRnWO0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now that the models are trained, we will evaluate their accuracy based on the test set. For that, we will build confusion matrices containing the true and predicted scenarions for each simulation on the test set.\n",
    "\n",
    "# first import the libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# load the trained models.\n",
    "model1 = load_model('./Trained_Models/Trained_Traits_Model_100BM.acc.mod')\n",
    "model2 = load_model('./Trained_Models/Trained_Traits_Model_50BM.acc.mod')\n",
    "model3 = load_model('./Trained_Models/Trained_Traits_Model_10BM.acc.mod')\n",
    "model4 = load_model('./Trained_Models/Trained_Traits_Model_100OU.acc.mod')\n",
    "model5 = load_model('./Trained_Models/Trained_Traits_Model_50OU.acc.mod')\n",
    "model6 = load_model('./Trained_Models/Trained_Traits_Model_10OU.acc.mod')\n",
    "model7 = load_model('./Trained_Models/Trained_Traits_Model_100disc.acc.mod')\n",
    "model8 = load_model('./Trained_Models/Trained_Traits_Model_50disc.acc.mod')\n",
    "model9 = load_model('./Trained_Models/Trained_Traits_Model_10disc.acc.mod')\n",
    "model10 = load_model('./Trained_Models/Trained_CNN_Model_1KSNPs.acc.mod')\n",
    "model11 = load_model('./Trained_Models/Trained_CNN_Model_50SNPs.acc.mod')\n",
    "model12 = load_model('./Trained_Models/Trained_CNN_Model_20SNPs.acc.mod')\n",
    "model13 = load_model('./Trained_Models/Trained_Comb_Model_100BM_1KSNPs.acc.mod')\n",
    "model14 = load_model('./Trained_Models/Trained_Comb_Model_50BM_1KSNPs.acc.mod')\n",
    "model15 = load_model('./Trained_Models/Trained_Comb_Model_10BM_1KSNPs.acc.mod')\n",
    "model16 = load_model('./Trained_Models/Trained_Comb_Model_100BM_50SNPs.acc.mod')\n",
    "model17 = load_model('./Trained_Models/Trained_Comb_Model_50BM_50SNPs.acc.mod')\n",
    "model18 = load_model('./Trained_Models/Trained_Comb_Model_10BM_50SNPs.acc.mod')\n",
    "model19 = load_model('./Trained_Models/Trained_Comb_Model_100BM_20SNPs.acc.mod')\n",
    "model20 = load_model('./Trained_Models/Trained_Comb_Model_50BM_20SNPs.acc.mod')\n",
    "model21 = load_model('./Trained_Models/Trained_Comb_Model_10BM_20SNPs.acc.mod')\n",
    "model22 = load_model('./Trained_Models/Trained_Comb_Model_100OU_1KSNPs.acc.mod')\n",
    "model23 = load_model('./Trained_Models/Trained_Comb_Model_50OU_1KSNPs.acc.mod')\n",
    "model24 = load_model('./Trained_Models/Trained_Comb_Model_10OU_1KSNPs.acc.mod')\n",
    "model25 = load_model('./Trained_Models/Trained_Comb_Model_100OU_50SNPs.acc.mod')\n",
    "model26 = load_model('./Trained_Models/Trained_Comb_Model_50OU_50SNPs.acc.mod')\n",
    "model27 = load_model('./Trained_Models/Trained_Comb_Model_10OU_50SNPs.acc.mod')\n",
    "model28 = load_model('./Trained_Models/Trained_Comb_Model_100OU_20SNPs.acc.mod')\n",
    "model29 = load_model('./Trained_Models/Trained_Comb_Model_50OU_20SNPs.acc.mod')\n",
    "model30 = load_model('./Trained_Models/Trained_Comb_Model_10OU_20SNPs.acc.mod')\n",
    "model31 = load_model('./Trained_Models/Trained_Comb_Model_100disc_1KSNPs.acc.mod')\n",
    "model32 = load_model('./Trained_Models/Trained_Comb_Model_50disc_1KSNPs.acc.mod')\n",
    "model33 = load_model('./Trained_Models/Trained_Comb_Model_10disc_1KSNPs.acc.mod')\n",
    "model34 = load_model('./Trained_Models/Trained_Comb_Model_100disc_50SNPs.acc.mod')\n",
    "model35 = load_model('./Trained_Models/Trained_Comb_Model_50disc_50SNPs.acc.mod')\n",
    "model36 = load_model('./Trained_Models/Trained_Comb_Model_10disc_50SNPs.acc.mod')\n",
    "model37 = load_model('./Trained_Models/Trained_Comb_Model_100disc_20SNPs.acc.mod')\n",
    "model38 = load_model('./Trained_Models/Trained_Comb_Model_50disc_20SNPs.acc.mod')\n",
    "model39 = load_model('./Trained_Models/Trained_Comb_Model_10disc_20SNPs.acc.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete after running\n",
    "# load the traits simulated under the BM model for the 3 scenarios. \n",
    "traits_BM = []\n",
    "traits_BM = np.loadtxt(\"./traits/traits_BM.txt\").reshape(30000,-1,100)\n",
    "# transform into a NumPy array. \n",
    "traits_BM = np.array(traits_BM)\n",
    "\n",
    "# standard scale the continuous (BM) traits\n",
    "scalers_BM = {}\n",
    "for i in range(traits_BM.shape[2]):\n",
    "    scalers_BM[i] = StandardScaler(copy=False)\n",
    "    traits_BM[:, :, i] = scalers_BM[i].fit_transform(traits_BM[:, :, i])\n",
    "\n",
    "# load the traits simulated under the OU model for the 3 scenarios. \n",
    "traits_OU = []\n",
    "traits_OU = np.loadtxt(\"./traits/traits_OU.txt\").reshape(30000,-1,100)\n",
    "# transform into a NumPy array. \n",
    "traits_OU = np.array(traits_OU)\n",
    "\n",
    "# standard scale the continuous (OU) traits\n",
    "scalers_OU = {}\n",
    "for i in range(traits_OU.shape[2]):\n",
    "    scalers_OU[i] = StandardScaler(copy=False)\n",
    "    traits_OU[:, :, i] = scalers_OU[i].fit_transform(traits_OU[:, :, i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jF6nrDm1vH0x",
    "outputId": "b29ca1db-ffd1-41af-fe19-f57e77cc2e17",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the traits simulated under the BM model for the 3 scenarios.\n",
    "traits_BM = []\n",
    "traits_BM = np.loadtxt(\"./testSims/traits/traits_BM.txt\").reshape(3000,-1,100)\n",
    "# transform into a NumPy array. \n",
    "traits_BM = np.array(traits_BM)\n",
    "\n",
    "#Use standard scaling for the continuous (BM) traits.\n",
    "for i in range(traits_BM.shape[2]):\n",
    "    traits_BM[:, :, i] = scalers_BM[i].transform(traits_BM[:, :, i]) \n",
    "    \n",
    "#Create subsets of the continuous (BM) traits.\n",
    "traits_BM10=traits_BM[:,0:10,:]\n",
    "traits_BM50=traits_BM[:,0:50,:]\n",
    "\n",
    "# load the traits simulated under the OU model for the 3 scenarios.\n",
    "traits_OU = []\n",
    "traits_OU = np.loadtxt(\"./testSims/traits/traits_OU.txt\").reshape(3000,-1,100)\n",
    "# transform into a NumPy array. \n",
    "traits_OU = np.array(traits_OU)\n",
    "\n",
    "#Use standard scaling for the continuous (OU) traits.\n",
    "for i in range(traits_OU.shape[2]):\n",
    "    traits_OU[:, :, i] = scalers_OU[i].transform(traits_OU[:, :, i]) \n",
    "\n",
    "#Create subsets of the continuous (OU) traits.\n",
    "traits_OU10=traits_OU[:,0:10,:]\n",
    "traits_OU50=traits_OU[:,0:50,:]\n",
    "\n",
    "# load the discrete traits simulated for the 3 scenarios.\n",
    "traits_disc = []\n",
    "traits_disc = np.loadtxt(\"./testSims/traits/traits_disc.txt\").reshape(3000,-1,100)\n",
    "# transform into a NumPy array. \n",
    "traits_disc = np.array(traits_disc)\n",
    "\n",
    "#Create subsets of the discrete traits.\n",
    "traits_disc10=traits_disc[:,0:10,:]\n",
    "traits_disc50=traits_disc[:,0:50,:]\n",
    "\n",
    "# load the SNPs simulated for the 3 scenarios. \n",
    "u1 = np.load(\"./testSims/Model_1sp.npz\",mmap_mode='r')\n",
    "u2 = np.load(\"./testSims/Model_2sp.npz\",mmap_mode='r')\n",
    "u3 = np.load(\"./testSims/Model_3sp.npz\",mmap_mode='r')\n",
    "\n",
    "# combine the loaded SNPs in a single NumPy array.\n",
    "xtest=np.concatenate((u1['Model_1sp'],u2['Model_2sp'],u3['Model_3sp']),axis=0)\n",
    "\n",
    "#transform major alleles in -1 and minor in 1\n",
    "for arr,array in enumerate(xtest):\n",
    "    for idx,row in enumerate(array):\n",
    "        if np.count_nonzero(row) > len(row)/2:\n",
    "            xtest[arr][idx][xtest[arr][idx] == 1] = -1\n",
    "            xtest[arr][idx][xtest[arr][idx] == 0] = 1\n",
    "        else:\n",
    "            xtest[arr][idx][xtest[arr][idx] == 0] = -1\n",
    "\n",
    "# create a label vector in the same order as the simulations.            \n",
    "ytest=[0 for i in range(len(u1['Model_1sp']))]\n",
    "ytest.extend([1 for i in range(len(u2['Model_2sp']))])\n",
    "ytest.extend([2 for i in range(len(u3['Model_3sp']))])\n",
    "ytest = np.array(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "id": "qfi_m7crw2Xo",
    "outputId": "d8eaef70-88e1-432a-f262-30b3f61b096d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define a funtion to build the confusion matrix\n",
    "def makeConfusionMatrixHeatmap(data, title, trueClassOrderLs, predictedClassOrderLs, ax):\n",
    "    data = np.array(data)\n",
    "    data = normalize(data, axis=1, norm='l1')\n",
    "    heatmap = ax.pcolor(data, cmap=plt.cm.Blues, vmin=0.0, vmax=1.0)\n",
    "\n",
    "    for i in range(len(predictedClassOrderLs)):\n",
    "        for j in reversed(range(len(trueClassOrderLs))):\n",
    "            val = 100*data[j, i]\n",
    "            if val > 50:\n",
    "                c = '0.9'\n",
    "            else:\n",
    "                c = 'black'\n",
    "            ax.text(i + 0.5, j + 0.5, '%.2f%%' % val, horizontalalignment='center', verticalalignment='center', color=c, fontsize=9)\n",
    "\n",
    "    cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n",
    "    cbar.set_label(\"Fraction of simulations assigned to class\", rotation=270, labelpad=20, fontsize=11)\n",
    "\n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_xticks(np.arange(data.shape[1]) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(data.shape[0]) + 0.5, minor=False)\n",
    "    ax.axis('tight')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    #labels\n",
    "    ax.set_xticklabels(predictedClassOrderLs, minor=False, fontsize=9, rotation=45)\n",
    "    ax.set_yticklabels(reversed(trueClassOrderLs), minor=False, fontsize=9)\n",
    "    ax.set_xlabel(\"Predicted class\")\n",
    "    ax.set_ylabel(\"True class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "id": "oVjUXRySZGmu",
    "outputId": "5514c41c-7ab3-4011-f97f-03b9c8e79bcd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000    0    0]\n",
      " [ 162  825   13]\n",
      " [  22   75  903]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEkCAYAAADTtG33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA+ZUlEQVR4nO3dd3hUZdrH8e8vgVBCCYgCUlQsoCIoIirSQQUb9l7XAra1oFheV3DtgAXbCqKCioAo7rriKhaQYqNIEZQiKmKn14R2v3+ckzCEZDLJhGQm3B+vuTKnPOc8Z9S55+kyM5xzzrlYpJR2BpxzziUPDxrOOedi5kHDOedczDxoOOeci5kHDeecczHzoOGccy5mHjRcqZFUSdJ/Ja2WNDqO61wkaVxx5q20SGoraX5p58O5/MjHabiCSLoQuBVoAqwFZgIPmtnkOK97CXAj0NrMtsSbz0QnyYADzWxRaefFuaLykoaLStKtwJPAQ0BtoCHwHNC9GC6/D7BgdwgYsZBUrrTz4FxBPGi4fEmqDvwTuN7MxpjZejPbbGb/NbPbw3MqSHpS0q/h60lJFcJjHSQtldRL0p+SfpN0RXjsPuBe4DxJ6yRdKamvpNci7r+vJMv+MpV0uaTFktZK+kHSRRH7J0ekay1paljtNVVS64hjEyTdL2lKeJ1xkmrl8/zZ+e8dkf/TJZ0kaYGkFZLujji/laTPJa0Kz31GUlp4bGJ42qzwec+LuP4dkn4HXs7eF6bZP7xHi3B7b0nLJHWI59+rc/HwoOGiORaoCLwd5Zz/A44BDgeaA62AeyKO1wGqA/WAK4FnJdUwsz4EpZdRZlbFzF6MlhFJ6cBTQDczqwq0Jqgmy31eTWBseO4ewOPAWEl7RJx2IXAFsBeQBtwW5dZ1CD6DegRB7gXgYuBIoC1wr6RG4blbgVuAWgSfXWfgOgAzaxee0zx83lER169JUOq6JvLGZvY9cAcwXFJl4GVgqJlNiJJf53YpDxoumj2AZQVUH10E/NPM/jSzv4D7gEsijm8Oj282s/eAdUDjIuZnG9BUUiUz+83M5uZxzsnAQjN71cy2mNkI4Dvg1IhzXjazBWa2EXiDIODlZzNB+81mYCRBQBhoZmvD+88FmgGY2XQz+yK874/AIKB9DM/Ux8yywvzswMxeABYCXwJ1CYK0c6XGg4aLZjlQq4C69r2BnyK2fwr35VwjV9DZAFQpbEbMbD1wHtAT+E3SWElNYshPdp7qRWz/Xoj8LDezreH77C/1PyKOb8xOL+kgSe9K+l3SGoKSVJ5VXxH+MrPMAs55AWgKPG1mWQWc69wu5UHDRfM5kAmcHuWcXwmqVrI1DPcVxXqgcsR2nciDZvaBmR1P8Iv7O4Iv04Lyk52nX4qYp8L4F0G+DjSzasDdgApIE7X7oqQqBB0RXgT6htVvzpUaDxouX2a2mqAe/9mwAbiypPKSuknqF542ArhH0p5hg/K9wGv5XbMAM4F2khqGjfB3ZR+QVFvSaWHbRhZBNdfWPK7xHnCQpAsllZN0HnAI8G4R81QYVYE1wLqwFHRtruN/AI12ShXdQGC6mV1F0FbzfNy5dC4OHjRcVGb2OMEYjXuAv4CfgRuAf4enPABMA2YDc4AZ4b6i3OtDYFR4rens+EWfAvQiKEmsIGgruC6PaywHTgnPXQ70Bk4xs2VFyVMh3UbQyL6WoBQ0KtfxvsCwsHfVuQVdTFJ3oCtBlRwE/x5aZPcac640+OA+55xzMfOShnPOuZh50HDOuQQh6aVwIOk3+RyXpKckLZI0O3vgZ0nyoOGcc4ljKEE7Vn66AQeGr2sIeuyVKA8azjmXIMxsIkFHj/x0B16xwBdAhqS6JZO7gE+Q5pxzyaMeQQ/GbEvDfb8V5WKSFpP/WCKZ2b65d5a5oKFylUxpVUs7G2XaEQc3LO0sOFcsZsyYvszM9oznGqnV9jHbstMMMHmyjX/NJRgwm22wmQ0uxO3y+oKPpwvsKbmu8xZwdsT7nZS9oJFWlQqNC+wC7+Iw5ctnSjsLzhWLSuWVe8qZQrMtmVRocn5M52Z+/XSmmbWM43ZLgQYR2/Up+gwMmNm8yG1JWdn7JOU5ZY23aTjnXDwEpKTG9orfO8ClYS+qY4DVZlakqql8WD7vc5S5koZzzpU4FTTFWKyX0QigA8FEoUuBPkB5ADN7nmCanJOARQSTbV5RLDfe7o6I9+PzOsGDhnPOxUWg4qm0MbMLCjhuwPXFcjNA0mV57TOzYWbWK680HjSccy5exVTSKAUnR7yvArQBpgDD8kvgQcM55+Ihiq2kUdLMbIdeQ5L2JVjiOV8eNJxzLi5K5pLGDszsR0kHRzvHg4ZzzsWreHpGlQpJVYHMcEljgCslpZjZtrzOT84ylXPOJYywITyWV4KRdBvB4mArJHWVtAfQJb+AAR40nHMuPiKonorllXiuJxgs2Aa4K1zELOpIRa+ecs65eCVgKSJGP4WBYnnE+vNR69qS9kmdcy4xJG/1FPA/SQ+EM+Vuk9SZHefG2omXNJxzLl4pCVn1FIuHwr93AVnAA0CPaAk8aDjnXDyy555KQmZW6Ix70HDOubgU3zQipUFSDaA1wQSFn5vZymjne9Bwzrl4JWbPqAKFM+WOAbKnSD9U0plm9nl+aTxoOOdcvJK3pPE4cIaZfQkg6WhgANA2vwQeNJxzLh6JOwYjFunZAQPAzL4MR4jny4OGc87FK0kbwoGtkVOGSBIFLB/rQcM55+KS1A3htwHVgFXhdjXg9mgJkvZJnXMuYSTpNCJm9omZrYrYXg20ipbGg4ZzzsUjez2NJBwRLulKSTMl/ZD9AvqE72/KK41XTznnXFySunqqN3A5sDrcNuAt4Gzgz7wSeNBwzrl4JWDVU4zW5x6TISnTzObll8CDhnPOxSt5e09dGOO+HB40nHMuHkrq6qnzlHcp6T5JPcxsUO4DHjSccy5eyVs9lZ7HvuyHqZhXAg8azjkXp3x+rSc8M+sd5djAvPZ70HDOuTgEq70mZ9CQlAJcAxxP0HPqY2BQtDXCPWg451w8xPYKneTzKNAMGErwFJcD+xOMFM+TBw3nnIuLSElJ2obwrsARZrYFQNIoYCZRgkbSPmlpG3r/+UwdcTPXn39czr4+PU9gVL9LGNL3XKpXCdqQqlepyJC+5zKq3yX06XlCntdqd2Qj3nzsMt587DLatmiUs/+6c1vzxoBLee3hi6i3V3UAzurSjLefuIIHbuiWc97DN53MHtUr74rHTEivDhtKh7at6djuOL6eMWOHY5mZmVx+yUV07tCWyy+5iMzMYLnjn378ka7Hd6Jju+Po90iwwuX69evpdkJn2hzbitmzZgEwZ/Zs7uvzj5J9oATln3PsJMX0SkDGjuWkAics9KBRRHc+OZZHXvwkZ7vdkY2oVKE85/V+lbETv6XH2ccC0OPsY3l34jzO6/0qlSum0e7IRjtcJyVF3Pm3Tlxx70iuuHckd13ZiZQU0aj+HhzbfF/Ove0VBg6fSO8rOgJwQbcjOOe2YTSsm0H1KhU5tvk+fLv4D5av3lByD1+KVq5cyXPPPMW4jyfw8rDX6HXL33c4/uqwoTRu0oSPJ0zioMaNeXXYUADu+b87uafPfYyfOIUJ4z9h/nff8dGH4+jYqTP9BjzBsKEvAfD4gH7c1vvOkn6shOOfc+EkcdB4Hxgr6SJJF4XbH0RL4EGjiH5fvnaH7WMO24dPvloEwMdfLeSopg0BOLpZxP4vF9Iq3J9t371r8vPvq1m7Pou167P4+ffV7FO3Bsc024fxU4N0U7/5mYP3qw1A5qYtpKamkJqSwrZtxnknHs5rY6fv0mdNJFO/+pLWbdqSlpbGvvvtx/p168jKyso5PnHiBLqddAoAJ518KpMnTwRg9qyZtGkTrCvTtdvJTJ40kfT0dDIzM9m4cQNVqlRh1MgRnNr9dNLT8+qFuHvxz7kQVIhX4rkDGA10B04P3+fbowpKKWgoMEjSZEmfSWolaaikZySNlfSFpL3Cc8+RNCk8997SyG8sqletxOp1GwFYsy6TjKrbq6fWrAuK7mvWZ5JRtdIO6TKqVsxJF3lORpWKrA7TAaSmBv/FPf7KBPrdfArvTJjLWcc3Y/h7M7jxgjbc2+MEGtbJ2JWPmBBWrFhBjRo1crarVa/OihUrcrZXRhzPyMhgxfLlAGzbtr0zSEZGBitWLKdT5y5s2LCBka8P59LLruCjcR/QoEFDet1yE089+UQJPVFi8s85diK2UkYiljQs8IKZnWtm55jZIDNLyOqp7kB5M2sDXAw8E+5fZGYnA+8A54YLnvcCOoXnHiHpsNwXk3SNpGmSptmWjbkPl4jVazdSLWzHqJpeIecLf/W6TKqmV4jYv2P+Vq3NzEmXfc6qtRtZtS6TamE6gK1bg3+PM779hZv6/ZuPvlhAwzo1qFC+HJlZW3jujSncfHG7XfqMiaBmzZqsWrUqZ3vN6tXUrFkzZ7tGxPHVq1dTIzwW2VC5evVqatSoSUpKCo/0G8ALLw3l9eGvclvvO3nw/r48/Gh/Fi1cwPeLFpXIMyUi/5wLJyUlJaZXopH0kqSXc7+ipSmtp2gMfAZgZouB7J802fUsS4A9gAOAfYAPJU0A9gu3d2Bmg82spZm1VLlKuQ+XiC+/WUKHlgcA0PGoA/hqzhIAvprzEx2PCvZ3aHkAX4b7s/346woa1M6gSqU0qlRKo0HtDH76bSVfzvmJ9i33B6DFwfX49oc/dkh37bmtee6NKVSumEZa+VTSyqWSXqkCZd1RrY7m8ymT2bx5M0uWLCG9ShUqVNj+3G3btueD998D4IP336Nt2/YAHNasOZ9/9hkA4z74H23abg+w3y9ahJnRuEkTVqxYgZmRlZXF2rU7VkHuTvxzLpxkLWkA04Cp4WsOQXfbzGgJSqvL7XzgNGCIpEZsXzUqslgkYDGwCOhiZlvCgSgJ8ck/9PeTaHFwfdLKp3LYgXW59oE36dTqAEb1u4R1GzbR67F3ABj05hc81us0LjqpBd/9+CeTZiwG4B/XHM+zI6ewYs0G+g8dz9AHLgCg/9DxbNtmfP/zcqbNW8obAy5l8+at3DlwbM69mx20Nz//sYplK9czacZiLj31SLoccxD9h44v+Q+ihNWoUYNrel7H8Z3aI4kBjw9k1syZfPzxh9za63Yuuexyelz9Nzp3aEu9+vUZPCT40XT/Aw/T85or2bRpEyd27UaTgw/OueYTj/Xnkf6PAdCj53U5aZsffnhpPGJC8M+5EBK3vaJAZvZc5Lakpwkaw/OlAqqvdonwy38QcDCQCtwC9ASGmNlkSRcDB5hZX0lnATcBW4HNwKVm9nt+106pvJdVaHzuLn+G3dnKqc8UfJJzSaBSeU03s5bxXKNcrUaWccpDMZ27fNgFcd9vV5JUHphrZgfld06plDTCIepX59r9RcTx1yLev0WwKIhzziWc7IbwYrmW1BUYSPBjeoiZPZLreHXgNaAhwff3ADOL2gZRwP1eYns5KRVoQdh0kB8fEe6cc3EqjqAhKRV4lmAeqKXAVEnv5FoQ6XpgnpmdKmlPYL6k4Wa2qYi3nRbxfgswzMw+jpbAg4ZzzsVDoJRiKWm0IuhBuhhA0kiCnqaRQcOAqgqiVBVgBcGXfZHkbtOIhQcN55yLUyFKGrUkRf66H2xmg8P39YCfI44tBY7Olf4ZgiEJvwJVgfOizUi7K3jQcM65OBUiaCyL0hCe10Vy91Q6kWBCwU4E3WM/lDTJzNbEmoF4Jd5oE+ecSyLFOCJ8KdAgYrs+QYki0hXAmHAk9yLgB6BJsT1MDLyk4Zxz8SqezlNTgQMl7Qf8ApwPXJjrnCVAZ2CSpNoEA6UXx3NTSYeE1zRgvJnNjXa+lzSccy4eKp4R4eGaFjcQzDL7LfCGmc2V1FNSz/C0+4HWkuYQrLJ3h5ktK3LWgzFxHwBNCRZjGifp0mhpvKThnHNxKq55pczsPeC9XPuej3j/K5D3wjxF0xs40sz+BAgniv0IeCW/BB40nHMuXkk6jQiwLTtgAJjZn5Ki9sbyoOGcc3FK0MkIY7FY0n1AdrffHsD30RJ4m4ZzzsUh1vaMBA0sPYADga+BWcBB4b58eUnDOefilKABoUBm9he5emhJqhItjQcN55yLUzFNI1LiJO20PhHwnqROZvZHHsc8aDjnXLyStaRBMDZE7DjyPANYIGmMmV2RO4EHDeeci4eSN2iY2V6590maYWYtwrEgO/Gg4ZxzcRCQpDEjP8PCv9/kddCDhnPOxSVhe0YViZkNDP9ekNdxDxrOORenMhQzCuRBwznn4iFISdLeU0Xhg/uccy4OIggasbwSjaQjJNUK31eTdLgKqGvzoOGcc3GSYnsloBeALZLSgOnAKIJ1yvPlQcM55+KUxNOIpJrZKqADMNHMGofv8+VtGs45F4/ELUXEopykFKALMD7clxU1wS7PknPOlWFCxbaeRil4H5hDMAr8IUnVgXXREnjQcM65OCVrScPMbpf0FrA4rKYCaBstjQcN55yLU4K2VxQonLDwN6BS5OSFZvaTpLpm9lvuNB40nHMuHsndppHXhIUC9gReAzrnTuBBwznn4hDMPZWcUSOvCQsjju0UMMCDhnPOxS1JY0aReNBwzrk4JeJo71hI2sr26qmchzCzfLuDedBwzrl4JPF6GkDViPcVgXOBmtESJG3nYuecSwTZ62kk4zQiZrYh4rXCzJ4HTo+WpsyVNA45sD5vvtevtLNRptX724jSzkKZ9/OQ80s7Cy5mCTtFSIFyrRGeCrSggJJGmQsazjlX0pI0ZsCOXW4rENQ+dY+WwIOGc87FKVlLGrm73ErqSjAP1Sf5pfE2Deeci4OUvOtp5GZm7wNdo53jJQ3nnItTspY0JLWP2EwFjqSAuOBBwznn4pSkMQOgf8T7LcAi4JxoCTxoOOdcnJK1pGFmrQqbxoOGc87FI0HHYMRK0jHA/kTEAzMblt/5HjSccy4OwSJMyRk1JD1H0FtqNrAtezfgQcM553aVlOQtanQGDjWzzbEm8C63zjkXp+KaRkRSV0nzJS2SdGc+53SQNFPSXEmfxpn1H4iYqDAWXtJwzrk4qJgmLJSUCjwLHA8sBaZKesfM5kWckwE8B3Q1syWS8l0PI0bzgbGS3gQys3d6m4Zzzu1CxdSk0QpYZGaLASSNJJjSY17EORcCY8xsCYCZ/RnnPesCK9lxhb742jQknQO8b2ZrJd1DMKHVA2Y2I87MOudcmVBMXW7rAT9HbC8Fjs51zkFAeUkTCKY1H2hmrxT1hmZ2bmHTxFLS+IeZjZbUBjgRGAD8i50fxjnndjuiUA3htSRNi9gebGaDIy6Vm+XaLkcwarszUAn4XNIXZragEFnOIemyaMfzqqaKJWhsDf+eDPzLzP4jqW/hs+ecc2VTIaqnlplZy3yOLQUaRGzXB37N45xlZrYeWC9pItAcKFLQIPhez0+e1VSxBI1fJA0i6Mv7qKTs6XOdc86p2NbTmAocKGk/4BfgfII2jEj/AZ6RVA5II6jxeaKoN9xV1VPnEsx6OMDMVkmqC9xe2Bs551xZVRwxw8y2SLoB+IBg8sCXzGyupJ7h8efN7FtJ77N9MN4QM/um6PlWQ+DvwCrgcYKapQwz+yO/NLEEjbrAWDPLktQBaAYUueHFOefKkkK2aURlZu8B7+Xa93yu7f7sONFgPEYDk4FDCNqrbwNGAJ3ySxBLNdNbwFZJBwAvAvsBr8edVeecKyOSdY1woJyZ9QIuA1qb2QaCXln5iiVobDOzLcCZwJNmdgtB6cM553Z7Sb4I08+S6oXTiChsK6kYLUEs1VObJV0AXAqcGu4rH18+nXOu7EjiuafWAdMl/QeoTdCeMjZagliCxhVAT+BBM/shbNl/Ld6cOudcWZG0ISPoqpvdXfdxYKaZjYuWoMCgEc578veI7R+AR+LIpHPOlSlJvAjTP3Pvk9Q0Wo+sWKYRORB4mKB1Paeuy8waFTGfzjlXZgS9p0o7F0UjaV/gDKBaxO6ekp4HJpjZTrPoxlI99TLQh2AASUeC6qok/Yicc66YKWEbuWMxhmBQ4eqIfQKqEAwe3EksQaOSmX0sSWb2E9BX0iSCQOKcc7u9ZK2eAjCzHpHbkrqYWb4DuGMJGpmSUoCF4WjFX4B453B3zrkyIZmrp4CRMe7LEUvQuBmoTNAYfj/BSMGoMyM659zuJIlLGqMk7ZN7H4Ckumb2W+4EsfSemhq+XUfQnuGccy5C0oaMoD1D7DgFu4A9CYZWdM6dIN+gIem/7DyXew4zO63I2XTOuTJCSt7BfWaWb1ODme0UMCB6SWNA3DnaTVx1wWnMmzOLS666jmtvvgOAf48ezn9GD2fbNuOcCy/nlDPP2yHNLT0u4fdff2Hbtq2cf+lVnHHeJQBMGj+OZx9/GIAbet1Nmw7H893c2fTpfSOVKlfmuWFvUrlyOsNfHsQ++zWiTYfjS/ZhS9Hd3Q/k0PpVSRUMm7SU8qni/GPrsWnLNv5au4m7R33L5q07/s554JwmNK6bzrrMraxYv4lew4OVM487qCbXdglK5c999COfLVhJ47rp9DmzMRs3beWGoXPYuHkb5x+7N0uWb+SzBStL/HlL02knd2XWzBlcd8PfueOue3Y4NvqNkQz617OkpKRQtWo1Xn5lONWqVeOnH3+kZ48r2ZSVRdduJ3H7HXezfv16zjmzO+vWreWZfw2mWbPmzJkzm7ffGs29fe8vpacrfkncewpJtYBjCQoJXxW0hGy+QSO7f66kdGCjmW0Lt1OBCnFmMgM4LZ5lChPJA4/9i88nfcLvvwXrpSycP4/PJ43npVFj863rvOmOPuzb6ACyMjM5rdNRnNT9HMqVL8+AB+7h1THBgMxLzjyBY9t2YszIV7iz76N8+dlEpnz6MS2PPo7v5s7moit65HntsuiA2ukcULsyFz07g8ppqbx1c0uuHjKLd7/+g20Gt3ZrxKktajNm6u87pX3onUV8/eP2HoUpgl4nNeKy52cCMKzn4Zy9cBpntKxLv3cX0apRBq0Pqsm0H1bRZO8qjPw89zo4Zd+/Bg3hk08+4tdflu50rPvpZ3LOuecDcP999zJi+Kv0uPZ67r3nLu75R1+Oa9OWk7sez2ndz2T+/G/p2KkTbdq255WhLzHg8YE88Vh/nn72+Z2um8yStKCBpBOAV4GZBNVSh0u61Mzezy9NLBMWfkzQEJ6tEvBRHPkEyCCYy6pMqLN3vR22x737bypVTufK80/lhr+dz++//rJTmn0bHQBAufLlUUoKkvhp8SLqN9iXatUzqFY9g/oN9mXJj4upVDmdrKxMMjduoHLldJ4f+Cg9wxLN7uLPNVls3mqUSxHpFVJZvWEzS1dksi0sWGzeamzZmndtau9T9mdYz8Pp2mxPAPapVZmlKzJZm7mFtZlbWLoikwZ7VGLjpq2klUuhYloqGzZtpUenfRj08U8l9YgJpV79+vkeS0vb3n1/w4YNHHzIoQDMnjWT49q0BaBrt5OYMnkilSunk5mZyYYNG6hSpQpvjBrBqad1Jz09fdc+QAkSIkWxvRLQw0BbMzvRzE4A2gIPRUsQS9CoaGbrsjfC95WjnB+LW4EjJU2Q9LWkFEmnSvoNQNI5ku5WYJCkyZI+k9QqzvuWiD//+I1VK5bz4sj/ctYFl9Hvn3fne+6gp/pzcvdzSKtQgdWrVlItIyPnWNXq1Vm1cgUXX3kt/3nzdTZlZVGtegZ71NqTqZ9N5OE+vfn043x/EJQpazZu4adlG3n39la8eXNLBn2y/cu80V6VadukJu/P/mundAPGfs8Fz8zgxmHfcGWHhtSvWZHqlcuxZuOWnHPWZm4ho3J5XpvyC6e1qENauRTWbtzCinWbOapRBr1P2Z+2jWuWyHMmi2Evv8hRLZoxZfKknKCxbdu2nOPVMzJYvmI5nTp3YcOGDYwa+TqXXHoFH304jgYNGnLbrTfx9MAiLziXWGKcFj0xYwapkeuLm9l8CogLsQSN9ZJaZG9IOhLYWOQsBh4HpptZB2AGcARBV96vJB0avh8PdAfKm1kb4GLgmTjvWyKqZ9TguPZdkESbDl1Y8N3cPM/79+jhLPxuHtf3ujsn3drV26tR1q1ZQ0ZGDfbcqw4PPzmY2+99iOEvP8+5F1/Jh++9w1339WPooKdL5JlKW+sDa1C7Whon9fuSUwd8xU1dG1E+VdSuXoEHzmlCr9fmsmnLtp3SrdqwGQiCzucLV9K4bhVWb9hC1Urba2arVCzH6g2bWb5uE/eM/i4INK3r8caXv9Kl6Z70e/d7Lm3bYKdr784uu+JKps6YzelnnMWTjwfrAaWkbP86WbN6NTVr1CQlJYWHHx3A4CEvM+L1V+l12x08eP99PPRIfxYtXMD3ixaV1iMUK4VLvhb0SkB/SbpC2/0N2PnXV4RYgsbNwGhJk8KR4KOAG+LPa46PCbp1HQQ8G75vSdAVrDHwGYCZLQZq5HUBSddImiZp2srly4oxa0XTqnVb5s6eAcDc2V/TcJ/9djrn4/ffZezbb/Do00Ny/mfbp9EBLP35R9atXcO6tWtY+vOPNNxv/5w0/3nzdU7qfjaSWL9+LQCrV64ogSdKAAq++LcZbMjaSvlUsUfVNJ64+FDuf3sBP6/IzDNZ1YpBcCiXKo7Ytzo/LtvAT8s2UL9GRdIrpJJeIZX6NSqyZPn230GntajN/2YFbYHpFVIByKgcy5Cm3UNm5vbPOiMjg8qVg4qHw5o154vPPwNg3Afvc1ybdjnnfb9oEWZG4yZNWLlyBWZG1qYs1q5bW7KZ30VSYnwloB7A1cAGgsLANeG+fMU0TkNSE4IvcAHfhQt2xGNTxL0/Ad4BviVYdvAfwJ/hernzgdOAIZIaEaxjm1ceBwODAZo2b5FvN+Fd5R+3Xc/X075k86Ys5s6awdMvjWTS+A+59KyubNu2jX/2C0oDb496lb3q7M1x7TvT+4a/sd8BB3HVBUHP5f7PvETtuntzy133cdWF3QG45a77SE0NvrTWr1vLzOlf0feRgQDsd0BjzjulAyeeemZJP26p+HzhSk5qXptXeh5BWjnx+pRf+Fv7huxVvQK9Twnah/779e+Mmfo73Y+sw59rsvh84UoGXHQIldNSKZcq3p3xB9//sQGAJ99fzKArm+W8z24bqZyWSvOG1bj/3wsB+OGvDQy/vgXj5kT98VXmXH/t1Xz5+edkZWUxY/p07v5HHz756ENu6XU7Tz7enwnjPwGgRo2a/GvwiwDcd/9DXNfzKjZt2sQJJ3alycEH51zvycf783C/xwC4use1HN+pHfXq1ad588NL/NmKm4DUJO09Ff4Ybx12eMLM1heURmYl/h1LOC3JWILo9hzwFDDAzF6W9CnwXzMbEJ43CDiYYKH1W8zsi2jXbtq8hb35/uRd+wC7uePu+E9pZ6HM+3nI+aWdhd1CeoWU6WbWMp5r1D6gqV30+JsxnftE94Pjvl9xktQ+r/15zW6brVTK3GH33W4Ruw6NONY+13lXl2DWnHOuUIJG7uQsaQD9I95XJKhRmkfQzpwnr6h1zrk4JWntFGa2Q49USc2A66KlKbBtJmxRv1jSveF2w2Tp+uqccyUhibvc7sDMZhOMDs9XLCWN54BtBN1g/wmsBd4Cjoo3g845l+wElEuGiJCHXG0aqcAxBN/3+YolaBxtZi0kfQ1gZisl5bmik3PO7Y6SNGbAjm0aW4Dvgai9MGIJGpvD+aYMQNKeFBCJnHNud6HEnSKkQLnbNGIRy3iTp4C3gb0kPUgwliLq3CTOObc7SdY2DUl3Sdo/fH+mpCclHRQtTYFBw8yGA70JJrb6DTjdzEYXR4adc64sSFFsrwR0EbBYUh2Cqqq/gKHREhRYPSWpIcEgvP9G7jOzJXFl1TnnyoBgjfDEjAgx2GRmFk6RPtzMHpR0drQEsbRpjCVozxDB4I/9gPlEDMhzzrndliA1QSeWisE2Sa0JShyPhPtSoyWIZe6pwyK3wxlvd5/Vf5xzrgBK3lXC7wZeAqaa2XhJ1Ym3eio3M5shycdoOOcc2dVTpZ2LojGzcUCTiO3VBEtX5CuWNo1bIzZTgBYUMN+6c87tTpI1aBRFLCWNqhHvtxC0cby1a7LjnHPJJ4knLCy0qEEjHNRXxcxuL6H8OOdcUlFyN4QXWr6PKqmcmW0lqI5yzjmXj5RwVHhBr4JI6ippvqRFku6Mct5RkrYW1D02hvulSjpFUptY00QraXxFEDBmSnoHGA3krOpkZmOKnFPnnCsjiqshPKzZeRY4HlgKTJX0jpnNy+O8R4EP4r8rw4FGQIak5wl6Tj1lZhfnlyCWNo2awHKCWW6zx2sY4EHDOecotilCWgGLwiVYkTQS6E6wKFKkGym+mcYPJ1gZtQYwzsweL2gakWhBY6+w59Q3bA8W2Up+jVjnnEtIIiX2cRq1JE2L2B5sZoPD9/WAnyOOLQWO3uFOUj3gDIIf8cURNJYCaWa2ImL28grREkQLGqlAFcjz0/Cg4ZxzBF+QhShpLIuyRngs37VPAneY2dZi6rE1DXhX0ktAZUn3A4uiJYgWNH4zs38WR66cc67MEpQrnoEaS4EGEdv1gV9zndMSGBkGjFrASZK2mNm/i3jP7KnRrwYWEBQW/hYtQbSgsft0PHbOuSIqZEkjmqnAgZL2A34hWAzpwsgTzGy/nPtKQ4F34wgYmFmnwqaJ1ru4c1Ez4pxzu5Pi6HJrZluAGwh6RX0LvGFmcyX1lNRzV+S7KOtp5FvSMLMVxZ1B55wri4prQLiZvQe8l2vf8/mce3kx3PIi4JGI9TReIuh22zq/BLvROEbnnCt+IvgijeWVgDaZmQE562kAlaIlSNDncM65JKFg7qlYXgkocj2N8eG++NbTcM45lz8BqYkZEGKx69fTcM45t6NkDRlFWU/Dq6eccy5OUmyvRCNpTHZvKUmPSZopqXu0NB40nHMuLrG1ZyRom8YBZrZA0qHAccD1wP3REnj1lHPOxSG791SS2hr+7QS8aWZTJG2JlsCDhnPOxSmWtTIS1EpJdwMXA+coKA5FjQtJHCCdcy4BJHeX2yuBhsBjZjYXSCcYlZ6vMlfSSCuXQv2aUcemuDjNeyauxcJcDPY4/anSzoKLUTJXT5nZD0DPiO11wMRoacpc0HDOuZKWoKWIAkn6hDx6DJtZR0kvmNnVuY950HDOuTglZ8gAYECUY0Pz2ulBwznn4pSkBY3sCRLzOzYlr/3JWhXnnHMJIXsakVheiULSYZIqSqov6U1JyyQtD9/vHS2tBw3nnIuLYv4ngbwCbAaGAdOBpuFrRngsX1495ZxzcUqgQkSsFK4zXtPMHo7Y/5CkC6Il9JKGc87FIehyq5heCaRcuPDSd5Jy1iWX1BBYHDXhrs6Zc86VaQk6GWEBHge+AmYDc8KutxAs8/1ptIQeNJxzLk7JFjTM7CVJk4BW7Li87EcFpfWg4ZxzcUjWRZjMbCGwsLDpPGg451ycEqxnVMwkvUTeI8KvyC+NBw3nnItTEhY0sk2LeF8ROB2YGy2BBw3nnItTspY0zOy5yG1JTwPvR0vjQcM55+IgICU5Y0Z+GkQ76EHDOefiISXtIky52jRSgRbAZ9HSeNBwzrk4JWfIAHZs09gCDDOzj6Ml8KDhnHNxCKqnkjNs5G7TiIVPI+Kcc3FSjK9EI6mKpBck/RG+XpBUNVoaDxrOORevZI0a0A/YBhwN/AZMIJhiJF9ePeWcc3FK1i63QFuguZltk2RmNlzSjdESeNBwzrk4JXGXWzOzbdkbChY7rxgtgVdPOedcvJK3eipT0h7h+0rAcGB8tARe0nDOuTgE8SAxI0IMbgaqAsuBfxNMYPhStAQeNJxzLh7JuZ4GAGb2GUDYY+pBM1tbUBqvnnLOuTgVV+2UpK6S5ktaJOnOPI5fJGl2+PpMUvO48i0dLOkr4A/gL0nTJB0cLY0HDeeci1cxRA1JqcCzQDfgEOACSYfkOu0HoL2ZNQPuBwbHmfOXgYFmVtnMKgJPhvvy5UHDOefiEsw9FcurAK2ARWa22Mw2ASOB7pEnmNlnZrYy3PwCqB9n5suZ2fCI679GAc0WHjSccy4OsRYyYqieqgf8HLG9NNyXnyuB/xUhy5GmS2qVvSHpaODbaAm8Idw55+IVe0N4LUmRkwQONrPsKqa8rmJ53k7qSBA02sR857wdAnwmaU64fRgwVdJ4ADPrmDuBBw3nnItTIbrcLjOzlvkcW8qOa1nUB37d6V5SM2AI0M3Mlhcmn3l4uLAJPGg451yciqnL7VTgQEn7Ab8A5wMX7ngfNQTGAJeY2YJ4b2hm7xU2jbdpFKNZM7+mS4c2nNi5PSef2JkfFi/e4fgTj/WjY9tj6NKhDbfdciNmQcnzpx9/5OQTO9OlQxv6P/oQAOvXr+eUrl3o0OZo5syeBcA3c2Zzf99/lOxDJaD5383jjJO7cMbJXTi5S1sO3rfODsdHDn+Fow47KOec3379BYAlP/3IWaecwKkntGfggEeA4HM++9QT6dqxNXPnBJ/zvG9m8+gDfUr2oRLEzd0PZfRdnXj99g40qV8dgD4XHsGoOzoy5O9tqJ6etlOaO89pxojeHXj7/zpz5znNcva3a1qHN+/uxJt3d6LtobUBaFK/OmP+rzOv3daeSmmpAFzS8YCc40kpHKcRyysaM9sC3AB8QNCu8IaZzZXUU1LP8LR7gT2A5yTNzFXVVSJ2SUlDUgZwmpm9IqkvQY+A13bFvRJJnTp1efu//6Nq1ap88P57PHR/X154+ZWc46d2P4NbevUG4NKLzuPT8Z/QoVNn+vzjLu7+R1+Oa9OWU7sdz2mnn8n8776lfcdOtGnbnleHvUS/xwby5GP9Gfjs86X1eAmjcZNDeHvsRwD8Z8xopkycsNM5F156ObfcfvcO+x7s+3/cfve9HNO6Deec1pWTTjudhfO/o237jhzbph0jXhvGA48+zrMDH6Pfk4VeZiDpHdwgg2b71eSchz+hbo1KDLjqaAb97zsqpaVy3qPjOePYfejRtTH93pqzQ7rHxnzD5q3B9EUjenfgwL2r8f1va7nz7Gac92gwI8WoOzoyZd6HnNN2Px4YOZNjmuxF20Pr8NWCvzi4YQavjl9U4s9bnIprRHj4y/+9XPuej3h/FXBVsdysiHZVSSMDuDTWkyWViRJP7Tp1qFo1mIo+rXwaqeV2jMkHHHBgzvu08mmUC4/PnjWT49q0BeDEbicxZdJE0iunk5WZycYNG0hPr8LoUSM45bTupKenl9DTJIe33nids867cKf9o0e8xmknduDRB/qwbVvwhTZ3ziyOaR20G3Y5sRtfTJlM5crpZGZlf87pvP3mSLqefNpu+TnvV7sK3/wU9Ob8beVGGtRKp92hdfhk1m8AfDzrV446aM+d0mUHjHKpYmPWVv5YtZF9a1fh52XrWbtxM2s3bubnZevZZ690NmZtpUL5VCqlpbIhaws3nHIIz7w7r+QechcQxVPSSBa76sv6VuBISROAk4GOkt4Ji1NNACRNkPSYpA8I6vGGSBovaXJ2FzBJh0n6SNInkt6QVGkX5bdYrV+/nn/2vYebb70tz+OTPp3A77//xnFt2wHkfKkBVK+ewYoVy+nYuQsbNm5g1MjXufiyK/jow3HUb9CQ3r1u4pmnniiR50h0K1YsZ9GC+bQ6pvUO+7uedCqTps7h7fc+5uefl/DWG68DO37O1apnsHLFctp17MzGDRt5a/QIzr/oMsZ//CH1GjTknjtuZdCzA0v0eUrbgl/WcEzjPSmfmkKT+tWpU6MSlSqksnrDJgDWbNhMRh7VUxBUYU145GT+XL2RtRuD87LT5aStUoGhHy3kjNb7kFY+lTUbNrF8bSbHNN6Te847nA6H1cnz2skgWecrlJQq6QhJ7SNe30jqIGmfvNLsqqDxODDdzDoAY4G1ZnYawYIfkUWraWZ2ItCRoAqrI3AWkP2t+CzwNzPrBEwh6GK2E0nXhMPfpy37669d8kCx2rx5M5ddfD633n4nTQ7OPZgzaJfoc+/dDH1tJAp/eqSkbP/XsGbNamrWqElKSgoPPTKAQUNeZuTwV7n19jt4+IH7eODh/ixauIDvv0/u4nxx+M9bozn19LNyPsdsGTVqkJqaSmpqKqefdS6zvp4B7Pg5r12zmozwc+774KM89a8XGT1qODfecjsDHr6fe+9/hO8XLeSH3ehzXvTbGt75cgmv9GrHFccfxMJf17B242aqVS4PQNVK5XcIBJHue/1r2t8xlhpVKtC+aR1Wrd9EtcrbA0zVyuVZtW4Ty9Zk0vulqTz8xiwu6XQgr3+6mBNb1OeBUTO58oTGJfKcu0SyRg14m2AQYf+I177h3xPySlBS1ULTw79LCBpxsn0W/j0MOC8smYwCqof7DwVeCfdfAOT5U8TMBptZSzNrWWvPnYvPJWXbtm1cdcUlnHJqd0497fSdjn///SKu63ElQ18ZQa1atXL2H9asOV98HnwUH37wPq3DEkh2GjOjceMmrFi5AjMjKyuLdWsLnFeszBszekSeVVOrV63KeT/50wnsf8BBABzStBlTv/wcgE8+/IBjjtvexf2H8HM+8KAmrAo/502bsli3bvf6nF8b/z0X9JvAi+PmM3/paj7/9k86HFYXgI7N6vLV/J1/lKWVC75Gtm4zNmZtYeOmrfz4xzoa1EqnSsVyVKlYjga10vnpz3U5ac44dh/e/WoJZkZ6xaCaNqNK3qWYZKAY/0lA+5pZYzNrlf0CFpjZUWb2Ql4JdlWX2025rh05QCXyk9sa/p1LUNJ4AkBS9n893wAXmNlvufYnpHf+PYYP/jeWP//4g1EjhnNo06ZcevmVfPLxh9x86+3ccdstrF61ih5XXQ7ATbfeRtduJ9P3nw9xfc+r2LRpEyec2JUmTbbPFzbw8f489OhjAFx9zbWc2Lkde9erT7Pmh5fCEyaOn35YTFZWFgc1Dj6rb2bP5NPxH3P9Tb147qnHmDjhE8qVK8f+Bx7E/13+AAD/1+cBbrmxB5s3baLT8SfmpAV47qnH6ftgPwAuv6oH3bt2ZO+969G02eEl/myladit7UhNEavWb6LPazNYsS6LTs33ZtQdHVmXuZleQ74C4Kzj9uWPlRuZPO8PnrzmGDLS0yiXmsL0Rcv4Mgws/d+azdBb2+W83xb2FkyvWI4W++/BP14LSoCLf1/LW3d35n9Tl5bCExePJF6E6bs89kUtXiu722dxChu2xwIbgL2AQWb2mqQ2wFVmdnlYerjYzJZKKg88DWSXT6eZ2e2SmgKPAeXD/Q+b2YfR7t3iyJY28bOpxf5Mbrv1WVtKOwtl3r7n7369t0pD5v9unh5lsF1MmjZvYWPGTY7p3MZ10uO+X3ELv3+bEPy4n29mm6Odv0tKGuHygd3y2D8ZmBy+7xCxfzPQM4/zvwFO3BV5dM654pDMizBJagm8CWQRPEoFSWebWb6/vH1EuHPOxSO5u9M+BVxmZp9CzpxWA4HW+SXwoOGcc3FK3phB5eyAAWBm4yVVjpagTAyqc8650iOk2F4JaH1YugBAUidgfbQEXtJwzrk4JWY8iMmNwFuSthA0hFcgGCuXLw8azjkXh8Qdt1cwM5sh6UDgIILHmB9OnJgvDxrOORevZI0a5MyuG/MEYB40nHMuTsna5bYoPGg451yckrhNo9A8aDjnXDyU1NOIFJp3uXXOubgl5zS3kqpLelHSH5L+lPSSpGrR0njQcM65OCT5IkxPAuuAI4EjgLVsX5oiT1495ZxzcUrMeBCTo8ysacT2TZJmR0vgQcM55+KUoKWIWOQ1o+3WPPbl8Oop55yLUxIvwvSppJyF8STVBCZFS+AlDeeci1OyljTM7OZc2yuAv0dL40HDOefikMCN3AWS1CfacTO7L/c+DxrOORenBK16ikV6YRN40HDOuXglacwws96FTeMN4c45F6fkHNoHkg6X9KakIZL2kpQuqWm0NB40nHMuLiJFsb0S0KvAp8AK4DFgE/BctARePeWcc3HIHhGepDaY2dMKlhWcZWabfblX55xz+fleUlMzM2CbpHSgYrQEXtJwzrk4JXFJowbwlaRJQEPgK2BQtAQeNJxzLk5J3OV2RPgCeJGgimp+tAQeNJxzLh5JPLgPGAlsMbNtsSbwNg3nnItDkk+N/hGwL4CktyStknRNtAQeNJxzLk5JPGFhdTNbLKklUBU4FLg5WgKvnnLOuTglaCkiFhb+7QS8Y2a/SMqMlsBLGs45F6fiGhEuqauk+ZIWSbozj+OS9FR4fLakFnFmfYmkwcB1wFhJ5SkgLnjQcM65eBVD1JCUCjwLdAMOAS6QdEiu07oBB4ava4B/xZnzy4DFQA8z+wFIBc6NlsCrp5xzLk7F1F7RClhkZosBJI0EugPzIs7pDrwSDsb7QlKGpLpm9lsR77kv8IKZLZdUDWgEzIqWoMwFja9nTF9WtWLKT6Wdj0KqBSwr7UyUcf4Zl4xk+5z3ifcCX8+Y/kHlNNWK8fSKkqZFbA82s8Hh+3rAzxHHlgJH50qf1zn1gKIGjReALpLSgOnANuBjguqqPJW5oGFme5Z2HgpL0jQza1na+SjL/DMuGbvj52xmXYvpUnkVV6wI5xRGqpmtknQCMNHMrpQ0L1oCb9NwzrnEsBRoELFdH/i1COcURjlJKUAXYHy4LytaAg8azjmXGKYCB0raL6wuOh94J9c57wCXhr2ojgFWx9GeAfA+MAe4CHhXUnVgXbQEZa56KkkNLvgUFyf/jEuGf85FZGZbJN0AfEDQi+klM5srqWd4/HngPeAkYBGwAbgiznveLuktYLGZrQp3t42WRkEjvHPOOVcwr55yzjkXMw8azjnnYuZBwznnXMw8aLjdQrgGcr7bzrnYeNBwZZ6kFDMzSRUlVQQIt/2//10kr8/WA3XZ4L2nEoSkGkBTYCawvjArabn8SVIYIOoBrwALCdYQuCDyeKlmsowJg/Q2SbWBDsB3wA9mtqZ0c+aKg//SSgCSGgBjgLOBYUAn/xVcPMKAURl4imCit55AqqQ3so+XagbLoDBg1ANeBg4GbgCuDmdxdUnOv5hKWRgcrgXuBx4iWDnrB+KbT8aFJKWZ2QZgDUEpAzM7F1gXzurpdo1LgecJfgQ1JxiUlu6BI/l50Egc3YEXCUob+wD3+/9gRRdOs5AG9JLUhmAGz2MlHSXpVKBx6eawbMmjZJwFHE9QwrsG2Av4J1CxhLPmipkHjVIiqbaktkB14FWgNUEJIw24GxhhZltLMYtJKaKxtZKZbQrfVwPeJCi93UrwJXa117EXj4g2jLqSTgj/u36RYAnRHwnWnr6HYBrw9aWYVVcMvCG8FEjaAxgJrAfmA18BC4ALgUoEi6LMLb0cJrewDWMKwapmK4DewGVm9q2kSkBlM1temnksayTVAd4iCBZ3AA8AkwiqqVKAN8ws6pTbLjl40ChhYS+p24AfzewFSRcQ9JqaYmbvSUr1EkbRSSoXTvz2NEEAHgH0A74FbjOz30s1g2VIRAkjFbiPoFQxAvgfQeCYHlHac2WEV0+VIEnlgCMJepSUk1SB4H+wRcDRkqp4wCg8Sc0lNQ0/3zGS2hFMM12VIFi8AewJZJZiNsuUiIBRh6CEPJtgXetxwN8IZmkd7J0Nyh6fGr2ESKpPUF0yhyBo/AC0ISjCv0lQ6os6j73L1yaCapFyBOsDnAwsIVjv+Awze1TS4Iipn12cwoCxB0HPvyUEHQ3OJ6hqPRy4HrjW243KHg8aJUBSVYJeJG8T/OptApxO8Ou3vJm9X3q5KxPmA78QBOM3CEoX+wPnEKx//KKZrSzF/JUZ2SWMcPMGggB9lZnNk/QsUJOgNN3DzBaUVj7druNtGiVAUgYwBLjbzBaEU1k8CHwGfG5m8SzX6IBwxbFDgb4EjbDZJY1FZrakFLNW5oTVqOvC9w8BdYDrzCwz3Oej7MswDxolIOzDfjuwlmBVrqYEv9JOMbOo6/G6wpF0AtCHoHvtuR6Qi4ek84FpwErgv+H7BWb2jKQBQD3gGjNb60GjbPOgUULCqUIuBloS9Oq53bvV7hph+5GZ2S+lnZeyQFJd4CZgFbA3wfxo0wgavH8ws4GSHgSe9t5pZZ8HjRIU9u7JAFLM7M9Szo5zBQp7on0PVCHobPAH8IiZTZV0MEH38elm9lwpZtOVIA8azrl8STqEIFiUD//uAWwG/m1m8yU1BlaZ2R+lmE1XgnychnMumu8IeqZVAD4HngYEXCxpXzOb7wFj9+JBwzmXr7B77ZVAD6A/QVfmnwi61fq4ot2QV08552Ii6USCnmnLgFvNbFEpZ8mVAg8azrmYhb0At3nPtN2XBw3nnHMx8zYN55xzMfOg4ZxzLmYeNJxzzsXMg4ZzzrmYedBwu4SkrZJmSvpG0uhwCdaiXmuopLPD90PCUcr5ndtBUusi3ONHSbViPPdySc8U9h7OlQUeNNyustHMDjezpgSLJPWMPBguEVpoZnZVAWtNdwAKHTScc7HxoOFKwiTggLAUMF7S68AcSamS+kuaKmm2pB4QrMcg6RlJ8ySNBfbKvpCkCZJahu+7SpohaZakjyXtSxCcbglLOW0l7SnprfAeUyUdF6bdQ9I4SV9LGkQwNcZOct8jj+OnSvoyvM5HkmqH+9uHeZgZHqsqqa6kiRElsLbF+ik7VwJ85T63S4Uz+3YjWIYVoBXQ1Mx+kHQNsNrMjgrXS58iaRxwBNAYOAyoDcwDXsp13T2BF4B24bVqmtkKSc8D68xsQHje68ATZjZZUkOC9UwOJhjZPNnM/inpZOCaPPK+0z3yeMTJwDFmZpKuAnoDvQhmf73ezKZIqkKwPvk1wAdm9mBY0ipylZ1zpcWDhttVKkmaGb6fRDBDamvgKzP7Idx/AtAsu70CqA4cCLQDRpjZVuBXSZ/kcf1jgInZ1zKzFfnkowtwiJRTkKgWLr/bDjgzTDtWUl7LwcZyj/rAqHDNiTSCtd8BpgCPSxoOjDGzpZKmAi9JKk8wS+zMPK7nXELz6im3q2S3aRxuZjea2aZw//qIcwTcGHHefmY2LjxW0FQFiuEcCP4bPzbiHvXMbG0x3uNp4BkzO4xgUr+KAGb2CHAVwYJbX0hqYmYTCYLVL8Crki6NIf/OJRQPGq40fQBcG/7yRtJBktKBicD5YZtHXaBjHmk/B9pL2i9Mm111tBaoGnHeOIKldQnPOzx8OxG4KNzXDahRiHtEqk4QBAAui7jP/mY2x8weJVjlromkfYA/zewFgpJXizyu51xC86DhStMQgvaKGZK+AQYRVJm+DSwE5gD/Aj7NndDM/iJoIxgjaRYwKjz0X+CM7IZw4O9Ay7ChfR7be3HdB7STNIOgmmxJIe4RqS8wWtIkgtlfs90cNnbPAjYC/yPo2TVT0tfAWcDAgj8i5xKLT1jonHMuZl7ScM45FzMPGs4552LmQcM551zMPGg455yLmQcN55xzMfOg4ZxzLmYeNJxzzsXMg4ZzzrmY/T8djtOw/DhsogAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[439 493  68]\n",
      " [  3 864 133]\n",
      " [  0 181 819]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[939  35  26]\n",
      " [101 486 413]\n",
      " [ 80 449 471]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEkCAYAAADTtG33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABAbklEQVR4nO3dd3gUVdvH8e8voYeQICgixQo27B0BKdJERB97w67YXnvjsWDBir2DXVFQxMcuKFItSBFBQBApAiKKdEJCu98/ZhI3IdksbMpuuD9ee7Ezc87OmQH33lPmHJkZzjnnXCxSyrsAzjnnkocHDeecczHzoOGccy5mHjScc87FzIOGc865mHnQcM45FzMPGq7cSKou6WNJKyS9F8fnnC1paEmWrbxIailpRnmXw7miyJ/TcMWRdBZwPbAXsAqYBPQ2szFxfu65wNVAczPbEG85E50kA5qY2azyLotzW8trGi4qSdcDTwD3A/WAxsBzQLcS+PidgZnbQsCIhaRK5V0G54rjQcMVSVIGcA9wpZkNNrM1ZrbezD42s5vCNFUlPSHpj/D1hKSq4bHWkhZIukHSX5IWSbogPHY3cCdwuqTVki6S1EvSWxHn30WS5X6ZSjpf0mxJqyTNkXR2xP4xEfmaSxoXNnuNk9Q84tgISfdK+ib8nKGS6hZx/bnlvzmi/CdKOk7STElLJfWMSH+4pO8kLQ/TPiOpSnhsVJjsp/B6T4/4/Fsk/Qm8mrsvzLN7eI6Dw+2dJC2R1Dqev1fn4uFBw0VzFFAN+CBKmv8CRwIHAgcAhwO3RxzfEcgAGgAXAc9Kqm1mdxHUXgaaWU0zezlaQSSlAU8Bnc0sHWhO0ExWMN12wKdh2jrAY8CnkupEJDsLuADYAagC3Bjl1DsS3IMGBEGuH3AOcAjQErhT0m5h2o3AdUBdgnvXDrgCwMxahWkOCK93YMTnb0dQ67o08sRm9htwC9BfUg3gVeA1MxsRpbzOlSoPGi6aOsCSYpqPzgbuMbO/zOxv4G7g3Ijj68Pj683sM2A1sOdWlmcT0ExSdTNbZGZTC0nTBfjVzN40sw1m9g7wC9A1Is2rZjbTzNYC7xIEvKKsJ+i/WQ8MIAgIT5rZqvD8U4H9Acxsgpl9H553LvAicEwM13SXmeWE5cnHzPoBvwJjgfoEQdq5cuNBw0XzD1C3mLb2nYB5Edvzwn15n1Eg6GQBNbe0IGa2Bjgd6AEskvSppL1iKE9umRpEbP+5BeX5x8w2hu9zv9QXRxxfm5tfUlNJn0j6U9JKgppUoU1fEf42s+xi0vQDmgFPm1lOMWmdK1UeNFw03wHZwIlR0vxB0LSSq3G4b2usAWpEbO8YedDMhphZe4Jf3L8QfJkWV57cMi3cyjJtiecJytXEzGoBPQEVkyfq8EVJNQkGIrwM9Aqb35wrNx40XJHMbAVBO/6zYQdwDUmVJXWW9HCY7B3gdknbhx3KdwJvFfWZxZgEtJLUOOyEvy33gKR6kk4I+zZyCJq5NhbyGZ8BTSWdJamSpNOBfYBPtrJMWyIdWAmsDmtBlxc4vhjYbbNc0T0JTDCziwn6al6Iu5TOxcGDhovKzB4jeEbjduBvYD5wFfC/MMl9wHhgMjAFmBju25pzfQkMDD9rAvm/6FOAGwhqEksJ+gquKOQz/gGOD9P+A9wMHG9mS7amTFvoRoJO9lUEtaCBBY73Al4PR1edVtyHSeoGdCJokoPg7+Hg3FFjzpUHf7jPOedczLym4ZxzLmYeNJxzLkFIeiV8kPTnIo5L0lOSZkmanPvgZ1nyoOGcc4njNYJ+rKJ0BpqEr0sJRuyVKQ8azjmXIMxsFMFAj6J0A96wwPdApqT6ZVO6gE+Q5pxzyaMBwQjGXAvCfYu25sMkzaboZ4lkZrsU3FnhgoYqp5mqZZZ3MSq0A5qW6Q+bbVJxTwS6kvHjxAlLzGz7eD4jtdbOZhs2mwGmULb276kED8zm6mtmfbfgdIX904hnCOzxBT7nfeCUiPebqXhBo1omVQ/tUXxCt9VGfu7TH5U2edQoE7WqpRaccmaL2YZsqu51Rkxps398OtvMDo3jdAuARhHbDdn6GRgws2mR25JycvdJKnTKGu/TcM65eAhISY3tFb+PgO7hKKojgRVmtlVNU0WwIt7nqXA1DeecK3MlVDWU9A7QmmCi0AXAXUBlADN7gWCanOOAWQSTbV5QIif+1y0R74cXlsCDhnPOxUWgkmm0MbMzizluwJUlcjJA0nmF7TOz183shsLyeNBwzrl4JW8nVJeI9zWBFsA3wOtFZfCg4Zxz8RAlVtMoa2aWb+JMSbsQLPFcJA8azjkXFyVzTSMfM5srae9oaTxoOOdcvEpmZFS5kJQOZIdLGgNcJCnFzDYVlj4561TOOZcwwo7wWF4JRtKNBIuDLZXUSVId4NiiAgZ40HDOufiIoHkqllfiuZLgYcEWwG3hImZRn1T05innnItXAtYiYjQvDBT/RKw/H7WtLWmv1DnnEkPyNk8Bn0u6L5wpd5OkduSfG2szXtNwzrl4pSRk01Ms7g//vA3IAe4DLouWwYOGc87FI3fuqSRkZltccA8azjkXl5KbRqQ8SKoNNCeYoPA7M1sWLb0HDeeci1dijowqVjhT7mAgd4r0fSX9x8y+KyqPBw3nnItX8tY0HgNOMrOxAJKOAPoALYvK4EHDOefikbjPYMQiLTdgAJjZ2PAJ8SJ50HDOuXglaUc4sDFyyhBJopjlYz1oOOdcXJK6I/xGoBawPNyuBdwULUPSXqlzziWMJJ1GxMy+NrPlEdsrgMOj5fGg4Zxz8chdTyMJnwiXdJGkSZLm5L6Au8L31xSWx5unnHMuLkndPHUzcD6wItw24H3gFOCvwjJ40HDOuXglYNNTjNYUfCZDUraZTSsqgwcN55yLV/KOnjorxn15PGg451w8lNTNU6er8FrS3ZIuM7MXCx7woOGcc/FK3uaptEL25V5MtcIyeNBwzrk4FfFrPeGZ2c1Rjj1Z2H4PGs45F4dgtdfkDBqSUoBLgfYEI6eGAS9GWyPcg4ZzzsVD/Nugk3weAvYHXiO4ivOB3QmeFC+UBw3nnIuLSElJ2o7wTsBBZrYBQNJAYBJRgkbSXmkiufbkg3mvV1fevr0LezXajsP32pF37+rKO3d0of9/j6P+dpv3NR3UZAfe69WVAXd04ZLj98vb32r/hgy6uyuD7u5Ky/0bALBX4+0YfM8JvPXf46heNYjz57bfO+/4tmblypW0b92CLh3a0qbFkYwYPizf8f5vvsZ+e+1Olw5t6dKhLX8sXAjAvHlzOb7TsXRo05I+Dz8AwJo1a+jauT1tWhzJlMk/AfDzlMncd/edZXtRCeanST/SvnVLOrVrzfEdj2XO7NmbpXm8z8N07dSe49q3ZeTwrwGYN3cux3c8lvatW9LnoYh73Kk9rQvc43t7VZx7LCmmVwIy8teTfMLC0rb3ztux/+7bc2qvj6m/XRp9Lj+G8x/8gtPu/hiAU49pynmd9uXBt3/Il++u7kdxxRNf8cc/a3j5pg58NX4e8xav4tazDuf0ez4BYOCdx/PNlA84tXVT7nvze47cZyda7teAH375k713rsObX04v8+tNBDVr1uTzr0ZQqVIl5syZzQXnnMmIb8bmS9P9/Au56db/5tvX6/bb6Hn7XTRv0ZITjuvACd1OYsYv0zmmTVtatGjFW6+/ykOPPsGTjz3CE8+8UJaXlHB23LE+gz/+jPT0dIZ88Rn339uLfq++kXd86JDPWbliBR9/8WW+fHfdcRs97wjvcecOnHBixD1u2Yo3X3+Vhx99gicefYQnn6049zhBA0IsvgA+lfR6uH0BMCRaBq9pxGnXHTP4ec4SABYtXUOjHdLzjb6rWb0yv/y+dLN86TWq8Mc/awCYMnsJR+xTn13q12L+X6tYlbWOVVnrmP/XKnaul87anA1UrZxK9aqVyMrewFUnHsgz/5tUFpeXkFJSUqhUKfi9s2rlSvbdb7/N0rzT/006tm3FfXffyaZNQZ/elMk/0bxFsLZMx07H8c2YUdRISyMnO5ustVmk1azJoIHv0KVrN9LSChuJuO2ot+OOpKcHyypUqVwl737n+mDQe2TnZNO1U3suuaA7K1YEs1BM+enfe9yh83F8M3oUNWqkkZ2dTVZWFjXTavLewHc4/oQKdI+1Ba/EcwvwHtANODF8X+SIKiinoKHAi5LGSPpW0uGSXpP0jKRPJX0vaYcw7amSRodpE64+O3PBMo7cpz6VU1PYq/F27LhdGrXSqtLmwEZ8eF83zmm/Dz/+uvkULktXZbNX4+2onJpC82YNyEyrSmZaVVasyclLszIrh8z0arz2xVROatmEKpVSWJmVwz8rszly7/rcfs4RtD6wYVlebsL4Y+FCOrZtxUldO9H1hBPzHTvu+G6MmzSVz74czvzf5/HugP4AecEDICMzg6VLl9Km7bFkZWXx3oC3Obv7+Qz7aiiNGjXmlhuu5dmnnijDK0pMa9as4Z5ed3DN9fmbuBct+oOUlBQ+/uJLDj38CB575EEg/z3OzAjvcbtjWbs2i3cHvM3Z553PsC+H0rBRY26+4VqeqQD3WMTWNJWItREL9DOz08zsVDN70cyiNk+VV02jG1DZzFoA5wDPhPtnmVkX4CPgtHDB8xuAtmHagyRt9rNS0qWSxksab+vXlNElhAVeuJyPvvmNN3p25oJO+/LrgmUsXZnN8Enz6Xb7hzz67nhuPP3QzfL17DeaW848jH43dWD+XytZvDyL5WtyqJVWJS9Neo0qLF+dw5IVa7n5xVE88PYPnNthH94e9gsdD9uF+94ay0XHbf4re1uwU4MGDPl6FF+P/p6brvu/fMdq165NamoqqampnHzq6fw4YQJAvs7KlStWUrt2bVJSUuj94CM83+9VBr79FtfdeAsP9L6bex94mFmzZvLbb7PK9LoSyfr16zn/nDO44aZb2GvvffIdq117O45t3xGAYzt05Ocpk4H893jFyvz3+IWXXmVA/7e4/qZbeOC+u7nvgYf57deKcY9TUlJieiUaSa9IerXgK1qe8rqKPYFvAcxsNlA73D8h/PN3oA6wB7Az8KWkEcCu4XY+ZtbXzA41s0NVueyrvG99NZ0z7/2Ulz/7mRnzl1GpUsSXU9Y61uZs2CzPrwuXc8FDQ7jkkaFk1qzKyEkLmLtoJY22T6dm9crUrF6ZRtunM+/PlXl5Tmq5B598NxvDSKteGYDMmlVL/wITTE7Ov7Wx9PRa1EzPvzrl8uXL896PHDGcPZruCUCz/fZn7HffAvDl0M85ukWrvHS//TYLM6PpnnuxbOkyzIx1OTmsXrWqFK8kcW3atIlLLjiX47t24/gCNTmAlq2O4ceJwf+uP04Yz2677wHAfvtH3OMhn3N0yyLu8bLgHudUkHucrDUNYDwwLnxNIRhumx0tQ3l1hM8ATgBekrQb/64aFVktEjAbmAUca2YbwgdREu7Ov35rJ1JTU1i+Opu7Xv2WE4/eg5Na7sGmTcb6jZvo+dIYAE5u1YTFS7MY8/NCLjquGW0PagxAv08ns3RV8Pf0yMBxvHZrp7z3m8KaYlq1yhzcpB53vPINALP/WM77d5/A52PnlPXllrtpU3+m5803kJqayvr163ngkceY/NMkhg/7imuuv5GnHu/DiK+HUalSJZo0bcr5994PwF333s/VPS5h3bp1tO/YiT332jvvM596vA+9H+wDwMWX9aBTu2PYqUED9j/gwPK4xHL30f8GM+Tzz/hr8V8MfOdt9mnWjO7nX5h3j8/ufj5XX34pXTq0o1LlSvR9OehHveue+7mqqHv8WB96PxTe40t70LHdMTSoCPc4cfsrimVmz0VuS3qaoHO8SCqm+apUhF/+LwJ7A6nAdUAP4CUzGyPpHGAPM+sl6WTgGmAjsB7obmZ/FvXZKekNrOqhPUr9GrZliz//b/GJXFwS80dpxVOrWuoEM9u8/XgLVKq7m2Uef39Maf95/cy4z1eaJFUGpppZ06LSlEtNI3xE/ZICu7+POP5WxPv3CRYFcc65hJPbEV4inyV1Ap4k+DH9kpk9WOB4BvAW0Jjg+7uPmUXtgyjmfK/wbz0pFTiYsOugKP6chnPOxakkgoakVOBZgnmgFgDjJH1UYEGkK4FpZtZV0vbADEn9zWzdVp52fMT7DcDrZjasqMTgQcM55+IjUEqJ1DQOJxhBOhtA0gCCkaaRQcOAdAVRqiawlODLfqsU7NOIhQcN55yL0xbUNOpKivx139fM+obvGwDzI44tAI4okP8ZgkcS/gDSgdOjzUhbGjxoOOdcnLYgaCyJ0hFe2IcUHKnUkWBCwbYEw2O/lDTazFYWzFhaEu9pE+ecSyIl+ET4AqBRxHZDghpFpAuAweGT3LOAOcBeJXYxMfCahnPOxatkBk+NA5pI2hVYCJwBnFUgze9AO2C0pHoED0pvPgXxFpC0T/iZBgw3s6nR0ntNwznn4qGSeSI8XNPiKoJZZqcD75rZVEk9JOU+fHYv0FzSFIJV9m4xsyVbXfTgmbghQDOCxZiGSuoeLY/XNJxzLk4lNa+UmX0GfFZg3wsR7/8AOpTIyQI3A4eY2V8A4USxXwFvFJXBg4ZzzsUreZ/g35QbMADM7C9JUUdjedBwzrk4JehkhLGYLeluIHfY72XAb9EyeJ+Gc87FIdb+jAQNLJcBTYAfgZ+ApuG+InlNwznn4pSgAaFYZvY3BUZoSaoZLY8HDeeci1MJTSNS5iRttj4R8Jmktma2uLA8HjSccy5OyVrTIHg2ROR/8jwTmClpsJldUDCDBw3nnIuHkjdomNkOBfdJmmhmB4fPgmzGg4ZzzsVBVLhFs14P//y5sIMeNJxzLi4JOzJqq5jZk+GfZxZ23IOGc87FqQLFjGJ50HDOuXgIUpJ09NTW8If7nHMuDiIIGrG8Eo2kgyTVDd/XknSgimlr86DhnHNxkmJ7JaB+wAZJVYAJwECCdcqL5EHDOefilMTTiKSa2XKgNTDKzPYM3xfJ+zSccy4eiVuLiEUlSSnAscDwcF9O1AylXiTnnKvAhEpsPY1y8AUwheAp8PslZQCro2XwoOGcc3FK1pqGmd0k6X1gdthMBdAyWh4PGs45F6cE7a8oVjhh4SKgeuTkhWY2T1J9M1tUMI8HDeeci0dy92kUNmGhgO2Bt4B2BTN40HDOuTgEc08lZ9QobMLCiGObBQzwoOGcc3FL0pixVTxoOOdcnBLxae9YSNrIv81TeRdhZkUOB/Og4Zxz8Uji9TSA9Ij31YDTgO2iZUjawcXOOZcIctfTSMZpRMwsK+K11MxeAE6MlqfC1TSa7bEjnw2+pbyLUaH1GjqzvItQ4TWuXbW8i+BilrBThBSrwBrhqcDBFFPTqHBBwznnylqSxgzIP+S2KkHrU7doGTxoOOdcnJK1plFwyK2kTgTzUH1dVB7v03DOuThIybueRkFm9gXQKVoar2k451yckrWmIemYiM1U4BCKiQseNJxzLk5JGjMAHol4vwGYBZwaLYMHDeeci1Oy1jTM7PAtzeNBwznn4pGgz2DEStKRwO5ExAMze72o9B40nHMuDsEiTMkZNSQ9RzBaajKwKXc34EHDOedKS0ryVjXaAfua2fpYM/iQW+eci1NJTSMiqZOkGZJmSbq1iDStJU2SNFXSyDiLPoeIiQpj4TUN55yLg0powkJJqcCzQHtgATBO0kdmNi0iTSbwHNDJzH6XVOR6GDGaAXwqaRCQnbvT+zScc64UlVCXxuHALDObDSBpAMGUHtMi0pwFDDaz3wHM7K84z1kfWEb+Ffri69OQdCrwhZmtknQ7wYRW95nZxDgL65xzFUIJDbltAMyP2F4AHFEgTVOgsqQRBNOaP2lmb2ztCc3stC3NE0tN4w4ze09SC6Aj0Ad4ns0vxjnntjliizrC60oaH7Hd18z6RnxUQVZguxLBU9vtgOrAd5K+N7Otmnpa0nnRjhfWTBVL0NgY/tkFeN7MPpTUa8uL55xzFdMWNE8tMbNDizi2AGgUsd0Q+KOQNEvMbA2wRtIo4ABga9cr6BLlWKHNVLEEjYWSXiQYy/uQpNzpc51zzqnE1tMYBzSRtCuwEDiDoA8j0ofAM5IqAVUIWnwe39oTllbz1GkEsx72MbPlkuoDN23piZxzrqIqiZhhZhskXQUMIZg88BUzmyqpR3j8BTObLukL/n0Y7yUz+3nry63GwP8By4HHCFqWMs1scVF5Ygka9YFPzSxHUmtgf2CrO16cc64i2cI+jajM7DPgswL7Xiiw/Qj5JxqMx3vAGGAfgv7qG4F3gLZFZYilmel9YKOkPYCXgV2Bt+MuqnPOVRDJukY4UMnMbgDOA5qbWRbBqKwixRI0NpnZBuA/wBNmdh1B7cM557Z5Sb4I03xJDcJpRBT2lVSLliGW5qn1ks4EugNdw32V4yunc85VHEk899RqYIKkD4F6BP0pn0bLEEvQuADoAfQ2szlhz/5b8ZbUOecqiqQNGcFQ3dzhuo8Bk8xsaLQMxQaNcN6T/4vYngM8GEchnXOuQkniRZjuKbhPUrNoI7JimUakCfAAQe96XluXme22leV0zrkKIxg9Vd6l2DqSdgFOAmpF7O4h6QVghJltNotuLM1TrwJ3ETxA0oaguSpJb5FzzpUwJWwndywGEzxUuCJin4CaBA8PbiaWoFHdzIZJkpnNA3pJGk0QSJxzbpuXrM1TAGZ2WeS2pGPNrMgHuGMJGtmSUoBfw6cVFwLxzuHunHMVQjI3TwEDYtyXJ5agcS1Qg6Az/F6CJwWjzozonHPbkiSuaQyUtHPBfQCS6pvZooIZYhk9NS58u5qgP8M551yEpA0ZQX+GyD8Fu4DtCR6taFcwQ5FBQ9LHbD6Xex4zO2Gri+mccxWElLwP95lZkV0NZrZZwIDo04j0AR6N8nKhs0/uwgFNGvBknwcAMDPuuOVa/nNcW84/40SWLVu6WZ7XX36BVoftS4tD9s63f/hXQ+jWoRXdOrRixLDgGZtpP0+m67EtOL1bR7LWrAHgtZeezzu+rVi2cA5P/mc/Fk6bQPbqFbx/10W82/NcBtxyFn/PnbFZ+vU5a/ny6dsZdMcFvPff7mSvDgaIzJ04mgE3n8GAm89g7sQxAPw95xfeufF0Bt1+PuuzswCY9Gn/vOPbkr/mz+aGNk2ZPXkcSxbO49GLT+CWjs2YPXlcoek/eu4Bnrn6DB6/9EQ+eu6BvP3Tx47kictP5onLT+aXH0YBsHDWdB6/7CSeveZsctYG93nM4DfyjierJJ5GBEl1JXWVdHwsa44XWdPIHZ8rKQ1Ya2abwu1UoGqchcwETohnmcJE0uepFxk98msW/bEQgBHDhrI2ay2DP/uaQQPe4oWnHuW2u3rny3Nc15M4q/tFtDly/7x9Gzdu5P5ePRn06TAATunSjpat2zHwrde4q/cjfDtmJCOHf8WRzVswbcpkzr/48rK7yATw/bvP02DfYP2aX0Z+wk57H8xRZ1zJ/Ck/8MO7L9Dl5vzLCnw/4FmatujMzgcdnbdv08aNjH6tD6fe/yYA7/U8l8YHHMXPXw3mmItuZf6Uscz78Rsa7Hsof8/5hQO7nF12F5gghr7+DLsfeDgAtersQI/H3uDDZ3oXmf64S26gUuVgdOYzV5/Bojkzqdd4dz5+/kGufnogAE9ffTpNDzmasZ++x4lX3c6sH79nxrjR7H7A4SycNZ0W/+le+hdWipK0ooGkDsCbwCSCZqkDJXU3sy+KyhPLhIXDCDrCc1UHvoqjnACZBHNZVQj1GzTMt/39N6No1/E4AI7t1IWx327+a3X7HepRuXL+Kbzm/PYrjXbehYyMTDIyMmm08y7Mm/Mb1dPSyMnJZu3aLNLS0niyzwP83423lt4FJaA/Z04mLXN70uvuCMB2DXdjXdZqALJXL6dGZp3N8vz+0/fMnTia9/7bnW/ffhqA5YvmUateQ6rVrEW1mrWoVa8hK/78ncrVqrNhfQ4bcrKpXL0GY999gSNO61F2F5gg5k37iVrbbU/m9sGcpFWqVSetVmbUPLkBY+OG9VSpVp2MuvX4e8Fc6tRvRPX0WlRPr0Wd+o1Y8sc8qlavzoZ1OazLWUvV6jUY+sYztO9+VWlfVqkSIkWxvRLQA0BLM+toZh2AlsD90TLEEjSqmdnq3I3wfY0o6WNxPXCIpBGSfpSUElaPFgFIOlVSTwVelDRG0reSDo/zvGVi+bKlZGZmApCRkcny5Zs3TxWebxkZmbXztjMyMlm2dCkXXnolgwb2Z11ODrUyMqm7/Q58N2YUvXreyNdffl4al5Bwxr77AoedfHHe9g6778uiGT/xxtVdGdHvfg7utvkYjX/mzaTR/kdwyn2vs3T+b8ydOJrsVSuoVvPfh1+rpqWzdtVyDjr+HKYP/5CNG9ZRNa0WNTLrMP/ncYx46QHmjN/sodgK68s3nqHd2VseLN9/ohf3nd6aWnV2oFpaOlkrl1M9PSPveLWatchasZyWJ5/PuCEfsGHdOqrXrEV67TrM+vF7Pnj6XqZ9N7wkL6XsxDgtemLGDFIj1xc3sxkUExdiCRprJB2cuyHpEGDtVhcx8BgwwcxaAxOBgwiG8v4gad/w/XCgG1DZzFoA5wDPxHneMpFZeztWrFgOwMqVK8jIqB09Q16+2qwM8+Xmzaxdmx3q7cjjz77E7fc8yOsvPc/Z51/M55/8j17396Hfc0+WwhUkltnjR1Bvj32pXuvf+zj+g5dp0rwD3Z/+mC43P87wFzebQoeq6RnscnBLJLHzQUfz99wZVEvPIGfNqrw067JWU61mJmm1t6fjNQ/Q8vybmPRpf/bveBqzvvuS1hffxoQPXyuLyyx3U7/7mkZ77UdajP9eI518bS9uHziSNSuW8cvYkdSolcna1SvzjmevWUWNWpnUqrM9Z/V8hBOuuI3Rg9/kqBPOYsqoIZx09R2MePflkrycMqVwydfiXgnob0kX6F8XAn9HyxBL0LgWeE/S6PBJ8IFASdYnhxEM62oKPBu+P5RgKNiewLcAZjYbKPRfs6RLJY2XNH7pkiUlWLStc2Tzlgz/MmgS/PrLLzjy6JYx5dt19ybMnzeXVStXsmrlSubPm8suu+2Rd/z9gf054aRTkcSa1UHlb9nS2Goxyezv2b+w4OdxDO51CfMmfcuoVx9mzdK/qZ6eCUCNjDp5ndyRGjU7nMWzgnnXFs+aSmb9xmTW35kVixeQk7WanKzVrFi8gMz6jfPyTB/+IXu2PA4k1q8NBh1kr9r8syuiP36dzqwfx/Lijeczc/wYPnruAZb+ubDYfOtzcgBIrVSJKtWrU6VadbZvuAtLF80ne80qstesYumi+dRt8O/jAOOHfMDB7Y5HEtlZwX3OWrm8VK6rLKTE+EpAlwGXAFkElYFLw31Fiuk5DUl7EXyBC/glXLAjHusizv018BEwnWDZwTuAv8L1cmcAJwAvSdqNYB3bwsrYF+gLsP9BhxQ5TLi03HzN5Uz44Tty1uUwedIE+r3xLl8N/Yz/HNeW9PR0nnj+FQDeffsNdqy/E63aHMsn/3uf/q/3Y/GfizjzpE7ccOtdHHrEUdx6572cc8rxANx6572kpqYCsHrVKiaM+54HHg0qW7s3acoJ7VvSpdvJZX25Ze6I03rk9S8MefI2mrU/hYx6jfjiiVuYOmwwG3JyaHHeDQBMHfYBNevswM4HHk2L7tfz5bN3snFdDpk77cweRxyLUlJoce51fNAraOpqce51pIT3eF3WGhbNmES7y3sBULvhrrxz0+k0Pbpj2V90OWjf/Urad78SgLfvv4kjjz+NGum1eO66c1g8dxZ/zp3J3ke2pvOF1/HD54PIqFuPPQ9ryVv3XsualcvZuGEDu+13CHscdCQAXS69iRduPD/vfe59zs5azdypEzn1hvsAqLfzbjzR4z8c0Lpz2V90CRCQmqAjo4oT/hhvHg54wszWFJdHZmX+HUs4LcmnBNHtOeApoI+ZvSppJPCxmfUJ070I7E2w0Pp1ZvZ9tM/e/6BD7LOvvyvdC9jGPTZ6dnkXocJrXDuuAYouRte12m2CmR0az2fU26OZnf3YoJjSPt5t77jPV5IkHVPY/sJmt80VyzQiJS4cvhv5s2LfiGPHFEh3SRkWzTnntkjQyZ2cNQ3gkYj31QhalKYR9DMXqlyChnPOVSRJ2jqFmeUbkSppf+CKaHmK7ZsJe9TPkXRnuN04WYa+OudcWUjiIbf5mNlk4KhoaWKpaTwHbCIYBnsPsAp4Hzgs3gI651yyE1ApGSJCIQr0aaQCRxJ83xcplqBxhJkdLOlHADNbJqnQFZ2cc25blKQxA/L3aWwAfgPOiJYhlqCxPpxvygAkbU8xkcg557YVStwpQopVsE8jFrE8b/IU8AGwg6TeBM9SRJ2bxDnntiXJ2qch6TZJu4fv/yPpCUlNo+UpNmiYWX/gZoKJrRYBJ5rZeyVRYOecqwhSFNsrAZ0NzJa0I0FT1d/Aa9EyFNs8JakxwUN4H0fuM7Pf4yqqc85VAMEa4YkZEWKwzswsnCK9v5n1lnRKtAyx9Gl8StCfIYKHP3YFZhDxQJ5zzm2zBKkJOrFUDDZJak5Q43gw3JcaLUMsc0/tF7kdzngbdUIr55zblih5VwnvCbwCjDOz4ZIyiLd5qiAzmyjJn9Fwzjlym6fKuxRbx8yGAntFbK8gWLqiSLH0aVwfsZkCHEwx860759y2JFmDxtaIpaaRHvF+A0Efx/ulUxznnEs+STxh4RaLGjTCh/pqmtlNZVQe55xLKkrujvAtVuSlSqpkZhsJmqOcc84VISV8Kry4V3EkdZI0Q9IsSbdGSXeYpI3FDY+N4Xypko6X1CLWPNFqGj8QBIxJkj4C3gPyVnUys8FbXVLnnKsgSqojPGzZeRZoDywAxkn6yMymFZLuIWBI/GelP7AbkCnpBYKRU0+Z2TlFZYilT2M74B+CWW5zn9cwwIOGc85RYlOEHA7MCpdgRdIAoBvBokiRrqbkZho/kGBl1NrAUDN7rLhpRKIFjR3CkVM/82+wyFX2a8Q651xCEimxP6dRV9L4iO2+ZtY3fN8AmB9xbAFwRL4zSQ2Akwh+xJdE0FgAVDGzpRGzl0ddazha0EgFakKhd8ODhnPOEXxBbkFNY0mUNcJj+a59ArjFzDaW0Iit8cAnkl4Baki6F5gVLUO0oLHIzO4piVI551yFJahUMg9qLAAaRWw3BP4okOZQYEAYMOoCx0naYGb/28pz5k6Nfgkwk6CycGG0DNGCxrYz8Ng557bSFtY0ohkHNJG0K7CQYDGksyITmNmueeeVXgM+iSNgYGZttzRPtNHF7ba2IM45ty0piSG3ZrYBuIpgVNR04F0zmyqph6QepVHurVlPo8iahpktLekCOudcRVRSD4Sb2WfAZwX2vVBE2vNL4JRnAw9GrKfxCsGw2+ZFZdiGnmN0zrmSJ4Iv0lheCWidmRmQt54GUD1ahgS9DuecSxIK5p6K5ZWAItfTGB7ui289Deecc0UTkJqYASEWpb+ehnPOufySNWRszXoa3jzlnHNxkmJ7JRpJg3NHS0l6VNIkSd2i5fGg4ZxzcYmtPyNB+zT2MLOZkvYFjgauBO6NlsGbp5xzLg65o6eS1Mbwz7bAIDP7RtKGaBk8aDjnXJxiWSsjQS2T1BM4BzhVQXUoalxI4gDpnHMJILmH3F4ENAYeNbOpQBrBU+lFqnA1DQGVUhPyL6fCyKxe4f7ZJJw/V60v7yK4GCVz85SZzQF6RGyvBkZFy+P/9zvnXJwStBZRLElfU8iIYTNrI6mfmV1S8JgHDeeci1NyhgwA+kQ59lphOz1oOOdcnJK0opE7QWJRx74pbH+yNsU551xCyJ1GJJZXopC0n6RqkhpKGiRpiaR/wvc7RcvrQcM55+KimP9LIG8A64HXgQlAs/A1MTxWJG+ecs65OCVQJSJWCtcZ387MHojYf7+kM6Nl9JqGc87FIRhyq5heCaRSuPDSL5Ly1iWX1BiYHTVjaZfMOecqtASdjLAYjwE/AJOBKeHQWwiW+R4ZLaMHDeeci1OyBQ0ze0XSaOBw8i8v+1VxeT1oOOdcHJJ1ESYz+xX4dUvzedBwzrk4JdjIqJhJeoXCnwi/oKg8HjSccy5OSVjRyDU+4n014ERgarQMHjSccy5OyVrTMLPnIrclPQ18ES2PBw3nnIuDgJTkjBlFaRTtoAcN55yLh5S0izAV6NNIBQ4Gvo2Wx4OGc87FKTlDBpC/T2MD8LqZDYuWwYOGc87FIWieSs6wUbBPIxY+jYhzzsVJMb4SjaSakvpJWhy++klKj5bHg4ZzzsUrWaMGPAxsAo4AFgEjCKYYKZI3TznnXJySdcgt0BI4wMw2STIz6y/p6mgZPGg451ycknjIrZnZptwNBYudV4uWwZunnHMuXsnbPJUtqU74vjrQHxgeLYPXNJxzLg5BPEjMiBCDa4F04B/gfwQTGL4SLYMHDeeci0dyrqcBgJl9CxCOmOptZquKy+PNU845F6eSap2S1EnSDEmzJN1ayPGzJU0OX99KOiCuckt7S/oBWAz8LWm8pL2j5fGg4Zxz8SqBqCEpFXgW6AzsA5wpaZ8CyeYAx5jZ/sC9QN84S/4q8KSZ1TCzasAT4b4iedBwzrm4BHNPxfIqxuHALDObbWbrgAFAt8gEZvatmS0LN78HGsZZ+Epm1j/i89+imG4LDxrOOReHWCsZMTRPNQDmR2wvCPcV5SLg860ocqQJkg7P3ZB0BDA9WgbvCHfOuXjF3hFeV1LkJIF9zSy3iamwT7FCTye1IQgaLWI+c+H2Ab6VNCXc3g8YJ2k4gJm1KZjBg4ZzzsVpC4bcLjGzQ4s4toD8a1k0BP7Y7FzS/sBLQGcz+2dLylmIB7Y0gwcN55yLUwkNuR0HNJG0K7AQOAM4K/951BgYDJxrZjPjPaGZfbalebxPo4T1vPEaurRrQafWR/HBoAH5jmVnZ3PFxd3p1qkNV1zcnezsbADmz5vLKcd34IQOx/BknwcByFqzhlO7dqRzm+ZMnfITANN+nsxD991VtheUQJYsmMPdnfdm3s//1u4nfvEed3cufITg/Gk/8tK1p/HK9Wcy5t1+eft/HTeKftecSr9rTmXW+NEA/PnbdPpefTKv3XQu69ZmATD2o7fyjm9Lli6cwyMn7MuCqeOZNuJj3r71XN6+9Vz6XdaZD3pvPi3RxE/60/eSjrx4cft8+2ePH8WbN5zOmzeczuwJwX38a/YvvHHdqbxzW3fWZWfl5c89npTC5zRieUVjZhuAq4AhBP0K75rZVEk9JPUIk90J1AGekzSpQFNXmSiVoCEpU1L38H0vSeeUxnkSzS/TfmbGL9P4dNgYBn08lIfu7ZXv+MD+b7BH0z358Ivh7NGkKQP7vwFA717/5caed/LR0JF8M2oEv878hRFff0mLY9pw9wN9eOet1wF49slHufq6m8v6shLGyP7Pssv+eX12rF+Xw/RvhpKx/Y6Fpv/suXs5pecTXPjYO8ydPJYlC+awaeNGvnzpYc7p/TLn9H6Zof0eYtPGjUwcMohOPf7LrgcdxW8TxpC1chl//jadPQ5tWVaXlzC+fec5GjU7DIB9WnflrAff5KwH32Tn/Y9gzxadNku/59Eduej5T/Lt27RxIyNefYRT7+7HqXf3Y8QrD7Np40YmfzmItpfcxs4HHMXcid+wduUyFs+ezm6HJPd9Voz/FcfMPjOzpma2u5n1Dve9YGYvhO8vNrPaZnZg+CqqqavUlFZNIxPoHmtiSRWixlNvx52oXLkK69evZ/XqVWTWrp3v+HdjRtK+43EAtO/UhbHfBr+ufp7yE0c2D/qz2nXszPffjKFGjTRycrJZm5VFWloaHwwaQOcuJ1AjLa1sLypBLPjlJ2rWrkutuvXy9o393+sc2uVMlFL4P5+cNavI3GEnAHZquh9zfxrLPwvnkrljQ6rXrEX1mrXI3LEhSxf9TpVqNdiwLof1OdlUqV6Dkf2f45izriiTa0skf8yYTFrtuqTXzR+IN25Yz+wJo2hyZLvN8qTVrktqpcr59i37Yy4Z9RpSrWYtqtWsRUa9hiz/83cqV6vBxvU5bMjJpnL1Gnw74Hman3F5qV5TaRMlU9NIFqX1ZX09cIikEUAXoI2kj8Lq1F4AkkZIelTSEIJ2vJckDZc0JncImKT9JH0l6WtJ70qqXkrlLRGZtWuz2+57cPTB+3Jsi8O49qbb8h1ftmwZmZlBIMnIyGTp0qUA2Ka8SSbJyMhk2dJ/aNWmHWuz1jL4vXc44+zzGDHsSxo0asztt1zPi88+WXYXlSBGvf0cLc+4LG977aoVzJsyjj2PbFtknhoZtfnzt+lsWL+O2RO/Ze2qFaxdtYLqNWvlpamWVou1K5dzxInd+emrD9i4fh3VatYiLbMOc38ay+fP92bmDyNK89ISyncDnuPIUy/dbP/s8aNo1OwwKleNOgFqnrWrVlCtZkbedrWawX0+pOu5/DzsQzasX0e1tHRqZNbh98k/MKzv/fw2bmSJXUdZS9b5CiWlSjpI0jERr58ltZa0c2F5SitoPAZMMLPWwKfAKjM7gWDBj4sj0o03s45AG4KHWtoAJwOPh8efBS40s7bANwRDzDYj6dLw8ffx//yzpFQuKBYjv/6KRYsW8t2k6YweN4UH7rmDnJycvOO1a9dmxYrlAKxcuYLaYU0k8pfyypUryKy9HSkpKdzV+yGefP5lBg3sz1XX3USfB+7lznsfZPasX5nz26wyvbbyNHPscHZq2owatf6tuY0e8AJHn3pJ1HwnXNubL19+hLfvvIza9RuRXmcHqqdnkL363+l1ctasonp6Bunbbc9JNz1Mh0tuYeyHb3FolzOY9s1QOl/+X757P+oDshXGbz+MYMcmzaheq/Zmx6YO/4h92pwQ82dVT88gZ83KvO2cNauolp5Bze22p8v1D9LmopuZ+El/Dux8OjO/HUq7S3sy7oMkvs/JGjXgA4KHCB+JeO0S/tmhsAxlNXpqQvjn70Bkb9m34Z/7Ac0l5TaY5v5E2Rd4I5jinWrAV4V9eDjOuS/AAQcdUui45rJgZmRm1iY1NZWa6emsX7eejRs35h0/6uhWDBv6Bc32P5BhQ7/gyKNbAbBvs/0ZN/Y7DjviKL7+cgj3PNgnL8+c32ZhZjRpuhfLly3FzFi3LofVq4udV6zCWPTbdOb+9ANvTruQxXNmsmT+bCpVrcbiOTMYPeAFVv3zN+/2vobT/pu/BrbDLk049/5X2LB+HQPuvoImh7WienomyxYvIHtNcP+WLV7Adjv9+4Pqp6/+x36tuyCJdVlrAMhauYxtweLZ0/l9yg8svOMi/p43k38WzKbbrY9TrWYGi2dNZZcDjor5s2rvtAvLFy8gJ2s1AMsXL6B2/X/v89SvP2SvVschxLq1wX1eu2p5iV5PWUriWW53MbM9I3dImmhmhxWVobSCxroCnx35RR55d3O/UacS1DQeB5BUJdz/M3CmmS0qsD8hHdP2WP73/kBO6NiadTk5XHjZFcyeNZNRw4dxxTU3cNrZ3bn+ykvo1qkNO+3UgMefewmAnnfdx/VXX8b6deto074jTff8dzTQc089Rq/eDwNw3sWXcWKnNtTfqQHN9j+wPC6xXBxz1hV5/QsfPHIzB3c+jZ2b/dv/9+T57fICxo9D36dWnXrsfkgLvh30CjPGfg3A0adeTFpmsGzAsRfewJs9L8x7n5KaCkBO1mrmT/+Rrv93DwB1G+1Gv/87hX1bdS6bCy1nzc+4PK9/4dPHbuWAjqeQsUMDJg8dRJOjjs1XI57y5WBq1q3HrgcdzS+jP2fS5wNZvfQvBvQ8nxbn/B8N9zmYY867gXfvCBoHjjkv/31e+MuPdLzybgDqNNyNN64/jb0K6WRPFkm8CNMvheyL2owhs5L/YR52bH8KZAE7AC+a2VuSWgAXm9n5YX/HOWa2QFJl4GkgN+KNN7ObJDUDHgVye9keMLMvo537gIMOsSEjvy/xa3L/6jt2XnkXocLLWr+p+EQubg912XNCvCOQmh1wsA0eOiamtHvumBb3+Upa+P27F8GP+xlmtj5a+lKpaYTLB27288zMxgBjwvetI/avB3oUkv5noGNplNE550pCMi/CJOlQYBCQQ3ApVSWdYmbjisrjT4Q751w8kns47VPAeWY2EvLmtHoSaF5UBg8azjkXp+SNGdTIDRgAZjZcUo1oGSrEQ3XOOVd+hBTbKwGtCWsXAEhqC6yJlsFrGs45F6fEjAcxuRp4X9IGgo7wqgTPyhXJg4ZzzsUhcZ/bK56ZTZTUBGhKcBkzwokTi+RBwznn4pWsUYO82XWnxZreg4ZzzsUpWYfcbg0PGs45F6ck7tPYYh40nHMuHkrqaUS2mA+5dc65uCXnNLeSMiS9LGmxpL8kvSKpVrQ8HjSccy4OSb4I0xPAauAQ4CBgFf8uTVEob55yzrk4JWY8iMlhZtYsYvsaSZOjZfCg4ZxzcUrQWkQsCpvRdmMh+/J485RzzsVJMf6XgEZKqpO7IWk7YHS0DF7TcM65OCVrTcPMri2wvRT4v2h5PGg451wcEriTu1iS7op23MzuLrjPg4ZzzsUpQZueYpG2pRk8aDjnXLySNGaY2c1bmsc7wp1zLk7J+WgfSDpQ0iBJL0naQVKapGbR8njQcM65uIgUxfZKQG8CI4GlwKPAOuC5aBm8eco55+KQ+0R4ksoys6cVLCv4k5mt9+VenXPOFeU3Sc3MzIBNktKAatEyeE3DOefilMQ1jdrAD5JGA42BH4AXo2XwoOGcc3FK4iG374QvgJcJmqhmRMvgQcM55+KRxA/3AQOADWa2KdYM3qfhnHNxSPKp0b8CdgGQ9L6k5ZIujZbBg4ZzzsUpiScszDCz2ZIOBdKBfYFro2Xw5innnItTgtYiYmHhn22Bj8xsoaTsaBm8puGcc3EqqSfCJXWSNEPSLEm3FnJckp4Kj0+WdHCcRf9dUl/gCuBTSZUpJi540HDOuXiVQNSQlAo8C3QG9gHOlLRPgWSdgSbh61Lg+ThLfh4wG7jMzOYAqcBp0TJ485RzzsWphPorDgdmmdlsAEkDgG7AtIg03YA3wofxvpeUKam+mS3aynPuAvQzs38k1QJ2A36KlqHCBY3JkyYuqZ9RZV55l2ML1QWWlHchKji/x2Uj2e7zzvF+wI8TJwypUUV1Y0xeTdL4iO2+ZtY3fN8AmB9xbAFwRIH8haVpAGxt0OgHHCupCjAB2AQMI2iuKlSFCxpmtn15l2FLSRpvZoeWdzkqMr/HZWNbvM9m1qmEPqqw6optRZotkWpmyyV1AEaZ2UWSpkXL4H0azjmXGBYAjSK2GwJ/bEWaLVFJUgpwLDA83JcTLYMHDeecSwzjgCaSdg2bi84APiqQ5iOgeziK6khgRRz9GQBfAFOAs4FPJGUAq6NlqHDNU0mqb/FJXJz8HpcNv89bycw2SLoKGEIwiukVM5sqqUd4/AXgM+A4YBaQBVwQ5zlvkvQ+MNvMloe7W0bLo6AT3jnnnCueN08555yLmQcN55xzMfOg4ZxzLmYeNNw2IVwDucht51xsPGi4Ck9SipmZpGqSqgGE2/7vv5QUdm89UFcMPnoqQUiqDTQDJgFrtmQlLVc0SQoDRAPgDeBXgjUEzow8Xq6FrGDCIL1JUj2gNfALMMfMVpZvyVxJ8F9aCUBSI2AwcArwOtDWfwWXjDBg1ACeIpjorQeQKund3OPlWsAKKAwYDYBXgb2Bq4BLwllcXZLzL6ZyFgaHy4F7gfsJVs6aQ3zzybiQpCpmlgWsJKhlYGanAavDWT1d6egOvEDwI+gAgofS0jxwJD8PGomjG/AyQW1jZ+Be/x9s64XTLFQBbpDUgmAGz6MkHSapK7Bn+ZawYimkZpwDtCeo4V0K7ADcA1Qr46K5EuZBo5xIqiepJZABvAk0J6hhVAF6Au+Y2cZyLGJSiuhsrW5m68L3tYBBBLW36wm+xC7xNvaSEdGHUV9Sh/Df9csES4jOJVh7+naCacDXlGNRXQnwjvByIKkOMABYA8wAfgBmAmcB1QkWRZlafiVMbmEfxjcEq5otBW4GzjOz6ZKqAzXM7J/yLGNFI2lH4H2CYHELcB8wmqCZKgV418yiTrntkoMHjTIWjpK6EZhrZv0knUkwauobM/tMUqrXMLaepErhxG9PEwTgd4CHgenAjWb2Z7kWsAKJqGGkAncT1CreAT4nCBwTImp7roLw5qkyJKkScAjBiJJKkqoS/A82CzhCUk0PGFtO0gGSmoX3d7CkVgTTTKcTBIt3ge2B7HIsZoUSETB2JKghTyZY13oocCHBLK19fbBBxeNTo5cRSQ0JmkumEASNOUALgir8IIJaX9R57F2R1hE0i1QiWB+gC/A7wXrHJ5nZQ5L6Rkz97OIUBow6BCP/ficYaHAGQVPrgcCVwOXeb1TxeNAoA5LSCUaRfEDwq3cv4ESCX7+VzeyL8itdhTADWEgQjN8lqF3sDpxKsP7xy2a2rBzLV2Hk1jDCzasIAvTFZjZN0rPAdgS16cvMbGZ5ldOVHu/TKAOSMoGXgJ5mNjOcyqI38C3wnZnFs1yjA8IVx/YFehF0wubWNGaZ2e/lWLQKJ2xGXR2+vx/YEbjCzLLDff6UfQXmQaMMhGPYbwJWEazK1YzgV9rxZhZ1PV63ZSR1AO4iGF57mgfkkiHpDGA8sAz4OHw/08yekdQHaABcamarPGhUbB40ykg4Vcg5wKEEo3pu8mG1pSPsPzIzW1jeZakIJNUHrgGWAzsRzI82nqDDe46ZPSmpN/C0j06r+DxolKFwdE8mkGJmf5VzcZwrVjgS7TegJsFgg8XAg2Y2TtLeBMPHJ5jZc+VYTFeGPGg454okaR+CYFE5/LMOsB74n5nNkLQnsNzMFpdjMV0Z8uc0nHPR/EIwMq0q8B3wNCDgHEm7mNkMDxjbFg8azrkihcNrLwIuAx4hGMo8j2BYrT9XtA3y5innXEwkdSQYmbYEuN7MZpVzkVw58KDhnItZOApwk49M23Z50HDOORcz79NwzjkXMw8azjnnYuZBwznnXMw8aDjnnIuZBw1XKiRtlDRJ0s+S3guXYN3az3pN0inh+5fCp5SLSttaUvOtOMdcSXVjTHu+pGe29BzOVQQeNFxpWWtmB5pZM4JFknpEHgyXCN1iZnZxMWtNtwa2OGg452LjQcOVhdHAHmEtYLikt4EpklIlPSJpnKTJki6DYD0GSc9ImibpU2CH3A+SNELSoeH7TpImSvpJ0jBJuxAEp+vCWk5LSdtLej88xzhJR4d560gaKulHSS8STI2xmYLnKOR4V0ljw8/5SlK9cP8xYRkmhcfSJdWXNCqiBtayRO+yc2XAV+5zpSqc2bczwTKsAIcDzcxsjqRLgRVmdli4Xvo3koYCBwF7AvsB9YBpwCsFPnd7oB/QKvys7cxsqaQXgNVm1idM9zbwuJmNkdSYYD2TvQmebB5jZvdI6gJcWkjZNztHIZc4BjjSzEzSxcDNwA0Es79eaWbfSKpJsD75pcAQM+sd1rS2usnOufLiQcOVluqSJoXvRxPMkNoc+MHM5oT7OwD75/ZXABlAE6AV8I6ZbQT+kPR1IZ9/JDAq97PMbGkR5TgW2EfKq0jUCpffbQX8J8z7qaTCloON5RwNgYHhmhNVCNZ+B/gGeExSf2CwmS2QNA54RVJlglliJxXyec4lNG+ecqUlt0/jQDO72szWhfvXRKQRcHVEul3NbGh4rLipChRDGgj+jR8VcY4GZraqBM/xNPCMme1HMKlfNQAzexC4mGDBre8l7WVmowiC1ULgTUndYyi/cwnFg4YrT0OAy8Nf3khqKikNGAWcEfZ51AfaFJL3O+AYSbuGeXObjlYB6RHphhIsrUuY7sDw7Sjg7HBfZ6D2FpwjUgZBEAA4L+I8u5vZFDN7iGCVu70k7Qz8ZWb9CGpeBxfyec4lNA8arjy9RNBfMVHSz8CLBE2mHwC/AlOA54GRBTOa2d8EfQSDJf0EDAwPfQyclNsRDvwfcGjY0T6Nf0dx3Q20kjSRoJns9y04R6RewHuSRhPM/prr2rCz+ydgLfA5wciuSZJ+BE4Gniz+FjmXWHzCQuecczHzmoZzzrmYedBwzjkXMw8azjnnYuZBwznnXMw8aDjnnIuZBw3nnHMx86DhnHMuZh40nHPOxez/AUa94vzLfxEQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[995   1   4]\n",
      " [178 792  30]\n",
      " [ 34  69 897]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000    0    0]\n",
      " [ 168  811   21]\n",
      " [  56   70  874]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEkCAYAAADTtG33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA9xElEQVR4nO3dd5xU1fnH8c93l+qCFBExCIKKgGIJEjRIRwVsaGJvWJEY81PBHhVUFBTEhkaxoVJtSUwsoAjSLAhS1AgCKqII0mGBBeT5/XHvrsOyOzu7d8vM8rx9zWvnlnPvuZdxnjnlniMzwznnnEtEWllnwDnnXOrwoOGccy5hHjScc84lzIOGc865hHnQcM45lzAPGs455xLmQcOVGUlVJf1H0npJr0Y4zoWSJhRn3sqKpHaSFpR1PpzLj/w5DVcQSRcAfYBmwEZgDnCfmU2LeNyLgb8BbcxsR9R8JjtJBjQxs0VlnRfnispLGi4uSX2AR4D7gf2AhsCTQI9iOPyBwMI9IWAkQlKFss6DcwXxoOHyJakGcA/wVzN7w8wyzWy7mf3HzG4K96ks6RFJP4WvRyRVDrd1lLRMUl9JKyUtl3RZuO1u4C7gXEmbJF0hqb+kkTHnbyTJsr9MJV0qaYmkjZK+lXRhzPppMenaSJoZVnvNlNQmZttkSfdKmh4eZ4KkOvlcf3b+b47J/xmSTpa0UNIaSbfH7N9a0keS1oX7DpNUKdw2Jdxtbni958Yc/xZJPwMvZK8L0xwcnqNluPw7SaskdYzy7+pcFB40XDx/BKoA/4yzz9+B44CjgaOA1sAdMdvrATWA+sAVwBOSaplZP4LSyzgzq2Zmz8XLiKQM4DGgu5lVB9oQVJPl3q828Fa47z7AUOAtSfvE7HYBcBlQF6gE3Bjn1PUI7kF9giD3DHARcAzQDrhL0kHhvr8CNwB1CO5dF+AaADNrH+5zVHi942KOX5ug1NUr9sRmthi4BRglaS/gBWCEmU2Ok1/nSpQHDRfPPsCqAqqPLgTuMbOVZvYLcDdwccz27eH27Wb2NrAJaFrE/OwEWkiqambLzezLPPY5BfjGzF42sx1mNgb4GjgtZp8XzGyhmW0BXiEIePnZTtB+sx0YSxAQHjWzjeH5vwSOBDCzWWb2cXje74CngQ4JXFM/M8sK87MLM3sG+Ab4BNifIEg7V2Y8aLh4VgN1Cqhr/x3wfczy9+G6nGPkCjqbgWqFzYiZZQLnAr2B5ZLektQsgfxk56l+zPLPhcjPajP7NXyf/aW+Imb7luz0kg6V9F9JP0vaQFCSyrPqK8YvZra1gH2eAVoAj5tZVgH7OleiPGi4eD4CtgJnxNnnJ4KqlWwNw3VFkQnsFbNcL3ajmY03sxMJfnF/TfBlWlB+svP0YxHzVBj/IMhXEzPbG7gdUAFp4nZflFSNoCPCc0D/sPrNuTLjQcPly8zWE9TjPxE2AO8lqaKk7pIeDHcbA9whad+wQfkuYGR+xyzAHKC9pIZhI/xt2Rsk7Sfp9LBtI4ugmuvXPI7xNnCopAskVZB0LnAY8N8i5qkwqgMbgE1hKegvubavAA7aLVV8jwKzzOxKgraapyLn0rkIPGi4uMxsKMEzGncAvwA/ANcC/wp3GQB8BswD5gOzw3VFOdd7wLjwWLPY9Ys+DehLUJJYQ9BWcE0ex1gNnBruuxq4GTjVzFYVJU+FdCNBI/tGglLQuFzb+wMvhr2rzinoYJJ6AN0IquQg+Hdomd1rzLmy4A/3OeecS5iXNJxzziXMg4ZzziUJSc+HD5J+kc92SXpM0iJJ87If/CxNHjSccy55jCBox8pPd6BJ+OpF0GOvVHnQcM65JGFmUwg6euSnB/CSBT4Gakrav3RyF/AB0pxzLnXUJ+jBmG1ZuG55UQ4maQn5P0skM2uUe2W5CxqqUNVUqXpZZ6Nc+33zhmWdBeeKxezZs1aZ2b5RjpG+94FmO3YbASZPtuWXLwkemM023MyGF+J0eX3BR+kCe2qu47wOnBXzfjflL2hUqk7lpgV2gXcRTP9kWFlnwbliUbWicg85U2i2YyuVm52X0L5bP398q5m1inC6ZUCDmOUDKPoIDJjZV7HLkrKy10nKc8gab9NwzrkoBKSlJ/aK7k3gkrAX1XHAejMrUtVUPiyf9znKXUnDOedKnQoaYizRw2gM0JFgoNBlQD+gIoCZPUUwTM7JwCKCwTYvK5YT/+aWmPeT8trBg4ZzzkUiUPFU2pjZ+QVsN+CvxXIyQFLPvNaZ2Ytm1jevNB40nHMuqmIqaZSBU2LeVwPaAtOBF/NL4EHDOeeiEMVW0ihtZrZLryFJjQimeM6XBw3nnItEqVzS2IWZfSepebx9PGg451xUxdMzqkxIqg5sDac0BrhCUpqZ7cxr/9QsUznnXNIIG8ITeSUZSTcSTA62RlI3SfsAJ+QXMMCDhnPORSOC6qlEXsnnrwQPC7YFbgsnMYv7pKJXTznnXFRJWIpI0PdhoFgdM/983Lq2lL1S55xLDqlbPQW8I2lAOFLuTkld2HVsrN14ScM556JKS8qqp0TcH/69DcgCBgBXx0vgQcM556LIHnsqBZlZoTPuQcM55yIpvmFEyoKkWkAbggEKPzKztfH296DhnHNRJWfPqAKFI+W+AWQPkX64pD+Z2Uf5pfGg4ZxzUaVuSWMocKaZfQIg6VhgCNAuvwQeNJxzLorkfQYjERnZAQPAzD4JnxDPlwcN55yLKkUbwoFfY4cMkSQKmD7Wg4ZzzkWS0g3hNwJ7A+vC5b2Bm+IlSNkrdc65pJGiw4iY2Qdmti5meT3QOl4aDxrOORdF9nwaKfhEuKQrJM2R9G32C+gXvr8urzRePeWcc5GkdPXUzcClwPpw2YDXgbOAlXkl8KDhnHNRJWHVU4Iycz+TIWmrmX2VXwIPGs45F1Xq9p66IMF1OTxoOOdcFErp6qlzlXcp6W5JV5vZ07k3eNBwzrmoUrd6KiOPddkXUyWvBB40nHMuonx+rSc9M7s5zrZH81rvQcM55yIIZntNzaAhKQ3oBZxI0HNqIvB0vDnCPWg451wU4rcKndTzAHAkMILgKi4FDiZ4UjxPHjSccy4SkZaWsg3h3YDfm9kOAEnjgDnECRope6XJ5PoL2/PqkJ6MHnQRzRrVpUrlCjxx+58YPegi/nHHWVTPqLxbmiF9T2P0oIsYPegiPh/Xh86tmwDQ/piDeO2hnrz2UE/atTwIgGaN6/LGw5cycuCFVK1cEYCLTz0mZ/ue5uUXR9CxXRs6tT+ez2fP3mXbRzNm0OroI6hZrQrLli3LWf/9d9/R7cTOdGp/PA8OCma4zMzMpPtJXWj7x9bMmzsXgPnz5nF3vztL72KSWLz7/NCQB2nX5lg6tT+eG677G2bBGHd76n2WlNArCRm7lpMKHLDQg0ZEzQ/ajyOb/o6zb3yRvkP+zZ1Xn8j53X7P/G+Wc8GtI/nvlC/p9ec/7pbuxof+wwW3jqTnHaPZkJnFtM+XkJYmbr28M5fdNZbL7hrLbVd0Ji1NnH3SUQwY/h4z5nxHu5YHUbN6VZoftB9TZy8pgysuW2vXruXJYY8xYeJkXnhxJH1v+L9dth92+OFMnvYRrY89bpf1d/z9Vu7odzeTpkxn8qQPWPD117z/3gQ6de7Cg0Me5sURzwMwdMiD3HjzraV2PcmqoPvco8eZTJ3xCZOmTGflyhVMnvQBsOfe5xQOGu8Cb0m6UNKF4fL4eAk8aETUuH5tvli0HIDlqzbSoF5NDjpgH+Z/E6ybu+AnjjvywHzTd27dhBlzv2Pb9l9p9Lva/PDzejZmZrExM4sffl7PgfvXYsvW7VSuVIGqlSuyees2rj3veIaNnVYq15dsZn76CW3atqNSpUo0atyYzE2byMrKytleo0YNqlWrtlu6eXPn0LZtMK9Mt+6nMG3qFDIyMti6dStbtmymWrVqjBs7htN6nEFGRl69EPcsBd3nQ5o0yXlfqWIlKlQIarr3yPusQrySzy3Aq0AP4Izwfb49qqCMgoYCT0uaJmmGpNaSRkgaJuktSR9Lqhvue7akqeG+d5VFfuNZ+N0vHHfEgVSskEazxnWpV2dvfvplA+2PORiATn84hJrV8+zuDMAZnVrw70lfAFCzehXWb9qSs21D5lZqVq/KiDdncmbnI6hUMZ0Nm7ayev1mjjviQO646gQ6tjq4ZC8wyaxZs4ZatWrlLO9dowZr1qwpMN3Onb91BqlZsyZr1qymc5cT2Lx5M2NHj+KSnpfx/oTxNGjQkL43XMdjjzxcIvlPFYne5ykfTubnn5fTtl17YM+8zyKxUkYyljQs8IyZnWNmZ5vZ05Zd15iPsipp9AAqmllb4CJgWLh+kZmdArwJnBNOeN4X6Bzu+3tJR+Q+mKRekj6T9Jnt2JJ7c4la9MMq3pz8JS/ddwGX9WjNN9//wnNvfELlShUYNfBC9tunOivWbMozbfWMyjRtXJdP5n8PwLqNW9m7WpVdtq/buIVVazO5+eH/MvC5iVx8WitGvz2brm2aMeCZ97nizGNL5TqTRe3atVm3bl3O8ob166ldu3aB6WIbKtevX0+tWrVJS0tj0INDeOb5EYwe9TI33nwr993bn4EPDGbRNwtZvGhRSVxCSkjkPs+fN487/34bL48el/OFuKfe57S0tIReyUbS85JeyP2Kl6asrqIpMAPAzJYA2T9pZoV/lwL7AIcABwLvSZoMNA6Xd2Fmw82slZm1UoWqJZz13Y18axbn3zKS5/75CQu+W8m2Hb/S/x/jufC2USxbsZ53p32dZ7pT2h3G+Olfkx3Xv/tpDQ32q0m1qpWoVrUSDfaryffL1+bsf2bnI/jvlK8wIGOvSgDU3Lv0r7cs/aH1sXw0fRrbt29n6dKlZFSrRuXKu3c0yO2II4/ioxkzAJgw/p2cX8YAixctwsxo2qwZa9aswczIyspi48aNJXYdya6g+7x40SJ6X3U5L40aS506dXLW76n3OVVLGsBnwMzwNZ+gu+3WeAnKqsvtAuB04FlJB/HbrFGxxSIBS4BFwAlmtiN8ECXp7vyLA84nPT2NdRu20O/JdzmkQR3u+Ws3du7cydffrmTgcxMB+PMJR7Ji9Uamff4tAGd0bkG/J9/NOc7OncbgEZMYMeB8AAaPmMTOncEtyahaiZbN63PnE8H+S35YzetDL+Wdqf8rzUstc7Vq1aJX72s4sXMHJDFk6KPMnTOHiRPfo0/fm/hm4UKu+9s1zJ83l54Xnc+5511Ar95/4d4BA+nd6wq2bdtG127dada8ec4xH35oMIMGPwTA1b2voUvHdtQ/4ACOOvroMrrKslfQfb6p7/WsW7+Oqy7vCcANfW+i+8mn7Jn3OXnbKwpkZk/GLkt6nKAxPF8qoPqqRIRf/k8DzYF04AagN/CsmU2TdBFwiJn1l/Rn4DrgV2A7cImZ/ZzfsdP2qmuVm55T4tewJ1s7c1jBOzmXAqpW1CwzaxXlGBXqHGQ1T70/oX1Xv3h+5POVJEkVgS/N7ND89imTkkb4iPpVuVZ/HLN9ZMz71wkmBXHOuaST3RBeLMeSugGPEvyYftbMBuXaXgMYCTQk+P4eYmZx2yAKON/z/FZOSgdaEjYd5MefCHfOuYiKI2hISgeeIBgHahkwU9KbuSZE+ivwlZmdJmlfYIGkUWa2rYin/Szm/Q7gRTObGC+BBw3nnItCoLRiKWm0JuhBugRA0liCnqaxQcOA6gqiVDVgDcGXfZHkbtNIhAcN55yLqBAljTqSYn/dDzez4eH7+sAPMduWAbn71A8jeCThJ6A6cG68EWlLggcN55yLqBBBY1WchvC8DpK7p1JXggEFOxN0j31P0lQz25BoBqJKvqdNnHMuhRTjE+HLgAYxywcQlChiXQa8ET7JvQj4FmhWbBeTAC9pOOdcVMXTeWom0ERSY+BH4Dzgglz7LAW6AFMl7UfwoHSkkUslHRYe04BJZvZlvP29pOGcc1GoeJ4ID+e0uJZglNn/Aa+Y2ZeSekvqHe52L9BG0nyCWfZuMbNVRc568EzceKAFwWRMEyRdEi+NlzSccy6i4hpXyszeBt7Ote6pmPc/AScVy8kCNwPHmNlKgHCg2PeBl/JL4EHDOeeiStFhRICd2QEDwMxWSorbG8uDhnPORZSkgxEmYomku4Hsbr9XA4vjJfA2DeeciyDR9owkDSxXA02Az4G5wKHhunx5ScM55yJK0oBQIDP7hVw9tCTtPvVlDA8azjkXUTENI1LqJOU1F/Xbkjqb2Yq80njQcM65iFK1pEHwbIjY9cnzmsBCSW+Y2WW5E3jQcM65KJS6QcPM6uZeJ2m2mbUMnwXZjQcN55yLQECKxoz8vBj+/SKvjR40nHMukqTtGVUkZvZo+Pf8vLZ70HDOuYjKUcwokAcN55yLQpCWor2nisIf7nPOuQhEEDQSeSUbSb+XVCd8v7eko1VAXZsHDeeci0hK7JWEngF2SKoEzALGEcxTni8PGs45F1EKDyOSbmbrgI7AFDNrGr7Pl7dpOOdcFMlbikhEBUlpwAnApHBdVtwEJZ4l55wrx4SKbT6NMvAuMJ/gKfD7JdUANsVL4EHDOeciStWShpndJOl1YElYTQXQLl4aDxrOORdRkrZXFCgcsHA5UDV28EIz+17S/ma2PHcaDxrOORdFardp5DVgoYB9gZFAl9wJPGg451wEwdhTqRk18hqwMGbbbgEDPGg451xkKRozisSDhnPORZSMT3snQtKv/FY9lXMRZpZvdzAPGs45F0UKz6cBVI95XwU4B6gdL0HKdi52zrlkkD2fRioOI2Jmm2Nea8zsKeCMeGnKXUnj6OYNmfrR42WdjXKtVvvbyzoL5d4vk+4r6yy4hCXtECEFyjVHeDrQkgJKGuUuaDjnXGlL0ZgBu3a5rUxQ+9QjXgIPGs45F1GqljRyd7mV1I1gHKoP8kvjbRrOOReBlLrzaeRmZu8C3eLt4yUN55yLKFVLGpI6xCymA8dQQFzwoOGccxGlaMwAGBzzfgewCDg7XgIPGs45F1GqljTMrHVh03jQcM65KJL0GYxESToOOJiYeGBmL+a3vwcN55yLIJiEKTWjhqQnCXpLzQN2Zq8GPGg451xJSUvdokYX4HAz255oAu9y65xzERXXMCKSuklaIGmRpFvz2aejpDmSvpT0YcSsf0vMQIWJ8JKGc85FoGIasFBSOvAEcCKwDJgp6U0z+ypmn5rAk0A3M1sqKd/5MBK0AHhL0mvA1uyV3qbhnHMlqJiaNFoDi8xsCYCksQRDenwVs88FwBtmthTAzFZGPOf+wFp2naEvWpuGpLOBd81so6Q7CAa0GmBmsyNm1jnnyoVi6nJbH/ghZnkZcGyufQ4FKkqaTDCs+aNm9lJRT2hm5xQ2TSIljTvN7FVJbYGuwBDgH+x+Mc45t8cRhWoIryPps5jl4WY2POZQuVmu5QoET213AaoCH0n62MwWFiLLOST1jLc9r2qqRILGr+HfU4B/mNm/JfUvfPacc658KkT11Coza5XPtmVAg5jlA4Cf8thnlZllApmSpgBHAUUKGgTf6/nJs5oqkaDxo6SnCfryPiApe/hc55xzKrb5NGYCTSQ1Bn4EziNow4j1b2CYpApAJYIan4eLesKSqp46h2DUwyFmtk7S/sBNhT2Rc86VV8URM8xsh6RrgfEEgwc+b2ZfSuodbn/KzP4n6V1+exjvWTP7ouj5VkPg/4B1wFCCmqWaZrYivzSJBI39gbfMLEtSR+BIoMgNL845V54Usk0jLjN7G3g717qnci0PZteBBqN4FZgGHEbQXn0jMAbonF+CRKqZXgd+lXQI8BzQGBgdOavOOVdOpOoc4UAFM+sL9ATamNlmgl5Z+UokaOw0sx3An4BHzOwGgtKHc87t8VJ8EqYfJNUPhxFR2FZSJV6CRKqntks6H7gEOC1cVzFaPp1zrvxI4bGnNgGzJP0b2I+gPeWteAkSCRqXAb2B+8zs27Blf2TUnDrnXHmRsiEj6Kqb3V13KDDHzCbES1Bg0AjHPfm/mOVvgUERMumcc+VKCk/CdE/udZJaxOuRlcgwIk2AgQSt6zl1XWZ2UBHz6Zxz5UbQe6qsc1E0khoBZwJ7x6zuLekpYLKZ7TaKbiLVUy8A/QgeIOlEUF2VorfIOeeKmZK2kTsRbxA8VLg+Zp2AagQPD+4mkaBR1cwmSpKZfQ/0lzSVIJA459weL1WrpwDM7OrYZUknmFm+D3AnEjS2SkoDvgmfVvwRiDqGu3POlQupXD0FjE1wXY5Egsb1wF4EjeH3EjwpGHdkROec25OkcEljnKQDc68DkLS/mS3PnSCR3lMzw7ebCNoznHPOxUjZkBG0Z4hdh2AXsC/BoxVdcifIN2hI+g+7j+Wew8xOL3I2nXOunJBS9+E+M8u3qcHMdgsYEH8YkSHAQ3FeLg89TunGgfXr8sDAAbtte/yRoXQ7sRPdTuzE4YcexG039wXg++++4+SuXTihY1sGP3A/AJmZmZzS9QQ6HH8s8+fNBeCL+fO4p/+dpXcxSeb6c4/l1fvOYvTdZ9LswH0AOLNDM0b2O4NRd5/J6W0P3S3NRV2PYOLjF/HBsIt3Wd/+6Ia8dv9ZvHb/WbQ7uiEAzQ6swxsDz2Zk/zOoWjn4PXVxtyNytu9J5s75nBM6tqVrlw6c0rUL3y5Zssv2hx96kE7tjuOEjm258Ya/YRb8vvz+u+84JY/P8qndTqBj210/y/eWo89yCg8jgqQ6kk6TdGoic47nGzTM7MOwj+5nwNSY5WkERZoomawp6ZIox0hWTz79LPcNfDDPbX+7vg/vvjeJd9+bRNNmzTnzz2cDcNcdt/H3O/vz/uRpfDhpEgu+/pqJ70+gY+fODBo8lJdGPA/Aww8Npu9Nt5batSST5o3qcOQh+3H231+j72Pvcefl7WnSoDbHH9mAi+7+Fxf2+ydvTtt9Hpp3P15E1+t3HV8zLU3cesnxXDbgTS4b8Ca3XXI8aWni7C7NGTBiKjPmL6PdUQ2pWa0KzRvty9Q5S0vrMpNGvXr788//vMP4iR/yfzf05f57+++y/bQeZzJp6se8P3kaK1eu5MNJHwDQ787buD38LE+ZPIkFC4LPcodOnRn44FBefjH4LD/y0GD6lKPPcqoOWCjpJOBL4FqCdusvJHWLlyaRAQsnEjSEZ6sKvF/UTIZqEoxlVe7UP+CAAvf55Zdf+O67b2l97HEAzJs7h+PbtgOgW/eTmT5tChl7ZbB161a2bN5MRrVqvDJuDKee3oOMjIwSzX+yavy7mnyxZCUAy1dvokHdvel+3CFsydrOS3f14B83n0y92rvfm1Xrt7Dj1527rGu0f01+WLGBjZu3sXHzNn5YsYED96vBlq07qFyxAlUrV2Dz1u1ce1Yrhr0e6fdRytqvXj2qVw8GO61UsRLpFXatyT7kkCY57ytVrESFcHvsZ7lr95OZPjX4LGdlf5YzqvFqOfssC5GmxF5JaCDQzsy6mtlJQDvg/ngJEgkaVcxsU/ZC+H6vOPsnog9wjKTJkj6XlBYWj5YDSDpb0u0KPC1pmqQZklpHPG9SeHXcGP501tk5y7bzty+1GjVrsmbNajp1OYEtmzczbuxoLr7kMia+N4EGDRpyU5/rGPZokSfqSlkLl67muMPrU7FCGs0OrEO9fapRt3YGtapX4ZJ7/s2rE7/itp5tEzpWzWqVWZ+ZlbO8ITOLmtWrMOLtuZzZsRmVKqSzITOL1eu3cNzh9bnj0rZ0bJm7g8meITMzk3v638H1fW7Mc/vUDyfz88/LOb5dewB2xn6Wa/z2Wd68JfgsX9TzMt5/bwIHNGjIzX2vY9hj5eCznGApIzljBumx84ub2QIKiAuJBI1MSS2zFyQdA2wpchYDQ4FZZtYRmA38nqAr76eSDg/fTwJ6ABXNrC1wETAs4nmTwitjR3Pe+RflLCvtt3+GDevXU6tWbdLS0rj/gSE8/ewLjBn9Mn1uvIX7772b+wYN5ptvFrJ40aKyyHqZWbRsLW9OXchLd53BZaccxTc/rGH9pq1MCauOpsxZStOwnaMg6zZlsXdG5Zzl6hmVWbdpK6vWbebmYe8z8KXpXNz9SEa/9wVdjz2YASOmccVpvy+R60pm27dvp+dF59Hnpltp1vyw3bZ/MX8e/e66nREjx+Z0OU2L/SxvWE/t7M/yoOCzPHbUy/S56RYGDribAQMHs+ibhSxenPqfZYVTvhb0SkK/SLpMv7kc+CVegkSCxvXAq5Kmhk+CjyOo/youEwm6dR0KPBG+b0XQbtIUmAFgZkuAWnkdQFIvSZ9J+mzVqrjXW+a+WbgQSRzS5Lfi/RFHHsXHH80AYML4dzm+bfucbYsXLcLMaNqsGWvXrsHM2LYti02bNpZ63svayPHzOf+uN3juP5+z4PtVfPzljxx5cNBu1+KgfVn68/oCjhD4bvk6GtTdm2pVK1KtakUa1N2b72PSntmhGf+d/g1mkFE1mAWgZrW4UwyUOzt37uTKyy7m1NN6cNrpZ+y2ffHiRVxz9RWMeGkMderUyVkf+1l+b/y7tGnXfpc0ZkbTps1YE36Ws7Ky2LQx9T/LaQm+ktDVwFXAZoLCQK9wXb4Sek5DUjOCL3ABX4cTdkSxLebcHwBvAv8jaGS/E1gZzpe7ADgdeFbSQQTz2OaVx+HAcICWx7TKt5twabj2L1fx8UcfsS0ri89nzeL2O/vxwfvvcX3f4Kn8sWNGcs55u84Vf/e993NN7yvZvm0bJ3btRrPmzXO2PTJ0MAMfDDqrXXX1Xzipc3t+V/8Ajjzq6FK7pmTx4p09SE8X6zZupd8zH7J6wxY6HN2Q0XefSVqauP2pSQD8uVMzVqzOZNq8H+j+x0O44KQW7Fc7g5f7ncHDYz9m9oKfGTxqBiPu7AHA4FEz2Lkz+NhkVKlIy6b1uHP4ZACW/LiW1weezTsfpf6v4cJ4819vMP6dt1i5YgXjxozi8BYtuOTSK/hg4ntc3+cmbrnxBtavW8fVV14KwHV9bqRb91Pof8/9/LX3lWzbto2TunajWbPfPsuPDh3M/Q+En+Vef6Frl/LxWRaQnqQ9owoS/hhvIykjXM4sKI2yu8qVpnBYkrcIotuTwGPAEDN7QdKHwH/MbEi439NAc4KJ1m8ws4/jHbvlMa1s6kd7ZuNlaanT8e9lnYVy75dJ95V1FvYI1aukzTKzVlGOsd8hLezCoa8ltO/DPZpHPl9xktQhr/V5jW6bLZFhRIqdme0EusesOjxmW4dc+11VillzzrlCCRq5U7OkAQyOeV+FoEbpK4J25jyVSdBwzrnyJEVrpzCzXXqkSjoSuCZemgLbZsIW9Ysk3RUuNywvXV+dc644pHCX212Y2Tzgj/H2SaSk8SSwk6Ab7D3ARuB14A9RM+icc6lOQIVUiAh5yNWmkQ4cR/B9n69EgsaxZtZS0ucAZrZWUp4zOjnn3J4oRWMG7NqmsQNYDJwXL0EiQWO7pHTCEW8l7UsBkcg55/YUSt4hQgqUu00jEYk8b/IY8E+grqT7CJ6liDs2iXPO7UlStU1D0m2SDg7f/0nSI5J2Hy46RoFBw8xGATcTDGy1HDjDzF4tjgw751x5kKbEXknoQmCJpHoEVVW/ACPiJSiwekpSQ4KH8P4Tu87M9rzxop1zLpdgjvDkjAgJ2GZmFg6RPsrM7pN0VrwEibRpvEXQniGChz8aAwuIeSDPOef2WIL0JB1YKgE7JbUhKHEMCtelx0uQyNhTR8QuhyPexh3Qyjnn9iRK3VnCbweeB2aa2SRJNYhaPZWbmc2W5M9oOOcc2dVTZZ2LojGzCUCzmOX1BFNX5CuRNo0+MYtpQEsKGG/dOef2JKkaNIoikZJG9Zj3OwjaOF4vmew451zqSeEBCwstbtAIH+qrZmY3lVJ+nHMupSi1G8ILLd9LlVTBzH4lqI5yzjmXj7TwqfCCXgWR1E3SAkmLJN0aZ78/SPq1oO6xCZwvXdKpktommiZeSeNTgoAxR9KbwKtAzqxOZvZGkXPqnHPlRHE1hIc1O08AJwLLgJmS3jSzr/LY7wFgfPSzMgo4CKgp6SmCnlOPmdlF+SVIpE2jNrCaYJTb7Oc1DPCg4ZxzFNsQIa2BReEUrEgaC/QgmBQp1t8ovpHGjyaYGbUWMMHMhhY0jEi8oFE37Dn1Bb8Fi2xlOg+3c84lD5GW+HMadSR9FrM83MyGh+/rAz/EbFsGHLvLmaT6wJkEP+KLI2gsAyqZ2ZqY0csrx0sQL2ikA9Ugz7vhQcM55wi+IAtR0lgVZ47wRL5rHwFuMbNfi6nH1mfAfyU9D+wl6V5gUbwE8YLGcjO7pzhy5Zxz5ZagQvE8qLEMaBCzfADwU659WgFjw4BRBzhZ0g4z+1cRz5k9NPpVwEKCwsLl8RLECxp7Tsdj55wrokKWNOKZCTSR1Bj4kWAypAtidzCzxjnnlUYA/40QMDCzzoVNE693cZeiZsQ55/YkxdHl1sx2ANcS9Ir6H/CKmX0pqbek3iWR76LMp5FvScPM1hR3Bp1zrjwqrgfCzext4O1c657KZ99Li+GUFwKDYubTeJ6g222b/BLsQc8xOudc8RPBF2kiryS0zcwMyJlPA6gaL0GSXodzzqUIBWNPJfJKQrHzaUwK10WbT8M551z+BKQnZ0BIRMnPp+Gcc25XqRoyijKfhldPOedcRFJir2Qj6Y3s3lKSHpI0R1KPeGk8aDjnXCSJtWckaZvGIWa2UNLhwPHAX4F74yXw6innnIsgu/dUivo1/NsZeM3MpkvaES+BBw3nnIsokbkyktRaSbcDFwFnKygOxY0LKRwgnXMuCaR2l9srgIbAQ2b2JZBB8FR6vspdSUNA+p40y3sZWDlpQFlnodzbt/3NZZ0Fl6BUrp4ys2+B3jHLm4Ap8dKUu6DhnHOlLUlLEQWS9AF59Bg2s06SnjGzq3Jv86DhnHMRpWbIAGBInG0j8lrpQcM55yJK0YJG9gCJ+W2bntf6VK2Kc865pJA9jEgir2Qh6QhJVSQdIOk1SaskrQ7f/y5eWg8azjkXiRL+L4m8BGwHXgRmAS3C1+xwW768eso55yJKokJEohTOM17bzAbGrL9f0vnxEnpJwznnIgi63CqhVxKpEE689LWknHnJJTUElsRNWNI5c865ci1JByMswFDgU2AeMD/segvBNN8fxkvoQcM55yJKtaBhZs9Lmgq0ZtfpZd8vKK0HDeeciyBVJ2Eys2+AbwqbzoOGc85FlGQ9oxIm6XnyfiL8svzSeNBwzrmIUrCgke2zmPdVgDOAL+Ml8KDhnHMRpWpJw8yejF2W9Djwbrw0HjSccy4CAeVsYO0G8TZ60HDOuSiklJ2EKVebRjrQEpgRL40HDeeciyg1Qwawa5vGDuBFM5sYL4EHDeeciyConkrNsJG7TSMRPoyIc85FpARfyUZSNUnPSFoRvp6RVD1eGg8azjkXVapGDXgQ2AkcCywHJhMMMZIvr55yzrmIUrXLLdAOOMrMdkoyMxsl6W/xEnjQcM65iFK4y62Z2c7sBQWTnVeJl8Crp5xzLqrUrZ7aKmmf8H1VYBQwKV4CL2k451wEQTxIzoiQgOuB6sBq4F8EAxg+Hy+BBw3nnIsiNefTAMDMZgCEPabuM7ONBaXx6innnIuouGqnJHWTtEDSIkm35rH9QknzwtcMSUdFyrfUXNKnwArgF0mfSWoeL40HDeeci6oYooakdOAJoDtwGHC+pMNy7fYt0MHMjgTuBYZHzPkLwKNmtpeZVQEeCdfly4OGc85FEow9lcirAK2BRWa2xMy2AWOBHrE7mNkMM1sbLn4MHBAx8xXMbFTM8UdSQLOFBw3nnIsg0UJGAtVT9YEfYpaXhevycwXwThGyHGuWpNbZC5KOBf4XL4E3hDvnXFSJN4TXkRQ7SOBwM8uuYsrrKJbn6aROBEGjbcJnztthwAxJ88PlI4CZkiYBmFmn3Ak8aDjnXESF6HK7ysxa5bNtGbvOZXEA8NNu55KOBJ4FupvZ6sLkMw8DC5vAg4ZzzkVUTF1uZwJNJDUGfgTOAy7Y9TxqCLwBXGxmC6Oe0MzeLmwab9MoZi+/OIKO7drQqf3xfD579i7bHhryIO3aHEun9sdzw3V/wywoeX7/3Xd0O7Ezndofz4OD7gcgMzOT7id1oe0fWzNv7lwA5s+bx9397izdC0pCc+d8zokd29GtS0dO7XoC3y5Zssv2US+N4IimB3PyiZ05+cTO/PTjj0Bwn0/tegIndmzHkAeCH1iZmZmc1u1EOrY9jvnzgvv8xfx53Nv/rtK9qCRx/Xl/5NVB5zF6wNk0O7AOp7dvxugBZzN6wNlMeLwnT95y2m5pbu3ZnjEDzuGfD17ArT3b56xv//tGvDboPF4bdB7tjj4QgGaN6vDGg+cz8p6zqFo5+M16cfejcranpPA5jURe8ZjZDuBaYDxBu8IrZvalpN6Seoe73QXsAzwpaU6uqq5SUSIlDUk1gdPN7CVJ/Ql6BIwsiXMlk7Vr1/LksMf4cPrH/PTjj1x+6cV88OG0nO09epxJ3xtvBuDC889h8qQP6NS5C3f8/Vbu6Hc3bdu24+SuJ9DjjD/x9df/o1PnLrRt14EXRzzPQw8/ytAhDzLsH0+X1eUljXr19ueN/7xN9erVGf/u29x/b3+eeeGlXfa5+NLLufm2v++yrt+dt3H7nf1o07Ydp3c/idPPOJMFX/+PDp0607Zde15+8QUefOgRHnloMI8+8VRpXlJSaN54X45sUo+zbx3L/nWqMeS67lx456u8OeVrAO65ujOffvnjbukeGjWN7TuC4YvGDDiHJg32YfGPa7i1ZzvO/fsrAIy77xym9xnJ2V1aMOC5yRx3RAPaHd2IT79aRvPGdXn5nbmld6EloLieCA9/+b+da91TMe+vBK4slpMVUUmVNGoClyS6s6RyUeKZ+ekntGnbjkqVKtGocWMyN20iKysrZ/shTZrkvK9UsRIVKgQxe97cObRt2w6Abt1PYdrUKWRkZLB161a2bNlMtWrVGDd2DKf1OIOMjIzSvagktF+9elSvHgz5H3sfY40Z9TIndWrPvf3vYufO4Att/ty5tAnv80ndT2b61CnstVdwnzdv3ky1jGq8Om4Mp57eY4+8z41/V4svFq8AYPmqTTTYb28qVUgHoEJ6Gh1aNua9Txfvli47YFRIT2NL1nZWrNlEo/1r8sOK9WzMzGJjZhY/rFjPgfVqsCVrO5UrVaBq5Yps3rqNa88+lmGvflx6F1kCRPGUNFJFSX1Z9wGOkTQZOAXoJOnNsDjVDEDSZEkPSRpPUI/3rKRJkqZldwGTdISk9yV9IOkVSVVLKL/FYs2aNdSqVStnee8aNVizZs1u+035cDI//7yctu2Conz2lxpAzZo1WbNmNZ27nMDmzZsZO3oUl/S8jPcnjKdBg4b0veE6Hnvk4ZK/mBSQmZnJPf3v5Lo+N+6y/uTTevDZ3C955/1J/LD0e8aNCbqh73Kfw3+bTl1OYMuWzbwydjQX9ryUie9N4IAGDbm57/UMe+yR0rycMrfw+1Uc16IBFSuk0axRHertU529q1UGoEPLRnz65TKytu3IM22/qzox+ekrWLk2k42bs6hZrQrrM3/7wbQhM4ua1asy4r+fc2anw6hUMZ0NmVmsXr+Z41o04I7LO9DxmMalcp0lIVXHK5SULun3kjrEvL6Q1FFSnnWGJRU0hgKzzKwj8Baw0cxOJ5jwI7Zo9ZmZdQU6EVRhdQL+DGR/Kz4BXG5mnYHpBF3MdiOpV/j4+2e/rPqlRC4oEbVr12bdunU5yxvWr6d27dq77DN/3jzu/PttvDx6HAp/eqSl/fbPsH79emrVqk1aWhqDHhzCM8+PYPSol7nx5lu5797+DHxgMIu+WcjiRYtK5ZqS1fbt27n0ovPoe9MtNGu+60OztWrVIj09nfT0dP58zrl8PnsWkOs+b9hArVq1SEtL475Bg3nq2RcYO2okfW66hYED7mbAwAdZ/M1CFi/ec+7zomVreHPq17zU/ywuO7Ul3yxdzZoNWwA4o2Nz/v1h/t33735mEh16PUut6lXo0LIx6zZtZe+Myjnbq2dUZt3Graxat5mbHxvPwBFTuPjkoxk9fj5djzuEAc9/yBWntyzxaywxqRo14J8EDxEOjnk1Cv+elFeC0qoWmhX+XUrQiJNtRvj3CODcsGQyDqgRrj8ceClcfz5QL6+Dm9lwM2tlZq32rbNvMWc9cX9ofSwfTZ/G9u3bWbp0KRnVqlG58m//4yxetIjeV13OS6PGUqdOnZz1Rxx5FB/NCG7FhPHv5JRAstOYGU2bNWPNmjWYGVlZWWzcWOC4YuXWzp07ueqyizn1tB6cevoZu22PDdxTJk+iyaFNATjiyCP55KPgPr83/h2Oj73Pi4P7fGjTZqxduzbnPm/aw+7zyHfmcv4dr/Dcm7NY8P0qdu40qlWtRIuD92P6vKV5pqlUMajC+nWnsSVrB1uytvPd8nU0qFuDalUrUa1qJRrUrcH3P6/LSXNmx+b8d9oCzIyMqpUAqFk9qSsS4lKC/yWhRmbW1MxaZ7+AhWb2BzN7Jq8EJdXldluuY8c+oBJ7534N/35JUNJ4GEBSpXD9F8D5ZrY81/qkVKtWLXr1voYTO3dAEkOGPsrcOXOYOPE9+vS9iZv6Xs+69eu46vKeANzQ9ya6n3wK9w4YSO9eV7Bt2za6dutOs+a/jRf28EODGTT4IQCu7n0NXTq2o/4BB3DU0UeXxSUmhTf/9Qbj33mblStWMm7MaA5r0YJLLr2cSRPf57o+N/LY0CFMmjSRCukVaHLoofS/N+iR1u+e+7m291Vs27aNE7t2o2mz3+7zY0OHcN8DQwC4sldvunbpQP369TnyqKPL4hLLzIv9/0R6WhrrNm6l3/CJAHRv04T3PlmExfxf/OfOh7Fi9SamzV3KI31Opmb1KlRIT2PW/37iky+WATB45DRG9PtTzvudO4MDZFSpSMumv+POp4PjL/lxDa8/cD7vzIjcg7TMpPAkTF/nsS5u8VpmeT5wGEnYsP0WsBmoCzxtZiMltQWuNLNLw9LDRWa2TFJF4HGgaXiIz8zsJkktgIeAiuH6gWb2XrxzH3NMK5v+San3QtujbP91Z8E7uUjqtr+lrLOwR9j66ZBZcR62S0iLo1raGxOmFbwj0LReRuTzFbfw+7cZwY/7BWa2Pd7+JVLSCKcP7J7H+mnAtPB9x5j124Heeez/BdC1JPLonHPFIZUnYZLUCngNyCK4lMqSzjKzmfml8SfCnXMuitTuTvsY0NPMPoScMa0eBdrkl8CDhnPORZS6MYO9sgMGgJlNkrRXvATl4qE655wrO0JK7JWEMsPSBQCSOgOZ8RJ4ScM55yJKzniQkL8Br0vaQdAQXpngWbl8edBwzrkIkve5vYKZ2WxJTYBDCS5jQThwYr48aDjnXFSpGjXIGV33q0T396DhnHMRpWqX26LwoOGccxGlcJtGoXnQcM65KJTSw4gUmne5dc65yFJzmFtJNSQ9J2mFpJWSnpe0d7w0HjSccy6CFJ+E6RFgE3AM8HtgI79NTZEnr55yzrmIkjMeJOQPZtYiZvk6SfPiJfCg4ZxzESVpKSIReY1o+2se63J49ZRzzkWUwpMwfSgpZ2I8SbWBqfESeEnDOeciStWShpldn2t5DfB/8dJ40HDOuQiSuJG7QJL6xdtuZnfnXudBwznnIkrSqqdEZBQ2gQcN55yLKkVjhpndXNg03hDunHMRpeajfSDpaEmvSXpWUl1JGZJaxEvjQcM55yIRaUrslYReBj4E1gAPAduAJ+Ml8Oop55yLIPuJ8BS12cweVzCt4Fwz2+7TvTrnnMvPYkktzMyAnZIygCrxEnhJwznnIkrhkkYt4FNJU4GGwKfA0/ESeNBwzrmIUrjL7ZjwBfAcQRXVgngJPGg451wUKfxwHzAW2GFmOxNN4G0azjkXQYoPjf4+0AhA0uuS1knqFS+BBw3nnIsohQcsrGFmSyS1AqoDhwPXx0vg1VPOORdRkpYiEmHh387Am2b2o6St8RJ4ScM55yIqrifCJXWTtEDSIkm35rFdkh4Lt8+T1DJi1pdKGg5cA7wlqSIFxAUPGs45F1UxRA1J6cATQHfgMOB8SYfl2q070CR89QL+ETHnPYElwNVm9i2QDpwTL4FXTznnXETF1F7RGlhkZksAJI0FegBfxezTA3gpfBjvY0k1Je1vZsuLeM5GwDNmtlrS3sBBwNx4Ccpd0Jg9e9aqqhX1fVnno5DqAKvKOhPlnN/j0pFq9/nAqAf4fPas8XtVUp0Ed68i6bOY5eFmNjx8Xx/4IWbbMuDYXOnz2qc+UNSg8QxwgqRKwCxgJzCRoLoqT+UuaJjZvmWdh8KS9JmZtSrrfJRnfo9Lx554n82sWzEdKq/iihVhn8JIN7N1kk4CppjZFZK+ipfA2zSccy45LAMaxCwfAPxUhH0Ko4KkNOAEYFK4LiteAg8azjmXHGYCTSQ1DquLzgPezLXPm8AlYS+q44D1EdozAN4F5gMXAv+VVAPYFC9BuaueSlHDC97FReT3uHT4fS4iM9sh6VpgPEEvpufN7EtJvcPtTwFvAycDi4DNwGURz3mTpNeBJWa2LlzdLl4aBY3wzjnnXMG8eso551zCPGg455xLmAcN55xzCfOg4fYI4RzI+S475xLjQcOVe5LSzMwkVZFUBSBc9s9/Ccnr3nqgLh+891SSkFQLaAHMATILM5OWy58khQGiPvAS8A3BHALnx24v00yWM2GQ3ilpP6Aj8DXwrZltKNucueLgv7SSgKQGwBvAWcCLQGf/FVw8woCxF/AYwUBvvYF0Sa9kby/TDJZDYcCoD7wANAeuBa4KR3F1Kc6/mMpYGBz+AtwL3E8wc9a3RBtPxoUkVTKzzcAGglIGZnYOsCkc1dOVjEuApwh+BB1F8FBahgeO1OdBI3n0AJ4jKG0cCNzr/4MVXTjMQiWgr6S2BCN4/lHSHySdBjQt2xyWL3mUjLOAEwlKeL2AusA9QJVSzporZh40yoik/SS1A2oALwNtCEoYlYDbgTFm9msZZjElxTS2VjWzbeH7vYHXCEpvfQi+xK7yOvbiEdOGsb+kk8LP9XMEU4h+RzD39B0Ew4BnlmFWXTHwhvAyIGkfYCyQCSwAPgUWAhcAVQkmRfmy7HKY2sI2jOkEs5qtAW4GeprZ/yRVBfYys9VlmcfyRlI94HWCYHELMACYSlBNlQa8YmZxh9x2qcGDRikLe0ndCHxnZs9IOp+g19R0M3tbUrqXMIpOUoVw4LfHCQLwGOBB4H/AjWb2c5lmsByJKWGkA3cTlCrGAO8QBI5ZMaU9V0549VQpklQBOIagR0kFSZUJ/gdbBBwrqZoHjMKTdJSkFuH9fUNSe4JhpqsTBItXgH2BrWWYzXIlJmDUIyghzyOY13oCcDnBKK3DvbNB+eNDo5cSSQcQVJfMJwga3wJtCYrwrxGU+uKOY+/ytY2gWqQCwfwApwBLCeY7PtPMHpA0PGboZxdRGDD2Iej5t5Sgo8F5BFWtRwN/Bf7i7UbljweNUiCpOkEvkn8S/OptBpxB8Ou3opm9W3a5KxcWAD8SBONXCEoXBwNnE8x//JyZrS3D/JUb2SWMcPFaggB9pZl9JekJoDZBafpqM1tYVvl0JcfbNEqBpJrAs8DtZrYwHMriPmAG8JGZRZmu0QHhjGOHA/0JGmGzSxqLzGxpGWat3AmrUTeF7+8H6gHXmNnWcJ0/ZV+OedAoBWEf9puAjQSzcrUg+JV2qpnFnY/XFY6kk4B+BN1rz/GAXDwknQd8BqwF/hO+X2hmwyQNAeoDvcxsoweN8s2DRikJhwq5CGhF0KvnJu9WWzLC9iMzsx/LOi/lgaT9geuAdcDvCMZH+4ygwftbM3tU0n3A4947rfzzoFGKwt49NYE0M1tZxtlxrkBhT7TFQDWCzgYrgEFmNlNSc4Lu47PM7MkyzKYrRR40nHP5knQYQbCoGP7dB9gO/MvMFkhqCqwzsxVlmE1Xivw5DedcPF8T9EyrDHwEPA4IuEhSIzNb4AFjz+JBwzmXr7B77RXA1cBggq7M3xN0q/XnivZAXj3lnEuIpK4EPdNWAX3MbFEZZ8mVAQ8azrmEhb0Ad3rPtD2XBw3nnHMJ8zYN55xzCfOg4ZxzLmEeNJxzziXMg4ZzzrmEedBwJULSr5LmSPpC0qvhFKxFPdYISWeF758Nn1LOb9+OktoU4RzfSaqT4L6XShpW2HM4Vx540HAlZYuZHW1mLQgmSeoduzGcIrTQzOzKAuaa7ggUOmg45xLjQcOVhqnAIWEpYJKk0cB8SemSBkuaKWmepKshmI9B0jBJX0l6C6ibfSBJkyW1Ct93kzRb0lxJEyU1IghON4SlnHaS9pX0eniOmZKOD9PuI2mCpM8lPU0wNMZucp8jj+2nSfokPM77kvYL13cI8zAn3FZd0v6SpsSUwNoV6112rhT4zH2uRIUj+3YnmIYVoDXQwsy+ldQLWG9mfwjnS58uaQLwe6ApcASwH/AV8Hyu4+4LPAO0D49V28zWSHoK2GRmQ8L9RgMPm9k0SQ0J5jNpTvBk8zQzu0fSKUCvPPK+2znyuMRpwHFmZpKuBG4G+hKM/vpXM5suqRrB/OS9gPFmdl9Y0ipylZ1zZcWDhispVSXNCd9PJRghtQ3wqZl9G64/CTgyu70CqAE0AdoDY8zsV+AnSR/kcfzjgCnZxzKzNfnk4wTgMCmnILF3OP1ue+BPYdq3JOU1HWwi5zgAGBfOOVGJYO53gOnAUEmjgDfMbJmkmcDzkioSjBI7J4/jOZfUvHrKlZTsNo2jzexvZrYtXJ8Zs4+Av8Xs19jMJoTbChqqQAnsA8Fn/I8x56hvZhuL8RyPA8PM7AiCQf2qAJjZIOBKggm3PpbUzMymEASrH4GXJV2SQP6dSyoeNFxZGg/8JfzljaRDJWUAU4DzwjaP/YFOeaT9COggqXGYNrvqaCNQPWa/CQRT6xLud3T4dgpwYbiuO1CrEOeIVYMgCAD0jDnPwWY238weIJjlrpmkA4GVZvYMQcmrZR7Hcy6pedBwZelZgvaK2ZK+AJ4mqDL9J/ANMB/4B/Bh7oRm9gtBG8EbkuYC48JN/wHOzG4IB/4PaBU2tH/Fb7247gbaS5pNUE22tBDniNUfeFXSVILRX7NdHzZ2zwW2AO8Q9OyaI+lz4M/AowXfIueSiw9Y6JxzLmFe0nDOOZcwDxrOOecS5kHDOedcwjxoOOecS5gHDeeccwnzoOGccy5hHjScc84lzIOGc865hP0/vdl0vjZ8hfEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3750513/1503990667.py:16: MatplotlibDeprecationWarning: The 'cmap' parameter to Colorbar has no effect because it is overridden by the mappable; it is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  cbar = plt.colorbar(heatmap, cmap=plt.cm.Blues, ax=ax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we will plot the confusion matrices for each trained model\n",
    "#first get the predictions\n",
    "pred = model1.predict(traits_BM.reshape(3000,-1))\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "classOrderLs=['one','two','three']\n",
    "\n",
    "# Print the confusion matrix\n",
    "print (confusion_matrix(ytest, pred_cat))\n",
    "#now do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions for the next dataset\n",
    "pred = model2.predict(traits_BM50.reshape(3000,-1))\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# Print the confusion matrix\n",
    "print (confusion_matrix(ytest, pred_cat))\n",
    "#now do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model3.predict(traits_BM10.reshape(3000,-1))\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# Print the confusion matrix\n",
    "print (confusion_matrix(ytest, pred_cat))\n",
    "#now do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model4.predict(traits_OU.reshape(3000,-1))\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "classOrderLs=['one','two','three']\n",
    "\n",
    "# Print the confusion matrix\n",
    "print (confusion_matrix(ytest, pred_cat))\n",
    "#now do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model5.predict(traits_OU50.reshape(3000,-1))\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "print (confusion_matrix(ytest, pred_cat))\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model6.predict(traits_OU10.reshape(3000,-1))\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model7.predict(traits_disc.reshape(3000,-1))\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model8.predict(traits_disc50.reshape(3000,-1))\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "#now do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model9.predict(traits_disc10.reshape(3000,-1))\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model10.predict(xtest)\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model11.predict(xtest[:,0:50,:])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model12.predict(xtest[:,0:20,:])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model13.predict([traits_BM.reshape(3000,-1), xtest])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model14.predict([traits_BM50.reshape(3000,-1), xtest])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model15.predict([traits_BM10.reshape(3000,-1), xtest])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model16.predict([traits_BM.reshape(3000,-1), xtest[:,0:50,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model17.predict([traits_BM50.reshape(3000,-1), xtest[:,0:50,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model18.predict([traits_BM10.reshape(3000,-1), xtest[:,0:50,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model19.predict([traits_BM.reshape(3000,-1), xtest[:,0:20,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model20.predict([traits_BM50.reshape(3000,-1), xtest[:,0:20,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model21.predict([traits_BM10.reshape(3000,-1), xtest[:,0:20,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model22.predict([traits_OU.reshape(3000,-1), xtest])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model23.predict([traits_OU50.reshape(3000,-1), xtest])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model24.predict([traits_OU10.reshape(3000,-1), xtest])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model25.predict([traits_OU.reshape(3000,-1), xtest[:,0:50,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model26.predict([traits_OU50.reshape(3000,-1), xtest[:,0:50,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model27.predict([traits_OU10.reshape(3000,-1), xtest[:,0:50,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model28.predict([traits_OU.reshape(3000,-1), xtest[:,0:20,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model29.predict([traits_OU50.reshape(3000,-1), xtest[:,0:20,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model30.predict([traits_OU10.reshape(3000,-1), xtest[:,0:20,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model31.predict([traits_disc.reshape(3000,-1), xtest])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model32.predict([traits_disc50.reshape(3000,-1), xtest])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model33.predict([traits_disc10.reshape(3000,-1), xtest])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model34.predict([traits_disc.reshape(3000,-1), xtest[:,0:50,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model35.predict([traits_disc50.reshape(3000,-1), xtest[:,0:50,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model36.predict([traits_disc10.reshape(3000,-1), xtest[:,0:50,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model37.predict([traits_disc.reshape(3000,-1), xtest[:,0:20,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model38.predict([traits_disc50.reshape(3000,-1), xtest[:,0:20,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()\n",
    "\n",
    "# get the predictions\n",
    "pred = model39.predict([traits_disc10.reshape(3000,-1), xtest[:,0:20,:]])\n",
    "pred_cat = [i.argmax() for i in pred]\n",
    "ytest_cat = [i.argmax() for i in ytest]\n",
    "\n",
    "counts=[[0.,0.,0.],[0.,0.,0.],[0.,0.,0.]]\n",
    "for i in range(len(ytest_cat)):\n",
    "    counts[ytest[i]][pred_cat[i]] += 1\n",
    "counts.reverse()\n",
    "\n",
    "# do the plotting\n",
    "fig,ax= plt.subplots(1,1)\n",
    "makeConfusionMatrixHeatmap(counts, \"Confusion matrix\", classOrderLs, classOrderLs, ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow-gpu-2.8.0_py3.9",
   "language": "python",
   "name": "module-conda-env-tensorflow-gpu-2.8.0_py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
